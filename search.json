[{"title":"HDFS","url":"/2022/08/13/BigData/HDFS/","content":"HDFS启动与关闭HDFS 和普通的硬盘上的文件系统不一样，是通过Java 虚拟机运行在整个集群当中的，所以当Hadoop 程序写好之后，需要启动HDFS 文件系统，才能运行。\nHDFS启动过程如下:\nbin/start-dfs.sh\n\n\n这一脚本会启动NameNode ， 然后根据conf&#x2F;slaves 中的记录逐个启动DataNode ，最后根据conf&#x2F;masters 中记录的Secondary NameNode 地址启动SecondaryNameNode 。\nHDFS 关闭过程如下:\nbin/stop-dfs.sh\n\n\n这一脚本的运行过程正好是bin&#x2F;start-dfs.sh 的逆过程，关闭Secondary NameNode ，然后是每个DataNode ，最后是NameNode自身。\nHDFS命令基本格式:hadoop fs -cmd &lt; args &gt;\n\n\nlshadoop fs -ls  /\n\n\n列出hdfs文件系统根目录下的目录和文件\nhadoop fs -ls -R /\n\n\n列出hdfs文件系统所有的目录和文件\nputhadoop fs -put &lt; local file &gt; &lt; hdfs file &gt;\n\n\nhdfs file的父目录一定要存在，否则命令不会执行\nhadoop fs -put  &lt; local file or dir &gt;...&lt; hdfs dir &gt;\n\n\nhdfs dir 一定要存在，否则命令不会执行\nhadoop fs -put - &lt; hdsf  file&gt;\n\n\n从键盘读取输入到hdfs file中，按Ctrl+D结束输入，hdfs file不能存在，否则命令不会执行\nmoveFromLocalhadoop fs -moveFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;\n\n\n与put相类似，命令执行后源文件 local src 被删除，也可以从从键盘读取输入到hdfs file中\ncopyFromLocalhadoop fs -copyFromLocal  &lt; local src &gt; ... &lt; hdfs dst &gt;\n\n\n与put相类似，也可以从从键盘读取输入到hdfs file中\ngethadoop fs -get &lt; hdfs file &gt; &lt; local file or dir&gt;\n\n\nlocal file不能和 hdfs file名字不能相同，否则会提示文件已存在，没有重名的文件会复制到本地\nhadoop fs -get &lt; hdfs file or dir &gt; ... &lt; local  dir &gt;\n\n\n拷贝多个文件或目录到本地时，本地要为文件夹路径\n注意：如果用户不是root， local 路径要为用户文件夹下的路径，否则会出现权限问题，\nmoveToLocal当前版本中还未实现此命令\ncopyToLocalhadoop fs -copyToLocal &lt; local src &gt; ... &lt; hdfs dst &gt;\n\n\n与get相类似\nrmhadoop fs -rm &lt; hdfs file &gt; ...hadoop fs -rm -r &lt; hdfs dir&gt;...\n\n\n每次可以删除多个文件或目录\nmkdirhadoop fs -mkdir &lt; hdfs path&gt;\n\n\n只能一级一级的建目录，父目录不存在的话使用这个命令会报错\nhadoop fs -mkdir -p &lt; hdfs path&gt; \n\n\n所创建的目录如果父目录不存在就创建该父目录\ngetmergehadoop fs -getmerge &lt; hdfs dir &gt;  &lt; local file &gt;\n\n\n将hdfs指定目录下所有文件排序后合并到local指定的文件中，文件不存在时会自动创建，文件存在时会覆盖里面的内容\nhadoop fs -getmerge -nl  &lt; hdfs dir &gt;  &lt; local file &gt;\n\n\n加上nl后，合并到local file中的hdfs文件之间会空出一行\ncphadoop fs -cp  &lt; hdfs file &gt;  &lt; hdfs file &gt;\n\n\n目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件还存在\nhadoop fs -cp &lt; hdfs file or dir &gt;… &lt; hdfs dir &gt;\n目标文件夹要存在，否则命令不能执行\nmvhadoop fs -mv &lt; hdfs file &gt;  &lt; hdfs file &gt;\n\n\n目标文件不能存在，否则命令不能执行，相当于给文件重命名并保存，源文件不存在\nhadoop fs -mv  &lt; hdfs file or dir &gt;...  &lt; hdfs dir &gt;\n\n\n源路径有多个时，目标路径必须为目录，且必须存在。\n注意：跨文件系统的移动（local到hdfs或者反过来）都是不允许的\ncounthadoop fs -count &lt; hdfs path &gt;\n\n\n统计hdfs对应路径下的目录个数，文件个数，文件总计大小\n显示为目录个数，文件个数，文件总计大小，输入路径\nduhadoop fs -du &lt; hdsf path&gt; \n\n\n显示hdfs对应路径下每个文件夹和文件的大小\nhadoop fs -du -s &lt; hdsf path&gt; \n\n\n显示hdfs对应路径下所有文件和的大小\nhadoop fs -du - h &lt; hdsf path&gt; \n\n\n显示hdfs对应路径下每个文件夹和文件的大小,文件的大小用方便阅读的形式表示，例如用64M代替67108864\ntexthadoop fs -text &lt; hdsf file&gt;\n\n\n将文本文件或某些格式的非文本文件通过文本格式输出\nsetrephadoop fs -setrep -R 3 &lt; hdfs path &gt;\n\n\n改变一个文件在hdfs中的副本个数，上述命令中数字3为所设置的副本个数，-R选项可以对一个人目录下的所有目录+文件递归执行改变副本个数的操作\nstathdoop fs -stat [format] &lt; hdfs path &gt;\n\n\n返回对应路径的状态信息\n[format]可选参数有：%b（文件大小），%o（Block大小），%n（文件名），%r（副本个数），%y（最后一次修改日期和时间）\n可以这样书写hadoop fs -stat %b%o%n &lt; hdfs path &gt;，不过不建议，这样每个字符输出的结果不是太容易分清楚\ntailhadoop fs -tail &lt; hdfs file &gt;\n\n\n在标准输出中显示文件末尾的1KB数据\narchivehadoop archive -archiveName name.har -p &lt; hdfs parent dir &gt; &lt; src &gt;* &lt; hdfs dst &gt;\n\n\n命令中参数name：压缩文件名，自己任意取；&lt; hdfs parent dir &gt; ：压缩文件所在的父目录；&lt; src &gt;：要压缩的文件名；&lt; hdfs dst &gt;：压缩文件存放路径\n*示例：hadoop archive -archiveName hadoop.har -p &#x2F;user 1.txt 2.txt &#x2F;des\n示例中将hdfs中&#x2F;user目录下的文件1.txt，2.txt压缩成一个名叫hadoop.har的文件存放在hdfs中&#x2F;des目录下，如果1.txt，2.txt不写就是将&#x2F;user目录下所有的目录和文件压缩成一个名叫hadoop.har的文件存放在hdfs中&#x2F;des目录下\n显示har的内容可以用如下命令：\nhadoop fs -ls /des/hadoop.jar\n\n\n显示har压缩的是那些文件可以用如下命令\nhadoop fs -ls -R har:///des/hadoop.har\n\n\n注意：har文件不能进行二次压缩。如果想给.har加文件，只能找到原来的文件，重新创建一个。har文件中原来文件的数据并没有变化，har文件真正的作用是减少NameNode和DataNode过多的空间浪费。\nbalancerhdfs balancer\n\n\n如果管理员发现某些DataNode保存数据过多，某些DataNode保存数据相对较少，可以使用上述命令手动启动内部的均衡过程\ndfsadminhdfs dfsadmin -help\n\n\n管理员可以通过dfsadmin管理HDFS，用法可以通过上述命令查看\nhdfs dfsadmin -report\n显示文件系统的基本数据\nhdfs dfsadmin -safemode &lt; enter | leave | get | wait &gt;\n\n\nenter：进入安全模式；leave：离开安全模式；get：获知是否开启安全模式；\nwait：等待离开安全模式\ndistcp用来在两个HDFS之间拷贝数据\n","categories":["Big Data"],"tags":["HDFS"]},{"title":"无门槛人人可用本地搭建chatglm-6b-int4-slim","url":"/2023/04/09/AI/%E6%97%A0%E9%97%A8%E6%A7%9B%E4%BA%BA%E4%BA%BA%E5%8F%AF%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%90%AD%E5%BB%BAchatglm-6b-int4-slim/","content":"涉及项目\njosStorer&#x2F;selfhostedAI: https://github.com/josStorer/selfhostedAI\n本地搭建懒人包，搭建完成后启动本地服务会启动一个本地服务器\n\n\njosStorer&#x2F;chatGPTBox: https://github.com/josStorer/chatGPTBox\nChrome插件: 可以发送请求到本地服务器，实现与本地模型进行交互\n\n\n\n搭建步骤1. 下载项目与模型文件josStorer&#x2F;selfhostedAI项目里面包含2个模型\n\nChatGLM 6B Int4: 该包基于ChatGLM, 遵循Apache-2.0协议开源, 内置模型为 https://huggingface.co/silver/chatglm-6b-int4-slim 的裁切版\nlama.cpp: 该包基于llama.cpp, 内置命令行交互示例为josStorer修改的版本, 以支持windows的unicode输入, 内置模型来自Chinese-LLaMA-Alpaca\n\n下载地址:\n\n百度网盘: https://pan.baidu.com/s/1wchIUHgne3gncIiLIeKBEQ?pwd=1111#list/path=%2F\nGitHub Releases: https://github.com/josStorer/selfhostedAI/releases\n\n下载文件: selfhostedAI-chatglm-6b-int4-windows-nvidia.7z\n2. 解压缩与运行解压缩到文件夹，文件结构如下图\n双击chatglm-6b-int4.bat运行\n\n\n由运行输出可知，运行需要 python3 环境和 C++ 环境。这里报错&#39;gcc&#39; 不是内部或外部命令，也不是可运行的程序或批处理文件。是需要gcc编译器，但是我没有配置到系统变量Path里，但是并不影响程序的运行\n3. 安装 Chrome Extension: chatGPTBox不一定要用 Chrome ，其它支持的浏览器也可以，支持的浏览器的插件地址如下:\n\nChrome: https://chrome.google.com/webstore/detail/chatgptbox/eobbhoofkanlmddnplfhnmkfbnlhpbbo\nEdge: https://microsoftedge.microsoft.com/addons/detail/fission-chatbox-best/enjmfilpkbbabhgeoadmdpjjpnahkogf\nSafari: https://apps.apple.com/app/fission-chatbox/id6446611121\nFirefox: https://addons.mozilla.org/zh-CN/firefox/addon/chatgptbox/\n\n安装完成后点开插件，如下图，需要修改以下配置项\n\nAPI模式: 改为自定义模型\n模型名称填写为: chatglm-6b-int4\n本地服务地址默认为: http://localhost:8000/chat/completions\n\n\n\n使用体验单词解释\n\n冒泡排序然后就可以愉快的开始聊天了！以下为聊天截图：\n\n\n注：在浏览器的插件中发送一句话给模型之后对应的在命令行上会打印接收到请求的日志，如下图：\n\n\n求解算法题\n\n显然01背包问题解错了，我们尝试提示下看能不能解对\n\n\n直接无响应了，查看后台日志，好家伙爆显存了\n\n\n我的显卡是 NVIDIA GeForce RTX2060 显存6G已经申请了5.07 G，然后又尝试申请116.00 MB空间申请不到了\nTried to allocate 116.00 MiB (GPU 0; 6.00 GiB total capacity; 5.07 GiB already allocated; 0 bytes free; 5.31 GiB reserved in total by PyTorch)\n\n\n重启后再次尝试：\n\n\n","categories":["AI"],"tags":["ChatGLM","ChatGPT"]},{"title":"Hadoop","url":"/2022/08/19/BigData/Hadoop/","content":"名词解释Hadoop：Hadoop是一个框架，它是由Java语言来实现的。Hadoop是处理大数据技术.Hadoop可以处理云计算产生大数据。\nCDH商业版：\nCloudera CDH是Hadoop的一个版本，比Apache Hadoop的优点如下：\n\nCDH基于稳定版Apache Hadoop，并应用了最新Bug修复或者Feature的Patch。Cloudera常年坚持季度发行Update版本，年度发行Release版本，更新速度比Apache官方快，而且在实际使用过程中CDH表现无比稳定，并没有引入新的问题。\nCloudera官方网站上安装、升级文档详细，省去Google时间。\nCDH支持Yum&#x2F;Apt包，Tar包，RPM包，Cloudera Manager四种方式安装，总有一款适合您。官方网站推荐Yum&#x2F;Apt方式安装，其好处如下：\n\n\n联网安装、升级，非常方便。当然你也可以下载rpm包到本地，使用Local Yum方式安装。\n自动下载依赖软件包，比如要安装Hive，则会级联下载、安装Hadoop。\nHadoop生态系统包自动匹配，不需要你寻找与当前Hadoop匹配的Hbase，Flume，Hive等软件，Yum&#x2F;Apt会根据当前安装Hadoop版本自动寻找匹配版本的软件包，并保证兼容性。\n自动创建相关目录并软链到合适的地方（如conf和logs等目录）；自动创建hdfs, mapred用户，hdfs用户是HDFS的最高权限用户，mapred用户则负责mapreduce执行过程中相关目录的权限。\n\n大数据的4个V:\nVelocity：实现快速的数据流传\nVariety： 具有多样的数据类型\nVolume： 存有海量的数据规模（TB，PB，EB级别）\nValue：存在着巨大的价值\n\n\nMapReduce\n\nHadoop实际上就是谷歌三宝的开源实现，\nHadoop MapReduce对应Google MapReduce，\nHBase对应BigTable，\nHDFS对应GFS。HDFS（或GFS）为上层提供高效的非结构化存储服务，\nHBase（或BigTable）是提供结构化数据服务的分布式数据库，Hadoop MapReduce（或Google MapReduce）是一种并行计算的编程模型，用于作业调度。\nHBaseHBase是一个分布式的、面向列的开源数据库，该技术来源于 Fay Chang 所撰写的Google论文“Bigtable：一个结构化数据的分布式存储系统”。就像Bigtable利用了Google文件系统（File System）所提供的分布式数据存储一样，HBase在Hadoop之上提供了类似于Bigtable的能力。HBase是Apache的Hadoop项目的子项目。\nHDFS(Hadoop Distributed File System)：\n默认的最基本的存储单位是64M的数据块。\n和普通文件系统相同的是，HDFS中的文件是被分成64M一块的数据块存储的。\n不同于普通文件系统的是，HDFS中，如果一个文件小于一个数据块的大小，并不占用整个数据块存储空间。\n\nhivehive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。\n联机事务处理OLTP(On-line Transaction Processing)、联机分析处理OLAP(On-Line Analytical Processing)OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。 \n\n\n分析型数据不允许update、delete操作\nSqoopSqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql…)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。\nZooKepperZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，是Google的Chubby一个开源的实现，是Hadoop和Hbase的重要组件。它是一个为分布式应用提供一致性服务的软件，提供的功能包括：配置维护、域名服务、分布式同步、组服务等。\nZooKeeper的目标就是封装好复杂易出错的关键服务，将简单易用的接口和性能高效、功能稳定的系统提供给用户。ZooKeeper包含一个简单的原语集，提供Java和C的接口。\nMahout\n\nMahout 是 Apache Software Foundation（ASF） 旗下的一个开源项目，提供一些可扩展的机器学习领域经典算法的实现，旨在帮助开发人员更加方便快捷地创建智能应用程序。Mahout包含许多实现，包括聚类、分类、推荐过滤、频繁子项挖掘。此外，通过使用 Apache Hadoop 库，Mahout 可以有效地扩展到云中。\n安装Hadoop支持平台\nGNU&#x2F;Linux是产品开发和运行的平台。Hadoop已在有2000个节点的GNU&#x2F;Linux主机组成的集群系统上得到验证。\nWin32平台是作为开发平台支持的。由于分布式操作尚未在Win32平台上充分测试，所以还不作为一个生产平台被支持。\n\n步骤：安装 VMware安装 Ubuntu安装 jdk解压tar -vzfx jdk-1.7.0.tar.gz\n配环境变量sudo vim /etc/profile\nexport JAVA_HOME=/home/master0/Desktop/jkd1.7.0_80export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:$PATH\n\n使配置文件生效：source /etc/profile\n安装Hadoop配环境变量sudo vim /etc/profile\nexport JAVA_HOME=/home/master0/Desktop/jdk1.7.0_80export HADOOP_HOME=/home/master0/Desktop/hadoop-2.6.0export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$HADOOP_HOME/share/hadoop/common/hadoop-common-2.6.0.jar:$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:$HADOOP_HOME/share/hadoop/common/lib/commons-1.2.jar:$CLASSPATHexport PATH=$JAVA_HOME/bin:$PATHexport PATH=$HADOOP_HOME/bin:$PATH\n\n配置~/hadoop-2.6.0/etc/hadoop/hadoop-env.sh\n# The java implementation to use.export JAVA_HOME=/home/master0/Desktop/jdk1.7.0_80\n\n测试hadoophadoop version\n\n\n使用hadoop的本地单独模式对某目录下的文档进行单词数的统计\n$ cd  /home/hadoop/\t$ mkdir  input$ cp   $HADOOP_HOME/etc/hadoop/*.xml   input/$ hadoop  jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep input output &#x27;dfs[a-z.]+&#x27;$ cat output/*\n\n克隆虚拟机修改主机名\nsudo gedit /etc/hostname\n\n\n配置静态IPsudo gedit /etc/network/interfaces\n\n编辑-&gt;虚拟网络编辑器-&gt;查看NAT模式的子网地址\n例如为：231\nmaster\nauto eth0iface eth0 inet staticaddress 192.168.231.129netmask 255.255.255.0network 192.168.231.0boardcast 192.168.231.255gateway 192.168.231.2dns-nameservers 192.168.1.1 8.8.8.8 8.8.8.4ping 192.168.231.130\n\nserve1\nauto eth0iface eth0 inet staticaddress 192.168.231.130netmask 255.255.255.0network 192.168.231.0boardcast 192.168.231.255gateway 192.168.231.2dns-nameservers 192.168.1.1 8.8.8.8 8.8.8.4ping 192.168.231.129\n\n若访问不了网页的话可以将物理机的dns填写在dns-nameservers第一个\n若拖文件拖不进虚拟机需检查：\n虚拟机ping与其对应的模式的虚拟网卡可不可以ping通\n主机ping与虚拟机可不可以ping通\nVMware Network Adapter VMnet1:桥接模式虚拟网卡\nVMware Network Adapter VMnet8:NAT模式虚拟网卡\n修改hosts文件sudo gedit /etc/hosts192.168.231.129  master192.168.231.130  serve1192.168.231.131  serve2\n\n安装sshsudo apt-get install ssh\n\n安装完毕就会出现/home/master/.ssh文件夹\n然后需要生成了一个公钥\nssh-keygen -t rsa -P &#x27;&#x27;会生成id_rsa  id_rsa.pub  known_hosts\n\nid_rsa为私钥\n-----BEGIN RSA PRIVATE KEY-----MIIEpAIBAAKCAQEAp6JLYxM9lm/ciNG5SuAd/0WBBY0VN98w1KLad5GrkZhM5iZ1mKnl1JHhT14//QSqtJ/tAAo8P1EZspvziS1q77DVBF4L/kInl0KEZOiFWMUOKqDjy+TWLSZmBK9uP5J2cb2wnIMZ4HeWw0y8hnaCpfg4FNVm8WL/EQh++EHx4VBQv0bt4s3qZ9LgYM0MGDrizYKCZ92vRE2CVgLlpAzXvD2uFfxlFwJl02l35fjaIW2ed6PVHrnT8D6BrpUIdKWzWsevj3W6IfO0upBtqOygJw0RxYSx646nDDdFXIk7bzdVFXdrsOjOblsPGqTJs+aApEQB3avOUZI0EixCr2h7/wIDAQABAoIBAQCY1je1lQ1J46NGezBdPAkdfNktnnwB/NQginp1GbM7g4hZLid5kS2iqX6rRltA7MhW9pi2uJ5FfEPZvKZGI8qjzq3o1XZJ0zcVief7uKQbU06fPyFx/KnpcGEDVI9IFtk2yqQDjuRA68fhOE2KqvJjL/Sxyf+ZhZDYjs50ums16PHxXlhAaP8EI78Dcff5sx+ZoKTVGum4Jrdlh0cXeDBcxJZg7wEtHPEUrduaiwEv88fD7aw2QwsYdCuPECncltR57iPi95hr7uaWXdtRZ+mAey5sBxJmZKrlPE6kK3yAvSs1tP0yz4R4azAYQqTpLmxcfMrqWRwb3IMA9Rl98FIBAoGBANpNaYJgaTvDT2Nski6sTu1oPefow4tosvPE1jZ/gWXExJ9m1OiIGcZGG0nM+UCx85+//B6gyLdvmUGgxN9vzmY3myuhQ9iesep7W+DiqDnz2J/VRM98eEso6P1jevlC90WJh1wNrVIuzxuN/5A5LghjNNuHCnZzJTRuSKjISjRhAoGBAMSU9hdNDliOXDIIRs/vjwiRuLvbECMFqETSyFdnc91dAi2cYfwlfKFlWGSPFO/LuTvL9PfWaKgfuAzMiZ5JoMPlo5iX8atX1V4Naz7e3OBR9rhyD0oO4aNyKtvDv7tIWTxmeWw/4hlmPp/wGYgfxlPOrbVfJcESYk9FmRxxeoxfAoGAP87ozCcKG2HXTqRphiLvXw1dKvAqWBFeXUpnor5aQDjnkAAqs100y3OqfkPfhz18jHE9bGZqxNNl5HztjrHLjq0qOfKFNkgMkRFFpdIagfX4l59q4YrsTmvCzm3JgBpG1JiCbDHDO4ZbGx7CWJGeFu2IgbJTKJQ3h7/ElTEWH4ECgYEAoxOr/vJ2hzI5+2twSwlBT+uLI5P8FAGacNWnSxLQRH/m0a2cf48dj8pCBNHJnZAUby2oX30nvujpRvza4UvVKQ20pF7QJcMshuR85l/9Pb3g/WvpkRc9SdjpAvylbpj7JicgbZOlXkq6gvWsSIeLgHTBF+gBquQ0V+y1sqnU7uMCgYBMSR2QDG5TuSp7pNOFBFuqhOCrUHZmKqoHCZ7rSh3etxc8D5tLXciEAPNWfGqSE2aT/PJgqNoxl5p42bnZrv3cXJuiD9Wid6yFzDH0oUa9K66vy1SWV+B83rHha5wLzizgNUQZjh1XSndp1WekYCLjV+Bn8b/odBClcHKX7M/BOg==-----END RSA PRIVATE KEY-----\n\nid_rsa.pub为公钥\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnoktjEz2Wb9yI0blK4B3/RYEFjRU33zDUotp3kauRmEzmJnWYqeXUkeFPXj/9BKq0n+0ACjw/URmym/OJLWrvsNUEXgv+QieXQoRk6IVYxQ4qoOPL5NYtJmYEr24/knZxvbCcgxngd5bDTLyGdoKl+DgU1WbxYv8RCH74QfHhUFC/Ru3izepn0uBgzQwYOuLNgoJn3a9ETYJWAuWkDNe8Pa4V/GUXAmXTaXfl+NohbZ53o9UeudPwPoGulQh0pbNax6+Pdboh87S6kG2o7KAnDRHFhLHrjqcMN0VciTtvN1UVd2uw6M5uWw8apMmz5oCkRAHdq85RkjQSLEKvaHv/ master@ubuntu\n\n要想免密登录则需要被免密登录方的公钥：这里可以先将各台分机的公钥发送给主机master，然后再由master合成一个文件再发送给分机。这样每台机器都会有其它所有机器的公钥\n生成公钥文件\ncat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys\n\nauthorized_keys如下，其实和公钥相同：ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCnoktjEz2Wb9yI0blK4B3/RYEFjRU33zDUotp3kauRmEzmJnWYqeXUkeFPXj/9BKq0n+0ACjw/URmym/OJLWrvsNUEXgv+QieXQoRk6IVYxQ4qoOPL5NYtJmYEr24/knZxvbCcgxngd5bDTLyGdoKl+DgU1WbxYv8RCH74QfHhUFC/Ru3izepn0uBgzQwYOuLNgoJn3a9ETYJWAuWkDNe8Pa4V/GUXAmXTaXfl+NohbZ53o9UeudPwPoGulQh0pbNax6+Pdboh87S6kG2o7KAnDRHFhLHrjqcMN0VciTtvN1UVd2uw6M5uWw8apMmz5oCkRAHdq85RkjQSLEKvaHv/ master@ubuntu\n\n分机serve1复制公钥到master主机上：scp .ssh/id_rsa.pub master@master:/home/master/id_rsa_1.pub将分机serve1的公钥追加到主机的authorized_keys上cat id_rsa_1.pub &gt;&gt; .ssh/authorized_keys\n\n重复以上两步直到主机master的authorized_keys有所有分机的公钥，再进行分发操作\nscp .ssh/authorized_keys master@serve1:/home/master/.ssh/authorized_keysscp .ssh/authorized_keys master@serve2:/home/master/.ssh/authorized_keys\n\n分发完毕后即可进行测试：\nssh masterssh serve1能连接成功即可\n\nSSH免密码设置失败解决\n\n权限问题\n\n.ssh目录，以及&#x2F;home&#x2F;当前用户 需要700权限，参考以下操作调整\n$sudo   chmod   777   ~/.ssh$sudo  chmod 700  /home/当前用户\n\n.ssh目录下的authorized_keys文件需要600或644权限，参考以下操作调整\n$sudo chmod   644   ~/.ssh/authorized_keys\n\nStrictModes问题\n\n$sudo gedit /etc/ssh/sshd_config\n\n找到\n\\#StrictModes yes\n\n改成\nStrictModes no\n如果还不行，可以用ssh -vvv 目标机器ip 查看详情\n配置Hadoop集群以下将会修改多个Hadoop配置文件均位于hadoop-2.6.0/etc目录下\n修改：hadoop-env.sh 、yarn-env.sh\ngedit etc/hadoop/hadoop-env.sh# The java implementation to use.export JAVA_HOME=/home/master/jdk1.7.0_80\n\ngedit etc/hadoop/yarn-env.sh\n\ncore-site.xml\ncore-site.xml的完整参数请参考: http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-common/core-default.xml\ngedit etc/hadoop/core-site.xml\n\n/home/hadoop/tmp 目录如不存在，则先mkdir手动创建\n&lt;configuration&gt; &lt;property&gt;   &lt;name&gt;fs.defaultFS&lt;/name&gt;   &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;!--主机名:端口号--&gt;      &lt;/property&gt; &lt;property&gt;     &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;     &lt;value&gt;/home/master/tmp&lt;/value&gt;&lt;!--/tmp/hadoop-$&#123;user.name&#125;--&gt;    &lt;/property&gt; &lt;/configuration&gt;\n\nhdfs-site.xml\nhdfs-site.xml的完整参数请参考: http://hadoop.apache.org/docs/r2.6.0/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml\ngedit etc/hadoop/hdfs-site.xml\n\n&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt;        &lt;value&gt;0.0.0.0:50020&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.http.address&lt;/name&gt;        &lt;value&gt;0.0.0.0:50075&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;        &lt;value&gt;file:/home/master/data/namenode&lt;/value&gt;        &lt;!--元数据--&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;        &lt;value&gt;file:/home/master/data/datanode&lt;/value&gt;        &lt;!--数据块--&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;        &lt;value&gt;slave1:9001&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.replication&lt;/name&gt;        &lt;value&gt;1&lt;/value&gt;        &lt;!--备份数量--&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;dfs.permissions&lt;/name&gt;        &lt;value&gt;false&lt;/value&gt;        &lt;!--权限验证--&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n配置slaves分机列表\ngedit etc/hadoop/slaves\n\nmasterserve1\n\n分发配置文件到集群的其它机器\nscp -r hadoop-2.6.0/etc/hadoop/ master@serve1:/home/master/hadoop-2.6.0/etc/\n\n格式化hdfs\nhdfs namenode -format\n\n等看到执行信息有has been successfully formatted表示格式化ok\n启动 dfs\nhadoop-2.6.0/sbin/start-dfs.sh\n\n验证hadoop是否启动成功：\n$jps显示有：4895 DataNode4775 NameNode\n\n安装 MapReducemapred-site.xml的完整参数请参考http://hadoop.apache.org/docs/r2.6.0/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml\n将mapred-site.xml.template改名成mapred-site.xml\n&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;        &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;        &lt;value&gt;master:10020&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;        &lt;value&gt;master:19888&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\nyarn-site.xml\nyarn-site.xml的完整参数请参考: http://hadoop.apache.org/docs/r2.6.0/hadoop-yarn/hadoop-yarn-common/yarn-default.xml\n&lt;configuration&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;        &lt;value&gt;master:8030&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;        &lt;value&gt;master:8025&lt;/value&gt;    &lt;/property&gt;    &lt;property&gt;        &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;        &lt;value&gt;master:8040&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;\n\n启动yarnhadoop-2.6.0/sbin/start-yarn.sh\n\n$jps多了ResourceManager和NodeManager表示启动yarn成功SecondaryNameNodeResourceManagerNameNode\n\nhadoop-2.6.0/sbin/start-dfs.shhadoop-2.6.0/sbin/start-yarn.shjpsmaster节点上有几下3个进程：7482 ResourceManager7335 SecondaryNameNode7159 NameNodeslave1、slave2上有几下2个进程：2296 DataNode2398 NodeManagerhadoop-2.6.0/sbin/stop-dfs.shhadoop-2.6.0/sbin/stop-yarn.sh\n\n或打开浏览器访问：hdfs管理界面: http://master:50070\nyarn的管理界面: http://master:8088/\n查看hadoop状态\nhdfs dfsadmin -report //查看hdfs的状态报告yarn  node -list   //查看yarn的基本信息Secondary// TODONameNode 元数据DataNode 数据块\n\n\nHDFS文件系统hadoop实现了一个分布式文件系统HDFS(Hadoop Distributed File System)\n\n\n元数据：用于描述数据的数据。\nNameNode 主服务器，用来管理整个文件系统的命名空间和元数据，以及处理来自外界的文件访问请求。整个集群中只有一个。含有：\n\n命名空间：整个分布式文件系统的目录结构\n数据块与文件名的映射表\n每个数据块副本的位置信息(每个数据块默认3个副本)\n\n元数据保存在NameNode的内存当中(1G内存可存放1000000个块对应的元数据信息，缺省每块64M计算可对应64T实际数据)\nDataNode通过心跳包(Heartbeats)与NameNode通讯\nHA(High Available)高可用\nDataNode 用来实际存储和管理文件的数据块\n数据块-64M(128M)数据块+备份公用一个ID\n主从架构：1个NameNode对应n个DataNode\nclient-java app -&gt; data NameNode(客户端向NameNode发起请求)client-sid datanode-&gt; datanode -&gt; r/w -&gt; dfs file(NameNode返回对应的DataNode给客户端让客户端来通过DataNode进行访问)                   -&gt; namenode(向NameNode汇报情况)\n\nJVM从HDFS读取文件流程\n\nclient会从距离最近的机子上读取\nHDFS文件存储的组织与读写：数据写入\n\n客户端调用FileSystem 实例的create 方法，创建文件。NameNode 通过一些检查，比如文件是否存在，客户端是否拥有创建权限等;通过检查之后，在NameNode 添加文件信息。注意，因为此时文件没有数据，所以NameNode 上也没有文件数据块的信息。\n创建结束之后， HDFS 会返回一个输出流DFSDataOutputStream 给客户端。\n客户端调用输出流DFSDataOutputStream 的write 方法向HDFS 中对应的文件写入数据。\n数据首先会被分包，这些分包会写人一个输出流的内部队列Data 队列中，接收完数据分包，输出流DFSDataOutputStream 会向NameNode 申请保存文件和副本数据块的若干个DataNode ， 这若干个DataNode 会形成一个数据传输管道。DFSDataOutputStream 将数据传输给距离上最短的DataNode ，这个DataNode 接收到数据包之后会传给下一个DataNode 。数据在各DataNode之间通过管道流动，而不是全部由输出流分发，以减少传输开销。\n因为各DataNode 位于不同机器上，数据需要通过网络发送，所以，为了保证所有DataNode 的数据都是准确的，接收到数据的DataNode 要向发送者发送确认包(ACK Packet ) 。对于某个数据块，只有当DFSDataOutputStream 收到了所有DataNode 的正确ACK. 才能确认传输结束。DFSDataOutputStream 内部专门维护了一个等待ACK 队列，这一队列保存已经进入管道传输数据、但是并未被完全确认的数据包。\n不断执行第3 - 5 步直到数据全部写完，客户端调用close 关闭文件。\nDFSDataInputStream 继续等待直到所有数据写人完毕并被确认，调用complete 方法通知NameNode 文件写入完成。NameNode 接收到complete 消息之后，等待相应数量的副本写入完毕后，告知客户端\n\n查看文件hadoop fs -cat /output/part-00000查看hadoop文件系统hadoop fs -ls /hadoop fs -ls -R /outputhadoop fs -ls /output创建文件夹hadoop fs -mkdir /tmphadoop fs -mkdir /inputhadoop fs -mkdir /output将文件放到hadoop文件系统-put 当前路径 /home/master/input 放到的路径hadoop fs -put /home/master/input/* /inputhadoop fs -get /output outputhadoop fs -rm -R /inputhadoop fs -rm -r /output/outputhadoop fs -mv /output/output/part-r-00000 /output/part-r-00000\n\n运行例子\nhadoop jar hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar grep /input /output &#x27;dfs[a-z.]+&#x27;\n\nHadoop IOHDFS数据完整性\n校验和+后台进程\n文件数据结构-解决大量小文件\nSequenceFile：用流来读写\nMapFile\nMapReduceMap&#x2F;Reduce是一个用于大规模数据处理的分布式计算模型，它最初是由Google工程师设计并实现的，Google已经将它完整的MapReduce论文公开发布了。其中对它的定义是，Map&#x2F;Reduce是一个编程模型（programming model），是一个用于处理和生成大规模数据集（processing and generating large data sets）的相关的实现。用户定义一个map函数来处理一个key&#x2F;value对以生成一批中间的key&#x2F;value对，再定义一个reduce函数将所有这些中间的有着相同key的values合并起来。很多现实世界中的任务都可用这个模型来表达。\n\n\n结构\n\nMapper、Reduce\n\n运行于Hadoop的MapReduce应用程序最基本的组成部分包括一个Mapper和一个Reducer类，以及一个创建JobConf的执行程序，在一些应用中还可以包括一个Combiner类，它实际也是Reducer的实现。\n\nJobTracker、TaskTracker\n\n它们都是由一个master服务JobTracker和多个运行于多个节点的slaver服务TaskTracker两个类提供的服务调度的。master负责调度job的每一个子任务task运行于slave上，并监控它们，如果发现有失败的task就重新运行它，slave则负责直接执行每一个task。TaskTracker都需要运行在HDFS的DataNode上，而JobTracker则不需要，一般情况应该把JobTracker部署在单独的机器上。\n\nJobClient\n\n每一个job都会在用户端通过JobClient类将应用程序以及配置参数Configuration打包成jar文件存储在HDFS，并把路径提交到JobTracker的master服务，然后由master创建每一个Task（即MapTask和ReduceTask）将它们分发到各个TaskTracker服务中去执行。\n\nJobInProgress\n\nJobClient提交job后，JobTracker会创建一个JobInProgress来跟踪和调度这个job，并把它添加到job队列里。JobInProgress会根据提交的job jar中定义的输入数据集（已分解成FileSplit）创建对应的一批TaskInProgress用于监控和调度MapTask，同时在创建指定数目的TaskInProgress用于监控和调度ReduceTask，缺省为1个ReduceTask。\n\nTaskInProgress\n\nJobTracker启动任务时通过每一个TaskInProgress来launchTask，这时会把Task对象（即MapTask和ReduceTask）序列化写入相应的TaskTracker服务中，TaskTracker收到后会创建对应的TaskInProgress（此TaskInProgress实现非JobTracker中使用的TaskInProgress，作用类似）用于监控和调度该Task。启动具体的Task进程是通过TaskInProgress管理的TaskRunner对象来运行的。TaskRunner会自动装载job jar，并设置好环境变量后启动一个独立的java child进程来执行Task，即MapTask或者ReduceTask，但它们不一定运行在同一个TaskTracker中。\n\nMapTask、ReduceTask\n\n一个完整的job会自动依次执行Mapper、Combiner（在JobConf指定了Combiner时执行）和Reducer，其中Mapper和Combiner是由MapTask调用执行，Reducer则由ReduceTask调用，Combiner实际也是Reducer接口类的实现。Mapper会根据job jar中定义的输入数据集按&lt;key1,value1&gt;对读入，处理完成生成临时的&lt;key2,value2&gt;对，如果定义了Combiner，MapTask会在Mapper完成调用该Combiner将相同key的值做合并处理，以减少输出结果集。MapTask的任务全完成即交给ReduceTask进程调用Reducer处理，生成最终结果&lt;key3,value3&gt;对。这个过程在下一部分再详细介绍。\n\n\n\n案例单词统计案例Mapper&lt;LongWritable, Text, Text, IntWritable&gt;public void map(LongWritable k1, Text v1, Context context)输入LongWritable k1, Text v1(LongWritable, Text)：序号,行处理：从行中split出每个单词，并将每个单词的值设为1输出Context context(Text, IntWritable)：单词,所有该单词的值的集合(数组)Reducer&lt;Text, IntWritable, Text, IntWritable&gt;public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)输入Text key, Iterable&lt;IntWritable&gt; values(Text, IntWritable)：单词,所有该单词的值的集合(数组)处理：使用迭代器Iterator来迭代每个单词的值的数组并将数组中的每个元素相加，和作为该单词新的值输出Context context(Text, IntWritable)：单词,单词出现次数\n\npackage mypro1;import java.io.IOException;import java.net.URI;import java.util.Iterator;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;   public class MyWordCount &#123;\tstatic class MyMapper  extends  Mapper&lt;LongWritable, Text, Text, IntWritable&gt;&#123;  \t\t// 输入LongWritable k1, Text v1(LongWritable, Text)：序号,行\t\tpublic void map(LongWritable k1, Text v1, Context context) \t\t\tthrows java.io.IOException, java.lang.InterruptedException&#123;\t\t\t// 处理：从行中split出每个单词，并将每个单词的值设为1\t\t\tString[]  lines= v1.toString().split(&quot;\\\\s+&quot;);\t\t\tfor(String word: lines)&#123;\t\t\t\t// 输出Context context(Text, IntWritable)：单词,所有该单词的值的集合(数组)\t\t\t\tcontext.write(new Text(word), new IntWritable(1));\t\t\t&#125;\t\t\t\t\t\tSystem.out.println(&quot;map......&quot;);\t\t&#125;\t\t\t&#125;\t\tstatic class  MyReduce extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt;&#123;\t\t// 输入Text key, Iterable&lt;IntWritable&gt; values(Text, IntWritable)：单词,所有该单词的值的集合(数组)\t\tpublic void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)\t\t \tthrows java.io.IOException, java.lang.InterruptedException&#123;\t\t\t// 处理：使用迭代器Iterator来迭代每个单词的值的数组并将数组中的每个元素相加，和作为该单词新的值\t\t\tint sum=0;\t\t\tIterator&lt;IntWritable&gt;  it = values.iterator();\t\t\twhile(it.hasNext())&#123;\t\t\t\tsum+= it.next().get();\t\t\t&#125;\t\t\t// 输出Context context(Text, IntWritable)：单词,单词出现次数\t\t\tcontext.write(key, new IntWritable(sum));    \t\t\t \t\t\tSystem.out.println(&quot;reduce......&quot;);\t\t&#125;\t\t    \t&#125;\t// 定义输入文件\tprivate static String INPUT_PATH=&quot;hdfs://master:9000/input/hdfs-site.xml&quot;;\t// 定义输出结果到目录\tprivate static String OUTPUT_PATH=&quot;hdfs://master:9000/output/c/&quot;;\tpublic static void main(String[] args) throws Exception &#123;\t\t\t// 加载配置文件\t\tConfiguration  conf=new Configuration();\t\tFileSystem  fs=FileSystem.get(new URI(OUTPUT_PATH),conf);\t \t// 若输出目录已存在则删除\t\tif(fs.exists(new Path(OUTPUT_PATH)))\t\t\t\tfs.delete(new Path(OUTPUT_PATH));\t\t\t\t// 开启一个作业\t\tJob job = new Job(conf,&quot;myjob&quot;);\t\t// 设置作业jar包\t\tjob.setJarByClass(MyWordCount.class);\t\t// 设置作业Mapper类\t\tjob.setMapperClass(MyMapper.class);\t\t// 设置作业Reducer类\t\tjob.setReducerClass(MyReduce.class);\t\t\t\t// Mapper&lt;LongWritable, Text, MyK2, LongWritable&gt;定义Mapper泛型输出类\t\t\t\t// Reducer&lt;Text, IntWritable, Text, IntWritable&gt;定义Reducer泛型输出类，因输入与输出相同可省略\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(IntWritable.class);\t\t// 使用文件读取系统读取文件到作业\t\tFileInputFormat.addInputPath(job,new Path(INPUT_PATH));\t\t// 使用文件读取系统输出作业结果\t\tFileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));\t\t\t\tjob.waitForCompletion(true);\t&#125;&#125;\n\n排序案例7 52 12 29 31 84 56 20 7Mapper&lt;LongWritable, Text, MyK2, LongWritable&gt;public void map(LongWritable k1, Text v1, Context context)输入LongWritable k1, Text v1(LongWritable, Text)：序号,行处理输出Context context(MyK2, LongWritable)：两个数,后面那个数(与排序无关,为空都可以)Reducer&lt;MyK2, LongWritable,LongWritable, LongWritable&gt;public void reduce(MyK2 myk2, Iterable&lt;LongWritable&gt; v2s,Context context)输入MyK2 myk2, Iterable&lt;LongWritable&gt; v2s(MyK2, LongWritable)：两个数，后面那个数(与排序无关,为空都可以)处理输出Context context(LongWritable, LongWritable)：第一个数,第二个数0\t71\t82\t12\t24\t56\t27\t59\t3\n\npackage demo;import java.io.DataInput;import java.io.DataOutput;import java.io.IOException;import java.net.URI;import java.util.Iterator;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.io.WritableComparable;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;   public class Sort &#123;\t\tstatic class MyK2 implements WritableComparable&lt;MyK2&gt;&#123;\t\t public long myk2;  \t\t public long myv2;  \t\t public MyK2() &#123;  \t\t        // TODO Auto-generated constructor stub  \t\t &#125;  \t\t  \t\t public MyK2(long myk2, long myv2) &#123;  \t\t     this.myk2 = myk2;  \t\t     this.myv2 = myv2;  \t\t &#125;\t\t@Override\t\tpublic void readFields(DataInput in) throws IOException &#123;\t\t\tthis.myk2=in.readLong();  \t        this.myv2=in.readLong();\t\t&#125;\t\t@Override\t\tpublic void write(DataOutput out) throws IOException &#123;\t\t\tout.writeLong(myk2);  \t        out.writeLong(myv2);\t\t&#125;\t\t@Override\t\tpublic int compareTo(MyK2 my) &#123;\t\t\tlong temp=this.myk2-my.myk2; \t        if(temp!=0)&#123;\t            return (int) temp; \t        &#125;\t        return (int) (this.myv2-my.myv2);\t\t&#125;  \t&#125;\t\tstatic class MyMapper  extends  Mapper&lt;LongWritable, Text, MyK2, LongWritable&gt;&#123;  \t\t public void map(LongWritable k1, Text v1, Context context) \t\t\t\t\t\t throws java.io.IOException, java.lang.InterruptedException\t\t &#123;\t\t\tString[]  lines= v1.toString().split(&quot;\\\\s&quot;);\t\t\tMyK2 myK2 = new MyK2(Long.parseLong(lines[0]), Long.parseLong(lines[1]));\t\t\tcontext.write(myK2, new LongWritable(Long.parseLong(lines[0])));\t\t\tSystem.out.println(&quot;map......&quot;);\t\t &#125;\t\t\t&#125;\t\tstatic class  MyReduce extends Reducer&lt;MyK2, LongWritable,LongWritable, LongWritable&gt;&#123;\t\t public void reduce(MyK2 myk2, Iterable&lt;LongWritable&gt; v2s,Context context) throws java.io.IOException, java.lang.InterruptedException\t\t &#123;\t\t\t context.write(new LongWritable(myk2.myk2), new LongWritable(myk2.myv2));    \t\t\t System.out.println(&quot;reduce......&quot;);\t\t &#125;\t\t    \t&#125;\tprivate static String INPUT_PATH=&quot;hdfs://master:9000/input/num&quot;;\tprivate static String OUTPUT_PATH=&quot;hdfs://master:9000/output/num/&quot;;\tpublic static void main(String[] args) throws Exception &#123;\t\t\t\t\tConfiguration  conf=new Configuration();\t\tFileSystem  fs=FileSystem.get(new URI(OUTPUT_PATH),conf);\t \t\tif(fs.exists(new Path(OUTPUT_PATH)))\t\t\t\tfs.delete(new Path(OUTPUT_PATH));\t\t\t\tJob  job=new Job(conf,&quot;myjob&quot;);\t\t\t\tjob.setJarByClass(Sort.class);\t\tjob.setMapperClass(MyMapper.class);\t\tjob.setReducerClass(MyReduce.class);\t\t\t\t// Mapper&lt;LongWritable, Text, MyK2, LongWritable&gt;定义Mapper泛型输出类\t\tjob.setMapOutputKeyClass(MyK2.class);\t\tjob.setMapOutputValueClass(LongWritable.class);\t\t// Reducer&lt;MyK2, LongWritable,LongWritable, LongWritable&gt;定义Reducer泛型输出类\t\tjob.setOutputKeyClass(LongWritable.class);\t\tjob.setOutputValueClass(LongWritable.class);\t\t\t\tFileInputFormat.addInputPath(job,new Path(INPUT_PATH));\t\tFileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));\t\t\t\tjob.waitForCompletion(true);\t\tSystem.out.println(&quot;end&quot;);\t&#125;&#125;\n\n图案例输入：child\tparent Tom\tLucyTom\tJackJone\tLucyJone\tJackLucy\tMaryLucy\tBenJack\t AliceJack\tJesseTerry\tAliceTerry\tJessePhilip\tTerryPhilip\tAlmaMark\tTerryMark\tAlma需求出输入中的所有的孙子与祖父母Mapper&lt;LongWritable, Text, Text, Text&gt;public void map(LongWritable k1, Text v1, Context context)输入LongWritable k1, Text v1(LongWritable, Text)：序号,行处理：读取行里的数据split，并以关系形式保存(以Tom\tLucy为例)：Tom,1,Tom,LucyTom,2,Lucy,Tom输出Context context(Text, Text)：人名，这个人与其他人的关系(数组)Reducer&lt;Text, Text, Text, Text&gt;public void reduce(Text key, Iterable&lt;Text&gt; values, Context context)输入Text key, Iterable&lt;Text&gt; values(Text, Text)：人名，这个人与其他人的关系(数组)处理：从数组中读出关系并将与该人有关的符合条件的人加入临时数组并输出输出Context context(Text, Text)：孙子，祖父母Jone\tAliceJone\tJesseTom\tAliceTom\tJesseJone\tMaryJone\tBenTom\tMaryTom\tBenMark\tAliceMark\tJessePhilip\tAlicePhilip\tJesse\n\npackage mr;import java.io.IOException;import java.net.URI;import java.util.ArrayList;import java.util.Iterator;import java.util.List;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem ;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.NullWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.Mapper.Context;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;   public class MyGL &#123;\tprivate static class MyGLMapper  extends  Mapper&lt;LongWritable, Text, Text, Text&gt;&#123;  \t\t\t\tpublic void map(LongWritable k1, Text v1, Context context) \t\t\tthrows java.io.IOException, java.lang.InterruptedException&#123;\t\t\t \t\t\t//  1   2  file   tab  ,\t\t\tString[]  lines = v1.toString().split(&quot;\\t&quot;);\t\t\t\t\t \t\t\tif(lines.length != 2 || lines[0].trim().equals(&quot;child&quot;))\t\t\t\treturn;   //child  parent\t\t\t\t\t\t\t\t\tString word1=lines[0].trim();  //  tom\t\t\tString word2=lines[1].trim();  //  lucy\t\t\t\t\t\t\t\t\tcontext.write(new Text(word1), new Text(&quot;1&quot;+&quot;,&quot;+word1+&quot;,&quot;+word2));\t\t\tcontext.write(new Text(word2), new Text(&quot;2&quot;+&quot;,&quot;+word1+&quot;,&quot;+word2));\t\t    System.out.println(&quot;map......&quot;+word1+&quot;-&quot;+word2);\t\t&#125;\t\t\t&#125;\t\tprivate static class  MyGLReduce extends Reducer&lt;Text, Text, Text, Text&gt;&#123;\t\tpublic void reduce(Text key, Iterable&lt;Text&gt; values, Context context)\t\t\tthrows java.io.IOException, java.lang.InterruptedException &#123;\t\t\t/*\t\t\t* lucy   2+tom+lucy\t\t\t* lucy   1+lucy+mary\t\t\t* \t\t\t* 2--&gt;split[1]  tom\t\t\t* 1--&gt;split[2]  mary\t\t\t* \t\t\t* k3=tom  v3=mary\t\t\t* */\t\t\tList&lt;String&gt;  grandch = new ArrayList();\t\t\tList&lt;String&gt;  grandpa = new ArrayList();\t\t\t \t\t\tIterator&lt;Text&gt;  it=values.iterator();\t\t\twhile(it.hasNext())&#123;\t\t\t\tString  lines= it.next().toString();   //2+tom+lucy\t\t\t\tString[] words=lines.split(&quot;,&quot;);      //[&quot;2&quot;,&quot;tom&quot;,&quot;lucy&quot;]\t\t\t\tif(words[0].equals(&quot;1&quot;))&#123;\t\t\t\t\tgrandpa.add(words[2]);\t\t\t\t&#125;\t\t\t\telse if(words[0].equals(&quot;2&quot;))&#123;\t\t\t\t\tgrandch.add(words[1]);\t\t\t\t\t\t\t\t\t&#125;\t\t\t\telse\t\t\t\t\treturn;\t\t\t\t\t\t\t\t\t\t\t&#125;\t\t\t \t\t\tfor(String ch:grandch)\t\t\t\t\tfor(String pa:grandpa)&#123;\t\t            context.write(new Text(ch), new Text(pa)); \t\t            System.out.println(&quot;reduce......&quot;+ch+&quot; - &quot;+pa);\t\t\t\t&#125;\t\t\t \t\t\tSystem.out.println(&quot;reduce......&quot;);\t\t&#125;\t\t        protected void cleanup(Context context) throws java.io.IOException, java.lang.InterruptedException&#123;\t\t\t     \t   \t\t\t \t\t\t \t\t&#125;\t\t    \t&#125;\tprivate static String INPUT_PATH=&quot;hdfs://master:9000/input/gl.dat&quot;;\tprivate static String OUTPUT_PATH=&quot;hdfs://master:9000/output/c/&quot;;\tpublic static void main(String[] args) throws Exception &#123;\t\t\t\t\tConfiguration  conf=new Configuration();\t\tFileSystem  fs=FileSystem.get(new URI(OUTPUT_PATH),conf);\t \t\tif(fs.exists(new Path(OUTPUT_PATH)))\t\t\t\tfs.delete(new Path(OUTPUT_PATH));\t\t\t\tJob  job=new Job(conf,&quot;myjob&quot;);\t\t\t\tjob.setJarByClass(MyGL.class);\t\tjob.setMapperClass(MyGLMapper.class);\t\tjob.setReducerClass(MyGLReduce.class);\t\t \t\t \t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(Text.class);\t\t\t\t \t\t\t\tFileInputFormat.addInputPath(job,new Path(INPUT_PATH));\t\tFileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));\t\t\t\tjob.waitForCompletion(true);\t&#125;&#125;\n\n\n\n\n矩阵乘法矩阵乘法公式：\n\n\n矩阵A(4*3)(i*n)1,2,34,5,07,8,910,11,12矩阵B(3*2)(n*j)10,150,211,9根据矩阵乘法的定义：矩阵A的列数=矩阵B的行数，即矩阵A和矩阵B都有相同的n矩阵乘法的结果是产生(i*j)的矩阵C矩阵C(4*2)(i*j)43,4640,70169,202232,2801*10+2*0+3*11=431*15+2*2+3*9=46计算每个矩阵C中的元素(i,j)都需要矩阵A的(i,r)与矩阵B的(r,j)相乘再加上下一个r取值[1,n]接下来看看进行一个矩阵计算需要哪些信息：因为每次计算r都是从1到n，所以r的值不需要保存进map，需要：计算结果是在C的哪里即(i,j)，A矩阵对应的值，B矩阵对应的值，这个值来自哪个矩阵(A还是B)那么如何唯一标识矩阵C的一个元素呢？使用矩阵C的坐标，将C的坐标(i,j)作为key(哪个矩阵,对应的r,矩阵的值)作为value，这样就可以保存进行矩阵计算的全部信息了分类讨论：(i,j为计算C的第(i,j)个元素的值，r取值[1,n])对于矩阵A的值：key(i,j) value(a,A的列即r,A[i,r])对于矩阵B的值：key(i,j) value(b,B的列即r,B[r,j])分类讨论的计算过程见下图\n\n\n\npackage demo;import java.io.IOException;import java.net.URI;import java.util.HashMap;import java.util.Iterator;import java.util.Map;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.FileSystem;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.LongWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.input.FileSplit;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;public class MatrixProdect &#123;\tstatic class MyMapper extends Mapper&lt;LongWritable, Text, Text, Text&gt; &#123;\t\tprivate int rowNum = 4;// 矩阵A的行数\t\tprivate int colNum = 2;// 矩阵B的列数\t\tprivate int rowIndexA = 1; // 矩阵A，当前在第几行\t\tprivate int rowIndexB = 1; // 矩阵B，当前在第几行\t\tpublic void map(LongWritable key, Text value, Context context)\t\t\t\tthrows java.io.IOException, java.lang.InterruptedException &#123;\t\t\tFileSplit fs = (FileSplit) context.getInputSplit();\t\t\tString fileName = fs.getPath().getName();\t\t\tString[] tokens = value.toString().split(&quot;,&quot;); // 读进一行数据\t\t\tif (&quot;a&quot;.equals(fileName)) &#123; // 通过文件名判断是矩阵A还是矩阵B\t\t\t\tfor (int j = 1; j &lt;= colNum; j++) &#123;\t\t\t\t\tText k = new Text(rowIndexA + &quot;,&quot; + j);\t\t\t\t\tfor (int r = 0; r &lt; tokens.length; r++) &#123;\t\t\t\t\t\tText v = new Text(&quot;a,&quot; + (r + 1) + &quot;,&quot; + tokens[r]);\t\t\t\t\t\tSystem.out.println(&quot;map......&quot; + fileName + &quot;(&quot; + k + &quot;)&quot; + v);\t\t\t\t\t\tcontext.write(k, v);\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\trowIndexA++;// 每执行一次map方法，扫描矩阵的下一行\t\t\t&#125; else if (&quot;b&quot;.equals(fileName)) &#123;\t\t\t\tfor (int i = 1; i &lt;= rowNum; i++) &#123;\t\t\t\t\tfor (int r = 0; r &lt; tokens.length; r++) &#123;\t\t\t\t\t\tText k = new Text(i + &quot;,&quot; + (r + 1));\t\t\t\t\t\tText v = new Text(&quot;b,&quot; + rowIndexB + &quot;,&quot; + tokens[r]);\t\t\t\t\t\tSystem.out.println(&quot;map......&quot; + fileName + &quot;(&quot; + k + &quot;)&quot; + v);\t\t\t\t\t\tcontext.write(k, v);\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\trowIndexB++;// 每执行一次map方法，扫描矩阵的下一行\t\t\t&#125;\t\t\t\t\t&#125;\t&#125;\tstatic class MyReduce extends Reducer&lt;Text, Text, Text, IntWritable&gt; &#123;\t\tpublic void reduce(Text key, Iterable&lt;Text&gt; values, Context context)\t\t\t\tthrows java.io.IOException, java.lang.InterruptedException &#123;\t\t\t\t\t\tMap&lt;String, String&gt; mapA = new HashMap&lt;String, String&gt;();\t\t\tMap&lt;String, String&gt; mapB = new HashMap&lt;String, String&gt;();\t\t\t// 根据矩阵来分类\t\t\tfor (Text value : values) &#123;\t\t\t\tString[] val = value.toString().split(&quot;,&quot;);\t\t\t\tif (&quot;a&quot;.equals(val[0])) &#123;\t\t\t\t\tmapA.put(val[1], val[2]);\t\t\t\t&#125; else if (&quot;b&quot;.equals(val[0])) &#123;\t\t\t\t\tmapB.put(val[1], val[2]);\t\t\t\t&#125;\t\t\t&#125;\t\t\tint result = 0;\t\t\tIterator&lt;String&gt; mKeys = mapA.keySet().iterator();\t\t\twhile (mKeys.hasNext()) &#123; // 取相同的r值的数相乘\t\t\t\tString mkey = mKeys.next();\t\t\t\tif (mapB.get(mkey) == null) &#123;\t\t\t\t\tcontinue;\t\t\t\t&#125;\t\t\t\tresult += Integer.parseInt(mapA.get(mkey)) * Integer.parseInt(mapB.get(mkey));\t\t\t&#125;\t\t\tSystem.out.println(&quot;reduce......&quot; + &quot;(&quot; + key + &quot;)&quot; + result);\t\t\tcontext.write(key, new IntWritable(result));\t\t&#125;\t&#125;\tprivate static String INPUT_PATH_A = &quot;hdfs://master:9000/input/a&quot;;\tprivate static String INPUT_PATH_B = &quot;hdfs://master:9000/input/b&quot;;\tprivate static String OUTPUT_PATH = &quot;hdfs://master:9000/output/matrix/&quot;;\tpublic static void main(String[] args) throws Exception &#123;\t\tConfiguration conf = new Configuration();\t\tFileSystem fs = FileSystem.get(new URI(OUTPUT_PATH), conf);\t\tif (fs.exists(new Path(OUTPUT_PATH)))\t\t\tfs.delete(new Path(OUTPUT_PATH));\t\tJob job = new Job(conf, &quot;myjob&quot;);\t\tjob.setJarByClass(MatrixProdect.class);\t\tjob.setMapperClass(MyMapper.class);\t\tjob.setReducerClass(MyReduce.class);\t\tjob.setMapOutputKeyClass(Text.class);\t\tjob.setMapOutputValueClass(Text.class);\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(IntWritable.class);\t\tFileInputFormat.addInputPath(job, new Path(INPUT_PATH_A));\t\tFileInputFormat.addInputPath(job, new Path(INPUT_PATH_B));\t\tFileOutputFormat.setOutputPath(job, new Path(OUTPUT_PATH));\t\tjob.waitForCompletion(true);\t\tSystem.out.println(&quot;end&quot;);\t&#125;&#125;\n\n计算方法与上面一样，只是矩阵的存储结构不一样。省略了值为0的元素，对于较大且稀疏的矩阵所占存储空间较小\n行,列,值\n\n\n\n","categories":["Big Data"],"tags":["HDFS","Hadoop","MapReduce"]},{"title":"Hive","url":"/2022/08/17/BigData/Hive/","content":"安装hivehive–&gt;hql–&gt;hive引擎–&gt;mapreduce Task\n配置mysql数据库前置条件：安装数据库mysql\nsudo apt-get install mysql-server mysql-client\n\n启动停止mysql服务\nsudo start mysqlsudo stop mysql  \n\n取消本地监听\n取消本地监听需要修改 my.cnf 文件：\n$sudo vim /etc/mysql/my.cnf// 找到如下内容，并注释#bind-address = 127.0.0.1\n\n修改了配置文件后需要重启 mysqld 才能使这些修改生效。\n检查 mysqld 进程是否已经开启： \n$pgrep mysqld\n\n如果进程开启，这个命令将会返回该进程的 id \nroot登录mysql\nmysql -uroot -p\n\n下载apache-hive-1.1.0\n解压到&#x2F;home&#x2F;master&#x2F;apache-hive-1.1.0\n配置环境变量sudo gedit /etc/profile#set hive environmentHIVE_HOME=/home/master/apache-hive-1.1.0PATH=$HIVE_HOME/bin:$PATHCLASSPATH=$CLASSPATH:$HIVE_HOME/libexport HIVE_HOMEexport PATHexport CLASSPATHsource /etc/profile\n\n配置hive-env.sh\ncd /home/master/apache-hive-1.1.0/confgedit hive-env.shHADOOP_HOME=/home/master/hadoop-2.6.0export HIVE_CONF_DIR=/home/master/hadoop-2.6.0/conf\n\n配置hive-site.xml\ncp hive-default.xml.template hive-site.xmlsudo gedit hive-site.xml\n\n&lt;property&gt;  &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt;  &lt;value&gt; /home/master/hive/warehouse&lt;/value&gt;  &lt;description&gt;location of default database for the warehouse&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.exec.scratchdir&lt;/name&gt;  &lt;value&gt; /home/master/hive/scratchdir&lt;/value&gt;  &lt;description&gt;Scratch space for Hive jobs&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;hive.querylog.location&lt;/name&gt;  &lt;value&gt;/home/master/apache-hive-1.1.0/logs&lt;/value&gt;  &lt;description&gt;    Location of Hive run time structured log file  &lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;  &lt;value&gt;jdbc:mysql://master:3306/hive_metadata?createDatabaseIfNotExist=true&lt;/value&gt;  &lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;  &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;  &lt;description&gt;Driver class name for a JDBC metastore&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;  &lt;value&gt;root&lt;/value&gt;  &lt;description&gt;username to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;  &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;  &lt;value&gt;root123&lt;/value&gt;  &lt;description&gt;password to use against metastore database&lt;/description&gt;&lt;/property&gt;&lt;property&gt;   &lt;name&gt;hive.exec.local.scratchdir&lt;/name&gt;    &lt;!--拼凑目录--&gt;    &lt;value&gt;/home/master/apache-hive-1.1.0/local/$&#123;system:user.name&#125;&lt;/value&gt;   &lt;description&gt;Local scratch space for Hive jobs&lt;/description&gt;  &lt;/property&gt;&lt;property&gt;   &lt;name&gt;hive.downloaded.resources.dir&lt;/name&gt;   &lt;value&gt;/home/master/apache-hive-1.1.0/local/$&#123;hive.session.id&#125;_resources&lt;/value&gt;   &lt;description&gt;Temporary local directory for added resources in theremote file system.&lt;/description&gt;  &lt;/property&gt;&lt;property&gt;   &lt;name&gt;hive.server2.logging.operation.log.location&lt;/name&gt;   &lt;value&gt;/home/master/apache-hive-1.1.0/logs/operation_logs&lt;/value&gt;   &lt;description&gt;Top leveldirectory where operation logs are stored if logging functionality isenabled&lt;/description&gt;  &lt;/property&gt;\n\n在apache-hive-1.1.0目录下创建local目录mkdir local\n配置log4j创建配置文件：\ncp hive-exec-log4j.properties.template  hive-exec-log4j.propertiescp hive-log4j.properties.template  hive-log4j.properties\n\n修改上面两个文件中的配置\nsudo gedit hive-exec-log4j.propertiessudo gedit hive-log4j.propertieshive.log.dir=/home/master/apache-hive-1.1.0/logslog4j.appender.EventCounter=org.apache.hadoop.log.metrics.EventCounter\n\n注意如果没有logs目录就建立一个 执行命令\n$mkdir /home/master/apache-hive-1.1.0/logs\n\n添加Mysql驱动包\n下载驱动包本实验使用的mysql是mysql 5.6 版本，配套的jdbc是mysql-connector-java-5.1.24-bin.jar这个jar在网上下载就可以了，一定要根据mysql版本选择配套的版本\n\n添加驱动包把驱动包放到 $HIVE_HOME&#x2F;lib 目录下\n\n修改hadoop的库文件在$HADOOP_HOME&#x2F;share&#x2F;hadoop&#x2F;yarn&#x2F;lib下备份jline-0.9.94.jar\n\n执行命令\ncd /home/master/hadoop-2.6.0/share/hadoop/yarn/lib$mv jline-0.9.94.jar jline-0.9.94.jar.bak\n\nCopy高版本的jline\n$cp $HIVE_HOME/lib/jline-2.12.jar $HADOOP_HOME/share/hadoop/yarn/libcp /home/master/apache-hive-1.1.0/lib/jline-2.12.jar /home/master/hadoop-2.6.0/share/hadoop/yarn/lib\n\n验证配置是否成功\n启动hive\nhive\n\n没有报错且显示hinve&gt;\ncreate table test(id int, name String);show tables;insert into test values(0, &#x27;Sombra&#x27;);select * from test;\n\n从文件导入数据create table shakespaeare(child string, parent string)row format delimited fields terminated by &#x27;,&#x27;stored as textfile;load data inpath &quot;hdfs://master:9000/input/gl.dat&quot;into table shakespaeare;\n","categories":["Big Data"],"tags":["Hive"]},{"title":"Clean Code","url":"/2019/10/26/Buffer/Clean%20Code/","content":"整洁代码单一权责原则(Single Responsibility ,SRP)一个类只负责一功能领域中的相应职，或者可以定义为：就一个类而言,应该只有一个引起它变化的原因.\n修改前:\npublic class CustomerDataChart&#123;    public Connection getConnection()&#123;    &#125;    public List&lt;Customers&gt; findCustomers()&#123;    &#125;    public void createChart()&#123;    &#125;    public void displayChart()&#123;    &#125;&#125;\n\n修改后:\npublic class DBUtil&#123;    public Connection getConnection()&#123;    &#125;&#125;public class CustomerDAO&#123;    private DBUtil util;    public List&lt;Customers&gt; findCustomers()&#123;    &#125;&#125;public class CustomerDataChart&#123;    private CustomerDAO dao;    public void createChart()&#123;    &#125;    public void displayChart()&#123;    &#125;&#125;\n\n\n开放闭合原则(Open Closed Principle,OCP)一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。\n修改前:\npublic class PieChart&#123;    public void display()&#123;        System.out.println(&quot;PieChart:&quot; + type);    &#125;&#125;public class BarChart&#123;    public void display()&#123;        System.out.println(&quot;BarChart:&quot; + type);    &#125;&#125;public class ChartDisplay &#123;    public void display(String type)&#123;        switch(type)&#123;            case &quot;PieChart&quot;:                PieChart pie = new PieChart();                pie.display();                break;            case &quot;BarChart&quot;:                BarChart bar = new BarChart();                bar.display();                break;        &#125;    &#125;&#125;\n\n修改后:\npublic abstract class AbstractChart&#123;    public void display();&#125;public class PieChart extends AbstractChart&#123;    @Override    public void display()&#123;        System.out.println(&quot;PieChart&quot;);    &#125;&#125;public class BarChart extends AbstractChart&#123;    @Override    public void display()&#123;        System.out.println(&quot;BarChart&quot;);    &#125;&#125;public class ChartDisplay&#123;    private AbstractChart chart;    public setChart(AbstractChart chart)&#123;        this.chart = chart;    &#125;    public void display()&#123;        chart.display();    &#125;&#125;\n\n\nLSP里氏代换原则(Liskov Substitution Principle)所有引用基类（父类）的地方必须能透明地使用其子类的对象。\n修改前:\npublic class CommonCustomer &#123;    private String name;    private String email;    public getName()&#123;        return this.name;    &#125;    public setName(String name)&#123;        this.name = name;    &#125;    public getEmail()&#123;        return this.email;    &#125;    public setEmail(String email)&#123;        this.email = email;    &#125;&#125;public class VIPCustomer &#123;    private String name;    private String email;    public getName()&#123;        return this.name;    &#125;    public setName(String name)&#123;        this.name = name;    &#125;    public getEmail()&#123;        return this.email;    &#125;    public setEmail(String email)&#123;        this.email = email;    &#125;&#125;public class EmailSender &#123;    public send(CommonCustomer customer)&#123;        //send    &#125;    public send(VIPCustomer customer)&#123;        //send    &#125;&#125;\n\n修改后:\npublic class Customer &#123;    private String name;    private String email;    public getName()&#123;        return this.name;    &#125;    public setName(String name)&#123;        this.name = name;    &#125;    public getEmail()&#123;        return this.email;    &#125;    public setEmail(String email)&#123;        this.email = email;    &#125;&#125;public class CommonCustomer extends Customer&#123;&#125;public class VIPCustomer extends Customer&#123;&#125;public class EmailSender &#123;    public send(Customer customer)&#123;        //send    &#125;&#125;\n\n\n接口隔离原则(Interface Segregation Principle, ISP)使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。\n修改前:\npublic interface CustomerDataDisplay &#123;    public void dataRead();    public void transformToXML();    public void createChart();    public void displayChart();    public void createReport();    public void displayReport();&#125;public class ConcreteClass implements CustomerDataDisplay&#123;&#125;\n\n修改后:\npublic interface DataHandler &#123;    public void dataRead();&#125;public interface XMLTransformer &#123;    public void transformToXML();&#125;public interface ChartHandler &#123;    public void createChart();    public void displayChart();&#125;public interface ReportHandler &#123;    public void createReport();    public void displayReport();&#125;public class ConcreteClass implements DataHandler, ChartHandler&#123;&#125;\n\n\n依赖倒置原则(Dependency Inversion Principle,DIP)抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。\n修改前:\npublic interface TXTDataConvertor &#123;    public void addCustomer();&#125;public interface ExcelDataConvertor &#123;    public void addCustomer();&#125;public class CustomerDAO implements TXTDataConvertor, ExcelDataConvertor&#123;    public void addCustomer()&#123;    &#125;&#125;\n\n修改后:\npublic interface TXTDataConvertor &#123;    public void readFile();&#125;public interface ExcelDataConvertor &#123;    public void readFile();&#125;public abstract class DataConvertor implements TXTDataConvertor, ExcelDataConvertor&#123;    public void readFile()&#123;    &#125;&#125;public class CustomerDAO extends DataConvertor&#123;    public void addCustomer()&#123;    &#125;&#125;\n\n...&lt;className&gt;TX TDataConvertor&lt;/className&gt;...\n\n\n有意义的命名名副其实如果名称需要注释来补充，那就不算是名副其实。\n避免误导 &amp; 做有意义的区分避免误导：避免留下掩藏代码本意的错误线索。应当避免使用与本意相悖的词。\ne.g:\n\n以数字系列命名\n错误的拼写\n命名一组账号：accountGroup、bunchOfAccounts和accounts 好于 accountList(List对程序员有特殊意义)\n废话都是冗余。Variable一词永远不应当出现在变量名中。Table一词永远不应当出现在表名中。\n\n使用读得出来的名称 &amp; 使用可搜索的名称使用读的出来的名称：\n\ngenymdhms(生成日期，年、月、日、时、分、秒)，他们一般读作“gen why emm dee aich emm ess”或“gen-yah-mudda-hims”\n\n使用可搜索的名称：\n\nWORK_DAYS_PER_WEEK 要比数字 5 好找\n长名称胜于短名称，搜得到的名称胜于用自造编码代写就的名称\n若变量或常量可能在代码中多处使用，则应赋其以便于搜索的名称\n\n避免使用编码\n如果编译器不做类型检查或动态类型语言，程序员需要匈牙利语标记法来帮助自己记住类型\n不推荐接口采用IShapeFactory，可以考虑接口ShapeFactory,实现采用ShapeFactoryImp或者丑陋的CShapeFactory，比对接口名称编码好\n\n常见误区\n避免思维映射:不应当让读者在脑中把你的名称翻译为他们熟知的名称。这种问题经常出现在选择是使用问题领域术语还是解决方案领域术语时。\n类名或对象名应该是名词或名词短语\n方法名应当是动词或者动词短语\n重构构造器，使用描述了参数的静态工厂方法名Complex fulcrumPoint = Complex.FromRealNumber(23.0); \n给每个抽象概念选一个词，并且一以贯之\n别用双关语\n使用解决方案领域名称\n采用从所涉问题领域而来的名称\n你需要用有良好命名的类、函数或名称空间来放置名称，给读者提供语境,如果没这么做，给名称添加前就是最后一招了\n\n\n函数Function should do one thing. They should do it well. They should do it only.\n函数的原则\n短小:\nif语句、else语句、while语句等，其中的代码块只能有一行\n函数的缩进层级不该多于一层或两层\n\n\n函数应该做一件事。做好这件事。只做这一件事。\n每个函数一个抽象层级:要让每个函数后面都跟着位于下一抽象层级的函数，这样一来，在查看函数列表时，就能偱抽象层级向下阅读了。我把这叫做向下规则。\nswith语句。\n\npublic Money calculatePay(Empoyee e) throws InvalidEmployeeType&#123;    switch (e.type) &#123;        case COMMISSIONED:            return calculateCommissionedPay(e);        case HOURLY:            return calculateHourlyPay(e);        case SELARIED:            return calculateSalariedPay(e);        default:          throw new InvalidEmployeeType(e.type);    &#125;&#125;\n\n- 太长，当出现新的雇员类型时，还会变得更长。\n- 明显做了不止一件事。\n- 违反了单以权责原则，有好几个修改的理由。\n- 违反了开放闭合原则，每当添加新类型时，就必须修改之。\n- 可能会到处出现类似的结构函数\n\n可以改成:\npublic abstract class Employee &#123;    public abstract boolean isPayday();    public abstract Money calculatePay();    public abstract void deliverPay();&#125;public interface EmployeeFactory &#123;    public Employee makeEmployee(EmployeeRecord r) throws InvalidEmployeeType;&#125;public class EmployeeFactoryImpl implements EmployeeFactory &#123;    public Employee makeEmployee(EmployeeRecord r) throws InvalidEmployeeType&#123;        switch (e.type) &#123;            case COMMISSIONED:              return CommissionedEmployee(r);            case HOURLY:              return HourlyPayEmployee(r);            case SELARIED:              return SalariedPayEmployee(r);            default:              throw new InvalidEmployeeType(e.type);        &#125;    &#125;&#125;\n\n将swith语句埋到抽象工厂下，该工厂使用 switch 语句为 Employee 的派生物创建适当的实体，而不同的函数，如 calculatePay、isPayday 和 deliverPay等，则藉由 Employee 接口多态地接受派遣。对于 switch 语句，我的规矩是如果只出现一次，用于创建多态对象，而且隐藏在某个继承关系中。\n\n使用描述性的名称。\n函数参数个数 &lt;&#x3D; 3。\n无副作用\n分割指令与询问。函数要么做什么事，要么回答什么事，但二者不可得兼。函数应该修改某对象的状态或是返回该对象的有关信息。两样都干常会导致混乱。\n使用异常替代返回错误码。从指令式函数返回错误码轻微违反了指令与询问分隔的规则。它鼓励了在if 语句判断中把指令当作表达式使用。这不会引起动词&#x2F;形容词混淆，但却导致更深层次的嵌套结构。当返回误码时，就是在要求调用者立刻处理错误。另一方面，如果使用异常替代返回错误码，错误处理代码就能从主路径代码中分离出来。\n别重复自己。\n结构化编程。每个函数、函数中的每个代码块都应该有一个入口、一个出口。每个函数中之该有一个return语句。\n\n函数修改的策略大师级程序员把系统当作故事来讲，而不是当作程序来写。他们使用选定编程语言提供的工具构建一种更为丰富且更具表达力的语言，用来讲那个故事。那种领域特定语言的一个部分，就是描述在系统中发生的各种行为的函数层级。在一种狡猾的递归操作中，这些行为使用它们定义的与领域紧密相关的语言讲述自己那个小故事。\n\n注释注释不能美化糟糕的代码\n好注释:\n\n唯一真正好的注释是你想办法不去写的注释\n法律信息:公司代码规范要求编写与法律有关的注释，只写引用即可\n阐释:注释把某些晦涩难明的参数或返回值的意义翻译为某种可读形式\n警示:警告其他程序员会出现某种后果的注释。\nTODO注释:有理由在源代码中放置要做的工作列表。定期查看，删除不再需要的。\n放大:注释可以用来放大某种看来不合理之物的重要性。\n公共API中的Javadoc,Javadoc也可能误导、不适用或者提供错误信息\n\n坏注释:\n\n喃喃自语\n多余的注释\n误导性注释\n循规式注释\n日志式注释:应由源代码控制系统来管理\n废话注释\n能用函数或变量时就别用注释\n位置标记\n括弧后面的注释:while,if等的多层嵌套，用短小的封装的函数代替\n归属与签名:源代码控制系统是这类信息最好的归属地\n注释掉的代码\nHTML注释\n非本地信息:别在本地注释的上下文环境中给出系统级的信息\n信息过多:有趣的历史话题或者无关的细节描述\n不明显的联系\n函数头\n非公共代码中的JavaDoc\n\n\n格式格式的目的\n垂直格式\n横向格式\n尽力保持代码行短小。无需拖动滚动条到右侧的原则。\n水平对齐。\n缩进。\n\n\n团队风格\n项目开始时制定一套编码风格，将规则编写进IDE。\n\n\n\n\n对象和数据结构数据抽象类并不简单地用取值器和赋值器将其变量推向外间，而是曝露抽象接口，以便用户无需了解数据的实现就能操作数据本体。过程式代码难以添加新数据结构，因为必须修改所有函数。面向对象代码难以添加新函数，因为必须修改所有类。\n得墨忒耳律模块不应了解所操作对象的内部情形。得墨忒耳律认为，类C的方法f只应该调用以下对象的方法：\n\nC\n由f创建的对象\n作为参数传递给f的对象\n由C持有的实体变量持有的对象\n\n数据传送对象DTO（Data Transfer Objects）经常用作与数据库通信、或解析套接字传递的消息之类场景中。\n\n错误处理\n使用异常而非返回码\n先写Try-Catch-Finally语句\n\n异常的使用\n使用不可控异常：可控异常的代价就是违反开放&#x2F;闭合原则。&#x2F;&#x2F;TODO:?\n给出异常发生的环境说明,都应当提供足够的环境说明，以便判断错误的来源和处所。\n定义常规流程：采用特例模式。创建一个类或配置一个对象，用来处理特例.\n别返回null值：在方法中返回null值，不如抛出异常，或是返回特例对象\n\n\n边界整洁的边界应该避免我们的代码过多地了解第三方代码中的特定信息。在这种场景下，适配器模式是非常好的设计，它不仅能将不兼容的接口改写成兼容的接口，还能够对通过对第三方工具重新封装来避免边界的变化对系统的影响。\n\n单元测试TDD三定律\n在编写不能通过的单元测试前，不可编写生产代码。\n只可编写刚好无法通过的单元测试，不能编译也算不通过。\n只可编写刚好足以通过当前失败测试的生产代码。\n\n整洁的测试\n测试与生产代码一起编写，这样可以保证：测试将覆盖所有生产代码。\n整洁测试的三个要素：可读性、可读性、可读性。要明确，简洁，有足够的表达力。\n测试呈现构造-操作-检验（BUILD-OPERATE-CHECK）模式。\n生产环境和测试环境可以用双重标准。\n每个测试一个断言。每个测试一个概念。\nGiven-when-then：Given在某种场景下 When发生了事件 Then导致了什么结果。\n\nF.I.R.S.T整洁的测试环境遵循以下5条规则：\n\n快速(Fast)\n测试应该快速，因为需要不断的运行测试得到反馈，我们需要的快速反馈，错误的快速定位。所以你的测试就不能依赖太多的外部资源，数据库，硬件环境等等，对于这些外部资源应该采用伪对象模式来隔离。\n\n\n独立(Independent)\n测试应该是相互独立的，独立于测试用例之间，独立于特定的环境，独立于测试的运行顺利。\n数据的独立方式:\n每个测试环境的独立\n数据的隔离\n\n\n\n\n可重复(Repeatable)\n测试应该可以在任何环境中重复通过，可运行，因为测试独立于环境外部资源。\n\n\n自足验证(Self-Validation)\n测试应该有通过失败的标示，从每一个测试上能得到一处代码逻辑的通过失败。\n\n\n及时(Timely)\n测试应该是及时编写的。TDD要求测试必须在实现代码之前，提前以使用者的角度定义使用接口方式。\n\n\n\n\n类类的组织类应该从一组变量列表开始。如果有公共静态常量，应该先出现。然后是私有静态变量，以及私有实体变量。很少会有公共变量。公共函数应更在变量列表之后，把由某个公共函数调用的私有工具函数紧随在该公共函数后面。符合自定向下的原则。\n内聚：类应该只有少量实体变量。\n为了修改而组织\n开放-闭合原则（OCP）：类应当对扩展开放，对修改封闭。\n隔离修改：具体类包含实现细节，而抽象类只呈现概念。可以借助接口和抽象类来隔离细节修改带来的风险。\n依赖倒置原则（Dependency Inversion Principle,DIP）:类应该依赖于抽象而不是依赖于具体细节。\n\n\n系统将系统的构造与使用分开软件系统应将启始过程和启始过程之后的运行时逻辑分离开，在启始过程中构建应用对象，也会存在相互缠结的依赖关系。依赖注入（Dependency Injection,DI）机制,可以实现分离构造与使用。控制反转（Inversion of Control,IoC）将第二权责从对象中拿出来，转移到另一个专注于此的对象中，从而遵循了单一权责原则。\n扩容我们应该只去实现今天的用户故事，然后重构，明天再扩展系统、实现新的用户故事。这就是迭代和增量敏捷的精髓所在。测试驱动开发、重构以及他们打造出的整洁代码，在代码层面保证了这个过程的实现。\n横切关注点横切关注点（Cross-Cutting Concerns）：在AOP中，被称为方面（aspect）的模块构造指明了系统中哪些点的行为会以某种一致的方式被修改，从而支持某种特定的场景。\nJava代理：适用于简单的情况，例如在单独的对象或类中包装方法调用。\n纯Java AOP框架：如Spring AOP和Jboss AOP等，在概念上更简单、更易于测试驱动。\n测试驱动系统架构用POJO编写应用程序的领域逻辑，在代码层面与架构关注面分离开，就有可能真正地用测试来驱动架构。\n没必要先做大设计（Big Design Up Front，DBUF）。实际上，它阻碍改进，架构上的方案选择影响到后续的设计思路\n系统需要领域特定语言领域特定语言（Domain-Specific Language,DSL）：在有效使用时能提升代码惯用法和设计模式之上的抽象层次。允许所有抽象层级和应用程序中的所有领域，从高级策略到底层细节，使用POJO来表达。\n\n迭代关于简单设计的四条规则：\n\n运行所有测试；\n不可重复；\n表达了程序员的意图；\n尽可能减少类和方法的数量；\n以上规则按其重要程度排列。\n\n\n并发编程并发是一种解耦策略，帮助把做什么（目的）和何时（时机）做分解开。\n解耦目的与时机能明显地改进应用程序的吞吐量和结构。\n挑战与并发防御原则单一权责原则\n限制数据作用域（采用synchronized保护临界区）\n建议：谨记数据封装，严格限制对可能被共享的数据的访问。\n推论：使用数据副本：假使使用对象复本能避免代码同步执行，则因避免了锁定而省下的价值有可能补偿得上额外的创建陈本和垃圾收集开销。\n推论：线程应尽可能地独立\n建议：尝试将数据分解到可被独立线程（可能在不同处理器上）操作的独立子集。\n了解执行模型警惕同步方法之间的依赖保持同步区域微小\nCode Smell List注释\n不恰当的注释\n让不恰当的注释保存到源代码控制系统。\n\n\n废弃的注释\n过时 、无关或不正确的注释就是废弃的注释不应该保留必马上删除。\n\n\n冗余的注释\n注释应该谈及代码自身没提到的东西，否则就是冗余的。\n\n\n糟糕的注释\n值得编写的注释必须正确写出最好的注释，如果不是就不写 。\n\n\n注释掉的代码\n注释掉的代码必须删除。\n\n\n\n环境\n需要多步才能实现的构建:构建系统应该是单步的小操作 。\n需要多步才能实现的测试:只需要单个指令就可以运行所有单元测试。\n\n函数\n过多的参数:函数参数应该越少越好，坚决避免有3个参数 的函数\n出参数:出参数违反直接，抵制出参数\n标识参数:布尔值参数令人迷惑，应该消灭掉\n死函数:永不被调用函数应该删除掉\n\n一般性问题\n一个源文件存在多个语言\n\n\n尽量减少源文件语言的数量和范围。\n\n\n明显的行为未被实现\n\n\n遵循 “最少惊异原则 ”，函数或者类应该实现其他程序员有理由期待的行为，不要让其他程序员看代码才清楚函数的作用。\n\n\n不正确的边界行为\n\n\n代码应该有正确的行为，追索每种边界条件并进行全面 测试。\n\n\n忽视安全\n\n\n关注可能引起问题的代码，注重安全与稳定。\n\n\n重复\n\n\n消除重复代码，使用设计模式。\n\n\n在错误的抽象层级上的代码\n\n\n抽象类和派类概念模型必须完整分离，例如 ：与实现细节有关的代码不应该在基类中出现。\n\n\n基类依赖于派类\n\n\n基类应该对派类一无所知。\n\n\n信息过多\n\n\n类中的方法，变量越少越好，隐藏所有实现，公开接口越少越好。\n\n\n死代码\n\n\n找到并删除所有不被调用的代码。\n\n\n垂直分隔\n\n\n变量和函数的定义应该靠近被调用代码。\n\n\n前后不一致\n\n\n函数参数变量应该从一而终，保持一致，让代码便于阅读和修改。\n\n\n混淆视听\n\n\n没用的变量，不被调用的函数，没有信息量的注释应该清理掉。\n\n\n人为耦合\n\n\n不互相依赖的东西不该耦合。\n\n\n特性依恋\n\n\n类的方法应该只对自身的方法和变量感兴趣，不应该垂青其他类的方法和变量。\n\n\n选择算参数\n\n\n避免布尔类型参数，使用多态代替。\n\n\n晦涩的意图\n\n\n代码要尽可能具有表达力，明白的意图比高效和性能重要。\n\n\n位置错误的权责\n\n\n“最少惊异原则 ”，把代码放在读者想到的地方，而不是对自己方便的地方。\n\n\n不恰当的静态方法\n\n\n如果要使用静态方法，必须确保 没机会打算让它有多态行为。\n\n\n使用解释性变量\n\n\n把计算过程打散成一系列命名良好的中间值使程序更加可读性。\n\n\n函数名称应该表达其行为\n理解算法\n把逻辑依赖改为物理依赖\n\n\n依赖应该是明显而不应该是假设的依赖。\n\n\n用多态替代If&#x2F;Else或Switch&#x2F;Case\n遵循标准约定\n用命名常量替代魔术数\n准确\n\n\n代码中的含糊和不准确要么是意见不同的结果，要么源于懒散，都必须消除。\n\n\n结构甚于约定\n封装条件\n\n\n把条件封装成方法。\n\n\n避免否定性条件\n\n\n使用肯定性条件。\n\n\n函数只该做一件事\n掩蔽时序耦合\n\n\n创建顺序队列暴露时序耦合，每个函数都产一下函数所需参数，就可保障正确的时序。\n\n\n别随意\n\n\n代码不能随意，需要谨慎考虑。\n\n\n封装边界条件\n\n\n例如 ：+1或-1操作必须封装起来。\n\n\n函数应该只在一个抽象层级上\n\n\n封装不在一个抽象层级上的代码，保持每个函数只在一个抽象层级上。\n\n\n在较高层级放置可配置数据\n\n\n把配置数据和常量放到基类里。\n\n\n避免传递浏览\n\n\n“得墨忒耳律 ”，编写害羞代码，让直接协作者提供所需的服务，而不要逛遍整个系统。\n\n名称\n采用描述性名称\n\n\n名称对应可读性有 90%的作用，必须认真命名。\n\n\n名称应与抽象层级相符\n\n\n不要取沟通实现的名称：取反映类或函数抽象层级的名称。\n\n\n尽可能使用标准命名法\n无歧义的名称\n为较大作用范围选用较长名称\n避免编码\n\n\n不应该在名称中包含类型或范围的信息，例如：m_，f等前缀。\n\n\n名称应该说明副作用\n\n\n名称应该说明类 、变量或函数的所有信息，不应该 隐藏副作用。\n\n测试\n测试不足\n\n\n保证足够的测试。\n\n\n使用覆盖率工具\n\n\n覆盖率工具可以更好地找到测试不足的模块 、类、函数。\n\n\n别略过小测试\n被忽略的测试就是对不确定事物的疑问\n\n\n用 @Ignore 表达我们对需求的疑问。\n\n\n测试边界条件\n\n\n边界判读错误很常见，必须测试边界条件。\n\n\n全面测试相近的缺陷\n\n\n缺陷趋向于扎堆，如果在函数中发现一个缺陷，那么就全面测试这个函数。\n\n\n测试失败的模式有启发性\n\n\n你可以通过测试失败找到问题所在。\n\n\n测试覆盖率的模式有启发性\n\n\n通过测试覆盖率检查，往往可以找 到测试失败的线索。\n\n\n测试应该快速\n\n\n慢测试会导致时间紧时会跳过，导致可能出现问题。\n\n","categories":["Java"],"tags":["Java"]},{"title":"Cordova Plugin 制作与发布流程","url":"/2018/12/21/Buffer/Cordova%20Plugin%20%E5%88%B6%E4%BD%9C%E4%B8%8E%E5%8F%91%E5%B8%83%E6%B5%81%E7%A8%8B/","content":"参考\nhttps://blog.csdn.net/Yoryky/article/details/78516291\nPlugin Development Guide\n\n制作 Cordova Plugin\n创建一个新的插件\n在已有的插件上修改代码并重新打包\n\n创建插件创建一个 Cordova 测试项目 hello 用于测试插件以加法器为例, 命令行创建一个名称为 Adder, id为 joe.adder 的插件, 初始版本为1.0.0：hello&gt; plugman create -name Adder -plugin_id cordova-plugin-adder -plugin_version 1.0.0\n\n用命令行声明这个插件是为Android平台服务的：这个命令会自动生成一个Adder.javacd Adderhello\\Adder&gt; plugman platform add --platform_name android\n\n重写 Adder.java 的 execute 方法@Overridepublic boolean execute(String action, JSONArray args, CallbackContext callbackContext) throws JSONException &#123;    if (action.equals(&quot;performAdd&quot;)) &#123;        int result = args.getInt(0) + args.getInt(1);        callbackContext.success(&quot;result calculated in Java: &quot; + result);        return true;    &#125;    return false;&#125;\n\n修改 Adder.js注入插件 js 函数到 windows 对象:\n修改 Adder.js\nvar exec = require(&#x27;cordova/exec&#x27;);module.exports.add = function(arg0, success, error) &#123;    exec(success, null, &quot;Adder&quot;, &quot;performAdd&quot;, arg0);&#125;;\n\n为插件添加 package.jsonhello\\Adder&gt; plugman createpackagejson &quot;./&quot;\n\n或\nplugman createpackagejson /path/to/your/plugin\n\n将插件添加到混合应用中hello&gt; cordova plugin add AdderInstalling &quot;joe.adder&quot; for androidAndroid Studio project detectedInstalling &quot;joe.adder&quot; for iosSaved plugin info for &quot;joe.adder&quot; to config.xml\n\n测试cordova.plugins.Adder.add([1,2],function(msg)&#123;console.log(msg);&#125;,null);\n\n参考\n\n在已有的插件上修改代码并重新打包\n下载插件源码\n修改需要修改的代码\n若需要修改插件名称则需要修改package.json与plugin.xml中的插件name属性与id属性\n\n\n发布 Plugin发布前版本号修改根据需要修改并补全插件的 package.json 文件注意: version: 每次发布到 NPM 都需要更改\n&#123;  &quot;name&quot;: &quot;cordova-plugin-adder&quot;,  &quot;version&quot;: &quot;1.1.4&quot;,  &quot;description&quot;: &quot;test cordova plugin&quot;, // 插件简介，用于NPM  &quot;cordova&quot;: &#123;    &quot;id&quot;: &quot;cordova-plugin-adder&quot;, // 插件id，同插件名    &quot;platforms&quot;: [      &quot;android&quot;,      &quot;ios&quot;    ]  &#125;,  &quot;keywords&quot;: [ // NPM搜索关键字    &quot;ecosystem:cordova&quot;,    &quot;test&quot;,    &quot;android&quot;,    &quot;add&quot;,    &quot;integer&quot;  ],  &quot;author&quot;: &quot;Joe&quot;,  &quot;license&quot;: &quot;Apache 2.0&quot;,  &quot;repository&quot;: &#123; // 仓库地址    &quot;type&quot;: &quot;git&quot;,    &quot;url&quot;: &quot;git+https://github.com/J0e9u0/cordova-plugin-adder&quot;  &#125;,  &quot;bugs&quot;: &#123; // issue反馈地址    &quot;url&quot;: &quot;https://github.com/J0e9u0/cordova-plugin-adder/issues&quot;  &#125;,  &quot;homepage&quot;: &quot;https://github.com/J0e9u0/cordova-plugin-adder#readme&quot;  // 项目地址&#125;\n\n根据需要修改 plugin.xml 文件plugin.xml 参数说明：\n\nid：插件唯一标识\nversion：版本号\njs-module\nsrc：js中间件相对文件地址（www目录下的那个js）\nname：模块名称\nclobbers&#x2F;merges\ntarget：H5通过它调用js中间件方法（ts调用方法的前缀）\n\n\n\n\nplatform\nname：对应平台android | ios\nsource-file\nsrc：类名\ntartget-dir：插件文件复制到到原生项目位置\nfeature\nname：js中间件通过它调用原生方法（包名）\n\n\nuses-permission：相关原生权限\n\n\n\n\n\n注意: version: 要与 package.json 保持一致\n&lt;?xml version=&#x27;1.0&#x27; encoding=&#x27;utf-8&#x27;?&gt;&lt;plugin id=&quot;cordova-plugin-adder&quot; version=&quot;1.1.8&quot;   xmlns=&quot;http://apache.org/cordova/ns/plugins/1.0&quot;   xmlns:android=&quot;http://schemas.android.com/apk/res/android&quot;&gt;  &lt;name&gt;Adder&lt;/name&gt;  &lt;js-module name=&quot;Adder&quot; src=&quot;www/Adder.js&quot;&gt;    &lt;clobbers target=&quot;cordova.plugins.Adder&quot; /&gt;  &lt;/js-module&gt;  &lt;platform name=&quot;android&quot;&gt;    &lt;config-file parent=&quot;/*&quot; target=&quot;res/xml/config.xml&quot;&gt;      &lt;feature name=&quot;Adder&quot;&gt;        &lt;param name=&quot;android-package&quot; value=&quot;org.apache.cordova.adder.Adder&quot; /&gt;      &lt;/feature&gt;    &lt;/config-file&gt;    &lt;config-file parent=&quot;/*&quot; target=&quot;AndroidManifest.xml&quot;&gt;&lt;/config-file&gt;    &lt;source-file src=&quot;src/android/Adder.java&quot; target-dir=&quot;src/org/apache/cordova/adder&quot; /&gt;  &lt;/platform&gt;&lt;/plugin&gt;\n\n参考\n发布到 NPM注册 NPM 账号本地登录账号npm addusernpm login\n\n上传插件进入插件根目录\nnpm publish+ cordova-plugin-adder@1.1.0\n\n或\nnpm publish /path/to/your/plugin\n\n测试是否发布成功npm i cordova-plugin-adder\n\n或者\ncordova plugin add cordova-plugin-adder\n\n发布到私有 NPM安装 NRM NPM 源切换工具nrm can help you easy and fast switch between different npm registries.\nInstall:\nnpm install -g nrm\n\n添加私有 NPM 源:nrm add &lt;registry&gt; &lt;url&gt;\n\nfor example:\nnrm add mbc http://xx.xx.xx.153:10011/repository/npm-cordova/\n\n查看 NPM 源列表检查是否添加成功:\nnrm ls\n\n切换到私有 NPM 源:nrm use &lt;registry&gt;\n\n添加账号npm addusernpm login\n\n上传插件进入插件根目录(即包含package.json文件的目录)\nnpm publish\n\n或\nnpm publish /path/to/your/plugin","categories":["App"],"tags":["Cordova"]},{"title":"How to search by using Internet","url":"/2018/03/09/Buffer/How-to-search-by-using-Internet/","content":"步骤1. 分析问题比如喜欢看美剧，经常需要在网上寻找资源，但是常常没有那么容易。如果分析下这个问题，会发现喜欢看美剧的人肯定不是少数，那有没有什么观看美剧的软件、论坛、APP、贴吧或者网页呢？这样就将对某部美剧的寻找转化为对美剧平台的寻找，美剧平台往往有丰富的美剧资源。\n2. 将搜索的问题转化为关键词搜索指令\nsite:网址: 可以只搜索某个网站中有关此关键词的信息。比如，百度搜索Apple Xs site:xinhuanet.com\nfiletype:文件格式: 可以只搜索某种文件类型的网页。比如：百度搜索2017年高考全国一卷数学真题 filetype:pdf\nintitle:被限定关键词: 可以只搜索到标题中包含被限定的关键词的信息。比如，百度搜索张宇 intitle:歌手\nintitle:关键词: 搜索结果的标题中必须含有这个关键词\n关键词 A -关键词 B: 不包含特定查询词，祛痘 -推广链接就可以去除广告\n关键词 A + 关键词 B: 表示你搜索结果中，必须同时包含关键词 A 和关键词 B\n\n附录attach: 在用的大数据检索工具\n\n虫部落搜索工具集合：http://search.chongbuluo.com/\nAnywhereAngthing:http://lackar.com/aa/\n大数据导航 http://hao.199it.com/\n果壳任意门：http://www.gkbang.cn/link/\n国外搜索引擎目录：http://www.baimin.com/world/557.htm\n百度指数：https://index.baidu.com/#/\n抖音数据：https://kolranking.com/\n应用检索工具：https://amazing-apps.gitbooks.io/windows-apps-that-amaze-us/content/zh-CN/\n生活信息查询工具：http://www.wncx.cn/\n\n"},{"title":"Docker","url":"/2019/10/27/Buffer/Docker/","content":"Docker — 从入门到实践\nDocker 是一个开源项目，诞生于 2013 年初，最初是 dotCloud 公司内部的一个业余项目。它基于 Google 公司推出的 Go 语言实现。 项目后来加入了 Linux 基金会，遵从了 Apache 2.0 协议，项目代码在 GitHub上进行维护\nDocker 项目的目标是实现轻量级的操作系统虚拟化解决方案。 Docker 的基础是 Linux 容器（LXC）等技术。在 LXC 的基础上 Docker 进行了进一步的封装，让用户不需要去关心容器的管理，使得操作更为简便。用户操作 Docker 的容器就像操作一个快速轻量级的虚拟机一样简单。Docker，它彻底释放了虚拟化的威力，极大降低了云计算资源供应的成本，同时让应用的部署、测试和分发都变得前所未有的高效和轻松！\n\n\n\n\n基础概念Docker 镜像Docker 镜像就是一个只读的模板。\n例如：一个镜像可以包含一个完整的 ubuntu 操作系统环境，里面仅安装了 Apache 或用户需要的其它应用程序。镜像可以用来创建 Docker 容器。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。\nDocker容器Docker 利用容器来运行应用。\n容器是从镜像创建的运行实例。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。\n*注：镜像是只读的，容器在启动的时候创建一层可写层作为最上层。\nDocker 仓库仓库是集中存放镜像文件的场所。有时候会把仓库和仓库注册服务器（Registry）混为一谈，并不严格区分。实际上，仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。仓库分为公开仓库（Public）和私有仓库（Private）两种形式。最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。用户也可以在本地网络内创建一个私有仓库。当用户创建了自己的镜像之后就可以使用 push 命令将它上传到公有或者私有仓库，这样下次在另外一台机器上使用这个镜像时候，只需要从仓库上 pull 下来就可以了。\n*注：Docker 仓库的概念跟 Git 类似，注册服务器可以理解为 GitHub 这样的托管服务。\n\n安装 dockerLinux 安装 dockerDocker 目前只能安装在 64 位平台上，并且要求内核版本不低于 3.10\n检查系统内核版本\n$ uname -aLinux Host 3.16.0-43-generic #58~14.04.1-Ubuntu SMP Mon Jun 22 10:21:20 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux$ cat /proc/versionLinux version 3.16.0-43-generic (buildd@brownie) (gcc version 4.8.2 (Ubuntu 4.8.2-19ubuntu1) ) #58~14.04.1-Ubuntu SMP Mon Jun 22 10:21:20 UTC 2015\n\n添加镜像源gpg密钥\n$ sudo apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D\n\n获取当前操作系统的代号\n$ lsb_release -cCodename:       trusty\n\n添加 Docker 的官方 apt 软件源\nsudo cat &lt;&lt;EOF &gt; /etc/apt/sources.list.d/docker.listdeb https://apt.dockerproject.org/repo ubuntu-trusty mainEOFsudo gedit /etc/apt/sources.list.d/docker.list\n\n更新apt包缓存\nsudo apt-get update\n\n安装Docker\nsudo apt-get install -y docker-engine\n\n或\n先安装curlsudo apt-get install curl再使用脚本自动安装curl -sSL https://get.docker.com/ | sh(若无法访问可使用国内源)阿里云：curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh -DaoCloud：curl -sSL https://get.daocloud.io/docker | sh\n\n镜像获取镜像\nsudo docker pull ubuntu:14:04\n\n运行docker\nsudo docker run –t –i ubuntu:14:04 /bin/bash\n\nWindows 安装 dockerdownload.docker.com\ndocker 命令查看所有的容器\ndocker ps -a\n\n移除这个指定容器\ndocker rm a37e6ca5cdc6\n\n启动容器\ndocker start fa69d210933c-i:以 交互模式启动 交互模式不懂点我 -t:以 附加进程方式启动 附加进程不懂的点我\n\n关闭容器\ndocker stop a37e6ca5cdc6\n\n\n查看端口占用\nnetstat -aon | findstr &#x27;2280&#x27;tasklist | findstr \n","categories":["Ops"],"tags":["Docker"]},{"title":"Daily Knowledge Point","url":"/2019/05/20/Buffer/Daily-Knowledge-Point/","content":"2020-05-19Q: SpringBoot 无法自动织入 mongoTemplate 对象A: 原因为引入的MongoDB版本问题。\n尝试以下两种写法均会出现此问题，固排除写法的原因\n@Repositorypublic class ArticleDaoImpl implements ArticleDao &#123;    @Autowired    private MongoTemplate mongoTemplate;    @Override    public void saveArticle(Article article)  &#123;        mongoTemplate.save(article);    &#125;&#125;\n\n@Componentpublic class ArticleDaoImpl implements ArticleDao &#123;    @Resource    private MongoTemplate mongoTemplate;    @Override    public void saveArticle(Article article)  &#123;        mongoTemplate.save(article);    &#125;&#125;\n\n从GitHub上找同类型demo项目souyunku&#x2F;SpringBootExamples，使用其springboot版本和MongoDB版本成功排除此问题\n原pom.xml文件：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\t&lt;parent&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\t\t&lt;version&gt;2.3.0.RELEASE&lt;/version&gt;\t\t&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\t&lt;/parent&gt;\t&lt;groupId&gt;com.sicmatr1x&lt;/groupId&gt;\t&lt;artifactId&gt;NoteBookServer&lt;/artifactId&gt;\t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\t&lt;name&gt;NoteBookServer&lt;/name&gt;\t&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\t&lt;properties&gt;\t\t&lt;java.version&gt;1.8&lt;/java.version&gt;\t&lt;/properties&gt;\t&lt;dependencies&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-data-mongodb-reactive&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t\t&lt;exclusions&gt;\t\t\t\t&lt;exclusion&gt;\t\t\t\t\t&lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;\t\t\t\t\t&lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;\t\t\t\t&lt;/exclusion&gt;\t\t\t&lt;/exclusions&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;io.projectreactor&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;reactor-test&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t&lt;/dependency&gt;\t\t&lt;!-- https://mvnrepository.com/artifact/org.jsoup/jsoup --&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.jsoup&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;jsoup&lt;/artifactId&gt;\t\t\t&lt;version&gt;1.11.3&lt;/version&gt;\t\t&lt;/dependency&gt;\t\t&lt;!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient --&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;httpclient&lt;/artifactId&gt;\t\t\t&lt;version&gt;4.5.2&lt;/version&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt;\t\t\t&lt;version&gt;1.9.13&lt;/version&gt;\t\t&lt;/dependency&gt;\t&lt;/dependencies&gt;\t&lt;build&gt;\t\t&lt;plugins&gt;\t\t\t&lt;plugin&gt;\t\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t\t&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\t\t\t&lt;/plugin&gt;\t\t&lt;/plugins&gt;\t&lt;/build&gt;&lt;/project&gt;\n\n修改后pom.xml文件：\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;\txsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;\t&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;\t&lt;parent&gt;\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t&lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;\t\t&lt;version&gt;1.5.10.RELEASE&lt;/version&gt;\t\t&lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;\t&lt;/parent&gt;\t&lt;groupId&gt;com.sicmatr1x&lt;/groupId&gt;\t&lt;artifactId&gt;NoteBookServer&lt;/artifactId&gt;\t&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;\t&lt;name&gt;NoteBookServer&lt;/name&gt;\t&lt;description&gt;Demo project for Spring Boot&lt;/description&gt;\t&lt;properties&gt;\t\t&lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;\t\t&lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;\t\t&lt;java.version&gt;1.8&lt;/java.version&gt;\t&lt;/properties&gt;\t&lt;dependencies&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;\t\t\t&lt;scope&gt;test&lt;/scope&gt;\t\t\t&lt;exclusions&gt;\t\t\t\t&lt;exclusion&gt;\t\t\t\t\t&lt;groupId&gt;org.junit.vintage&lt;/groupId&gt;\t\t\t\t\t&lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt;\t\t\t\t&lt;/exclusion&gt;\t\t\t&lt;/exclusions&gt;\t\t&lt;/dependency&gt;&lt;!--\t\t&lt;dependency&gt;--&gt;&lt;!--\t\t\t&lt;groupId&gt;io.projectreactor&lt;/groupId&gt;--&gt;&lt;!--\t\t\t&lt;artifactId&gt;reactor-test&lt;/artifactId&gt;--&gt;&lt;!--\t\t\t&lt;scope&gt;test&lt;/scope&gt;--&gt;&lt;!--\t\t&lt;/dependency&gt;--&gt;\t\t&lt;!-- https://mvnrepository.com/artifact/org.jsoup/jsoup --&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.jsoup&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;jsoup&lt;/artifactId&gt;\t\t\t&lt;version&gt;1.11.3&lt;/version&gt;\t\t&lt;/dependency&gt;\t\t&lt;!-- https://mvnrepository.com/artifact/org.apache.httpcomponents/httpclient --&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;httpclient&lt;/artifactId&gt;\t\t\t&lt;version&gt;4.5.2&lt;/version&gt;\t\t&lt;/dependency&gt;\t\t&lt;dependency&gt;\t\t\t&lt;groupId&gt;org.codehaus.jackson&lt;/groupId&gt;\t\t\t&lt;artifactId&gt;jackson-mapper-asl&lt;/artifactId&gt;\t\t\t&lt;version&gt;1.9.13&lt;/version&gt;\t\t&lt;/dependency&gt;\t&lt;/dependencies&gt;\t&lt;build&gt;\t\t&lt;plugins&gt;\t\t\t&lt;plugin&gt;\t\t\t\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t\t\t\t&lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;\t\t\t&lt;/plugin&gt;\t\t&lt;/plugins&gt;\t&lt;/build&gt;&lt;/project&gt;\n\n2020-05-23Q: Cannot resolve symbol ‘BASE64Encoder’import sun.misc.BASE64Encoder;//...            // 对字节数组Base64编码            BASE64Encoder encoder = new BASE64Encoder();            return encoder.encode(dataByte);//...\n\nError:(74, 13) java: 找不到符号  符号:   类 BASE64Encoder  位置: 类 com.sicmatr1x.spider.translator.Img2Base64Translator\n\nA: sun.misc.BASE64Encoder 不建议使用java.sun自带包中的内容\n在项目中，设计到64位编码的。有时开发会用到JDK中自带的BASE64工具。但sun公司是建议不这样做的。尤其是更新了JDK版本，项目甚至还存在保存的信息。可引用 import org.apache.commons.codec.binary.Base64;进行替换\nimport org.apache.commons.codec.binary.Base64;//...            // 对字节数组Base64编码            Base64 encoder = new Base64();            return encoder.encodeToString(dataByte);//...\n\nQ: SpringBoot抛出WARNING: An illegal reflective access operation has occurredWARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by org.springframework.cglib.core.ReflectUtils$1 (file:/C:/Users/Sicmatr1x/.m2/repository/org/springframework/spring-core/4.3.14.RELEASE/spring-core-4.3.14.RELEASE.jar) to method java.lang.ClassLoader.defineClass(java.lang.String,byte[],int,int,java.security.ProtectionDomain)WARNING: Please consider reporting this to the maintainers of org.springframework.cglib.core.ReflectUtils$1WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future release\n\nA: 该警告是因为jdk版本太高（我用的是10.0，据说9.0的也会这样），具体的原理还没有研究\n解决方案是把项目jdk降低到1.8及以下，建议1.8\n2020-05-25Q: SpringBoot抛出Overriding bean definition for bean &#39;person&#39; with a different definitionMay 25, 2020 5:20:16 PM org.springframework.beans.factory.support.DefaultListableBeanFactory registerBeanDefinitionINFO: Overriding bean definition for bean &#x27;person&#x27; with a different definition: replacing [Root bean: class [null]; scope=; abstract=false; lazyInit=true; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=mainConfig2; factoryMethodName=person; initMethodName=null; destroyMethodName=(inferred); defined in class path resource [com/sicmatr1x/config/MainConfig2.class]] with [Root bean: class [null]; scope=; abstract=false; lazyInit=false; autowireMode=3; dependencyCheck=0; autowireCandidate=true; primary=false; factoryBeanName=mainConfig; factoryMethodName=person; initMethodName=null; destroyMethodName=(inferred); defined in com.sicmatr1x.config.MainConfig]\n\n意思是有一个叫person的bean被重复注入到IOT容器了\nA: 导致的原因是：\n启动的时候用的是MainConfig.class这个配置类\nAnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfig.class);\n\n我在该类中注册了person，然后启用了包扫描\n@Configuration@ComponentScan(value = &quot;com.sicmatr1x&quot;, excludeFilters = &#123;        @Filter(type = FilterType.CUSTOM, classes = &#123;MyTypeFilter.class&#125;)&#125;)public class MainConfig &#123;    @Bean(&quot;person&quot;)    public Person person()&#123;        return new Person(&quot;Abby&quot;, 20);    &#125;&#125;\n\n然后扫描到了另外一个配置类，我在另外的这个配置类里面又注册了person\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.*;@Configurationpublic class MainConfig2 &#123;//    @Scope(&quot;prototype&quot;)    @Lazy    @Bean(&quot;person&quot;)    public Person person()&#123;        return new Person(&quot;Bob&quot;, 30);    &#125;&#125;\n\n2020-05-26Q: @Override is not allowed when implementing interface method\n\nA:\n@Override从jdk1.5开始出现的，是用来标注方法重写的。通常方法重写发生在继承父类，重写父类方法，或者实现接口，实现接口方法。@Override能够保证你正确重写方法，当你重写方法出错时，比如方法名误写，或者漏掉参数，编译器会提示编译错误。  出现以上问题，则跟编译器版本问题有关。编译器1.5只支持@Override注释重写父类方法，不支持实现接口方法。而我的IDE默认使用jdk1.5的编译器。我这个用的是jdk1.7的，我们将language level设置高于jdk1.5版本即可\nFile —&gt; Project Structure —&gt; [ 项目名称 ] —&gt; Language level 修改成 7 - Diamonds,ARM,multi-catch etc.\n或者直接根据idea的提升修改配置即可\n2020-05-27Q: git修改已经提交的用户名A: 如果是已经push到remote仓库的则不能做到完全消除提交记录，只能追加修改提交用户名的commit，之前有几个commit需要修改的就追加几个。如果只是本地commit可以undo commit再重新commit\n\n（n）代表提交次数git rebase -i HEAD~n\n然后按i编辑，把pick 改成 edit，按’Esc’退出编辑，按:wq保存退出\ngit commit --amend --author=&quot;作者 &lt;邮箱@xxxx.com&gt;&quot; --no-edit\ngit rebase --continue\ngit push --force\n\n这种情况只能预防，建议在配置了全局用户名的情况下再为每个project单独配置用户名\ngit全局配置路径：\n\nWindows: C:\\Users\\GUOJO\\.gitconfig\nMac: &#96;&#96;\n\ngit项目配置路径：.git\\config\n配置格式如下：\n[user]\tname = Sicmatr1x\temail = sicmatr1x@outlook.com\n\n有一种方法可以强制重写错误的commit，使用过滤器(git filter-branch)\n警告： 这个操作会破坏你的仓库历史， 如果你和别人在协同开发这个仓库，重写已发布的历史记录是一个不好的操作。建议只在紧急情况操作\ngit filter-branch -f --commit-filter &#x27;        if [ &quot;$GIT_COMMITTER_NAME&quot; = &quot;Sic&quot; ];        then                GIT_COMMITTER_NAME=&quot;Joe Guo&quot;;                GIT_AUTHOR_NAME=&quot;$GIT_COMMITTER_NAME&quot;;                git commit-tree &quot;$@&quot;;        else                git commit-tree &quot;$@&quot;;        fi&#x27; HEAD\n\n修改完之后还需要force push\ngit push --force --tags origin &#x27;refs/heads/*&#x27;\n\n参考：\n\nGit 修改 commit 的作者信息\nChanging author info\ngit如何修改已经提交的用户名?\n\nIDEA查找接口实现类双击选中接口名 + ctrl + alt + B\n2020-05-29Oracle什么时候需要CommitSQL语言分为五大类：\n\nDDL(数据定义语言) - Create、Alter、Drop 这些语句自动提交，无需用Commit提交。\nDQL（数据查询语言）- Select查询语句不存在提交问题。\nDML(数据操纵语言) - Insert、Update、Delete 这些语句需要Commit才能提交。\nDTL(事务控制语言) - Commit、Rollback 事务提交与回滚语句。\nDCL(数据控制语言) - Grant、Revoke 授予权限与回收权限语句。\n\n执行完DML语句，若没有commit再执行DDL语句，也会自动commit未被commit的数据。\nDDL语句在执行前后会自动执行commit，所以你不能使用rollback去回滚它。但是在该语句执行过程中，如果由于某种原因而失败，系统会自动将其回滚，这就是语句级回滚的意思，它属于oracle的隐式回滚，我们不能进行控制。教材上说的DDL语句不能进行回滚，只是不能输入ROLLBACK去回滚DDL语句的结果而已。\n2020-06-02Q: Springboot读取配置文件并初始化到bean失败，无法识别$&#123;person.nickname&#125;作为运行时环境@Value(&quot;$&#123;person.nickname&#125;&quot;)private String nickname;\n\nA: 查了一下发现是@PropertySource注解配错位置了，本来应该配在Configuration类上的结果配到bean上面去了\n@PropertySource(value = &#123;&quot;classpath:/person.properties&quot;&#125;, encoding = &quot;UTF-8&quot;)@Configurationpublic class MainConfigOfPropertyValues &#123;    @Bean    public Person person()&#123;        return new Person();    &#125;&#125;\n\n2020-06-03Q: 如何在git上删除误提交的大文件A: \n首先使用下面查询git中前5名最大的文件:\ngit verify-pack -v .git/objects/pack/pack-*.idx | sort -k 3 -g | tail -5\n\n记下上面的文件id使用下面命令查看对应文件的路径\ngit rev-list --objects --all | grep ed9253b5bbaaa6b0eb04db1dd9840121657b68f3\n\n从当前激活的分支最近30次提交中删除指定文件\ngit filter-branch --force --prune-empty  --tree-filter &#x27;git rm -f --cached --ignore-unmatch 文件路径&#x27; HEAD~30..HEAD\n\n如果出现不能创建新的备份的话，就加上强制覆盖覆盖参数 –force\n如果操作完成后没出现没有改变的情况,如下\nWARNING: Ref ‘refs&#x2F;heads&#x2F;master’ is unchanged\n可以尝试把上面命令中的–tree-filter换成 –index-filter再次运行命令\n操作完成后,查看日志就会发现已经没有提交这个文件的日志记录啦,但是还有一个问题 .git 这个文件夹还是原来的大小，想减小它的大小就要对这个仓库进行分析重新打包,也就是清理垃圾\ngit rm -rf --ignore-unmatch .git/refs/original/git reflog expire --expire=now --allgit fsck --full --unreachablegit repack -A -dgit gc --aggressive --prune=now\n\n最后强制推送到远端\ngit push origin master --force\n\n参考: \n\ngit filter-branch 命令修改删除提示记录,删除误提交的大文件.减小.git的大小\n\n2020-06-17Q: Postman访问自签名证书服务器访问不可信任的证书签发机构签发的证书的服务器时，Chrome浏览器会提示：您与网站之间建立的连接不安全\n你可以在高级选项里面选择继续访问该网站\n但是使用Postman call就会提示：Error: Protocol “https:” not supported. Expected “http:”\nA: Postman Settings -&gt; REQUEST -&gt; SSL certificate verification 关闭该选项\n2020-06-26Q: org.bson.BsonSerializationException: Document size of 44088405 is larger than maximum of 16777216.mongodb中的大小限制, 即单个文档大小不能超过16M. 基于性能的考虑，这个限制无法取消。\nUnderstanding MongoDB BSON Document size limit\n2020-07-10Q: npm install 时 node-sass安装出现问题“D:\\Repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sass\\build\\binding.sln”(默认目标) (1) -&gt;“D:\\Repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sass\\build\\binding.vcxproj.metaproj”(默认目标) (2) -&gt;“D:\\Repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sass\\build\\binding.vcxproj”(默认目标) (4) -&gt;(ClCompile 目标) -&gt;   d:\\repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sass\\src\\create_string.cpp(17): error C2664: “v8::String::Utf8Value::Utf8Value(const v8::String::Utf8Value &amp;)”: 无法将参数 1 从“v8::Local&lt;v8::Value&gt;”转换为“const v8::String::Utf8Value &amp;” [D:\\Repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sass\\build\\binding.vcxproj]gyp ERR! cwd D:\\Repositories\\bilibili\\renren-fast-vue\\node_modules\\node-sassgyp ERR! node -v v12.15.0gyp ERR! node-gyp -v v3.8.0gyp ERR! not ok\n\nA: 老版本的SASS调用到的v8::String::Utf8Value string(value);函数在node12版本的V8引擎里面出现了修改\n解决方案：\n\n降级node版本\n或者升级SASS版本\n\n\nsupport for node.js 12.x #2632\n\n2020-07-13maven install -source 1.5 中不支持 diamond 运算符A: idea File-&gt;Project Struct-&gt;Modules-&gt;Sources-&gt;Language level这里改成&gt;&#x3D;8的级别，如果多次反复maven install之后这个选项还是会弹回6及以下的级别的话就直接pom文件里面强制设置成package时为1.8的\n&lt;build&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;            &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;            &lt;configuration&gt;                &lt;source&gt;1.8&lt;/source&gt;                &lt;target&gt;1.8&lt;/target&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n\nError:(8,14) java: 程序包lombok不存在背景：common的module里面导入了lombok包，然后product的module里依赖了common的module，根据maven的依赖传递性，product应该引入了lombok包这个依赖\ncommon module的pom.xml\n     &lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;     &lt;dependency&gt;         &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;         &lt;artifactId&gt;lombok&lt;/artifactId&gt;         &lt;version&gt;1.18.8&lt;/version&gt;&lt;scope&gt;provided&lt;/scope&gt;     &lt;/dependency&gt;\n\nproduct module的pom.xml\n&lt;dependency&gt;    &lt;groupId&gt;com.sicmatr1x.gulimall&lt;/groupId&gt;    &lt;artifactId&gt;gulimall-common&lt;/artifactId&gt;    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;\n\nA: 在涉及到maven的依赖传递性时，若存在间接依赖的情况时，主工程对间接依赖的jar可以访问吗？这需要看间接依赖的jar包引入时的依赖范围——只有依赖范围为compile时可以访问(若不写scope则默认值为compile)\n所以这里修改pom.xml文件删去&lt;scope&gt;provided&lt;/scope&gt;或者改为&lt;scope&gt;compile&lt;/scope&gt;即可\n&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;    &lt;artifactId&gt;lombok&lt;/artifactId&gt;    &lt;version&gt;1.18.8&lt;/version&gt;&lt;/dependency&gt;\n\n操作完之后记得重新对common module做maven install，重新生成jar文件\nCaused by: java.lang.RuntimeException: Driver com.mysql.jdbc.Driver claims to not accept jdbcUrl, jdbc:mysql:&#x2F;&#x2F;192.168.33.10:3306&#x2F;gulimall_pmsA:  JDBC驱动程序的5.2版本与UTC时区配合使用，必须在连接字符串中明确指定serverTimezone。\nspring:  datasource:    username: root    password: root    url: jdbc:mysql://192.168.33.10:3306/gulimall_pms    driver-class-name: com.mysql.jdbc.Driver\n\n改成\nspring:  datasource:    username: root    password: root    url: jdbc:mysql://192.168.33.10:3306/gulimall_pms?useUnicode=true&amp;characterEncoding=UTF-8&amp;serverTimezone=Asia/Shanghai    driver-class-name: com.mysql.jdbc.Driver\n\n2020-09-20git彻底删除大文件(包括提交历史)步骤一: 从你的资料库中清除文件\n$ git filter-branch --force --index-filter &#x27;git rm --cached --ignore-unmatch path-to-your-remove-file&#x27; --prune-empty --tag-name-filter cat -- --all\n\n如果你要删除的目标不是文件，而是文件夹，那么请在 git rm --cached&#39; 命令后面添加 -r 命令，表示递归的删除（子）文件夹和文件夹下的文件，类似于 rm -rf&#96; 命令。\n例如删除根目录下的2018文件夹里面的全部文件\ngit filter-branch --force --index-filter &#x27;git rm -r --cached --ignore-unmatch 2018&#x27; --prune-empty --tag-name-filter cat -- --all\n\n看到例如以下的提示表示成功了\nRef &#x27;refs/heads/master&#x27; was rewrittenRef &#x27;refs/remotes/origin/master&#x27; was rewritten\n\n步骤二: 推送我们修改后的repo\n$ git push origin master --force --all\n\n这个过程其实是重新上传我们的repo, 比较耗时, 虽然跟删掉重新建一个repo有些类似, 但是好处是保留了原有的更新记录, 所以还是有些不同的. 如果你实在不在意这些更新记录, 也可以删掉重建, 两者也差不太多, 也许后者还更直观些.\n","categories":["杂项"],"tags":["Java"]},{"title":"JavaScript 设计模式","url":"/2019/12/06/Buffer/JavaScript%20%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/","content":"设计原则\n单一职责原则（SRP）：一个对象或方法只做一件事情。如果一个方法承担了过多的职责，那么在需求的变迁过程中，需要改写这个方法的可能性就越大。应该把对象或方法划分成较小的粒度\n\n最少知识原则（LKP）：一个软件实体应当 尽可能少地与其他实体发生相互作用。应当尽量减少对象之间的交互。如果两个对象之间不必彼此直接通信，那么这两个对象就不要发生直接的 相互联系，可以转交给第三方进行处理\n\n开放-封闭原则（OCP）：软件实体（类、模块、函数）等应该是可以 扩展的，但是不可修改。当需要改变一个程序的功能或者给这个程序增加新功能的时候，可以使用增加代码的方式，尽量避免改动程序的源代码，防止影响原系统的稳定\n\n\n设计模式单例模式保证一个类仅有一个实例，并提供一个访问它的全局访问点\nfunction SetManager(name) &#123;    this.manager = name;&#125;SetManager.prototype.getName = function() &#123;    console.log(this.manager);&#125;;var SingletonSetManager = (function() &#123;    var manager = null;    return function(name) &#123;        if (!manager) &#123;            manager = new SetManager(name);        &#125;        return manager;    &#125;&#125;)();SingletonSetManager(&#x27;a&#x27;).getName(); // aSingletonSetManager(&#x27;b&#x27;).getName(); // aSingletonSetManager(&#x27;c&#x27;).getName(); // a\n\n策略模式定义一系列的算法，把它们一个个封装起来，并且使它们可以相互替换。\n将算法的使用和算法的实现分离开来。\n一个基于策略模式的程序至少由两部分组成：\n第一个部分是一组策略类，策略类封装了具体的算法，并负责具体的计算过程。\n第二个部分是环境类Context，Context接受客户的请求，随后把请求委托给某一个策略类。要做到这点，说明Context 中要维持对某个策略对象的引用\n// 加权映射关系var levelMap = &#123;    S: 10,    A: 8,    B: 6,    C: 4&#125;;// 组策略var scoreLevel = &#123;    basicScore: 80,    S: function() &#123;        return this.basicScore + levelMap[&#x27;S&#x27;];     &#125;,    A: function() &#123;        return this.basicScore + levelMap[&#x27;A&#x27;];     &#125;,    B: function() &#123;        return this.basicScore + levelMap[&#x27;B&#x27;];     &#125;,    C: function() &#123;        return this.basicScore + levelMap[&#x27;C&#x27;];     &#125;&#125;// 调用function getScore(level) &#123;    return scoreLevel[level] ? scoreLevel[level]() : 0;&#125;console.log(    getScore(&#x27;S&#x27;),    getScore(&#x27;A&#x27;),    getScore(&#x27;B&#x27;),    getScore(&#x27;C&#x27;),    getScore(&#x27;D&#x27;)); // 90 88 86 84 0\n\n代理模式为一个对象提供一个代用品或占位符，以便控制对它的访问\n当客户不方便直接访问一个 对象或者不满足需要的时候，提供一个替身对象 来控制对这个对象的访问，客户实际上访问的是 替身对象。\n替身对象对请求做出一些处理之后， 再把请求转交给本体对象\n代理和本体的接口具有一致性，本体定义了关键功能，而代理是提供或拒绝对它的访问，或者在访问本体之前做一 些额外的事情\n代理模式主要有三种：保护代理、虚拟代理、缓存代理\n// 主体，发送消息function sendMsg(msg) &#123;    console.log(msg);&#125;// 代理，对消息进行过滤function proxySendMsg(msg) &#123;    // 无消息则直接返回    if (typeof msg === &#x27;undefined&#x27;) &#123;        console.log(&#x27;deny&#x27;);        return;    &#125;        // 有消息则进行过滤    msg = (&#x27;&#x27; + msg).replace(/泥\\s*煤/g, &#x27;&#x27;);    sendMsg(msg);&#125;sendMsg(&#x27;泥煤呀泥 煤呀&#x27;); // 泥煤呀泥 煤呀proxySendMsg(&#x27;泥煤呀泥 煤&#x27;); // 呀proxySendMsg(); // deny\n\n迭代器模式迭代器模式是指提供一种方法顺序访问一个聚合对象中的各个元素，而又不需要暴露该对象的内部表示。\n在使用迭代器模式之后，即使不关心对象的内部构造，也可以按顺序访问其中的每个元素\nfunction each(obj, cb) &#123;    var value;    if (Array.isArray(obj)) &#123;        for (var i = 0; i &lt; obj.length; ++i) &#123;            value = cb.call(obj[i], i, obj[i]);            if (value === false) &#123;                break;            &#125;        &#125;    &#125; else &#123;        for (var i in obj) &#123;            value = cb.call(obj[i], i, obj[i]);            if (value === false) &#123;                break;            &#125;        &#125;    &#125;&#125;each([1, 2, 3], function(index, value) &#123;    console.log(index, value);&#125;);each(&#123;a: 1, b: 2&#125;, function(index, value) &#123;    console.log(index, value);&#125;);// 0 1// 1 2// 2 3// a 1// b 2\n\n发布-订阅模式也称作观察者模式，定义了对象间的一种一对多的依赖关系，当一个对象的状态发 生改变时，所有依赖于它的对象都将得到通知\n取代对象之间硬编码的通知机制，一个对象不用再显式地调用另外一个对象的某个接口。\n与传统的发布-订阅模式实现方式（将订阅者自身当成引用传入发布者）不同，在JS中通常使用注册回调函数的形式来订阅\n// 订阅document.body.addEventListener(&#x27;click&#x27;, function() &#123;    console.log(&#x27;click1&#x27;);&#125;, false);document.body.addEventListener(&#x27;click&#x27;, function() &#123;    console.log(&#x27;click2&#x27;);&#125;, false);// 发布document.body.click(); // click1  click2\n\n命令模式用一种松耦合的方式来设计程序，使得请求发送者和请求接收者能够消除彼此之间的耦合关系\n命令（command）指的是一个执行某些特定事情的指令\n命令中带有execute执行、undo撤销、redo重做等相关命令方法，建议显示地指示这些方法名\n// 自增function IncrementCommand() &#123;    // 当前值    this.val = 0;    // 命令栈    this.stack = [];    // 栈指针位置    this.stackPosition = -1;&#125;;IncrementCommand.prototype = &#123;    constructor: IncrementCommand,    // 执行    execute: function() &#123;        this._clearRedo();                // 定义执行的处理        var command = function() &#123;            this.val += 2;        &#125;.bind(this);                // 执行并缓存起来        command();                this.stack.push(command);        this.stackPosition++;        this.getValue();    &#125;,        canUndo: function() &#123;        return this.stackPosition &gt;= 0;    &#125;,        canRedo: function() &#123;        return this.stackPosition &lt; this.stack.length - 1;    &#125;,    // 撤销    undo: function() &#123;        if (!this.canUndo()) &#123;            return;        &#125;                this.stackPosition--;        // 命令的撤销，与执行的处理相反        var command = function() &#123;            this.val -= 2;        &#125;.bind(this);                // 撤销后不需要缓存        command();        this.getValue();    &#125;,        // 重做    redo: function() &#123;        if (!this.canRedo()) &#123;            return;        &#125;                // 执行栈顶的命令        this.stack[++this.stackPosition]();        this.getValue();    &#125;,        // 在执行时，已经撤销的部分不能再重做    _clearRedo: function() &#123;        this.stack = this.stack.slice(0, this.stackPosition + 1);    &#125;,        // 获取当前值    getValue: function() &#123;        console.log(this.val);    &#125;&#125;;\n\n组合模式是用小的子对象来构建更大的 对象，而这些小的子对象本身也许是由更小 的“孙对象”构成的。\n可以用树形结构来表示这种“部分- 整体”的层次结构。\n调用组合对象 的execute方法，程序会递归调用组合对象 下面的叶对象的execute方法\n但要注意的是，组合模式不是父子关系，它是一种HAS-A（聚合）的关系，将请求委托给它所包含的所有叶对象。基于这种委托，就需要保证组合对象和叶对象拥有相同的接口\n此外，也要保证用一致的方式对待 列表中的每个叶对象，即叶对象属于同一类，不需要过多特殊的额外操作\n模板方法模式模板方法模式由两部分结构组成，第一部分是抽象父类，第二部分是具体的实现子类。\n在抽象父类中封装子类的算法框架，它的 init方法可作为一个算法的模板，指导子类以何种顺序去执行哪些方法。\n由父类分离出公共部分，要求子类重写某些父类的（易变化的）抽象方法\n模板方法模式一般的实现方式为继承\n以运动作为例子，运动有比较通用的一些处理，这部分可以抽离开来，在父类中实现。具体某项运动的特殊性则有自类来重写实现。\n最终子类直接调用父类的模板函数来执行\n","categories":["Design Patterns"],"tags":["JavaScript"]},{"title":"Microservices 微服务学习","url":"/2020/03/23/Buffer/Microservices%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AD%A6%E4%B9%A0/","content":"参考\nMartin Fowler 微服务论文\nMartin Fowler 微服务论文翻译\n\n","categories":["Micro Service"]},{"title":"Hello World","url":"/2019/10/26/Buffer/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\nMarkdown Write ExampleCode Highlightpackage com.sic.moocspringboot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class MoocSpringbootApplication &#123;\tpublic static void main(String[] args) &#123;\t\tSpringApplication.run(MoocSpringbootApplication.class, args);\t&#125;&#125;\n\nhexotheme: hexo-theme-obsidianmarkdown head templatetitle: My awesome titledate: 2019-07-14 18:38:45categories:    - Category1    - Category2tags:     - Tag1    - Tag2mp3: http://domain.com/awesome.mp3cover: statics/A Cruel Angel&#x27;s Thesis Bilingual two-channel effects version.mp3preview: 300\n","categories":["杂项"],"tags":["hexo"]},{"title":"hexo 上使用highlight.js代码高亮","url":"/2018/08/16/Buffer/hexo-%E4%B8%8A%E4%BD%BF%E7%94%A8highlight-js%E4%BB%A3%E7%A0%81%E9%AB%98%E4%BA%AE/","content":"Hexo 自带了在渲染网页时进行代码高亮的功能\n然鹅本站使用的theme: Shen-Yu&#x2F;hexo-theme-ayer本身不含有代码高亮且与hexo默认的代码高亮不兼容，顾使用 highlight.js 来进行代码高亮～\n首先要把 Hexo 和 Material Theme 自带的高亮关掉(。・&#96;ω´・)\n打开根目录下的_config.yml文件：\n# Writinghighlight:  enable: false  line_number: false  auto_detect: false  tab_replace:\n\n然后需要在theme里面引入 highlight.js 的本体和启用初始化方法( つ•̀ω•́)つ\n以Shen-Yu/hexo-theme-ayer为例:\n在\\themes\\ayer\\layout\\_partial\\head.ejs文件的&lt;head&gt;DOM里增加：\n&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@latest/build/styles/vs2015.min.css&quot;&gt;&lt;!- highlight.js -&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@latest/build/highlight.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;  hljs.initHighlightingOnLoad();&lt;/script&gt;\n\n参考\n","categories":["杂项"],"tags":["hexo"]},{"title":"MAC 开发环境配置","url":"/2021/03/07/Buffer/MAC-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","content":"MAC 设置环境变量path的几种方法Mac系统的环境变量，加载顺序为：\n\n&#x2F;etc&#x2F;profile: 系统级别的，系统启动就会加载\n&#x2F;etc&#x2F;paths: 系统级别的，系统启动就会加载(全局建议修改这个文件)\n~&#x2F;.bash_profile: 这级开始往下为当前用户级的环境变量，若其中前面的文件存在则不继续往下读取(用户级建议修改这个文件)\n~&#x2F;.bash_login\n~&#x2F;.profile\n~&#x2F;.bashrc\n\nexport M2_HOME=/Users/sicmatr1x/Documents/Develop/MAVEN/apache-maven-3.5.0export PATH=$PATH:$M2_HOME/bin\n\n意思是在PATH变量后面加多一个目录，这个目录的值来自M2_HOME这个变量\n查看变量值可以使用:\nsicmatr1xMacBook-Pro:~ sicmatr1x$ echo $M2_HOME/Users/sicmatr1x/Documents/Develop/MAVEN/apache-maven-3.5.0\n\nmysqlbrew install mysql\n\nTo connect run:    mysql -urootTo have launchd start mysql now and restart at login:  brew services start mysqlOr, if you don&#x27;t want/need a background service you can just run:  mysql.server start\n\n使用密码登录\nmysql -uroot -p\n\n\n\n执行安全设置\nmysql_secure_installation\n\n登录\nmysql -u root -p\n\ncreate database blog default charset utf8 collate utf8_general_ci;\n","categories":["杂项"],"tags":["Mac","踩坑"]},{"title":"虚拟机相关","url":"/2020/07/08/Buffer/%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9B%B8%E5%85%B3/","content":"使用Vagrant快速创建虚拟机\n官网\n\nvagrant init centos/7\n\nvagrant upvagrant up --provider=vmware_desktop\n\n若提示找不到provider则需要安装对应的utility：\n列如：这里的provider是VMware，参考步骤:\n\n安装Download Vagrant VMWare Utility\n运行vagrant plugin install vagrant-vmware-desktop或vagrant plugin install vagrant-vmware-workstation\n\n如果还是搞不好的话就还是用Vagrant默认支持的VirtualBox吧Download\n如果出现如下下载慢的情况的话可以使用链接手动下载然后导入：\nBringing machine &#x27;default&#x27; up with &#x27;virtualbox&#x27; provider...==&gt; default: Box &#x27;centos/7&#x27; could not be found. Attempting to find and install...    default: Box Provider: virtualbox    default: Box Version: &gt;= 0==&gt; default: Loading metadata for box &#x27;centos/7&#x27;    default: URL: https://vagrantcloud.com/centos/7==&gt; default: Adding box &#x27;centos/7&#x27; (v2004.01) for provider: virtualbox    default: Downloading: https://vagrantcloud.com/centos/boxes/7/versions/2004.01/providers/virtualbox.boxDownload redirected to host: cloud.centos.orgProgress: 0% (Rate: 0/s, Estimated time remaining: 94:22:44)\n\n先查看本地安装的box：\nvagrant box list\n\n再将得到的box文件手动添加进去：\nvagrant box add --name centos/7 D:\\VirtualMachine_centerOS7\\virtualbox.box\n\n添加完之后再run一下命令vagrant up：\n当虚拟机安装完成之后会自动启动，启动完成会出现以下提示：\n==&gt; default: Importing base box &#x27;centos/7&#x27;...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Setting the name of the VM: VirtualMachine_centerOS7_default_1594193913731_41252==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration...    default: Adapter 1: nat==&gt; default: Forwarding ports...    default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes...    default: SSH address: 127.0.0.1:2222    default: SSH username: vagrant    default: SSH auth method: private key    default:    default: Vagrant insecure key detected. Vagrant will automatically replace    default: this with a newly generated keypair for better security.    default:    default: Inserting generated public key within guest...    default: Removing insecure key from the guest if it&#x27;s present...    default: Key inserted! Disconnecting and reconnecting using new SSH key...==&gt; default: Machine booted and ready!==&gt; default: Checking for guest additions in VM...    default: No guest additions were detected on the base box for this VM! Guest    default: additions are required for forwarded ports, shared folders, host only    default: networking, and more. If SSH fails on this machine, please install    default: the guest additions and repackage the box to continue.    default:    default: This is not an error message; everything may continue to work properly,    default: in which case you may ignore this message.==&gt; default: Rsyncing folder: /cygdrive/d/VirtualMachine_centerOS7/ =&gt; /vagrant\n\n使用ssh连接虚拟机：\nvagrant ssh\n\n查看当前用户：whoami\n退出ssh连接：exit;\n端口转发可以直接在VirtualBox设置-&gt;网络-&gt;连接方式：网络地址转换(NAT)-&gt;端口转发 里面设置\n也可通过修改Vagrantfile配置文件来改\n通过修改Vagrantfile配置文件来配置虚拟机IPipconfig以太网适配器 VirtualBox Host-Only Network #2:   连接特定的 DNS 后缀 . . . . . . . :   本地链接 IPv6 地址. . . . . . . . : fe80::8c1a:1f35:e70:a9%25   IPv4 地址 . . . . . . . . . . . . : 192.168.33.1   子网掩码  . . . . . . . . . . . . : 255.255.255.0   默认网关. . . . . . . . . . . . . :\n\nconfig.vm.network &quot;private_network&quot;, ip:&quot;192.168.33.10&quot;vagrant reloadvagrant sship addr3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:f2:b4:fb brd ff:ff:ff:ff:ff:ff    inet 192.168.33.10/24 brd 192.168.33.255 scope global noprefixroute eth1       valid_lft forever preferred_lft forever    inet6 fe80::a00:27ff:fef2:b4fb/64 scope link       valid_lft forever preferred_lft forever\n\n可以看到IP地址已经是192.168.33.10了\nping 192.168.33.10ping 192.168.2.148\n测试一下都可以ping通即可\n配置Docker安装docker engineInstall Docker Engine on CentOS\n按照官方文档配即可，不再赘述\n设置Docker开机自启动[vagrant@localhost ~]$ sudo systemctl enable dockerCreated symlink from /etc/systemd/system/multi-user.target.wants/docker.service to /usr/lib/systemd/system/docker.service.\n\n配置镜像加速登录阿里云，然后访问容器镜像服务-&gt;镜像中心-&gt;镜像加速器\neg: https://sb0h74rp.mirror.aliyuncs.com\nsudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;  &quot;registry-mirrors&quot;: [&quot;https://sb0h74rp.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker\n\nDock安装镜像(mysql)sudo docker pull mysql:5.7sudo docker run -p 3306:3306 --name mysql \\-v /mydata/mysql/log:/var/log/mysql \\-v /mydata/mysql/data:/var/lib/mysql \\-v /mydata/mysql/conf:/var/etc/mysql \\-e MYSQL_ROOT_PASSWORD=root \\-d mysql:5.7sudo docker ps\n\n-p表示端口映射\n-v挂载docker容器内部目录到外部目录\n-d表示后台运行\n进入mysql容器内部\nsudo docker exec -it mysql /bin/bash\n\n配置一下utf8 encoding\nvi /mydata/mysql/conf/my.cnf[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect=&#x27;SET collation_connection = utf8_unicode_ci&#x27;init_connect=&#x27;SET NAMES utf8&#x27;character-set-server=utf8collation-server=utf8_unicode_ciskip-character-set-client-handshakeskip-name-resolve\n\nDock安装镜像(redis)docker pull redismkdir -p /mydata/redis/conftouch /mydata/redis/conf/redis.confdocker run -p 6379:6379 --name redis \\-v /mydata/redis/data:/data \\-v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \\-d redis redis-server /etc/redis/redis.confdocker start c24743e3c322docker rm -f c24743e3c322\n\n-d后面的是启动额外命令，表示以该配置文件启动\n快速调用redis cli工具来运行redis命令docker exec -it redis redis-cli127.0.0.1:6379&gt; set a bOK127.0.0.1:6379&gt; get a&quot;b&quot;\n\ndocker开机自动启动容器sudo docker update redis --restart=alwayssudo docker update mysql --restart=always\n","categories":["Ops"],"tags":["环境搭建"]},{"title":"我是如何使用frp内网穿透来访问局域网web服务的","url":"/2020/06/08/Buffer/%E6%88%91%E6%98%AF%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E6%9D%A5%E8%AE%BF%E9%97%AE%E5%B1%80%E5%9F%9F%E7%BD%91web%E6%9C%8D%E5%8A%A1%E7%9A%84/","content":"想从公网访问家里PC上的web服务，但是运营商又不给公网IP？VPS服务器+frp+web服务器\n背景局域网有一台MAC已经配置了静态IP和DMZ\nIP: 192.168.2.104\n已经启动了一台web服务器，这里使用的是Spring Boot，端口为8090\n提供一个测试用的接口：http://localhost:8090/notebook/version\nfrp简介\nA fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.\n\nFrp是go写的免费开源的内网穿透软件，可以在windows&#x2F;linux&#x2F;mac下运行，:Github链接。其支持 TCP、UDP、HTTP、HTTPS等协议的网络连接，尝试性地支持了点对点穿透。部署时，需要在本地（内网服务器）和公网服务器同时部署，内网是frp客户端、公网是frp服务端，客户端之间通过ssh连接。当用户访问公网frp服务器时，服务器通过ssh连接到内网服务器上的端口，将本地客户端上对应端口的内容转发给用户，即反向代理。\n开始配置前注意frp需要启动服务端与客户端，服务端运行在你位于公网的VPS上，客户端运行在你家的局域网下\n\n服务端对应的配置文件为: frps.ini\n客户端对应的配置文件为: frpc.ini\n\n服务端配置查看系统信息\n# uname -aLinux VM_0_3_centos 3.10.0-1062.9.1.el7.x86_64 #1 SMP Fri Dec 6 15:49:49 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\n\n下载frp对应的包\n# wget https://github.com/fatedier/frp/releases/download/v0.33.0/frp_0.33.0_linux_amd64.tar.gz2020-06-08 09:47:05 (3.53 MB/s) - ‘frp_0.33.0_linux_amd64.tar.gz’ saved [9028588/9028588]\n\n解压缩\nsudo tar -xzvf frp_0.33.0_linux_amd64.tar.gzcd frp_0.33.0_linux_amd64\n\n查看配置文件frps.ini\n# cat frps.ini[common]bind_port = 7000\n\n使用vim修改配置文件frps.ini\n# sudo vim frps.ini[common]bind_port = 7000token = passwordvhost_http_port = 8090\n\n按i进入insert模式，然后增加修改成如上，按ESC退出insert模式，然后输入:进入命令模式，wq保持并退出\n启动服务端\n# ./frps -c ./frps.ini2020/06/08 10:16:18 [I] [service.go:178] frps tcp listen on 0.0.0.0:70002020/06/08 10:16:18 [I] [service.go:220] http service listen on 0.0.0.0:80902020/06/08 10:16:18 [I] [root.go:209] start frps success\n\n启动frp服务器并后台运行,启动完成后可通过lsof -i :7000查看端口占用情况\nnohup ./frps -c ./frps.ini &amp;\n\n需要重启的话可以先：\n# lsof -i :7000COMMAND  PID USER   FD   TYPE    DEVICE SIZE/OFF NODE NAMEfrps    1817 root    3u  IPv6  16887360      0t0  TCP *:afs3-fileserver (LISTEN)# kill 1817# nohup ./frps -c ./frps.ini &amp;\n\n客户端配置查看系统信息\n# uname -aDarwin sicmatr1xMacBook-Pro.local 19.4.0 Darwin Kernel Version 19.4.0: Wed Mar  4 22:28:40 PST 2020; root:xnu-6153.101.6~15/RELEASE_X86_64 x86_64\n\n下载frp对应的包: https://github.com/fatedier/frp/releases/download/v0.33.0/frp_0.33.0_darwin_amd64.tar.gz\n解压缩并修改配置文件frpc.ini\n[common]server_addr = 45.**.**.**9server_port = 7000token = password[web]#配置类型为tcp协议type = http#内网需要监听的端口,即本地运行的服务所使用的端口local_port = 8090#公网服务器的IP或者已解析的域名custom_domains=45.**.**.**9\n\n实际上这里要是还想开放4000端口可以不需要修改服务器文件只用在frpc.ini里增加如下的test_tcp部分就行\n[common]server_addr = 45.**.**.**9server_port = 7000token = password[web]#配置类型为tcp协议type = http#内网需要监听的端口,即本地运行的服务所使用的端口local_port = 8090#公网服务器的IP或者已解析的域名custom_domains=45.**.**.**9[test_tcp]type = tcplocal_ip = 127.0.0.1local_port = 4000remote_port = 4000\n\ncd /Users/sicmatr1x/Develop/frp_0.33.0_darwin_amd64./frpc -c ./frpc.ini\n\n连接成功的话服务端会提示\n2020/06/08 10:16:20 [I] [service.go:432] [97bed4f24fba649a] client login info: ip [119.**.**.**:26698] version [0.33.0] hostname [] os [darwin] arch [amd64]\n\n","categories":["Network"],"tags":["踩坑","内网穿透","frp"]},{"title":"BIP39助记词库","url":"/2022/02/26/Crypto/BIP39/","content":"现在加密钱包最常用的协议是BIP39，然后给你生成12个助记词害怕你记不住，然后如果英文不好，反复核对麻烦到不行，其实这英文单词都来自一个单词库，单词库里有2048个单词，2048个单词对应着多个国家的单词体系。\n\nBIP39词库总览: https://github.com/bitcoin/bips/blob/master/bip-0039/bip-0039-wordlists.md\n\n英文助记词库: \nabandonabilityableaboutaboveabsentabsorbabstractabsurdabuseaccessaccidentaccountaccuseachieveacidacousticacquireacrossactactionactoractressactualadaptaddaddictaddressadjustadmitadultadvanceadviceaerobicaffairaffordafraidagainageagentagreeaheadaimairairportaislealarmalbumalcoholalertalienallalleyallowalmostalonealphaalreadyalsoalteralwaysamateuramazingamongamountamusedanalystanchorancientangerangleangryanimalankleannounceannualanotheranswerantennaantiqueanxietyanyapartapologyappearappleapproveaprilarcharcticareaarenaarguearmarmedarmorarmyaroundarrangearrestarrivearrowartartefactartistartworkaskaspectassaultassetassistassumeasthmaathleteatomattackattendattitudeattractauctionauditaugustauntauthorautoautumnaverageavocadoavoidawakeawareawayawesomeawfulawkwardaxisbabybachelorbaconbadgebagbalancebalconyballbamboobananabannerbarbarelybargainbarrelbasebasicbasketbattlebeachbeanbeautybecausebecomebeefbeforebeginbehavebehindbelievebelowbeltbenchbenefitbestbetraybetterbetweenbeyondbicyclebidbikebindbiologybirdbirthbitterblackbladeblameblanketblastbleakblessblindbloodblossomblouseblueblurblushboardboatbodyboilbombbonebonusbookboostborderboringborrowbossbottombounceboxboybracketbrainbrandbrassbravebreadbreezebrickbridgebriefbrightbringbriskbroccolibrokenbronzebroombrotherbrownbrushbubblebuddybudgetbuffalobuildbulbbulkbulletbundlebunkerburdenburgerburstbusbusinessbusybutterbuyerbuzzcabbagecabincablecactuscagecakecallcalmcameracampcancanalcancelcandycannoncanoecanvascanyoncapablecapitalcaptaincarcarboncardcargocarpetcarrycartcasecashcasinocastlecasualcatcatalogcatchcategorycattlecaughtcausecautioncaveceilingcelerycementcensuscenturycerealcertainchairchalkchampionchangechaoschapterchargechasechatcheapcheckcheesechefcherrychestchickenchiefchildchimneychoicechoosechronicchucklechunkchurncigarcinnamoncirclecitizencitycivilclaimclapclarifyclawclaycleanclerkcleverclickclientcliffclimbclinicclipclockclogcloseclothcloudclownclubclumpclusterclutchcoachcoastcoconutcodecoffeecoilcoincollectcolorcolumncombinecomecomfortcomiccommoncompanyconcertconductconfirmcongressconnectconsidercontrolconvincecookcoolcoppercopycoralcorecorncorrectcostcottoncouchcountrycouplecoursecousincovercoyotecrackcradlecraftcramcranecrashcratercrawlcrazycreamcreditcreekcrewcricketcrimecrispcriticcropcrosscrouchcrowdcrucialcruelcruisecrumblecrunchcrushcrycrystalcubeculturecupcupboardcuriouscurrentcurtaincurvecushioncustomcutecycledaddamagedampdancedangerdaringdashdaughterdawndaydealdebatedebrisdecadedecemberdecidedeclinedecoratedecreasedeerdefensedefinedefydegreedelaydeliverdemanddemisedenialdentistdenydepartdependdepositdepthdeputyderivedescribedesertdesigndeskdespairdestroydetaildetectdevelopdevicedevotediagramdialdiamonddiarydicedieseldietdifferdigitaldignitydilemmadinnerdinosaurdirectdirtdisagreediscoverdiseasedishdismissdisorderdisplaydistancedivertdividedivorcedizzydoctordocumentdogdolldolphindomaindonatedonkeydonordoordosedoubledovedraftdragondramadrasticdrawdreamdressdriftdrilldrinkdripdrivedropdrumdryduckdumbduneduringdustdutchdutydwarfdynamiceagereagleearlyearneartheasilyeasteasyechoecologyeconomyedgeediteducateefforteggeighteitherelbowelderelectricelegantelementelephantelevatoreliteelseembarkembodyembraceemergeemotionemployempoweremptyenableenactendendlessendorseenemyenergyenforceengageengineenhanceenjoyenlistenoughenrichenrollensureenterentireentryenvelopeepisodeequalequiperaeraseerodeerosionerroreruptescapeessayessenceestateeternalethicsevidenceevilevokeevolveexactexampleexcessexchangeexciteexcludeexcuseexecuteexerciseexhaustexhibitexileexistexitexoticexpandexpectexpireexplainexposeexpressextendextraeyeeyebrowfabricfacefacultyfadefaintfaithfallfalsefamefamilyfamousfanfancyfantasyfarmfashionfatfatalfatherfatiguefaultfavoritefeaturefebruaryfederalfeefeedfeelfemalefencefestivalfetchfeverfewfiberfictionfieldfigurefilefilmfilterfinalfindfinefingerfinishfirefirmfirstfiscalfishfitfitnessfixflagflameflashflatflavorfleeflightflipfloatflockfloorflowerfluidflushflyfoamfocusfogfoilfoldfollowfoodfootforceforestforgetforkfortuneforumforwardfossilfosterfoundfoxfragileframefrequentfreshfriendfringefrogfrontfrostfrownfrozenfruitfuelfunfunnyfurnacefuryfuturegadgetgaingalaxygallerygamegapgaragegarbagegardengarlicgarmentgasgaspgategathergaugegazegeneralgeniusgenregentlegenuinegestureghostgiantgiftgigglegingergiraffegirlgivegladglanceglareglassglideglimpseglobegloomglorygloveglowgluegoatgoddessgoldgoodgoosegorillagospelgossipgoverngowngrabgracegraingrantgrapegrassgravitygreatgreengridgriefgritgrocerygroupgrowgruntguardguessguideguiltguitargungymhabithairhalfhammerhamsterhandhappyharborhardharshharvesthathavehawkhazardheadhealthheartheavyhedgehogheighthellohelmethelphenherohiddenhighhillhinthiphirehistoryhobbyhockeyholdholeholidayhollowhomehoneyhoodhopehornhorrorhorsehospitalhosthotelhourhoverhubhugehumanhumblehumorhundredhungryhunthurdlehurryhurthusbandhybridiceiconideaidentifyidleignoreillillegalillnessimageimitateimmenseimmuneimpactimposeimproveimpulseinchincludeincomeincreaseindexindicateindoorindustryinfantinflictinforminhaleinheritinitialinjectinjuryinmateinnerinnocentinputinquiryinsaneinsectinsideinspireinstallintactinterestintoinvestinviteinvolveironislandisolateissueitemivoryjacketjaguarjarjazzjealousjeansjellyjeweljobjoinjokejourneyjoyjudgejuicejumpjunglejuniorjunkjustkangarookeenkeepketchupkeykickkidkidneykindkingdomkisskitkitchenkitekittenkiwikneeknifeknockknowlablabellaborladderladylakelamplanguagelaptoplargelaterlatinlaughlaundrylavalawlawnlawsuitlayerlazyleaderleaflearnleavelectureleftleglegallegendleisurelemonlendlengthlensleopardlessonletterlevelliarlibertylibrarylicenselifeliftlightlikelimblimitlinklionliquidlistlittlelivelizardloadloanlobsterlocallocklogiclonelylonglooplotteryloudloungeloveloyalluckyluggagelumberlunarlunchluxurylyricsmachinemadmagicmagnetmaidmailmainmajormakemammalmanmanagemandatemangomansionmanualmaplemarblemarchmarginmarinemarketmarriagemaskmassmastermatchmaterialmathmatrixmattermaximummazemeadowmeanmeasuremeatmechanicmedalmediamelodymeltmembermemorymentionmenumercymergemeritmerrymeshmessagemetalmethodmiddlemidnightmilkmillionmimicmindminimumminorminutemiraclemirrormiserymissmistakemixmixedmixturemobilemodelmodifymommomentmonitormonkeymonstermonthmoonmoralmoremorningmosquitomothermotionmotormountainmousemovemoviemuchmuffinmulemultiplymusclemuseummushroommusicmustmutualmyselfmysterymythnaivenamenapkinnarrownastynationnaturenearneckneednegativeneglectneithernephewnervenestnetnetworkneutralnevernewsnextnicenightnoblenoisenomineenoodlenormalnorthnosenotablenotenothingnoticenovelnownuclearnumbernursenutoakobeyobjectobligeobscureobserveobtainobviousoccuroceanoctoberodoroffofferofficeoftenoilokayoldoliveolympicomitonceoneoniononlineonlyopenoperaopinionopposeoptionorangeorbitorchardorderordinaryorganorientoriginalorphanostrichotheroutdoorouteroutputoutsideovalovenoverownowneroxygenoysterozonepactpaddlepagepairpalacepalmpandapanelpanicpantherpaperparadeparentparkparrotpartypasspatchpathpatientpatrolpatternpausepavepaymentpeacepeanutpearpeasantpelicanpenpenaltypencilpeoplepepperperfectpermitpersonpetphonephotophrasephysicalpianopicnicpicturepiecepigpigeonpillpilotpinkpioneerpipepistolpitchpizzaplaceplanetplasticplateplaypleasepledgepluckplugplungepoempoetpointpolarpolepolicepondponypoolpopularportionpositionpossiblepostpotatopotterypovertypowderpowerpracticepraisepredictpreferpreparepresentprettypreventpriceprideprimaryprintpriorityprisonprivateprizeproblemprocessproduceprofitprogramprojectpromoteproofpropertyprosperprotectproudprovidepublicpuddingpullpulppulsepumpkinpunchpupilpuppypurchasepuritypurposepursepushputpuzzlepyramidqualityquantumquarterquestionquickquitquizquoterabbitraccoonracerackradarradiorailrainraiserallyrampranchrandomrangerapidrarerateratherravenrawrazorreadyrealreasonrebelrebuildrecallreceivereciperecordrecyclereducereflectreformrefuseregionregretregularrejectrelaxreleasereliefrelyremainrememberremindremoverenderrenewrentreopenrepairrepeatreplacereportrequirerescueresembleresistresourceresponseresultretireretreatreturnreunionrevealreviewrewardrhythmribribbonricerichrideridgeriflerightrigidringriotrippleriskritualrivalriverroadroastrobotrobustrocketromanceroofrookieroomroserotateroughroundrouteroyalrubberruderugrulerunrunwayruralsadsaddlesadnesssafesailsaladsalmonsalonsaltsalutesamesamplesandsatisfysatoshisaucesausagesavesayscalescanscarescattersceneschemeschoolsciencescissorsscorpionscoutscrapscreenscriptscrubseasearchseasonseatsecondsecretsectionsecurityseedseeksegmentselectsellseminarseniorsensesentenceseriesservicesessionsettlesetupsevenshadowshaftshallowshareshedshellsheriffshieldshiftshineshipshivershockshoeshootshopshortshouldershoveshrimpshrugshuffleshysiblingsicksidesiegesightsignsilentsilksillysilversimilarsimplesincesingsirensistersituatesixsizeskatesketchskiskillskinskirtskullslabslamsleepslendersliceslideslightslimsloganslotslowslushsmallsmartsmilesmokesmoothsnacksnakesnapsniffsnowsoapsoccersocialsocksodasoftsolarsoldiersolidsolutionsolvesomeonesongsoonsorrysortsoulsoundsoupsourcesouthspacesparespatialspawnspeakspecialspeedspellspendspherespicespiderspikespinspiritsplitspoilsponsorspoonsportspotsprayspreadspringspysquaresqueezesquirrelstablestadiumstaffstagestairsstampstandstartstatestaysteaksteelstemstepstereostickstillstingstockstomachstonestoolstorystovestrategystreetstrikestrongstrugglestudentstuffstumblestylesubjectsubmitsubwaysuccesssuchsuddensuffersugarsuggestsuitsummersunsunnysunsetsupersupplysupremesuresurfacesurgesurprisesurroundsurveysuspectsustainswallowswampswapswarmswearsweetswiftswimswingswitchswordsymbolsymptomsyrupsystemtabletackletagtailtalenttalktanktapetargettasktastetattootaxiteachteamtelltentenanttennistenttermtesttextthankthatthemethentheorytheretheythingthisthoughtthreethrivethrowthumbthundertickettidetigertilttimbertimetinytiptiredtissuetitletoasttobaccotodaytoddlertoetogethertoilettokentomatotomorrowtonetonguetonighttooltoothtoptopictoppletorchtornadotortoisetosstotaltouristtowardtowertowntoytracktradetraffictragictraintransfertraptrashtraveltraytreattreetrendtrialtribetricktriggertrimtriptrophytroubletrucktruetrulytrumpettrusttruthtrytubetuitiontumbletunatunnelturkeyturnturtletwelvetwentytwicetwintwisttwotypetypicaluglyumbrellaunableunawareuncleuncoverunderundounfairunfoldunhappyuniformuniqueunituniverseunknownunlockuntilunusualunveilupdateupgradeupholduponupperupseturbanurgeusageuseusedusefuluselessusualutilityvacantvacuumvaguevalidvalleyvalvevanvanishvaporvariousvastvaultvehiclevelvetvendorventurevenueverbverifyversionveryvesselveteranviablevibrantviciousvictoryvideoviewvillagevintageviolinvirtualvirusvisavisitvisualvitalvividvocalvoicevoidvolcanovolumevotevoyagewagewagonwaitwalkwallwalnutwantwarfarewarmwarriorwashwaspwastewaterwavewaywealthweaponwearweaselweatherwebweddingweekendweirdwelcomewestwetwhalewhatwheatwheelwhenwherewhipwhisperwidewidthwifewildwillwinwindowwinewingwinkwinnerwinterwirewisdomwisewishwitnesswolfwomanwonderwoodwoolwordworkworldworryworthwrapwreckwrestlewristwritewrongyardyearyellowyouyoungyouthzebrazerozonezoo\n","categories":["Crypto"],"tags":["Bitcoin"]},{"title":"Bitcoin","url":"/2019/09/13/Crypto/Bitcoin/","content":"比特币是一种运用 SHA-256 算法、链式加密结构、点对点（P2P）形式的数字货币，它利用 P2P 网络中众多节点构成的分布式数据库来确认并记录所有的交易行为。\n采用非对称曲线加密算法和哈希算法两种\nUTXO比特币在基于UTXO的结构中存储有关用户余额的数据：系统的整个状态就是一组UTXO的集合，每个UTXO都有一个所有者和一个面值（就像不同的硬币），而交易会花费若干个输入的UTXO，并根据规则创建若干个新的UTXO：\n每个引用的输入必须有效且尚未花费；对于一个交易，必须包含有与每个输入的所有者匹配的签名；总输入必须大于等于总输出值所以，系统中用户的余额（balance)是用户具有私钥的UTXO的总值\n所以系统中用户的余额(Balance)是用户具有私钥的UTXO的总值\n比特币UTXO模式优点：\n\n更高程度的隐私：如果用户为他们收到的每笔交易使用新地址，那么通常很难将帐户相互链接。这很大程度上适用于货币，但不太适用于任意dapps，因为dapps通常涉及跟踪和用户绑定的复杂状态，可能不存在像货币那样简单的用户状态划分方案。\n潜在的可扩展性：UTXO在理论上更符合可扩展性要求。因为我们只需要依赖拥有UTXO的那些人去维护基于Merkle树的所有权证明就够了，即使包括所有者在内的每个人都决定忘记该数据，那么也只有所有者受到对应UTXO的损失，不影响接下来的交易。而在帐户模式中，如果每个人都丢失了与帐户相对应的Merkle树的部分，那将会使得和该帐户有关的消息完全无法处理，包括发币给它。\n\n以太坊账户模式优点：\n\n可以节省大量空间：不将UTXOs分开存储，而是合为一个账户；每个交易只需要一个输入、一个签名并产生一个输出。\n更好的可替代性：货币本质上都是同质化、可替代的；UTXO的设计使得货币从来源分成了“可花费”和“不可花费”两类，这在实际应用中很难有对应的模型。\n更加简单：更容易编码和理解，特别是设计复杂脚本的时候。UTXO在脚本逻辑复杂时更令人费解。\n便于维护持久轻节点：只要沿着特定方向扫描状态树，轻节点可以很容易地随时访问账户相关的所有数据。而UTXO的每个交易都会使得状态引用发生改变，这对轻节点来说长时间运行Dapp会有很大压力。\n\n","categories":["Crypto"],"tags":["Bitcoin"]},{"title":"EIP-20: ERC-20 Token Standard","url":"/2020/09/16/Crypto/EIP-20-ERC-20-Token-Standard/","content":"EIP-20: ERC-20 Token StandardSimple SummaryA standard interface for tokens.\nAbstractThe following standard allows for the implementation of a standard API for tokens within smart contracts. This standard provides basic functionality to transfer tokens, as well as allow tokens to be approved so they can be spent by another on-chain third party.\nMotivationA standard interface allows any tokens on Ethereum to be re-used by other applications: from wallets to decentralized exchanges.\nSpecificationTokenMethodsNOTES:\n\nThe following specifications use syntax from Solidity 0.4.17 (or above)\nCallers MUST handle false from returns (bool success). Callers MUST NOT assume that false is never returned!\n\nnameReturns the name of the token - e.g. “MyToken”.\nOPTIONAL - This method can be used to improve usability, but interfaces and other contracts MUST NOT expect these values to be present.\nfunction name() public view returns (string)\n\nsymbolReturns the symbol of the token. E.g. “HIX”.\nOPTIONAL - This method can be used to improve usability, but interfaces and other contracts MUST NOT expect these values to be present.\nfunction symbol() public view returns (string)\n\ndecimalsReturns the number of decimals the token uses - e.g. 8, means to divide the token amount by 100000000 to get its user representation.\nOPTIONAL - This method can be used to improve usability, but interfaces and other contracts MUST NOT expect these values to be present.\nfunction decimals() public view returns (uint8)\n\ntotalSupply\nReturns the total token supply.\nfunction totalSupply() public view returns (uint256)\n\nbalanceOf\nReturns the account balance of another account with address _owner.\nfunction balanceOf(address _owner) public view returns (uint256 balance)\n\ntransfer\nTransfers _value amount of tokens to address _to, and MUST fire the Transfer event. The function SHOULD throw if the message caller’s account balance does not have enough tokens to spend.\nNote Transfers of 0 values MUST be treated as normal transfers and fire the Transfer event.\nfunction transfer(address _to, uint256 _value) public returns (bool success)\n\ntransferFrom\nTransfers _value amount of tokens from address _from to address _to, and MUST fire the Transfer event.\nThe transferFrom method is used for a withdraw workflow, allowing contracts to transfer tokens on your behalf. This can be used for example to allow a contract to transfer tokens on your behalf and&#x2F;or to charge fees in sub-currencies. The function SHOULD throw unless the _from account has deliberately authorized the sender of the message via some mechanism.\nNote Transfers of 0 values MUST be treated as normal transfers and fire the Transfer event.\nfunction transferFrom(address _from, address _to, uint256 _value) public returns (bool success)\n\napprove\nAllows _spender to withdraw from your account multiple times, up to the _value amount. If this function is called again it overwrites the current allowance with _value.\nNOTE: To prevent attack vectors like the one described here and discussed here, clients SHOULD make sure to create user interfaces in such a way that they set the allowance first to 0 before setting it to another value for the same spender. THOUGH The contract itself shouldn’t enforce it, to allow backwards compatibility with contracts deployed before\nfunction approve(address _spender, uint256 _value) public returns (bool success)\n\nallowance\nReturns the amount which _spender is still allowed to withdraw from _owner.\nfunction allowance(address _owner, address _spender) public view returns (uint256 remaining)\n\nEventsTransfer\nMUST trigger when tokens are transferred, including zero value transfers.\nA token contract which creates new tokens SHOULD trigger a Transfer event with the _from address set to 0x0 when tokens are created.\nevent Transfer(address indexed _from, address indexed _to, uint256 _value)\n\nApproval\nMUST trigger on any successful call to approve(address _spender, uint256 _value).\nevent Approval(address indexed _owner, address indexed _spender, uint256 _value)\n\nImplementationThere are already plenty of ERC20-compliant tokens deployed on the Ethereum network. Different implementations have been written by various teams that have different trade-offs: from gas saving to improved security.\nExample implementations are available at\n\nOpenZeppelin implementation\nConsenSys implementation\n\nHistoryHistorical links related to this standard:\n\nOriginal proposal from Vitalik Buterin: https://github.com/ethereum/wiki/wiki/Standardized_Contract_APIs/499c882f3ec123537fc2fccd57eaa29e6032fe4a\nReddit discussion: https://www.reddit.com/r/ethereum/comments/3n8fkn/lets_talk_about_the_coin_standard/\nOriginal Issue #20: https://github.com/ethereum/EIPs/issues/20\n\nCopyrightCopyright and related rights waived via CC0.\nCitationPlease cite this document as:\nFabian Vogelsteller, Vitalik Buterin, “EIP-20: ERC-20 Token Standard,” Ethereum Improvement Proposals, no. 20, November 2015. [Online serial]. Available: https://eips.ethereum.org/EIPS/eip-20.\n","categories":["Crypto"],"tags":["Ethereum","SmartContract"]},{"title":"ETH Solidity智能合约入门","url":"/2020/09/05/Crypto/ETH-Solidity%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E5%85%A5%E9%97%A8/","content":"Solidity 是一门面向合约的、为实现智能合约而创建的高级编程语言。这门语言受到了 C++，Python 和 Javascript 语言的影响，设计的目的是能在以太坊虚拟机（EVM）上运行。\nSolidity 是静态类型语言，支持继承、库和复杂的用户定义类型等特性。\n目前尝试 Solidity 编程的最好的方式是使用 Remix （需要时间加载，请耐心等待）。Remix 是一个基于 Web 浏览器的 IDE，它可以让你编写 Solidity 智能合约，然后部署并运行该智能合约。\nSolidity Doc: https://solidity-cn.readthedocs.io/zh/develop/\nSolidity源码和智能合约Solidity源代码要成为可以运行在以太坊上的智能合约需要经历如下的步骤：\n\n用Solidity编写的智能合约源代码需要先使用编译器编译为字节码（Bytecode)，编译过程中会同时产生智能合约的二进制接口规范（Application Binary Interface，简称为ABl）；\n通过交易（Transaction)的方式将字节码部署到以太坊网络，每次成功部署都会产生一个新的智能合约账户；\n使用Javascript编写的DApp通常通过web3.js+ABI去调用智能合约中的函数来实现数据的读取和修改。\n\n\n\n安装Solidity编译器RemixRemix 可在线使用，而无需安装任何东西。如果你想离线使用，可按 https://github.com/ethereum/browser-solidity/tree/gh-pages 的页面说明下载 zip 文件来使用。 该页面有进一步详细说明如何安装 Solidity 命令行编译器到你计算机上。如果你刚好要处理大型合约，或者需要更多的编译选项，那么你应该选择使用命令行编译器 solc。\nsolcjssolc是Solidity源码库的构建目标之一，它是Solidity的命令行编译器\n使用npm可以便捷地安装Solidity编译器solcjs\nnpm install -g solc\n\n根据例子学习Solidity创建水龙头合约打开remix在线开发环境：\n选择new file创建Fucet.sol文件\n\n\n输入代码\n编译合约：\n选择solidity compiler tab，点击compile Faucet.sol按钮编译代码为字节码文件\n\n\n编译完成后solidity compiler tab上面的旋转箭头会变成一个成功的绿色小勾\n发布合约：\n需要浏览器安装MetaMask插件并登录ETH钱包\n\n\n这里选择Ropsten测试环境\n选择Deploy &amp; Run Transactions tab，Environment选择Injected Web3，当你选择成功之后metamask会自动提示是否授权网页访问metamask钱包，选择同意你的钱包地址就会出现在Account下面的选项卡里，如选图所示：\n\n\n点击deploy，metamask会弹出是否支付一定的gas来创建合约，点确定，等一下，等待时间取决于你的网络状况\n如果deploy成功会这个tab里出现如上图所示的Deployed Contracts一栏且内容为部署成功之后的合约的地址\n本例中为：0x3280EB0E28d1715C6fBfFb18952fB4D8A548B93d\n使用Etherscan查询deploy合约的transaction：https://ropsten.etherscan.io/tx/0x1b0a4f6223a539870cc216c98d70742fc550879648ae2235bbc77cf222f24ba7\n\n\n使用Etherscan查询deploy合约的地址：https://ropsten.etherscan.io/address/0x3280eb0e28d1715c6fbffb18952fb4d8a548b93d\n\n\n这个案例合约的作用是任何人可以提供一个amount参数然后该合约会给你发对应的币，但是当前合约里面没有ETH。所以需要添加一个接受ETH币的函数。重新deploy不是在旧的合约上面修改而是部署一个新的合约，因为合约一旦部署到区块链上就无法修改了。\npragma solidity ^0.4.17;引入solidity的版本，^表示高于0.4.17但小于0.5这个大版本，&gt;表示大于当前版本\npragma solidity ^0.4.17;contract Fucet &#123;    function withdraw(uint amount) public &#123;        require(amount &lt;= 100000000000000000);        msg.sender.transfer(amount); // wei    &#125;            function () public payable &#123;            &#125;&#125;\n\n重新deploy，使用Etherscan查询deploy合约的地址：https://ropsten.etherscan.io/address/0x7124eA18277f9a7764848470733F1aD98aFF9154\n\n\n使用metamask发送1个ETH到新的合约地址：https://ropsten.etherscan.io/tx/0xff2c7d0568ab8b994ef1e0feeb779b2be19367186ba2a0e23c1014915dd5fe38\n\n\n可以看到发送成功之后新的合约上的交易就从1个变成2个了，第一个transaction是合约创建的transaction，第二个是我们转了1个ETH到这个合约的transaction\n\n\n好了终于可以测试水龙头的代码了：我们输入100000000000000000到amount参数框里，尝试从水龙头获取0.1个ETH\n\n\n交易成功，看下transaction详情：\n\n\n再看下水龙头合约的transaction记录：\n\n\n注意：这里第三个transaction的value怎么是0，我们不是从合约得到了0.1个ETH吗，合约不是把ETH直接从一个账户转到另外一个账户而是走内部交易\n\n\n那么我们的测试钱包是否也有一个对应的内部交易呢？是的\n\n\n到这里就宣布水龙头合约大功告成啦！！！\n简单数据存储合约pragma solidity &gt;0.4.22;contract SimpleStorage &#123;    uint myData;    function setData(uint newData) public &#123;        myData = newData;    &#125;    // view表明该function只读取数据不修改数据    function getData() public view returns(uint) &#123;        return myData;    &#125;&#125;\n\n\nDeploy success at: 0x3280eb0e28d1715c6fbffb18952fb4d8a548b93d\nEtherscan: https://rinkeby.etherscan.io/address/0x3280eb0e28d1715c6fbffb18952fb4d8a548b93d\n\n与合约交互测试一下效果：\n\n\n这里设置值需要消耗gas但是获取值getData不需要消耗gas\n\n\n\n","categories":["Solidity"],"tags":["Ethereum","SmartContract"]},{"title":"ETH Solidity智能合约进阶","url":"/2020/09/16/Crypto/ETH-Solidity%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6%E8%BF%9B%E9%98%B6/","content":"根据例子学习Solidity创建一个简单的发行代币的合约pragma solidity &gt;0.4.22 &lt;0.6.0;contract Coin &#123;    address public minter;    mapping(address =&gt; uint) public balances;    event Sent(address from, address to, uint amount);    constructor() public &#123;        minter = msg.sender;    &#125;    function mint(address receiver, uint amount) public &#123;        require(msg.sender == minter);        balances[receiver] += amount;    &#125;        function send(address receiver, uint amount) public &#123;        require(amount &lt;= balances[msg.sender]);        balances[msg.sender] -= amount;        balances[receiver] += amount;        emit Sent(msg.sender, receiver, amount);    &#125;&#125;\n\n以上代码就是一个合约创建人可以无限发币的中心化代币合约\n下面这个就是一个规定了发行代币总量的简单代币模型：\npragma solidity &gt;0.4.22 &lt;0.6.0;contract Token &#123;        mapping(address =&gt; uint) public balances;    event Sent(address from, address to, uint amount);    constructor(uint initalSupply) public &#123;        balances[msg.sender] = initalSupply;    &#125;        function send(address receiver, uint amount) public returns(bool success)&#123;        require(amount &lt;= balances[msg.sender]);        require(balances[receiver] + amount &gt;= balances[receiver]);        balances[msg.sender] -= amount;        balances[receiver] += amount;        return true;        emit Sent(msg.sender, receiver, amount);    &#125;&#125;\n\n将以上代币模型抽象出来增加细节就成了ERC20\n这里使用ConsenSys implementation对ERC20的实现来讲解\n/*Implements EIP20 token standard: https://github.com/ethereum/EIPs/blob/master/EIPS/eip-20.md.*/pragma solidity ^0.4.21;import &quot;./EIP20Interface.sol&quot;;contract EIP20 is EIP20Interface &#123;    uint256 constant private MAX_UINT256 = 2**256 - 1;    mapping (address =&gt; uint256) public balances;    //  允许别人用你的地址转币的映射    mapping (address =&gt; mapping (address =&gt; uint256)) public allowed;    /*    NOTE:    The following variables are OPTIONAL vanities. One does not have to include them.    They allow one to customise the token contract &amp; in no way influences the core functionality.    Some wallets/interfaces might not even bother to look at this information.    */    string public name;                   //fancy name: eg Simon Bucks    uint8 public decimals;                //How many decimals to show.    string public symbol;                 //An identifier: eg SBX    function EIP20(        uint256 _initialAmount,        string _tokenName,        uint8 _decimalUnits,        string _tokenSymbol    ) public &#123;        balances[msg.sender] = _initialAmount;               // Give the creator all initial tokens        totalSupply = _initialAmount;                        // Update total supply        name = _tokenName;                                   // Set the name for display purposes        decimals = _decimalUnits;                            // Amount of decimals for display purposes        symbol = _tokenSymbol;                               // Set the symbol for display purposes    &#125;    function transfer(address _to, uint256 _value) public returns (bool success) &#123;        require(balances[msg.sender] &gt;= _value);        balances[msg.sender] -= _value;        balances[_to] += _value;        emit Transfer(msg.sender, _to, _value); //solhint-disable-line indent, no-unused-vars        return true;    &#125;    function transferFrom(address _from, address _to, uint256 _value) public returns (bool success) &#123;        uint256 allowance = allowed[_from][msg.sender];        require(balances[_from] &gt;= _value &amp;&amp; allowance &gt;= _value);        balances[_to] += _value;        balances[_from] -= _value;        if (allowance &lt; MAX_UINT256) &#123;            allowed[_from][msg.sender] -= _value;        &#125;        emit Transfer(_from, _to, _value); //solhint-disable-line indent, no-unused-vars        return true;    &#125;    function balanceOf(address _owner) public view returns (uint256 balance) &#123;        return balances[_owner];    &#125;    function approve(address _spender, uint256 _value) public returns (bool success) &#123;        allowed[msg.sender][_spender] = _value;        emit Approval(msg.sender, _spender, _value); //solhint-disable-line indent, no-unused-vars        return true;    &#125;    //  允许别人用你的地址转币    function allowance(address _owner, address _spender) public view returns (uint256 remaining) &#123;        return allowed[_owner][_spender];    &#125;&#125;\n\n创建一个简单的投票合约\n电子投票的主要问题是如何将投票权分配给正确的人员以及如何防止被操纵。这个合约展示了如何进行委托投票，同时，计票又是自动和完全透明的\n为每个（投票）表决创建一份合约，然后作为合约的创造者——即主席，将给予每个独立的地址以投票权\n地址后面的人可以选择自己投票，或者委托给他们信任的人来投票\n在投票时间结束时，winningProposal()将返回获得最多投票的提案\n\npragma solidity &gt;=0.4.22 &lt;0.7.0;/**  * @title Ballot * @dev Implements voting process along with vote delegation */contract Ballot &#123;       struct Voter &#123;        uint weight; // weight is accumulated by delegation        bool voted;  // if true, that person already voted        address delegate; // person delegated to        uint vote;   // index of the voted proposal    &#125;    struct Proposal &#123;        // If you can limit the length to a certain number of bytes,         // always use one of bytes1 to bytes32 because they are much cheaper        bytes32 name;   // short name (up to 32 bytes)        uint voteCount; // number of accumulated votes    &#125;    address public chairperson;    mapping(address =&gt; Voter) public voters;    Proposal[] public proposals;    /**      * @dev Create a new ballot to choose one of &#x27;proposalNames&#x27;.     * @param proposalNames names of proposals     */    constructor(bytes32[] memory proposalNames) public &#123;        chairperson = msg.sender;        voters[chairperson].weight = 1;        for (uint i = 0; i &lt; proposalNames.length; i++) &#123;            // &#x27;Proposal(&#123;...&#125;)&#x27; creates a temporary            // Proposal object and &#x27;proposals.push(...)&#x27;            // appends it to the end of &#x27;proposals&#x27;.            proposals.push(Proposal(&#123;                name: proposalNames[i],                voteCount: 0            &#125;));        &#125;    &#125;        /**      * @dev Give &#x27;voter&#x27; the right to vote on this ballot. May only be called by &#x27;chairperson&#x27;.     * @param voter address of voter     */    function giveRightToVote(address voter) public &#123;        require(            msg.sender == chairperson,            &quot;Only chairperson can give right to vote.&quot;        );        require(            !voters[voter].voted,            &quot;The voter already voted.&quot;        );        require(voters[voter].weight == 0);        voters[voter].weight = 1;    &#125;    /**     * @dev Delegate your vote to the voter &#x27;to&#x27;.     * @param to address to which vote is delegated     */    function delegate(address to) public &#123;        Voter storage sender = voters[msg.sender];        require(!sender.voted, &quot;You already voted.&quot;);        require(to != msg.sender, &quot;Self-delegation is disallowed.&quot;);        while (voters[to].delegate != address(0)) &#123;            to = voters[to].delegate;            // We found a loop in the delegation, not allowed.            require(to != msg.sender, &quot;Found loop in delegation.&quot;);        &#125;        sender.voted = true;        sender.delegate = to;        Voter storage delegate_ = voters[to];        if (delegate_.voted) &#123;            // If the delegate already voted,            // directly add to the number of votes            proposals[delegate_.vote].voteCount += sender.weight;        &#125; else &#123;            // If the delegate did not vote yet,            // add to her weight.            delegate_.weight += sender.weight;        &#125;    &#125;    /**     * @dev Give your vote (including votes delegated to you) to proposal &#x27;proposals[proposal].name&#x27;.     * @param proposal index of proposal in the proposals array     */    function vote(uint proposal) public &#123;        Voter storage sender = voters[msg.sender];        require(sender.weight != 0, &quot;Has no right to vote&quot;);        require(!sender.voted, &quot;Already voted.&quot;);        sender.voted = true;        sender.vote = proposal;        // If &#x27;proposal&#x27; is out of the range of the array,        // this will throw automatically and revert all        // changes.        proposals[proposal].voteCount += sender.weight;    &#125;    /**      * @dev Computes the winning proposal taking all previous votes into account.     * @return winningProposal_ index of winning proposal in the proposals array     */    function winningProposal() public view            returns (uint winningProposal_)    &#123;        uint winningVoteCount = 0;        for (uint p = 0; p &lt; proposals.length; p++) &#123;            if (proposals[p].voteCount &gt; winningVoteCount) &#123;                winningVoteCount = proposals[p].voteCount;                winningProposal_ = p;            &#125;        &#125;    &#125;    /**      * @dev Calls winningProposal() function to get the index of the winner contained in the proposals array and then     * @return winnerName_ the name of the winner     */    function winnerName() public view            returns (bytes32 winnerName_)    &#123;        winnerName_ = proposals[winningProposal()].name;    &#125;&#125;\n\nSolidity源文件布局\n源文件可以被版本杂注pragma所注解，表明要求的编译器版本\n例如：pragma solidity A0.4.0；\n源文件将既不允许低于0.4.0版本的编译器编译，也不允许高于（包含）0.5.0版本的编译器编译（第二个条件因使用A被添加）import（导入其它源文件）\nSolidity所支持的导入语句import，语法同JavaScript（从ES6起）非常类似\n\nimportimport &quot;filename&quot;;\n\n从“filename”中导入所有的全局符号到当前全局作用域中 \nimport * as symbolName from &quot;filename&quot;;\n\n创建一个新的全局符号symbolName，其成员均来自“filename”中全局符号 \nimport &#123;symbol1 as alias,symbol2&#125;from &quot;filename&quot;;\n\n创建新的全局符号alias和symbol2，分别从”filename”引 用symbol1和symbol2\nimport &quot;filename&quot;as symbolName;\n\n这条语句等同于import * as symbolName from “filename”;\n基本数据类型\n布尔（bool）：可能的取值为字符常量值true或false\n整型（int&#x2F;uint)：分别表示有符号和无符号的不同位数的整型变量；支持关键字uint8到uint256（无符号，从8位到256位）以及int8到int256，以8位为步长递增\n定长浮点型（fixed&#x2F;ufixed)：表示各种大小的有符号和无符号的定长浮点型；在关键字ufixedMxN和fixedMxN中，M表示该类型占用的位数，N表示可用的小数位数\n地址（address)：存储一个20字节的值（以太坊地址大小）\n定长字节数组：关键字有bytes1,bytes2,bytes3,…,bytes32\n枚举（enum)：一种用户可以定义类型的方法，与C语言类似，默认从0开始递增，一般用来模拟合约的状态\n函数（function)：一种表示函数的类型\n\n数组（Array)\n\n数组可以在声明时指定长度（定长数组），也可以动态调整大小（变长数组、动态数组）\n对于存储型（storage）的数组来说，元素类型可以是任意的（即元素也可以是数组类型，映射类型或者结构体）；对于内存型(memory)的数组来说，元素类型不能是映射（mapping)类型\n\n结构（Struct)\n\nSolidity支持通过构造结构体的形式定义新的类型\n\n映射（Mapping)\n\n映射可以视作哈希表，在实际的初始化过程中创建每个可能的key，并将其映射到字节形式全是零的值（类型默认值）\n\naddress\n\n地址类型存储一个20字节的值（以太坊地址的大小）；地址类型也有成员变量，并作为所有合约的基础\n\naddress payable(v0.5.0引入)\n\n与地址类型基本相同，不过多出了transfer和send两个成员变量\n\n两者区别和转换\n\nPayable地址是可以发送ether的地址，而普通address不能\n允许从payable address到address的隐式转换，而反过来的直接转换是不可能的（唯一方法是通过uint160来进行中间转换）\n从0.5.0版本起，合约不再是从地址类型派生而来，但如果它有payable的回退函数，那同样可以显式转换为address或者address payable类型\n\n&lt;address&gt;.balance(uint256)\n\n该地址的ether余额，以Wei为单位\n\n&lt;address payable&gt;.transfer(uint256 amount)\n\n向指定地址发送数量为amount的ether（以Wei为单位），失败时抛出异常，发 送2300gas的矿工费，不可调节\n\n&lt;address payable&gt;.send(uint256 amount)returns(bool)\n\n向指定地址发送数量为amount的 ether（以Wei为单位），失败时返回false，发 送2300gas的矿工费用，不可调节\n\n&lt;address&gt;.call(bytes memory)returns(bool,bytes memory)\n\n发出底层函数CALL，失败时返回false，发送所有可用gas，可调节\n\n&lt;address&gt;.delegatecall(bytes memory)returns(bool,bytes memory)\n\n发出底层函数DELEGATECALL，失败时返回false，发送所有可用gas，可调节\n\n&lt;address&gt;.staticcall(bytes memory)returns(bool,bytes memory)\n\n发出底层函数STATICCALL，失败时返回false，发送所有可用gas，可调节\n\nSolidity数据位置\n所有的复杂类型，即数组、结构和映射类型，都有一个额外属性，“数据位置”，用来说明数据是保存在内存memory中还是存储storage中\n根据上下文不同，大多数时候数据有默认的位置，但也可以通过在类型名后增加关键字storage或memory进行修改\n函数参数（包括返回的参数）的数据位置默认是memory，局部变量的数据位置默认是storage，状态变量的数据位置强制是storage\n另外还存在第三种数据位置，calldata，这是一块只读的，且不会永久存储的位置，用来存储函数参数。外部函数的参数（非返回参数）的数据位置被强制指定为calldata，效果跟memory差不多\n\n强制指定的数据位置\n\n外部函数的参数（不包括返回参数）：calldata；\n状态变量：storage\n\n默认数据位置\n\n函数参数（包括返回参数）：memory；\n引用类型的局部变量：storage\n值类型的局部变量：栈（stack)\n\n特别要求\n\n公开可见（publicly visible)的函数参数一定是memory类型，如果要求是storage类型则必须是private或者internal函数，这是为了防止随意的公开调用占用资源\n\n未初始化的storage类型指针会指向第一个状态变量pragma solidity ^0.4.0;/**这个案例涉及到solidity的一个坑a, b, data和x都是storge的x是一个可变长度的数组的引用，默认指向该合约空间的头部合约空间大致如下：a-b-data^|x而一个可变数组的指针指向的空间默认存储该可变数组的长度，所以每调一次f()就会导致变量a++而又因为solidity的可变数组的内容是采用hash表的形式存储的，所以b的值大概率不变，真正push进去的值不知道存到哪里去了 */contract C &#123;    uint public a;    uint public b;    uint[] public data;    function f() public &#123;        uint[] x;        x.push(2);        data = x;    &#125;&#125;\n\n接下来看一个更加真实的例子：\npragma solidity ^0.4.17;/**这里你即使猜52合约也不会返还你给的value*2的ETH，因为这个newGuess是sorage类型的指针未初始化导致其指向此合约第一个状态变量即luckyNumber，导致会把address类型的值赋给luckyNumber覆盖掉原本的值 */contract Honeypot &#123;    uint luckyNumber = 52;    struct Guess &#123;        address player;        uint number;    &#125;    Guess[] public guessHistory;    address owner = msg.sender;    function guess(uint _num) public payable &#123;        Guess newGuess;        newGuess.player = msg.sender;        newGuess.number = _num;        guessHistory.push(newGuess);        if (_num == luckyNumber) &#123;            msg.sender.transfer(msg.value * 2);        &#125;    &#125;&#125;\n\nsolidity函数的可见性函数的可见性可以指定为external，public，internal 或者private；对于状态变量，不能设置为external，默认是internal。\n\nexternal：外部函数作为合约接口的一部分，意味着我们可以从其他合约和交易中调用。一个外部函数f不能从内部调用（即f不起作用，但this.f()可以）。当收到大量数据的时候，外部函数有时候会更有效率。\n\npuhlic：public函数是合约接口的一部分，可以在内部或通过消息调用。对于public状态变量，会自动生成一个getter函数。\n\ninternal：这些函数和状态变量只能是内部访问（即从当前合约内部或从它派生的合约访问），不使用this调用。\n\nprivate：private函数和状态变量仅在当前定义它们的合约中使用，并且不能被派生合约使用。\n\npure：纯函数，不允许修改或访问状态\n\nview：不允许修改状态\n\npayable：允许从消息调用中接收以太币Ether。\n\nconstant：与view相同，一般只修饰状态变量，不允许赋值（除初始化以外）\n\n\n以下情况被认为是修改状态：\n\n修改状态变量。\n产生事件。\n创建其它合约。\n使用selfdestruct。\n通过调用发送以太币。\n调用任何没有标记为view或者pure的函数。\n使用低级调用。\n使用包含特定操作码的内联汇编。\n\n以下被认为是从状态中进行读取：\n\n读取状态变量。\n访问this.balance或者&lt;address&gt;.balance。\n访问block，tx，msg中任意成员（除msg.sig和msg.data之外）。\n调用任何未标记为pure的函数。\n使用包含某些操作码的内联汇编。\n\n函数修饰器(modifier)使用修饰器modifier可以轻松改变函数的行为。例如，它们可以在执行函数之前自动检查某个条件。修饰器modifier是合约的可继承属性，并可能被派生合约覆盖\n如果同一个函数有多个修饰器modifier，它们之间以空格隔开，修饰器modifier会依次检查执行。\n回退函数(fallback)\n回退函数（fallback function)是合约中的特殊函数；没有名字，不能有参数也不能有返回值\n如果在一个到合约的调用中，没有其他函数与给定的函数标识符匹配（或没有提供调用数据），那么这个函数（fallback函数）会被执行\n每当合约收到以太币（没有任何数据），回退函数就会执行。此外，为了接收以太币，fallback函数必须标记为payable。如果不存在这样的函数，则合约不能通过常规交易接收以太币\n在上下文中通常只有很少的gas可以用来完成回退函数的调用，所以使fallback函数的调用尽量廉价很重要\n\n事件(event)事件是以太坊EVM提供的一种日志基础设施。事件可以用来做操作记录，存储为日志。也可以用来实现一些交互功能，比如通知UI，返回函数调用结果等\n当定义的事件触发时，我们可以将事件存储到EVM的交易日志中，日志是区块链中的一种特殊数据结构；日志与合约关联，与合约的存储合并存入区块链中；只要某个区块可以访问，其相关的日志就可以访问；但在合约中，我们不能直接访问日志和事件数据\n可以通过日志实现简单支付验证SPV（Simplified PaymentVerification)如果一个外部实体提供了一个带有这种证明的合约，它可以检查日志是否真实存在于区块链中\nsolidity异常处理Solidity使用“状态恢复异常”来处理异常。这样的异常将撤消对当前调用（及其所有子调用）中的状态所做的所有更改，并且向调用者返回错误。\n函数assert和require可用于判断条件，并在不满足条件时抛出异常\n\nassert()一般只应用于测试内部错误，并检查常量\nrequire()应用于确保满足有效条件《如输入或合约状态变量），或验证调用外部合约的返回值\nrevert()用于抛出异常，它可以标记一个错误并将当前调用回退\n\nweb3.js\nWeb3 JavaScript app API\nweb3.js是一个JavaScriptAPI库。要使DApp在以太坊上运行，我们可以使用web3.js库提供的web3对象\nweb3.js通过RPC调用与本地节点通信，它可以用于任何暴露了RPC层的以太坊节点\nweb3包含eth对象-web3.eth（专门与以太坊区块链交互）和shh对象-web3.shh（用于与Whisper交互）\n\nweb3模块加载首先需要将web3模块安装在项目中：\nnpm install web3@0.20.1 \n\n然后创建一个web3实例，设置一个“provider”\n为了保证我们的MetaMask设置好的provider不被覆盖掉，在引入 web3之前我们一般要做当前环境检查（以v0.20.1为例）：\nif (typeof web3!==undefined) &#123;    web3 = new Web3(web3.currentProvider); &#125; else &#123;     web3 = new Web3(new Web3.providers .HttpProvider(&quot;http://localhost:8545&quot;);&#125;\n\n异步回调(callback)web3jsAPI设计的最初目的，主要是为了和本地RPC节点共同使用，所以默认情况下发送的是同步HTTP请求\n如果要发送异步请求，可以在函数的最后一个参数位置上，传入一个回调函数。回调函数是可选（optioanl)的\n我们一般采用的回调风格是所谓的“错误优先”，例如：\nweb3.eth.getBlock(48,function(error,result)&#123;     if (!error) &#123;        console.log(JSON.stringify(result));    &#125; else &#123;        console.error(error);    &#125;&#125;);\n\n回调Prmise事件(v1.0.0)为了帮助web3集成到不同标准的所有类型项目中，1.0.0版本提供了多种方式来处理异步函数。大多数的web3对象允许将一个回调函数作为最后一个函数参数传入，同时会返回一个promise用于链式函数调用。\n以太坊作为一个区块链系统，一次请求具有不同的结束阶段。为了满足这样的要求，1.0.0版本将这类函数调用的返回值包成一个“承诺事件”（promiEwent)，这是一个promise和EventEmitter的结合体。\nPromiEvent的用法就像promise一样，另外还加入了.on，.once和.off方法\nweb3.eth.sendTransaction(&#123;from:&#x27;Ox123...&#x27;,data:&#x27;Ox432..&#x27;&#125;).once(&#x27;transactionHash&#x27;, function(hash)&#123;...&#125;) .once(&#x27;receipt&#x27;, function(receipt)&#123;..&#125;).on(&#x27;confirmation&#x27;, function(confNumber,receipt)&#123;...&#125;).on(&#x27;error&#x27;, function(error)&#123;...&#125;).then(function(receipt)(&#123;    //will be fired once the receipt is mined &#125;);\n\n应用二进制接口(ABI)web3.js通过以太坊智能合约的json接口（Application Binary Interface,ABl)创建一个JavaScript对象，用来在js 代码中描述 \n函数(functions) \n\ntype:函数类型，默认function，也可能是constructor\nconstant, payable, stateMutability:函数的状态可变性 \ninputs,outputs:函数输入、输出参数描述列表\n\n事件(events) \n\ntype：类型，总是event\ninputs：输入对象列表，包括name、type、indexed\n\n","categories":["Solidity"],"tags":["Ethereum","SmartContract"]},{"title":"比特币是什么","url":"/2019/10/30/Crypto/%E6%AF%94%E7%89%B9%E5%B8%81%E6%98%AF%E4%BB%80%E4%B9%88/","content":"使用简单的js代码来讲述比特币的工作原理需求\n在一个含有N(N&gt;2)个人的小团体里建立一个通用的系统\n该货币系统使用的货币没有实体媒介，即为数据形式存在\n该转账操作需要通过互联网(或是团体里的局域网)来进行\n\n步骤假设存在一个有10个人的小团体，每个人都有自己的私有存储空间\nconst peopleList = []for (let i = 0; i &lt; 10; i++) &#123;    peopleList.push(&#123;        name: i,        note: [],        historyList: []    &#125;)&#125;\n\n首先要假设每个人账户里面都有至少1000块来自系统(-1)，否则无法进行转账\nfor (let i = 0; i &lt; 10; i++) &#123;    for (let j = 0; j &lt; 10; j++) &#123;        peopleList[i].note.push(&#123;            from: -1,            to: j,            money: 1000        &#125;)    &#125;&#125;\n\n第3个人转100给第9个人：记做 3-&gt;9: 100，全部人记录下来这个事件\nfor (let i = 0; i &lt; 10; i++) &#123;    peopleList[i].note.push(&#123;        from: 3,        to: 9,        money: 100    &#125;)&#125;\n\n这样，一笔转账就被认为是完成了。\n但是当转账的记录太多的时候每个人的存储空间就会出现不够用的情况，这个时候就要进行压缩操作。那么问题来了，压缩密钥怎么办，若是保存在一个人的手上肯定不行，所以就需要使用该网络中每个人都同意的唯一一把钥匙来密封它。通过密封，我们可以保证，一旦历史记录的备份已经被存入每一个人的文件夹，没有人能够对它作出任何更改。因此一旦压缩完成，那么这个压缩包就是绝对可信的。\n这个压缩包的hash值被人们称为“矿”，同时也是工作证明。\n一旦每个人都用尽自己的空间、无法记录进一步的交易，他们就开始卖力地计算历史交易记录的hash，使得它可以被藏入历史hash值列表historyList中。在网络中，每个人都进行这个计算，而最早算出hash值的那个人会向其他所有人宣布这个值。\nconst maxHistory = 10let sealingNumberif (peopleList[7].note.length &gt;= maxHistory) &#123;    sealingNumber = hash(JSON.stringify(peopleList[7].note))    peopleList[7].note = []&#125;\n\n听到hash值之后，每个人都立即验证check()它是否能产生要求的输出值。如果是的，每个人都为他们的历史hash值列表historyList存入该值。\nfor (let i = 0; i &lt; 10; i++) &#123;    if (check(sealingNumber) === JSON.stringify(peopleList[i].note)) &#123;        peopleList[i].historyList.push(sealingNumber)        peopleList[i].note = []    &#125;&#125;\n\n如果对某人，比如7来说，那个sealingNumber无法产生要求的输出值，怎么办？\n可能的原因有：\n\n他获取到的sealingNumber与之前在网络中宣布的不同\n他可能记录错了note数组\n\n他只能放弃自己错误的sealingNumber然后从网络里获取别人的 note数组和historyList数组，否则他将被禁止进入网络\n前面提到了hash值即sealingNumber也可以被称作矿，这是因为第一个计算出hash值的人将得到免费的金钱作为对他的努力（比如：付出的CPU算力和电力）的奖励。\n下面假设奖励为1\nconst maxHistory = 10let sealingNumberif (peopleList[7].note.length &gt;= maxHistory) &#123;    sealingNumber = hash(JSON.stringify(peopleList[7].note))    peopleList[7].note = []    if (isFirst(sealingNumber)) &#123;        peopleList[7].note.push(&#123;            from: -1,            to: 7,            money: 1        &#125;)    &#125;&#125;for (let i = 0; i &lt; 10; i++) &#123;    peopleList[i].note = []    peopleList[i].historyList.push(sealingNumber)    peopleList[i].note.push(&#123;        from: -1,        to: 7,        money: 1    &#125;)&#125;\n\n这就是比特币变为现实的方式。它是在区块链上被用来交易的第一种货币。同时，人们被奖励以比特币作为回报，以使在网络上，计算hash值努力会继续进行。\n但是这里有个问题如果有人将很久之前的 note数组和historyList数组中对应的一项同时进行修改在检查上面将会成本较高，但是我们可以将每一个 note数组的最后一项改为上一个historyList数组的值也就是上一个 note数组的hash值。这样，每一个hash值都依赖于它之前的 note数组。因此，如果有人要修改一个 note数组的历史记录，他将同样必须改变该页以后所有 note数组的内容和hash值，以使这条链保持一致。\n如果有人想要这么做的话那么他将会从改变的那个 note数组开始计算hash值，但是计算也是需要消耗算力的，他的链增长速度肯定赶不上整个社区的链的增长速度，除非他拥有超越整个社区的算力，当然这都是后话了。有句话叫：在绝对的力量面前任何技巧都是花拳绣腿。\n所以这保证了在一个网络中，最长的链就是可信的链。\nconst maxHistory = 10let sealingNumberif (peopleList[7].note.length &gt; maxHistory) &#123;    peopleList[7].note.push(&#123;        from: null,        to: null,        money: peopleList[7].historyList[historyList.length - 1]    &#125;)    sealingNumber = hash(JSON.stringify(peopleList[7].note))    peopleList[7].note = []    if (isFirst(sealingNumber)) &#123;        peopleList[7].note.push(&#123;            from: -1,            to: 7,            money: 1        &#125;)    &#125;&#125;for (let i = 0; i &lt; 10; i++) &#123;    peopleList[i].note = []    peopleList[i].historyList.push(sealingNumber)    peopleList[i].note.push(&#123;        from: -1,        to: 7,        money: 1    &#125;)&#125;\n\n万一，是6个人呢？\n在这种情况下，这个协议将会变成一纸空文。使得整个社区变成这6个人的后花园。它就是人们所知的“51%攻击”。\n","categories":["Crypto"],"tags":["Bitcoin"]},{"title":"Ethereum","url":"/2019/07/25/Crypto/Ethereum/","content":"\n以太坊的目的是基于脚本、竞争币和链上元协议（on-chain meta-protocol）概念进行整合和提高，使得开发者能够创建任意的基于共识的、可扩展的、标准化的、特性完备的、易于开发的和协同的应用。以太坊通过建立终极的抽象的基础层-内置有图灵完备编程语言的区块链-使得任何人都能够创建合约和去中心化应用并在其中设立他们自由定义的所有权规则、交易方式和状态转换函数。域名币的主体框架只需要两行代码就可以实现，诸如货币和信誉系统等其它协议只需要不到二十行代码就可以实现。智能合约-包含价值而且只有满足某些条件才能打开的加密箱子-也能在我们的平台上创建，并且因为图灵完备性、价值知晓（value-awareness）、区块链知晓（blockchain-awareness）和多状态所增加的力量而比比特币脚本所能提供的智能合约强大得多。\n\n以太坊白皮书-译文：https://ethfans.org/wikis/%E4%BB%A5%E5%A4%AA%E5%9D%8A%E7%99%BD%E7%9A%AE%E4%B9%A6\n常用ETH客户端\ngo-ethereum(Go)：官方推荐，开发使用最多 \n地址：https://github.com/ethereum/go-ethereum\n\n\nparity（Rust)：最轻便客户端，在历次以太坊网络攻击中表现卓越 \n地址：https://github.com/ethcore/parity/releases\n\n\ncpp-ethereum(C++) \n地址：https://github.com/ethereum/cpp-ethereum\n\n\npyethapp(python) \n地址：https://github.com/heikoheiko/pyethapp\n\n\nethereumjs-lib(javascript) \n地址：https://github.com/ethereumis/ethereumis-lib\n\n\nEthereumJ&#x2F;Harmony(Java) \n地址：https://github.com/ethereum/ethereumi\n\n\n\n节点全节点全节点是整个主链的一个副本，存储并维护链上的所有数据，并随时验证新区块的合法性。区块链的健康和扩展弹性，取决于具有许多独立操作和地理上分散的全节点。每个全节点都可以帮助其他新节点获取区块数据，并提供所有交易和合约的独立验证。运行全节点将耗费巨大的成本，包括硬件资源和带宽。以太坊开发不需要在实时网络（主网）上运行的全节点。我们可以使用测试网络的节点来代替，也可以用本地私链，或者使用服务商提供的基于云的以太坊客户端；这些几乎都可以执行所有操作。\n优点：\n\n为以太坊网络的灵活性和抗审查性提供有力支持。\n权威地验证所有交易。\n可以直接与公共区块链上的任何合约交互。\n可以离线查询区块链状态（帐户，合约等）。\n可以直接把自己的合约部署到公共区块链中。\n\n缺点：\n\n需要巨大的硬件和带宽资源，而且会不断增长。\n第一次下载往往需要几天才能完全同步。\n必须及时维护、升级并保持在线状态以同步区块\n\n运行全节点配置要求：\n最低要求：\n\n双核以上CPU\n硬盘存储可用空间至少80GB\n如果是SSD，需要4GB以上RAM，如果是HDD，至少8GB RAM\n8MB&#x2F;s下载带宽\n\n推荐配置：\n\n四核以上的快速CPU\n16GB以上RAM\n500GB以上可用空间的快速SSD\n25+MB&#x2F;s下载带宽\n\n远程客户端不存储区块链的本地副本或验证块和交易。这些客户端一般只提供钱包的功能，可以创建和广播交易。远程客户端可用于连接到现有网络，MetaMask就是一个这样的客户端。\n轻节点不保存链上的区块历史数据，只保存区块链当前的状态。轻节点可以对块和交易进行验证。\n本地私链优点：\n\n磁盘上几乎没有数据，也不同步别的数据，是一个完全“干净”的环境。\n无需获取测试以太，你可以任意分配以太，也可以随时自己挖矿获得。\n没有其他用户，也没有其他合约，没有任何外部干扰。\n\n缺点：\n\n没有其他用户意味与公链的行为不同。发送的交易并不存在空间或交易顺序的竞争。\n除自己之外没有矿工意味着挖矿更容易预测，因此无法测试公链上发生的某些情况。\n没有其他合约，意味着你必须部署要测试的所有内容，包括所有的依赖项和合约库。\n\nETH客户端Geth(go-ethereum(Go))的使用下载完毕后进入根目录：\ngeth --datadir G:\\Ethereum\n\n使用--datadir参数指定数据存放目录，因为我使用的windows版本所以这里的路径是Windows的路径\nJSON-RPC以太坊客户端提供了API和一组远程调用（RPC）命令，这些命令被编码为JSON。这被称为JSON-RPCAPI。本质上，JSON-RPCAPI就是一个接口，允许我们编写的程序使用以太坊客户端作为网关，访问以太坊网络和链上数据。\n通常，RPC接口作为一个HTTP服务，端口设定为8545。出于安全原因，默认情况下，它仅限于接受来自localhost的连接。\n要访问JSON-RPCAPI，我们可以使用编程语言编写的专用库，例如JavaScript的 web3.js。\n或者也可以手动构建HTTP请求并发送&#x2F;接收JSON编码的请求，如：\n$curl -X POST -H &quot;Content-Type:application/json&quot; --data \\ &#123;&quot;jsonrpc&quot;:&quot;2.0&quot;&quot;method&quot;:&quot;web3_clientVersion&#x27;&quot;,&quot;params&quot;:],&quot;id&quot;:1&quot;I http://localhost:8545\n\n以太坊没有UTXO，但是又Account以太坊的“状态”，就是系统中所有帐户的列表\n每个账户都包括了一个余额（balance)，和以太坊特殊定义的数据（代码和内部存储）\n如果发送帐户有足够的余额来支付，则交易有效；在这种情况下发送帐户先扣款，而收款帐户将记入这笔收入\n如果接收帐户有相关代码，则代码会自动运行，并且它的内部存储也可能被更改，或者代码还可能向其他帐户发送额外的消息，这就会导致进一步的借贷资金关系\n交易(Transaction)签名的数据包，由EOA发送到另一个账户：\n\n(To)消息的接收方地址\nv,r,s：发送方EOA的ECDSA签名的三个组成部分\n金额(Value)\n数据(Data)可选：可变长度二进制数据负载(payload)\nSTART GAS：交易发起人愿意支付的最大gas量\nGAS PRICE：交易发起人愿意支付的gas单价(单位：wei)\nnonce：发起人EOA发出的序列号，防止交易消息重播\n\n消息(Message)\n合约可以向其它合约发送“消息”\n\n消息是不会被序列化的虚拟对象，只存在于以太坊执行环境（EVM）中，而交易会被矿工打包到区块中，若消息不涉及到转账就不会被序列号并打包到区块中\n\n可以看作函数调用\n\n消息发送方\n\n消息接收方\n\n金额（VALUE)\n\n数据（DATA，可选）\n\nSTART GAS\n\n\n合约(Contract)可以读&#x2F;写自己的内部存储（32字节key-value的数据库）\n可向其他合约发送消息，依次触发执行\n一旦合约运行结束，并且由它发送的消息触发的所有子执行（sub-execution)结束，EVM就会中止运行，直到下次交易被唤醒\n交易中的gas当由于交易或消息触发EVM运行时，每个指令都会在网络的每个节点上执行。这具有成本：对于每个执行的操作，都存在固定的成本，我们把这个成本用一定量的gas表示。\ngas是交易发起人需要为EVM上的每项操作支付的成本名称。发起交易时，我们需要从执行代码的矿工那里用以太币购买gas。\ngas与消耗的系统资源对应，这是具有自然成本的。因此在设计上gas和ether有意地解耦，消耗的gas数量代表了对资源的占用，而对应的交易费用则还跟gas对以太的单价有关。这两者是由自由市场调节的：gas的价格实际上是由矿工决定的，他们可以拒绝处理gas价格低于最低限额的交易。我们不需要专门购买gas，只需将以太币添加到帐户即可，客户端在发送交易时会自动用以太币购买gas。而以太币本身的价格通常由于市场力量而波动。\n交易的接收者(To)交易接收者在to字段中指定，是一个20字节的以太坊地址。地址可以是EOA或合约地址。\n以太坊没有进一步的验证，任何20字节的值都被认为是有效的。如果20字节值对应于没有相应私钥的地址，或不存在的合约，则该交易仍然有效。以太坊无法知道地址是否是从公钥正确派生的。\n如果将交易发送到无效地址，将销毁发送的以太，使其永远无法访问。\n验证接收人地址是否有效的工作，应该在用户界面一层完成。\n交易的value和data交易的主要“有效负载”包含在两个字段中：value和data。交易可以同时有value和data，仅有value，仅有data，或者既没有value也没有data。所有四种组合都有效。\n\n仅有value的交易就是一笔以太的付款\n仅有data的交易一般是合约调用\n进行合约调用的同时，我们除了传输data，还可以发送以太，从而交易中同时包含data和value没有value也\n没有data的交易，只是在浪费gas，但它是有效的\n\n向EOA或合约传递data当交易包含数据有效负载时，它很可能是发送到合约地址的，但它同样可以发送给EOA\n如果发送data给EOA，数据负载（data payload）的解释取决于钱包\n如果发送数据负载给合约地址，EVM会解释为函数调用，从payload里解码出函数名称和参数，调用该函数并传入参数\n发送给合约的数据有效负载是32字节的十六进制序列化编码：\n\n函数选择器：函数原型的Keccak256哈希的前4个字节。这允许EVM明确地识别将要调用的函数。\n函数参数：根据EVM定义的各种基本类型的规则进行编码。\n\n以太坊虚拟机(EVM)\n以太坊虚拟机EVM是智能合约的运行环境\n作为区块验证协议的一部分，参与网络的每个节点都会运行EVM。他们会检查正在验证的块中列出的交易，并运行由EVM中的交易触发的代码\nEVM不仅是沙盒封装的，而且是完全隔离的，也就是说在EVM中运行的代码是无法访问网络、文件系统和其他进程的，甚至智能合约之间的访问也是受限的\n合约以字节码的格式（EVMbytecode)存在于区块链上\n合约通常以高级语言（solidity)编写，通过EVM编译器编译为字节码，最终通过客户端上载部署到区块链网络中\n\nEVM和账户\n以太坊中有两类账户：外部账户和合约账户，它们共用EVM中同一个地址空间\n无论帐户是否存储代码，这两类账户对EVM来说处理方式是完全一样的\n每个账户在EVM中都有一个键值对形式的持久化存储。其中key和value的长度都是256位，称之为存储空间(storage)\n\nEVM和交易\n交易可以看作是从一个帐户发送到另一个帐户的消息，它可以包含二进制数据（payload)和以太币\n如果目标账户含有代码，此代码会在EVM中执行，并以payload作为入参，这就是合约的调用\n如果目标账户是零账户（账户地址为0），此交易就将创建一个新合约，这个用来创建合约的交易的payload会被转换为EVM字节码并执行，执行的输出作为合约代码永久存储\n\nEVM和gas\n合约被交易触发调用时，指令会在全网的每个节点上执行：这需要消耗算力成本；每一个指令的执行都有特定的消耗，gas就用来量化表示这个成本消耗\n一经创建，每笔交易都按照一定数量的gas预付一笔费用，目的是限制执行交易所需要的工作量和为交易支付手续费\nEVM执行交易时，gas将按特定规则逐渐耗尽\ngas price是交易发送者设置的一个值，作为发送者预付手续费的单价。如果交易执行后还有剩余，gas会原路返还\n无论执行到什么位置，一旦gas被耗尽（比如降为负值），将会触发一个out-of-gas异常。当前调用帧（call frame)所做的所有状态修改都将被回滚\n\nEVM数据存储Storage\n\n每个账户都有一块持久化的存储空间，称为storage，这是一个将256位字映射到256位字的key-value存储区，可以理解为合约的数据库\n永久储存在区块链中，由于会永久保存合约状态变量，所以读写的gas开销也最大Memory(内存）\n每一次消息调用，合约会临时获取一块干净的内存空间·生命周期仅为整个方法执行期间，函数调用后回收，因为仅保存临时变量，故读写gas开销较小Stack(栈）\nEVM不是基于寄存器的，而是基于栈的，因此所有的计算都在一个被称为栈(stack)的区域执行\n存放部分局部值类型变量，几乎免费使用的内存，但有数量限制\n\nEVM指令集\n所有的指令都是针对“256位的字（word)“这个基本的数据类型来进行操作\n具备常用的算术、位、逻辑和比较操作，也可以做到有条件和无条件跳转\n合约可以访问当前区块的相关属性，比如它的块高度和时间戳\n\n消息调用(Message Calls)\n合约地址到合约地址的value&#x3D;0的调用被称为消息调用\n合约可以通过消息调用的方式来调用其它合约或者发送以太币到非合约账户\n合约可以决定在其内部的消息调用中，对于剩余的gas，应发送和保留多少\n如果在内部消息调用时发生了out-of-gas异常（或其他任何异常），这将由一个被压入栈顶的错误值所指明；此时只有与该内部消息调用一起发送的gas会被消耗掉\n\n委托调用(Delegatecall)\n一种特殊类型的消息调用\n目标地址的代码将在发起调用的合约的上下文中执行，并且msg.sender和msg.value不变\n可以由此实现“库”（library)：可复用的代码库可以放在一个合约的存储上，通过委托调用引入相应代码\n\n合约的创建和自毁\n通过一个特殊的消息调用create calls，合约可以创建其他合约（不是简单的调用零地址）\n合约代码从区块链上移除的唯一方式是合约在合约地址上的执行自毁操作selfdestruct；合约账户上剩余的以太币会发送给指定的目标，然后其存储和代码从状态中被移除\n\n","categories":["Crypto"],"tags":["Ethereum"]},{"title":"JVM-10_对象实例化内存布局与访问定位","url":"/2022/07/05/JVM/JVM-10_%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E4%B8%8E%E8%AE%BF%E9%97%AE%E5%AE%9A%E4%BD%8D/","content":"对象实例化面试题\n对象在JVM中是怎么存储的？\n对象头信息里面有哪些东西？\nJava对象头有什么？\n\n从对象创建的方式 和 步骤开始说\n\n\n对象创建方式\nnew：最常见的方式、单例类中调用getInstance的静态类方法，XXXFactory的静态方法\nClass的newInstance方法：在JDK9里面被标记为过时的方法，因为只能调用空参构造器\nConstructor的newInstance(XXX)：反射的方式，可以调用空参的，或者带参的构造器\n使用clone()：不调用任何的构造器，要求当前的类需要实现Cloneable接口中的clone接口\n使用序列化：序列化一般用于Socket的网络传输\n第三方库 Objenesis\n\n创建对象的步骤(共6步)对象实例化的过程:\n\n加载类元信息\n为对象分配内存\n处理并发问题\n属性的默认初始化（零值初始化）\n设置对象头信息\n属性的显示初始化、代码块中初始化、构造器中初始化\n\n1. 判断对象对应的类是否加载、链接、初始化虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载，解析和初始化。（即判断类元信息是否存在）。如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader + 包名 + 类名为key进行查找对应的 .class文件，如果没有找到文件，则抛出ClassNotFoundException异常，如果找到，则进行类加载，并生成对应的Class对象。\n2. 为对象分配内存首先计算对象占用空间的大小，接着在堆中划分一块内存给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小\n\nfloat, int 占4个字节\nshort, char 占2个字节\nbyte, boolean 占1个字节 \nString 4 占4个字节\ndouble, long 8 占4个字节\n\n为对象分配空间需要找到内存中至少存在一块足够大小的连续空间\n判断内存是否规整\n\n如果内存规整：指针碰撞\n如果内存不规整\n虚拟表需要维护一个列表\n空闲列表分配\n\n\n\n如果内存是规整的，那么虚拟机将采用的是指针碰撞法（Bump The Point）来为对象分配内存。\n意思是所有用过的内存在一边，空闲的内存放另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针指向空闲那边挪动一段与对象大小相等的距离罢了。如果垃圾收集器选择的是Serial ，ParNew这种基于压缩算法的，虚拟机采用这种分配方式。一般使用带Compact（整理）过程的收集器时，使用指针碰撞。\n如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表来为对象分配内存。意思是虚拟机维护了一个列表，记录上那些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为了 “空闲列表（Free List）”\n选择哪种分配方式由Java堆是否规整所决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n3. 处理并发问题\n采用CAS配上失败重试保证更新的原子性\n在Eden区每个线程预先分配TLAB - 通过设置 -XX:+UseTLAB参数来设置（区域加锁机制）\n在Eden区给每个线程分配一块区域\n\n\n\n4. 初始化分配到的内存(属性的默认初始化)给对象属性赋值的操作\n\n属性的默认初始化\n\n显示初始化\n\n代码块中的初始化\n\n构造器初始化\n\n所有属性设置默认值，保证对象实例字段在不赋值可以直接使用\n\n\n5. 设置对象的对象头将对象的所属类（即类的元数据信息）、对象的HashCode和对象的GC信息、锁信息等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。\n稍后详细讲\n6. 执行init方法进行初始化在Java程序的视角看来，初始化才正式开始。初始化成员变量，执行实例化代码块，调用类的构造方法，并把堆内对象的首地址赋值给引用变量\n因此一般来说（由字节码中跟随invokespecial指令所决定），new指令之后会接着就是执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完成创建出来。\n对象内存布局\n\n对象头对象头包含了两部分，分别是运行时元数据（Mark Word）和 类型指针\n\n运行时元数据\n\n\n哈希值(HashCode)：对象在堆空间里面的地址\nGC分代年龄\n锁状态标志\n线程持有的锁\n偏向线程ID\n翩向时间戳\n\n\n类型指针：指向类元数据InstanceKlass，确定该对象所属的类型。指向的其实是方法区中存放的类元信息\n\n\n如果是数组，还需要记录数组的长度\n\n实例数据（Instance Data）说明不是必须的，也没有特别的含义，仅仅起到占位符的作用\n小结\n\n对象的访问定位图示JVM是如何通过栈帧中的对象引用访问到其内部的对象实例呢？\n\n\n对象访问的两种方式句柄访问\n\n句柄访问就是说栈的局部变量表中，记录的对象的引用，然后在堆空间中开辟了一块空间，也就是句柄池\n优点reference中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference本身不需要被修改\n直接指针（HotSpot采用）\n\n直接指针是局部变量表中的引用，直接指向堆中的实例，在对象实例中有类型指针，指向的是方法区中的对象类型数据\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-11_直接内存","url":"/2022/07/16/JVM/JVM-11_%E7%9B%B4%E6%8E%A5%E5%86%85%E5%AD%98/","content":"不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。\n直接内存是在Java堆外的、直接向系统申请的内存区间。\n来源于NIO，通过存在堆中的DirectByteBuffer操作Native内存\n通常，访问直接内存的速度会优于Java堆。即读写性能高。\n\n因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。\nJava的NIO库允许Java程序使用直接内存，用于数据缓冲区\n\n使用下列代码，直接分配本地内存空间\nint BUFFER = 1024*1024*1024; // 1GBByteBuffer byteBuffer = ByteBuffer.allocateDirect(BUFFER);\n\n\n非直接缓存区和缓存区原来采用BIO的架构，我们需要从用户态切换成内核态\n\n\nNIO的方式使用了缓存区的概念\n存在的问题也可能导致outofMemoryError异常\n由于直接内存在Java堆外，因此它的大小不会直接受限于-xmx指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。缺点\n\n分配回收成本较高\n不受JVM内存回收管理\n\n直接内存大小可以通过MaxDirectMemorySize设置\n如果不指定，默认与堆的最大值-xmx参数值一致\n\n\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-12_执行引擎","url":"/2022/08/24/JVM/JVM-12-%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/","content":"执行引擎属于JVM的下层，里面包括 解释器、及时编译器、垃圾回收器\nJava代码编译和执行过程大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过上图中的各个步骤\n\n前面橙色部分是生成字节码文件的过程，和JVM无关\n后面蓝色和绿色才是JVM需要考虑的过程\n\n\nJava代码编译是由Java源码编译器来完成，流程图如下所示：\n\n\nJava字节码的执行是由JVM执行引擎来完成，流程图 如下所示\n\n\n我们用一个总的图，来说说 解释器和编译器\n\n\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-1_JVM与Java体系结构","url":"/2022/05/27/JVM/JVM-1_JVM%E4%B8%8EJava%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/","content":"基于栈的指令集架构与基于寄存器的指令集架构Java编译器输入的指令流基本上是一种基于栈的指令集架构，另外一种指令集架构则是基于寄存器的指令集架构。\n基于栈式架构：\n\n设计和实现更简单，适用于资源受限的系统\n避开了寄存器的分配难题：使用零地址指令方式分配\n指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现\n不需要硬件支持\n\n基于寄存器架构：\n\n例如x86的二进制指令集\n指令集架构完全依赖硬件\n性能优秀，执行更高效\n花费更少指令完成一项操作\n通常为一地址指令、二地址指令、三地址指令。\n\n例如：计算2+3\n基于栈：\niconst_2 // 常量2入栈istore_1iconst_3 // 常量3入栈istore_2iload_1iload_2iadd  // 常量2，3出栈，执行相加istore_0 // 结果5入栈\n\n基于寄存器：\nmov eax,2 // 将eax寄存器值设为2add eax,3 // 使eax寄出器的值加3\n\n反编译字节码案例StackStruTest.java\npackage com.sicmatr1x.java;public class StackStruTest &#123;    public static void main(String[] args) &#123;        int i = 2;        int j = 3;        int k = i + j;    &#125;&#125;\n\n使用javap反编译指令反编译StackStruTest.class字节码文件：\njavap -v StackStruTest.class\n\n反编译结果：\n  Last modified 2020-7-30; size 486 bytes  MD5 checksum 618bcdd36b54bf88b6efa145bd258086  Compiled from &quot;StackStruTest.java&quot;public class com.sicmatr1x.java.StackStruTest  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #3.#21         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Class              #22            // com/sicmatr1x/java/StackStruTest   #3 = Class              #23            // java/lang/Object   #4 = Utf8               &lt;init&gt;   #5 = Utf8               ()V   #6 = Utf8               Code   #7 = Utf8               LineNumberTable   #8 = Utf8               LocalVariableTable   #9 = Utf8               this  #10 = Utf8               Lcom/sicmatr1x/java/StackStruTest;  #11 = Utf8               main  #12 = Utf8               ([Ljava/lang/String;)V  #13 = Utf8               args  #14 = Utf8               [Ljava/lang/String;  #15 = Utf8               i  #16 = Utf8               I  #17 = Utf8               j  #18 = Utf8               k  #19 = Utf8               SourceFile  #20 = Utf8               StackStruTest.java  #21 = NameAndType        #4:#5          // &quot;&lt;init&gt;&quot;:()V  #22 = Utf8               com/sicmatr1x/java/StackStruTest  #23 = Utf8               java/lang/Object&#123;  public com.sicmatr1x.java.StackStruTest();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 3: 0      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       5     0  this   Lcom/sicmatr1x/java/StackStruTest;  public static void main(java.lang.String[]);    descriptor: ([Ljava/lang/String;)V    flags: ACC_PUBLIC, ACC_STATIC    Code:      stack=2, locals=4, args_size=1         0: iconst_2         1: istore_1         2: iconst_3         3: istore_2         4: iload_1         5: iload_2         6: iadd         7: istore_3         8: return      LineNumberTable:        line 5: 0        line 6: 2        line 7: 4        line 8: 8      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       9     0  args   [Ljava/lang/String;            2       7     1     i   I            4       5     2     j   I            8       1     3     k   I&#125;SourceFile: &quot;StackStruTest.java&quot;\n\n看code部分：\nCode:    stack=2, locals=4, args_size=1        0: iconst_2 // 定义常量2        1: istore_1 // 保存到操作数1的栈中        2: iconst_3 // 定义常量3        3: istore_2 // 保存到操作数2的栈中        4: iload_1 // 加载操作数1的值        5: iload_2 // 加载操作数2的值        6: iadd // 求和        7: istore_3 // 保存到操作数3的栈中        8: return\n\nJVM的生命周期\n虚拟机的启动：JVM的启动时通过引导类加载器(bootstrap class loader)创建一个初始类(initial class)来完成的，这个类是由JVM的具体实现指定的。\n虚拟机的执行\n虚拟机的终止：\n\n\n程序正常执行结束\n程序在执行过程中遇到异常或错误而异常终止\n操作系统出现错误而导致JVM进程终止\n某线程调用Runtime类或System类的exit方法或Runtime类的halt方法，并且Java安全管理器也允许这个词exit或halt操作\nJNI(Java Native Interface)规范描述了用JNI Invocation API来加载或卸载JVM时JVM的退出情况\n\nJVM发展历程Sum Classic VM世界上第一款商用Java虚拟机，虚拟机内部只提供了解释器\nExact VMJDK1.2\n准确式内存管理(Exact Memory Management)：虚拟机可以知道内存中某个位置的数据具体是什么类型\nHotSpot VMJDK1.3\n是JDK6, JDK8默认虚拟机\nBEA的JRockit专注于服务器端应用\nJRockit JVM是世界上最快的JVM\nIBM的J9IBM Techology for Java Virtual Machine简称IT4J，内部代号J9\nKVM和CDC&#x2F;CLDC Hotspot目前移动领域地位尴尬，KVM简单、轻量、高度可移植，面向低端可移动设备\nAzul VMAzul VM和BEA Liquid VM与特定硬件平台绑定、软硬件配合的专有虚拟机\n每个Azul VM实例都可以管理至少数十个CPU和数百GB内存的硬件资源，提供在巨大内存内实现可控的GC时间的垃圾收集器、专有硬件优化的线程调度等\nBEA Liquid VMBEA开发用于自家Hypervisor系统，不需要操作系统的支持，它本身实现了一个专用操作系统的必要功能\nApache HarmonyJDK1.5, JDK1.6\n由IBM于Intel联合开发\nMicrosoft JVMTaobao JVM基于OpenJDK HotSpot VM深度定制且开源的高性能服务器\nDalvik VM是虚拟机但不是Java虚拟机，不能直接执行Java的class文件，美原油遵循Java虚拟机规范\n基于寄存器架构，不是JVM的栈架构，执行dex(Dalvik Executable)文件，可由class文件转化来\nGraal VMGraal VM在HotSpot VM基础上增强而成的跨语言全栈虚拟机，可以作为任何语言的运行平台使用(包括：Java, Scala, Groovy, Kotlin; C, C++, JavaScript, Ruby, Python, R等)\n支持不同语言中混用对方的接口和对象，支持这些语言使用已经编写好的本地库文件。工作原理是将这些语言的源码或源码编译后的中间格式通过解释器转换成能被Graal VM接受的中间表示。\n还提供Truffle工具集快速构建面向一种新语言的解释器。\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-2_类加载子系统","url":"/2022/08/23/JVM/JVM-2_%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/","content":"内存与垃圾回收内存结构概述\n\n\n\n\n类加载子系统负责从文件系统或网络中加载class文件，class文件在文件开头有特定的文件标识\nClassLoader只负责class文件的加载，至于它是否可以运行，则由Execution Engine决定\n加载的类信息存放在叫做方法区的内存空间。除了类信息外，方法区还存放运行时常量池信息，可能还有字符串和数字常量\nclass file加载到JVM中被称为DNA元数据模板，放在方法区\n字节码文件.class使用二进制查看器打开任意字节码文件可以观察到期开头4个字节用十六进制表示为CA FE BA BE(可记为咖啡宝贝)，这是字节码文件固定头部\n1. 加载 Loading\n通过一个类的全限定名获取定义此类的二进制字节流\n将这个字节流所代表的今天存储结构转化为方法区的运行时数据结构\n在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n\n可以从哪些地方加载.class文件呢：\n\n本地文件加载\n网络获取，典型场景：web Applet\nzip压缩包中读取\n运行时计算生成，使用最多的是：动态代理技术\n其它文件生成，例如：JSP应用\n专有数据库提取.class文件，少见\n加密文件中获取，可防止class文件被反编译\n\n2. 链接 Linking该阶段分为以下几步：\n\n验证(Verify)\n\n\n目的在于确保class文件的字节流中包含信息符合当前虚拟机的要求，保证被加载类的正确性，不会危害虚拟机自身安全\n主要包括四种验证：\n文件格式验证\n元数据验证\n字节码验证\n符号引用验证\n\n\n\n\n准备(Prepare)\n\n\n为变量分配内存并且设置该类变量的默认初始值，即零值\n这里不包含用final修饰的static，因为final在编译的时候就会分配了，准备阶段会显示初始化\n这里不会为实例变量分配初始化，类变量会分配在方法区中，而实例变量会随着对象一起分配到java堆中\n\n\n解析(Resolve)\n\n\n将常量池内的符号引用转换为直接引用的过程\n解析操作往往伴随JVM在执行完初始化之后再执行\n符号引用就是一组符号来描述所引用的目标。\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。\n\n3. 初始化 Initialization\n初始化阶段就是执行类构造器方法&lt;clinit&gt;()的过程\n此方法不需定义，是由javac编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并而来\n构造器方法中指令按语句在源文件中出现的顺序执行\n&lt;clinit&gt;()不同于类的构造器&lt;init&gt;()，若一个类中没有静态变量和静态代码块则字节码文件中无&lt;clinit&gt;()方法\n虚拟机必须保证一个类的&lt;clinit&gt;()方法在多线程下被同步加锁\n\npackage com.sicmatr1x.java;public class ClinitTest &#123;    private int a = 1;    private static int c = 3;    public static void main(String[] args) &#123;        int b = 2;    &#125;    public ClinitTest() &#123;        a = 10;        int d = 20;    &#125;&#125;\n\n反编译字节码文件可以看到存在&lt;clinit&gt;()和&lt;init&gt;()\n&lt;init&gt;如下：\n 0 aload_0 1 invokespecial #1 &lt;java/lang/Object.&lt;init&gt;&gt; 4 aload_0 5 iconst_1 6 putfield #2 &lt;com/sicmatr1x/java/ClinitTest.a&gt; 9 aload_010 bipush 1012 putfield #2 &lt;com/sicmatr1x/java/ClinitTest.a&gt;15 bipush 2017 istore_118 return\n\n可以看到先给a赋值10再给d赋值20\n类的加载过程类加载器的分类JVM支持两种类型的类加载器：\n\n引导类加载器(Bootstrap ClassLoader)\n自定义类加载器(User-Defined ClassLoader)：所有派生于抽象类ClassLoader的类加载器都可划分为自定义类加载器\n\n启动类加载器(引导类加载器, Bootstrap ClassLoader)：\n\n使用C&#x2F;C++语言实现，嵌套在JVM内部\n用于加载Java的核心库(JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;rt.jar, resources.jar或sun.boot.class.path路径下的内容)\n不继承于java.lang.ClassLoader，没有父加载器\n加载扩展类和应用程序类加载器，并制定为他们的父类加载器\n处于安全考虑，Bootstrap启动类加载器只加载包名为java, javax, sun等开头的类\n\n扩展类加载器(Extension ClassLoader)\n\nJava语言编写，由sun.misc.Launcher$ExtClassLoader实现\n派生于ClassLoader类\n父类加载器为启动类加载器\n从java.ext.dirs系统属性所指定的目录中加载类库，或从JDK的安装目录的jre&#x2F;lib&#x2F;ext子目录下加载类库。如果用户创建的JAR放在此目录，也会自动由扩展类加载器加载。\n\n应用程序类加载器(系统类加载器, AppClassLoader)\n\nJava语言编写，由sun.misc.Launcher$AppClassLoader实现\n派生于ClassLoader类\n父类加载器为扩展类加载器\n负责加载环境变量classpath或系统属性java.class.path指定路径下的类库\n该类加载器是程序中默认的类加载器，通常Java应用的类都由它来加载\n通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器\n\n获取Bootstrap ClassLoader类加载器和Extension ClassLoader类加载器可以加载的路径和jar包\npackage com.sicmatr1x.java;import sun.misc.Launcher;import sun.misc.URLClassPath;import java.net.URL;public class ClassLoaderTest1 &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;引导类加载器：&quot;);        URLClassPath urlClassPath = Launcher.getBootstrapClassPath();        URL[] urls = urlClassPath.getURLs();        for (URL url : urls) &#123;            System.out.println(url.toExternalForm());        &#125;        System.out.println(&quot;扩展类加载器：&quot;);        String extDirs = System.getProperty(&quot;java.ext.dirs&quot;);        for (String dir : extDirs.split(&quot;;&quot;)) &#123;            System.out.println(dir);        &#125;    &#125;&#125;\n\n引导类加载器：file:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/resources.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/rt.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/sunrsasign.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/jsse.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/jce.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/charsets.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/lib/jfr.jarfile:/C:/Program%20Files/Java/jdk1.8.0_231/jre/classes扩展类加载器：C:\\Program Files\\Java\\jdk1.8.0_231\\jre\\lib\\extC:\\Windows\\Sun\\Java\\lib\\ext\n\n用户自定义类加载器：\n\n什么时候需要用户自定义类加载器：\n隔离加载类：例如：确保应用中引用的jar包与中间件引用的第三方jar包不冲突\n修改类加载方式：例如：需要时候动态加载\n扩展加载源：例如：从数据库中加载\n防止源码泄露\n\n\n用户自定义类加载器实现步骤：\n开发人员可以通过继承抽象类java.lang.ClassLoader类的方式实现自己的类加载器\n在JDK1.2之前，自定义类加载器需要继承ClassLoader类并重写loadClass()方法，从而实现自定义的类加载器。JDK1.2之后不建议用户覆盖loadClass()方法，建议把自定义的类加载逻辑写在findClass()方法中\n编写自定义类加载器时若无过于复杂的需求建议直接继承URLClassLoader类，这样可以避免自己去编写findClass()方法及获取字节码流的方式，是自定义类加载器编写更加简洁\n\n\n\npackage com.sicmatr1x.java;import java.io.FileNotFoundException;public class CustomClassLoader extends ClassLoader&#123;    @Override    protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123;        try &#123;            byte[] result = getClassFromCustomPath(name);            if(result == null)&#123;                throw new FileNotFoundException();            &#125;else&#123;                return defineClass(name,result,0,result.length);            &#125;        &#125; catch (FileNotFoundException e) &#123;            e.printStackTrace();        &#125;        throw new ClassNotFoundException(name);    &#125;    private byte[] getClassFromCustomPath(String name)&#123;        //从自定义路径中加载指定类:细节略        //如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。        return null;    &#125;    public static void main(String[] args) &#123;        CustomClassLoader customClassLoader = new CustomClassLoader();        try &#123;            Class&lt;?&gt; clazz = Class.forName(&quot;One&quot;,true,customClassLoader);            Object obj = clazz.newInstance();            System.out.println(obj.getClass().getClassLoader());        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\n\n关于ClassLoader常用方法：\n\ngetParent(): 返回该类加载器的超类加载器\nloadClass(String name): 加载名称为name的类，返回结果为java.lang.Class类的实例\nfindClass(String name): 查找名称为name的类，返回结果为java.lang.Class类的实例\nfindLoadedClass(String name): 查找名称为name的已经被加载过的类，返回结果为java.lang.Class类的实例\ndefineClass(String name, byte[] b, int off, int len): 把字节数组b中的内容转换为一个Java类，返回结果为java.lang.Class类的实例\nresolveClass(Class&lt;?&gt; c): 连接指定的一个Java类\n\n双亲委派机制JVM对class文件采用按需加载的方式，即需要使用到该类时才会把class文件加载到内存生成class对象。而且在加载时JVM采用的是双亲委派机制，即把请求交由父类处理，它是一种任务委派模式。\n\n如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行\n如果父类加载器还存在其父类加载器，则进一步向上委托，一次递归，请求最终将到达顶层的启动类加载器\n如果父类加载器可以完成类加载任务，就成功返回，若无法完成，子类加载器才会去加载。\n\n优点：\n\n避免类的重复加载：一旦一个类被父加载器加载则不会再被子加载器加载\n保护程序安全，防止核心API被篡改：比如你自己定义一个java.lang.String就不会被AppClassLoader加载而是Bootstrap ClassLoader加载java的String\n\n沙箱安全机制：自定义String类在加载的时候回率先使用引导类加载器加载，而引导类加载器会先加载JDK自带的文件rt.jar包中的java\\lang\\String.class，这样可以保证对java核心源代码的保护\n其它JVM中表示两个class对象是否为同一个类存在的两个必要条件：\n\n类的完整类名必须一致，包括包名\n加载这个类的ClassLoader(指ClassLoader实例对象)必须相同\n\n对类加载器的引用JVM知道一个类时由启动类加载器加载器加载的还是由用户类加载器加载的。若是由用户类加载器加载的，JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中。当解析一个类到另一个类的时候，JVM需要保证这两个类的类加载器是相同的。\n类的主动使用与被动使用主动使用的七种情况：\n\n创建类的实例\n访问某个类或接口的静态变量，或对该静态变量赋值\n调用类的静态方法\n反射\n初始化一个类的子类\nJava虚拟机启动时被标明为启动类的类\nJDK7开始提供动态语言支持：\n\n\njava.lang,invoke.MethodHandle实例的解析结果\nREF_getStatic, REF_putStatic, REF_invokeStatic句柄对应的类没有初始化，则初始化\n\n除了主动使用的七种情况外都算被动使用\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-3_运行时数据区概述及线程","url":"/2022/04/06/JVM/JVM-3_%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E6%A6%82%E8%BF%B0%E5%8F%8A%E7%BA%BF%E7%A8%8B/","content":"运行时数据区(Runtime Data Area)内部结构运行时数据区的完整图\n\n\n运行时数据区可简单分为：\n\n程序计数器(Program Counter Register, 或PC寄存器)\n虚拟机栈(Java Virtual Machine Stack)\n本地方法栈(Native Method Stack)\n堆(Heap)\n方法区(Method Area)\n\n\n\nJava虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程对应的数据区域会随着线程开始和结束而创建和销毁。\n\n每个线程：独立包括程序计数器、栈、本地栈。\n线程间共享：堆、堆外内存（永久代或元空间、代码缓存）\n\n\n\n线程线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行。在Hotspot JVM里，每个线程都与操作系统的本地线程直接映射。\n\n当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收。\n\n操作系统负责所有线程的安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，它就会调用Java线程中的run()方法。\nJVM系统线程如果你使用console或者是任何一个调试工具，都能看到在后台有许多线程在运行。这些后台线程不包括调用public static void main（String[]）的main线程以及所有这个main线程自己创建的线程。|这些主要的后台系统线程在Hotspot JVM里主要是以下几个：\n\n虚拟机线程：这种线程的操作是需要JVM达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要JVM达到安全点，这样堆才不会变化。这种线程的执行类型包括”stop-the-world”的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销。\n周期任务线程：这种线程是时间周期事件的体现（比如中断），他们一般用于周期性操作的调度执行。\nGC线程：这种线程对在JVM里不同种类的垃圾收集行为提供了支持。\n编译线程：这种线程在运行时会将字节码编译成到本地代码。\n信号调度线程：这种线程接收信号并发送给JVM，在它内部通过调用适当的方法进行处理。\n\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-4_程序计数器","url":"/2022/04/16/JVM/JVM-4_%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8/","content":"程序计数器JVM中的程序计数寄存器（Program Counter Register）中，Register的命名源于CPU的寄存器，寄存器存储指令相关的现场信息。CPU只有把数据装载到寄存器才能够运行。这里，并非是广义上所指的物理寄存器，或许将其翻译为PC计数器（或指令计数器）会更加贴切（也称为程序钩子），并且也不容易引起一些不必要的误会。JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟。\n作用：PC寄存器用来存储指向下一条指令的地址，也即将要执行的指令代码。由执行引擎读取下一条指令。\n在JVM规范中，每个线程都要它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。\n任何时间都只有一个方法在执行，程序计数器会存储当前线程正在执行的Java方法的JVM指令地址，若为native方法则为undefined\n面试常见问题\n使用PC寄存器存储字节码指令地址有什么用？为什么使用PC寄存器记录当前线程的执行地址？\n\n因为CPU需要不停的切换各个线程，这时候切换回来以后就需要知道从哪开始继续执行。JVM的字节码解释器需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。\n\nPC寄存器为什么会被设定为线程私有？\n\n我们都知道所谓的多线程在一个特定的时间段内只会执行其中某一个线程的方法，CPU会不停地做任务切换，这样必然导致经常中断或恢复，如何保证分毫无差呢？为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PC寄存器，这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。\n由于CPU时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。\n这样必然导致经常中断或恢复，如何保证分毫无差呢？每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器在各个线程之间互不影响。\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-5_虚拟机栈","url":"/2022/05/01/JVM/JVM-5_%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/","content":"堆与栈首先栈是运行时的单位，而堆是存储的单位\n\n栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。\n堆解决的是数据存储的问题，即数据怎么放，放哪里\n\n虚拟机栈Java虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的Java方法调用。\n\n每个方法执行，伴随着进栈（入栈、压栈）\n执行结束后的出栈工作\n\n对于栈来说不存在垃圾回收问题（栈存在溢出的情况）\n虚拟机栈包括多个栈帧，每个栈帧包括：\n\n局部变量表\n操作数栈\n动态链接\n方法返回地址\n\n栈中可能出现的异常Java 虚拟机规范允许Java栈的大小是动态的或者是固定不变的。\n如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将会抛出一个StackOverflowError 异常。\n如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个OutOfMemoryError 异常。\n设置栈内存大小我们可以使用参数 -Xss选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度，可以设置到idea的VM Options里面\n-Xss1m-Xss1k\n\n栈的存储单位每个线程都有自己的栈，栈中的数据都是以栈帧（Stack Frame）的格式存在。\n在这个线程上正在执行的每个方法都各自对应一个栈帧（Stack Frame）。\n栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。\n在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只用当前正在执行方法的栈帧(栈顶栈帧)是有效的，也被称为当前栈帧(Current Frame)，与当前栈帧相对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class）\n执行引擎运行的所有字节码指令只针对当前栈帧进行操作。\n如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前帧。\n栈运行原理不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。\n如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧。\nJava方法有两种返回函数的方式，一种是正常的函数返回，使用return指令；另外一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。\n栈帧的内部结构每个栈帧中存储着：\n\n局部变量表（Local Variables）\n操作数栈（operand Stack）（或表达式栈）\n动态链接（DynamicLinking）（或指向运行时常量池的方法引用）\n方法返回地址（Return Address）（或方法正常退出或者异常退出的定义）\n一些附加信息\n\n\n\n局部变量表(Local Variables)局部变量表：Local Variables，被称之为局部变量数组或本地变量表\n定义为一个数字数组，主要用于存储方法参数和定义在方法体内的局部变量。这些数据类型包括各类基本数据类型、对象引用（reference），以及returnAddress类型。\n由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题\n局部变量表所需的容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum local variables数据项中。在方法运行期间是不会改变局部变量表的大小的。\n方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。\n局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。\n关于Slot的理解参数值的存放总是在局部变量数组的index0开始，到数组长度-1的索引结束。\n局部变量表，最基本的存储单元是Slot（变量槽）局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型（reference），returnAddress类型的变量。\n在局部变量表里，32位以内的类型只占用一个slot（包括returnAddress类型），64位的类型（long和double）占用两个slot。\n\nbyte、short、char 在存储前被转换为int，boolean也被转换为int，0表示false，非0表示true。long和double则占据两个slot。\n\nJVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值\n当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个slot上\n如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。（比如：访问long或double类型变量）\n如果当前帧是由构造方法或者实例方法创建的，那么该对象引用this将会存放在index为0的slot处，其余的参数按照参数表顺序继续排列。\n\n\n栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。\n静态变量与局部变量的对比变量的分类：\n\n按数据类型分：基本数据类型、引用数据类型\n按类中声明的位置分：成员变量（类变量，实例变量）、局部变量\n类变量：linking的paper阶段，给类变量默认赋值，init阶段给类变量显示赋值即静态代码块\n实例变量：随着对象创建，会在堆空间中分配实例变量空间，并进行默认赋值\n局部变量：在使用前必须进行显式赋值，不然编译不通过。\n\n\n\n我们知道类变量表有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。\n和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。\n在栈帧中，与性能调优关系最为密切的部分就是前面提到的局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递。\n局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收。\n操作数栈操作数栈：Operand Stack\n每一个独立的栈帧除了包含局部变量表以外，还包含一个后进先出（Last - In - First -Out）的 操作数栈，也可以称之为 表达式栈（Expression Stack）\n操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈（push）和 出栈（pop）\n\n某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈\n比如：执行复制、交换、求和等操作\n\n\n\n操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间。\n操作数栈就是JVM执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，这个方法的操作数栈是空的。\n反编译字节码解读示例package com.sicmatr1x.java;public class OperandStackTest &#123;    public void testAddOperation() &#123;        byte i = 15;        int j = 8;        int k = i + j;    &#125;&#125;\n\n  Last modified 2020-8-5; size 459 bytes  MD5 checksum 0c86be65af756c867db277302bedf1fa  Compiled from &quot;OperandStackTest.java&quot;public class com.sicmatr1x.java.OperandStackTest  minor version: 0  major version: 52  flags: ACC_PUBLIC, ACC_SUPERConstant pool:   #1 = Methodref          #3.#19         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Class              #20            // com/sicmatr1x/java/OperandStackTest   #3 = Class              #21            // java/lang/Object   #4 = Utf8               &lt;init&gt;   #5 = Utf8               ()V   #6 = Utf8               Code   #7 = Utf8               LineNumberTable   #8 = Utf8               LocalVariableTable   #9 = Utf8               this  #10 = Utf8               Lcom/sicmatr1x/java/OperandStackTest;  #11 = Utf8               testAddOperation  #12 = Utf8               i  #13 = Utf8               B  #14 = Utf8               j  #15 = Utf8               I  #16 = Utf8               k  #17 = Utf8               SourceFile  #18 = Utf8               OperandStackTest.java  #19 = NameAndType        #4:#5          // &quot;&lt;init&gt;&quot;:()V  #20 = Utf8               com/sicmatr1x/java/OperandStackTest  #21 = Utf8               java/lang/Object&#123;  public com.sicmatr1x.java.OperandStackTest();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=1, locals=1, args_size=1         0: aload_0         1: invokespecial #1                  // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V         4: return      LineNumberTable:        line 3: 0      LocalVariableTable:        Start  Length  Slot  Name   Signature            0       5     0  this   Lcom/sicmatr1x/java/OperandStackTest;  public void testAddOperation();    descriptor: ()V    flags: ACC_PUBLIC    Code:      stack=2, locals=4, args_size=1         0: bipush        15         2: istore_1         3: bipush        8         5: istore_2         6: iload_1         7: iload_2         8: iadd         9: istore_3        10: return      LineNumberTable:        line 5: 0        line 6: 3        line 7: 6        line 8: 10      LocalVariableTable:        Start  Length  Slot  Name   Signature            0      11     0  this   Lcom/sicmatr1x/java/OperandStackTest;            3       8     1     i   B            6       5     2     j   I           10       1     3     k   I&#125;SourceFile: &quot;OperandStackTest.java&quot;\n\n常量池：\nConstant pool:   #1 = Methodref          #3.#19         // java/lang/Object.&quot;&lt;init&gt;&quot;:()V   #2 = Class              #20            // com/sicmatr1x/java/\n\n如果操作指令有用到常量池里的常量会出现#2这样的表示调用的是哪个常量\nCode:  stack=1, locals=1, args_size=1\n\n这里的stack=1表示操作数栈深度为1，locals=4表示本地变量表长度为4\n本地变量表：\nLocalVariableTable:  Start  Length  Slot  Name   Signature      0      11     0  this   Lcom/sicmatr1x/java/OperandStackTest;      3       8     1     i   B      6       5     2     j   I     10       1     3     k   I\n\n这里的start和length指的是该变量的生命周期对应操作指令的地址。这里因为没有double, long所以都是每个变量占用一个slot。byte, short, char, boolean都以int型来保存\n分析操作指令：\n0: bipush        152: istore_13: bipush        85: istore_26: iload_17: iload_28: iadd9: istore_310: return\n\n手动执行指令，因为局部变量表所需的容量大小是在编译期确定下来的，所以这里没值的用[]来占位，且省略局部变量表第0号元素this：\n\n0: bipush        15\nPC寄存器: 0\n局部变量表: \n[]\n[]\n[]\n\n\n操作数栈 : \n[]\n[15] &lt;-栈顶\n\n\n\n\n2: istore_1: i指int类型，store存放到局部变量表，_1索引位1的位置\nPC寄存器: 2\n局部变量表: \n[15]\n[]\n[]\n\n\n操作数栈 : \n[]\n[] &lt;-栈顶\n\n\n\n\n3: bipush        8\nPC寄存器: 3\n局部变量表: \n[15]\n[]\n[]\n\n\n操作数栈 : \n[]\n[8] &lt;-栈顶\n\n\n\n\n5: istore_2\nPC寄存器: 2\n局部变量表: \n[15]\n[8]\n[]\n\n\n操作数栈 : \n[]\n[] &lt;-栈顶\n\n\n\n\n6: iload_1: 从局部比那里表中取索引位1的数据到操作数栈\nPC寄存器: 6\n局部变量表: \n[15]\n[8]\n[]\n\n\n操作数栈 : \n[]\n[15] &lt;-栈顶\n\n\n\n\n7: iload_2: 从局部比那里表中取索引位2的数据到操作数栈\nPC寄存器: 7\n局部变量表: \n[15]\n[8]\n[]\n\n\n操作数栈 : \n[8] &lt;-栈顶\n[15]\n\n\n\n\n8: iadd: 操作数栈出栈并做加法运算\nPC寄存器: 8\n局部变量表: \n[15]\n[8]\n[]\n\n\n操作数栈 : \n[]\n[23] &lt;-栈顶\n\n\n\n\n9: istore_3\nPC寄存器: 9\n局部变量表: \n[15]\n[8]\n[23]\n\n\n操作数栈 : \n[]\n[] &lt;-栈顶\n\n\n\n\n\n如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。\n操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译器期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。|\n另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。\n最后PC寄存器的位置指向10，也就是return方法，则直接退出方法\ni++和++i的区别\n栈顶缓存技术栈顶缓存技术：Top Of Stack Cashing\n前面提过，基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读&#x2F;写次数。\n由于操作数是存储在内存中的，因此频繁地执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存（Tos，Top-of-Stack Cashing）技术，将栈顶元素全部缓存在物理CPU的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率。\n\n寄存器：指令更少，执行速度快\n\n动态链接(Dynamic Linking)\n\n\n动态链接、方法返回地址、附加信息 ： 有些地方被称为帧数据区\n\n每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用，包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接（Dynamic Linking）。比如：invokedynamic指令\n在Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（symbolic Reference）保存在class文件的常量池里。\n比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用。\n\n\n\n为什么需要运行时常量池？\n因为在不同的方法，都可能调用常量或者方法，所以只需要存储一份即可，节省了空间\n常量池的作用：就是为了提供一些符号和常量，便于指令的识别\n\n方法调用：解析与分配在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关\n静态链接当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时，这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接\n动态链接如果被调用的方法在编译期无法被确定下来，也就是说，只能够在程序运行期将调用的方法的符号转换为直接引用，由于这种引用转换过程具备动态性，因此也被称之为动态链接。\n绑定机制对应的方法的绑定机制为：早期绑定（Early Binding）或静态绑定和晚期绑定（Late Binding）或动态绑定（auto binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。\n早期绑定：\n早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。\n晚期绑定：\n如果被调用的方法在编译期无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式也就被称之为晚期绑定。\nJava中任何一个普通的方法其实都具备虚函数的特征，它们相当于C++语言中的虚函数（C++中则需要使用关键字virtual来显式定义）。如果在Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字final来标记这个方法。\n相信大家都知道，java的三大特性：封装，继承和多态，动态绑定就和多态有关。\n由于继承和重写的存在，当方法中的类型为父类的时候，编译的时候不太好判断，方法到底要和哪个类绑定，也就是调用的方法依赖于隐式参数的实际类型。\n虚方法和非虚方法\n如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法。\n静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。\n其他方法称为虚方法。\n\n\n子类对象的多态的使用前提\n\n类的继承关系\n方法的重写\n\n\n虚拟机中提供了以下几条方法调用指令：\n普通调用指令：\n\ninvokestatic：调用静态方法，解析阶段确定唯一方法版本\ninvokespecial：调用&lt;init&gt;方法、私有及父类方法，解析阶段确定唯一方法版本\ninvokevirtual：调用所有虚方法\ninvokeinterface：调用接口方法\n\n动态调用指令：\n\ninvokedynamic：动态解析出需要调用的方法，然后执行\n\n前四条指令固化在虚拟机内部，方法的调用执行不可人为干预，而invokedynamic指令则支持由用户确定方法版本。其中invokestatic指令和invokespecial指令调用的方法称为非虚方法，其余的（final修饰的除外）称为虚方法。\ninvokednamic指令JVM字节码指令集一直比较稳定，一直到Java7中才增加了一个invokedynamic指令，这是Java为了实现动态类型语言】支持而做的一种改进。\n但是在Java7中并没有提供直接生成invokedynamic指令的方法，需要借助ASM这种底层字节码工具来产生invokedynamic指令。直到Java8的Lambda表达式的出现，invokedynamic指令的生成，在Java中才有了直接的生成方式。\nJava7中增加的动态语言类型支持的本质是对Java虚拟机规范的修改，而不是对Java语言规则的修改，这一块相对来讲比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言的编译器。\n动态类型语言和静态类型语言动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期，满足前者就是静态类型语言，反之是动态类型语言。\n说的再直白一点就是，静态类型语言是判断变量自身的类型信息；动态类型语言是判断变量值的类型信息，变量没有类型信息，变量值才有类型信息，这是动态语言的一个重要特征。\n\nJava：String info &#x3D; “mogu blog”;     (Java是静态类型语言的，会先编译就进行类型检查)\nJS：var name &#x3D; “shkstart”;    var name &#x3D; 10;    （运行时才进行检查）\n\n方法重写的本质注意：在调用对象方法前会将这个对象的引用压入操作数栈顶，因为后面需要需到其实际类型\nJava 语言中方法重写的本质：\n\n找到操作数栈顶的第一个元素所执行的对象的实际类型，记作C。\n如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，如果通过则返回这个方法的直接引用，查找过程结束；如果不通过，则返回java.lang.IllegalAccessError 异常。\n否则，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。\n如果始终没有找到合适的方法，则抛出java.lang.AbstractMethodsrror异常。\n\nIllegalAccessError介绍：程序试图访问或修改一个属性或调用一个方法，这个属性或方法，你没有权限访问。一般的，这个会引起编译器异常。这个错误如果发生在运行时，就说明一个类发生了不兼容的改变\n方法的调用：虚方法表在面向对象的编程中，会很频繁的使用到动态分派，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用在类的方法区建立一个虚方法表（virtual method table）（非虚方法不会出现在表中）来实现。使用索引表来代替查找。\n每个类中都有一个虚方法表，表中存放着各个方法的实际入口。\n虚方法表是什么时候被创建的呢？\n虚方法表会在类加载的链接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的方法表也初始化完毕。\n方法返回地址存放调用该方法的pc寄存器的值。一个方法的结束，有两种方式：\n\n正常执行完成\n\n出现未处理的异常，非正常退出\n\n\n无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的pc计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。\n当一个方法开始执行后，只有两种方式可以退出这个方法：\n执行引擎遇到任意一个方法返回的字节码指令（return），会有返回值传递给上层的方法调用者，简称正常完成出口；\n\n一个方法在正常调用完成之后，究竟需要使用哪一个返回指令，还需要根据方法返回值的实际数据类型而定。\n在字节码指令中，返回指令包含ireturn（当返回值是boolean，byte，char，short和int类型时使用），lreturn（Long类型），freturn（Float类型），dreturn（Double类型），areturn。另外还有一个return指令声明为void的方法，实例初始化方法，类和接口的初始化方法使用。\n\n在方法执行过程中遇到异常（Exception），并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，简称异常完成出口。\n方法执行过程中，抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码\n\n\n本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。\n正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。\n一些附加信息栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如：对程序调试提供支持的信息。\n栈的相关面试题\n举例栈溢出的情况？(StackOverflowError)\n通过虚拟机参数-Xss设置栈的大小\nJava 虚拟机规范允许Java栈的大小是动态的或者是固定不变的：\n固定不变的：如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，JVM将会抛出一个StackOverflowError 异常。\n动态的：如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，JVM将会抛出一个OutOfMemoryError 异常。\n\n\n\n\n调整栈大小，就能保证不出现溢出么？\n不能保证不溢出\n\n\n分配的栈内存越大越好么？\n不是，一定时间内降低了OOM概率，但是会挤占其它的线程空间，因为整个空间是有限的。\n\n\n垃圾回收是否涉及到虚拟机栈？\n不会\n\n\n方法中定义的局部变量是否线程安全？\n具体问题具体分析\n\n\n\n/** * 面试题 * 方法中定义局部变量是否线程安全？具体情况具体分析 * 何为线程安全？ *    如果只有一个线程才可以操作此数据，则必是线程安全的 *    如果有多个线程操作，则此数据是共享数据，如果不考虑共享机制，则为线程不安全 */public class StringBuilderTest &#123;    // s1的声明方式是线程安全的    public static void method01() &#123;        // 线程内部创建的，属于局部变量        StringBuilder s1 = new StringBuilder();        s1.append(&quot;a&quot;);        s1.append(&quot;b&quot;);    &#125;    // 这个也是线程不安全的，因为有返回值，有可能被其它的程序所调用    public static StringBuilder method04() &#123;        StringBuilder stringBuilder = new StringBuilder();        stringBuilder.append(&quot;a&quot;);        stringBuilder.append(&quot;b&quot;);        return stringBuilder;    &#125;    // stringBuilder 是线程不安全的，操作的是共享数据    public static void method02(StringBuilder stringBuilder) &#123;        stringBuilder.append(&quot;a&quot;);        stringBuilder.append(&quot;b&quot;);    &#125;    /**     * 同时并发的执行，会出现线程不安全的问题     */    public static void method03() &#123;        StringBuilder stringBuilder = new StringBuilder();        new Thread(() -&gt; &#123;            stringBuilder.append(&quot;a&quot;);            stringBuilder.append(&quot;b&quot;);        &#125;, &quot;t1&quot;).start();        method02(stringBuilder);    &#125;    // StringBuilder是线程安全的，但是String也可能线程不安全的    public static String method05() &#123;        StringBuilder stringBuilder = new StringBuilder();        stringBuilder.append(&quot;a&quot;);        stringBuilder.append(&quot;b&quot;);        return stringBuilder.toString();    &#125;&#125;\n\n总结一句话就是：如果对象是在内部产生，并在内部消亡，没有返回到外部，那么它就是线程安全的，反之则是线程不安全的。\n运行时数据区，是否存在Error和GC？\n运行时数据区各部分是否存在Error与GC：\n\n程序计数器\nError: 不存在\nGC: 不存在，空间小速度快，没必要\n\n\n虚拟机栈\nError: 存在，比如StackOverflowError\nGC: 不存在，只有进栈出栈，出栈即可\n\n\n本地方法栈\nError: 存在\nGC: 不存在，空间小速度快，没必要\n\n\n堆\nError: 存在，比如OutOfMemoryError\nGC: 存在\n\n\n方法区\nError: 存在\nGC: 存在\n\n\n\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-6_本地方法接口","url":"/2022/05/16/JVM/JVM-6_%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%8E%A5%E5%8F%A3/","content":"什么是本地方法简单地讲，一个Native Methodt是一个Java调用非Java代码的接囗。一个Native Method是这样一个Java方法：该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其它的编程语言都有这一机制，比如在C++中，你可以用extern “c” 告知c++编译器去调用一个c的函数。\n“A native method is a Java method whose implementation is provided by non-java code.”（本地方法是一个非Java的方法，它的具体实现是非Java代码的实现）\n在定义一个native method时，并不提供实现体（有些像定义一个Java interface），因为其实现体是由非java语言在外面实现的。\n本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C&#x2F;C++程序。\n\n\n为什么使用Native Method？\n\n与Java环境的交互：有时Java应用需要与Java外面的环境交互，这是本地方法存在的主要原因。你可以想想Java需要与一些底层系统，如操作系统或某些硬件交换信息时的情况。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐的细节。\n与操作系统的交互：JVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一底层系统的支持。这些底层系统常常是强大的操作系统。通过使用本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用c写的。还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。\n\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-7_本地方法栈","url":"/2022/05/20/JVM/JVM-7_%E6%9C%AC%E5%9C%B0%E6%96%B9%E6%B3%95%E6%A0%88/","content":"Java虚拟机栈于管理Java方法的调用，而本地方法栈用于管理本地方法的调用。\n本地方法栈，也是线程私有的。\n允许被实现成固定或者是可动态扩展的内存大小。（在内存溢出方面是相同的）\n\n如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个stackoverflowError 异常。\n如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么Java虚拟机将会抛出一个outofMemoryError异常。\n\n本地方法是使用C语言实现的。\n它的具体做法是Native Method Stack中登记native方法，在Execution Engine 执行时加载本地方法库。\n\n\n当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。\n\n本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区。\n它甚至可以直接使用本地处理器中的寄存器\n直接从本地内存的堆中分配任意数量的内存。\n\n并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果JVM产品不打算支持native方法，也可以无需实现本地方法栈。\n在Hotspot JVM中，直接将本地方法栈和虚拟机栈合二为一\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-9_方法区","url":"/2022/06/20/JVM/JVM-9_%E6%96%B9%E6%B3%95%E5%8C%BA/","content":"什么是方法区PermGen（永久代）PermGen ， 就是 PermGen space ，全称是 Permanent Generation space ，是指内存的永久保存区域。这块内存主要是被JVM存放Class和Meta信息的， Class 在被 Loader 时就会被放到 PermGen space 中。\n绝大部分 Java 程序员应该都见过 java.lang.OutOfMemoryError: PermGen space 这个异常。这里的 PermGen space 其实指的就是 方法区 。不过方法区和 PermGen space又有着本质的区别。\n方法区 是 JVM 的规范，所有虚拟机 必须遵守的。\nPermGen space 则是 HotSpot 虚拟机 基于 JVM 规范对 方法区 的一个落地实现， 并且只有 HotSpot 才有 PermGen space。\n而如 JRockit（Oracle）、J9（IBM） 虚拟机有 方法区 ，但是就没有 PermGen space。\nPermGen space 是 JDK7及之前， HotSpot 虚拟机 对 方法区 的一个落地实现。在JDK8被移除。\nMetaspace（元空间）是 JDK8及之后， HotSpot 虚拟机 对 方法区 的新的实现。\nJDK6、JDK7 时，方法区 就是 PermGen（永久代）。\nJDK8 时，方法区就是 Metaspace（元空间）\n复习一下Java运行时数据区\n\n从线程共享与否的角度来看\n\n\nThreadLocal：如何保证多个线程在并发环境下的安全性？典型应用就是数据库连接管理，以及会话管理\n栈、堆、方法区的交互关系下面就涉及了对象的访问定位\n\n\n\nPerson：存放在元空间，也可以说方法区\nperson：存放在Java栈的局部变量表中\nnew Person()：存放在Java堆中\n\n方法区的理解《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。”但对于HotSpotJVM而言，方法区还有一个别名叫做Non-Heap（非堆），目的就是要和堆分开。\n所以，方法区看作是一块独立于Java堆的内存空间。\n\n\n方法区主要存放的是 Class，而堆中主要存放的是 实例化的对象\n\n方法区（Method Area）与Java堆一样，是各个线程共享的内存区域。\n方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以是不连续的。\n方法区的大小，跟堆空间一样，可以选择固定大小或者可扩展。\n方法区的大小决定了系统可以保存多少个类，如果系统定义了太多的类，导致方法区溢出，虚拟机同样会抛出内存溢出错误：java.lang.OutofMemoryError：PermGen space 或者java.lang.OutOfMemoryError:Metaspace\n加载大量的第三方的jar包\nTomcat部署的工程过多（30~50个）\n大量动态的生成反射类\n\n\n关闭JVM就会释放这个区域的内存。\n\nHotSpot中方法区的演进在jdk7及以前，习惯上把方法区，称为永久代。jdk8开始，使用元空间取代了永久代。\n\nJDK 1.8后，元空间存放在堆外内存中\n\n本质上，方法区和永久代并不等价。仅是对hotspot而言的。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEAJRockit &#x2F; IBM J9 中不存在永久代的概念。            \n\n现在来看，当年使用永久代，不是好的idea。导致Java程序更容易oom（超过-XX:MaxPermsize上限）\n\n\n\n而到了JDK8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替\n\n\n元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代最大的区别在于：元空间不在虚拟机设置的内存中，而是使用本地内存\n永久代、元空间二者并不只是名字变了，内部结构也调整了\n根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常\n设置方法区大小与OOM方法区的大小不必是固定的，JVM可以根据应用的需要动态调整。 \njdk7及以前\n通过-xx:Permsize来设置永久代初始分配空间。默认值是20.75M\n-XX:MaxPermsize来设定永久代最大可分配空间。32位机器默认是64M，64位机器模式是82M\n当JVM加载的类信息容量超过了这个值，会报异常OutofMemoryError:PermGen space。\n\n\n\nJDK8以后元数据区大小可以使用参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize指定\n默认值依赖于平台。windows下，-XX:MetaspaceSize是21M，-XX:MaxMetaspaceSize的值是-1，即没有限制。\n与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常OutOfMemoryError:Metaspace\n-XX:MetaspaceSize：设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的-xx:MetaspaceSize值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活）然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值。\n如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将-XX:MetaspaceSize设置为一个相对较高的值。\n如何解决这些OOM\n要解决ooM异常或heap space的异常，一般的手段是首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏（Memory Leak）还是内存溢出（Memory Overflow）\n\n内存泄漏（Memory Leak）\n内存泄漏就是有大量的引用指向某些对象，但是这些对象以后不会使用了，但是因为它们还和GC ROOT有关联，所以导致以后这些对象也不会被回收，这就是内存泄漏的问题\n\n如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象是通过怎样的路径与GCRoots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GCRoots引用链的信息，就可以比较准确地定位出泄漏代码的位置。\n\n如果不存在内存泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。\n\n\n内存溢出（Memory Overflow）\n\n内存溢出排查\n排查其实最主要的就是检查代码，而且内存溢出往往都是代码的问题。当然一下几点都是需要注意的：\n\n内存中加载的数据量过于庞大，如一次从数据库取出过多数据；\n集合类中有对对象的引用，使用完后未清空，使得JVM不能回收；\n代码中存在死循环或循环产生过多重复的对象实体；\n使用的第三方软件中的BUG；\n启动参数内存值设定的过小；\n\n最后就是解决了。\n\n修改JVM启动参数，直接增加内存。\n检查错误日志\n对代码进行走查和分析，找出可能发生内存溢出的位置。\n\n方法区的内部结构\n\n《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。\n\n\n类型信息对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVm必须在方法区中存储以下类型信息：\n\n这个类型的完整有效名称（全名&#x3D;包名.类名）\n这个类型直接父类的完整有效名（对于interface或是java.lang.object，都没有父类）\n这个类型的修饰符（public，abstract，final的某个子集）\n这个类型直接接口的一个有序列表\n\n字段信息JVM必须在方法区中保存类型的所有字段的相关信息以及字段的声明顺序。\n字段的相关信息包括：字段名称、字段类型、字段修饰符（public，private，protected，static，final，volatile，transient的某个子集）\n方法（Method）信息JVM必须保存所有方法的以下信息，同字段信息一样包括声明顺序：\n\n方法名称\n方法的返回类型（或void）\n方法参数的数量和类型（按顺序）\n方法的修饰符（public，private，protected，static，final，synchronized，native，abstract的一个子集）\n方法的字节码（bytecodes）、操作数栈、局部变量表及大小（abstract和native方法除外）\n异常表（abstract和native方法除外）\n\n\n每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引\n\nnon-final的类变量静态变量和类关联在一起，随着类的加载而加载，他们成为类数据在逻辑上的一部分\n类变量被类的所有实例共享，即使没有类实例时，你也可以访问它\n/** * non-final的类变量 */public class MethodAreaTest &#123;    public static void main(String[] args) &#123;        Order order = new Order();        order.hello();        System.out.println(order.count);    &#125;&#125;class Order &#123;    public static int count = 1;    public static final int number = 2;    public static void hello() &#123;        System.out.println(&quot;hello!&quot;);    &#125;&#125;\n\n如上代码所示，即使我们把order设置为null，也不会出现空指针异常\n全局常量全局常量就是使用 static final 进行修饰\n被声明为final的类变量的处理方法则不同，每个全局常量在编译的时候就会被分配了。 \n运行时常量池 VS 常量池\n\n\n方法区，内部包含了运行时常量池\n字节码文件，内部包含了常量池\n要弄清楚方法区，需要理解清楚ClassFile，因为加载类的信息都在方法区。\n要弄清楚方法区的运行时常量池，需要理解清楚classFile中的常量池。\n\n常量池\n\n一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述符信息外，还包含一项信息就是常量池表（Constant Pool Table），包括各种字面量和对类型、字段和方法的符号引用\n为什么需要常量池一个java源文件中的类、接口，编译后产生一个字节码文件。而Java中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候会用到运行时常量池，之前有介绍。比如：\npublic class SimpleClass &#123;    public void sayHello() &#123;        System.out.println(&quot;hello&quot;);    &#125;&#125;\n\n虽然上述代码只有194字节，但是里面却使用了String、System、PrintStream及Object等结构。这里的代码量其实很少了，如果代码多的话，引用的结构将会更多，这里就需要用到常量池了。\n常量池中有什么\n数量值\n字符串值\n类引用\n字段引用\n方法引用\n\n例如下面这段代码\npublic class MethodAreaTest2 &#123;    public static void main(String args[]) &#123;        Object obj = new Object();    &#125;&#125;\n\n将会被翻译成如下字节码\nnew #2  dupinvokespecial\n\n运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分。\n常量池表（Constant Pool Table）是Class文件的一部分，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。\n运行时常量池，在加载类和接口到虚拟机后，就会创建对应的运行时常量池。\nJVM为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的。\n运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，这里换为真实地址。\n运行时常量池，相对于Class文件常量池的另一重要特征是：具备动态性。\n运行时常量池类似于传统编程语言中的符号表（symboltable），但是它所包含的数据却比符号表要更加丰富一些。\n当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则JVM会抛outofMemoryError异常。\n方法区使用举例如下代码\npublic class MethodAreaDemo &#123;    public static void main(String args[]) &#123;        int x = 500;        int y = 100;        int a = x / y;        int b = 50;        System.out.println(a+b);    &#125;&#125;\n\n字节码执行过程展示\n\n\n首先现将操作数500放入到操作数栈中\n\n\n然后存储到局部变量表中\n\n\n然后重复一次，把100放入局部变量表中，最后再将变量表中的500 和 100 取出，进行操作\n\n\n将500 和 100 进行一个除法运算，在把结果入栈\n\n\n在最后就是输出流，需要调用运行时常量池的常量\n\n\n最后调用invokevirtual（虚方法调用），然后返回\n\n\n返回时\n\n\n程序计数器始终计算的都是当前代码运行的位置，目的是为了方便记录 方法调用后能够正常返回，或者是进行了CPU切换后，也能回来到原来的代码进行执行。\n方法区的演进细节首先明确：只有Hotspot才有永久代。BEA JRockit、IBMJ9等来说，是不存在永久代的概念的。原则上如何实现方法区属于虚拟机实现细节，不受《Java虚拟机规范》管束，并不要求统一\nHotspot中方法区的变化：\n\n\n\nJDK1.6及以前\n有永久代，静态变量存储在永久代上\n\n\n\nJDK1.7\n有永久代，但已经逐步 “去永久代”，字符串常量池，静态变量移除，保存在堆中\n\n\nJDK1.8\n无永久代，类型信息，字段，方法，常量保存在本地内存的元空间，但字符串常量池、静态变量仍然在堆中。\n\n\nJDK6的时候\n\n\nJDK7的时候\n\n\nJDK8的时候，元空间大小只受物理内存影响\n\n\n\n为什么永久代要被元空间替代？JRockit是和HotSpot融合后的结果，因为JRockit没有永久代，所以他们不需要配置永久代\n随着Java8的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了。这些数据被移到了一个与堆不相连的本地内存区域，这个区域叫做元空间（Metaspace）。\n由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间，这项改动是很有必要的，原因有：\n\n为永久代设置空间大小是很难确定的。\n\n在某些场景下，如果动态加载类过多，容易产生Perm区的oom。比如某个实际Web工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误。\n“Exception in thread‘dubbo client x.x connector’java.lang.OutOfMemoryError:PermGen space”\n而元空间和永久代之间最大的区别在于：元空间并不在虚拟机中，而是使用本地内存。因此，默认情况下，元空间的大小仅受本地内存限制。\n\n对永久代进行调优是很困难的。\n主要是为了降低Full GC\n\n\n\n有些人认为方法区（如HotSpot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK11时期的ZGC收集器就不支持类卸载）。一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏\n方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不在使用的类型\nStringTable为什么要调整位置jdk7中将StringTable放到了堆空间中。因为永久代的回收效率很低，在full gc的时候才会触发。而full gc是老年代的空间不足、永久代不足时才会触发。\n这就导致stringTable回收效率不高。而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。放到堆里，能及时回收内存。\n静态变量存放在那里？静态引用对应的对象实体始终都存在堆空间\n可以使用 jhsdb.ext，需要在jdk9的时候才引入的\nstaticobj随着Test的类型信息存放在方法区，instanceobj随着Test的对象实例存放在Java堆，localobject则是存放在foo（）方法栈帧的局部变量表中。\n\n\n测试发现：三个对象的数据在内存中的地址都落在Eden区范围内，所以结论：只要是对象实例必然会在Java堆中分配。\n接着，找到了一个引用该staticobj对象的地方，是在一个java.lang.Class的实例里，并且给出了这个实例的地址，通过Inspector查看该对象实例，可以清楚看到这确实是一个java.lang.Class类型的对象实例，里面有一个名为staticobj的实例字段：\n\n\n从《Java虚拟机规范》所定义的概念模型来看，所有Class相关的信息都应该存放在方法区之中，但方法区该如何实现，《Java虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。JDK7及其以后版本的HotSpot虚拟机选择把静态变量与类型在Java语言一端的映射class对象存放在一起，存储于Java堆之中，从我们的实验中也明确验证了这一点\n方法区的垃圾回收有些人认为方法区（如Hotspot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK11时期的zGC收集器就不支持类卸载）。\n一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的。以前sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。\n方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。\n先来说说方法区内常量池之中主要存放的两大类常量：字面量和符号引用。字面量比较接近Java语言层次的常量概念，如文本字符串、被声明为final的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量：\n\n类和接口的全限定名\n字段的名称和描述符\n方法的名称和描述符\n\nHotSpot虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收。\n回收废弃常量与回收Java堆中的对象非常类似。（关于常量的回收比较简单，重点是类的回收）\n判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就比较苛刻了。需要同时满足下面三个条件：\n\n该类所有的实例都已经被回收，也就是Java堆中不存在该类及其任何派生子类的实例。加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如osGi、JSP的重加载等，否则通常是很难达成的。\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。I Java虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot虚拟机提供了-Xnoclassgc参数进行控制，还可以使用-verbose:class 以及 -XX:+TraceClass-Loading、-XX:+TraceClassUnLoading查看类加载和卸载信息\n在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及oSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。\n\n总结\n\n常见面试题百度三面：说一下JVM内存模型吧，有哪些区？分别干什么的？\n蚂蚁金服：Java8的内存分代改进JVM内存分哪几个区，每个区的作用是什么？一面：JVM内存分布&#x2F;内存结构？栈和堆的区别？堆的结构？为什么两个survivor区？二面：Eden和survior的比例分配\n小米：jvm内存分区，为什么要有新生代和老年代\n字节跳动：二面：Java的内存分区二面：讲讲vm运行时数据库区什么时候对象会进入老年代？\n京东：JVM的内存结构，Eden和Survivor比例。JVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和survivor。\n天猫：一面：Jvm内存模型以及分区，需要详细到每个区放什么。一面：JVM的内存模型，Java8做了什么改\n拼多多：JVM内存分哪几个区，每个区的作用是什么？\n美团：java内存分配jvm的永久代中会发生垃圾回收吗？一面：jvm内存分区，为什么要有新生代和老年代？\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"JVM-8_堆","url":"/2022/06/06/JVM/JVM-8_%E5%A0%86/","content":"堆的核心概念堆针对一个JVM进程来说是唯一的，也就是一个进程只有一个JVM，但是进程包含多个线程，他们是共享同一堆空间的。\n一个JVM实例只存在一个堆内存，堆也是Java内存管理的核心区域。\nJava堆区在JVM启动的时候即被创建，其空间大小也就确定了。是JVM管理的最大一块内存空间。\n\n堆内存的大小是可以调节的。\n\n《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。\n所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer，TLAB）。\n\n-Xms10m：最小堆内存\n-Xmx10m：最大堆内存\n\n下图就是使用：Java VisualVM(C:\\Program Files\\Java\\jdk1.8.0_231\\bin\\jvisualvm.exe)查看堆空间的内容，通过 jdk bin提供的插件\n\n\n《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。\n\nThe heap is the run-time data area from which memory for all class instances and arrays is allocated\n\n我要说的是：“几乎”所有的对象实例都在这里分配内存。—从实际使用角度看的。\n\n因为还有一些对象是在栈上分配的\n\n数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。\n在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除。\n\n也就是触发了GC的时候，才会进行回收\n如果堆中对象马上被回收，那么用户线程就会收到影响，因为有stop the word\n\n堆，是GC（Garbage Collection，垃圾收集器）执行垃圾回收的重点区域。\n\n\n堆内存细分Java 7及之前堆内存逻辑上分为三部分：新生区+养老区+永久区\n\n(Young Generation Space)新生区: Young&#x2F;New, 又被划分为Eden区和Survivor区\n(Tenure generation space)养老区: Old&#x2F;Tenure\n(Permanent Space)永久区: Perm\n\nJava 8及之后堆内存逻辑上分为三部分：新生区养老区+元空间\n\n(Young Generation Space)新生区: Young&#x2F;New, 又被划分为Eden区和Survivor区\n(Tenure generation space)养老区: Old&#x2F;Tenure\n(Meta Space)元空间: Meta\n\n约定同义词：\n\nYoung Generation Space &#x3D; 新生区 &#x3D; 新生代 &#x3D; 年轻代 \nTenure generation space &#x3D; 养老区 &#x3D; 老年区 &#x3D; 老年代\nPermanent Space &#x3D; 永久区 &#x3D; 永久代\n\n\n\n堆空间内部结构，JDK1.8之前从永久代 -&gt;  元空间\n\n\n设置堆内存大小与OOMJava堆区用于存储Java对象实例，那么堆的大小在JVM启动时就已经设定好了，大家可以通过选项”-Xmx”和”-Xms”来进行设置。\n\n-Xms用于表示堆区的起始内存，等价于-xx:InitialHeapSize\n-Xmx则用于表示堆区的最大内存，等价于-XX:MaxHeapSize\n\n一旦堆区中的内存大小超过-xmx所指定的最大内存时，将会抛出outofMemoryError异常。\n通常会将-Xms和-Xmx两个参数配置相同的值，其目的是为了能够在ava垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，避免频繁的扩容或释放，对系统造成额外的压力，从而提高性能。\n默认情况下:\n\n初始内存大小：物理电脑内存大小&#x2F;64\n最大内存大小：物理电脑内存大小&#x2F;4\n\n如何查看堆内存的内存分配情况\njps  -&gt;  staat -gc  进程id\n\n在程序运行结束后打印堆空间详情：\n-XX:+PrintGCDetails\n\nOutOfMemory举例package com.sicmatr1x.java;import java.util.ArrayList;import java.util.Random;public class OOMTest &#123;    public static void main(String[] args) &#123;        ArrayList&lt;Picture&gt; list = new ArrayList&lt;&gt;();        while(true)&#123;            try &#123;                Thread.sleep(20);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;            list.add(new Picture(new Random().nextInt(1024 * 1024)));        &#125;    &#125;&#125;class Picture&#123;    private byte[] pixels;    public Picture(int length) &#123;        this.pixels = new byte[length];    &#125;&#125;\n\n然后设置启动参数\n-Xms600m -Xmx600m\n\n\n\n错误提示：\nException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space\tat com.sicmatr1x.java.Picture.&lt;init&gt;(OOMTest.java:24)\tat com.sicmatr1x.java.OOMTest.main(OOMTest.java:15)Process finished with exit code 1\n\n\n\n年轻代与老年代存储在JVM中的Java对象可以被划分为两类：\n\n一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速\n生命周期短的，及时回收即可\n\n\n另外一类对象的生命周期却非常长，在某些极端的情况下还能够与JVM的生命周期保持一致\n\nJava堆区进一步细分的话，可以划分为年轻代（YoungGen）和老年代（oldGen）\n其中年轻代又可以划分为Eden空间、Survivor0空间和Survivor1空间（有时也叫做from区、to区）\n\n\n下面这参数开发中一般不会调：\n\n\n\n默认-XX:NewRatio&#x3D;2，表示新生代占1，老年代占2，新生代占整个堆的1&#x2F;3\n\n可以修改-XX:NewRatio&#x3D;4，表示新生代占1，老年代占4，新生代占整个堆的1&#x2F;5\n\n\n当发现在整个项目中，生命周期长的对象偏多，那么就可以通过调整 老年代的大小，来进行调优\n查看新生代区占几份：jinfo -flag NewRatio 60636\n\n-XX:NewRatio: 设置新生代与老年代的比例。默认值是2.\n-XX:SurvivorRatio: 设置新生代中Eden区与Survivor区的比例。默认值是8。在HotSpot中，Eden空间和另外两个survivor空间缺省所占的比例是8：1：1当然开发人员可以通过选项-xx:SurvivorRatio调整这个空间比例。比如-xx:SurvivorRatio=8\n-XX:-UseAdaptiveSizePolicy: 关闭自适应的内存分配策略  （暂时用不到）\n-Xmn: 设置新生代的空间的大小。 （一般不设置）\n\n几乎所有的Java对象都是在Eden区被new出来的。绝大部分的Java对象的销毁都在新生代进行了。（有些大的对象在Eden区无法存储时候，将直接进入老年代）\n\nIBM公司的专门研究表明，新生代中80%的对象都是“朝生夕死”的。\n可以使用选项”-Xmn”设置新生代最大内存大小\n这个参数一般使用默认值就可以了。\n\n\n\n图解对象分配过程为新对象分配内存是一件非常严谨和复杂的任务，JM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生内存碎片。\n\nnew的对象先放伊甸园区。此区有大小限制。\n当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收（MinorGC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区\n然后将伊甸园中的剩余对象移动到幸存者0区。\n如果再次触发垃圾回收，此时上次幸存下来的放到幸存者0区的，如果没有回收，就会放到幸存者1区。\n如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区。\n啥时候能去养老区呢？可以设置次数。默认是15次。\n\n\n在养老区，相对悠闲。当养老区内存不足时，再次触发GC：Major GC，进行养老区的内存清理\n若养老区执行了Major GC之后，发现依然无法进行对象的保存，就会产生OOM异常。\n\n图解过程我们创建的对象，一般都是存放在Eden区的，当我们Eden区满了后，就会触发GC操作，一般被称为 Y(oung)GC &#x2F; Minor GC操作。注意：S0或S1区满的时候是不会触发YGC的。如果Survivor区满了后，将会触发一些特殊的规则(参考下面的对象分配的特殊情况)，也就是可能直接晋升老年代\n\n\n\n当我们进行一次垃圾收集后，红色的将会被回收，而绿色的还会被占用着，存放在S0(Survivor From)区。同时我们给每个对象设置了一个年龄计数器，一次回收后就是1。\n\n\n\n\n同时Eden区继续存放对象，当Eden区再次存满的时候，又会触发一个MinorGC操作，此时GC将会把 Eden和Survivor From中的对象 进行一次收集，把存活的对象放到 Survivor To区，同时让年龄 + 1\n\n\n\n\n我们继续不断的进行对象生成 和垃圾回收，当Survivor中的对象的年龄达到15的时候(可以设置参数：-Xx:MaxTenuringThreshold=15进行设置，默认为15)，将会触发一次 Promotion晋升的操作，也就是将年轻代中的对象晋升到老年代中\n\n总结\n针对Survivor区的总结：复制之后有交换，谁空谁是to\n关于垃圾回收：频繁在新生代收集，很少在老年代收集，几乎不在永久代&#x2F;元空间收集\n\n对象分配的特殊情况\n\n\n代码演示对象分配过程import java.util.ArrayList;import java.util.Random;public class HeapInstanceTest &#123;    byte[] buffer = new byte[new Random().nextInt(1024 * 200)];    public static void main(String[] args) &#123;        ArrayList&lt;HeapInstanceTest&gt; list = new ArrayList&lt;HeapInstanceTest&gt;();        while (true) &#123;            list.add(new HeapInstanceTest());            try &#123;                Thread.sleep(10);            &#125; catch (InterruptedException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\n\n然后设置JVM参数\n-Xms600m -Xmx600m\n\n\n\n最终，在老年代和新生代都满了，就出现OOM\n常用的调优工具\nJDK命令行\nEclipse：Memory Analyzer Tool\nJconsole\nVisual VM（实时监控  推荐~）\nJprofiler（推荐~）\nJava Flight Recorder（实时监控）\nGCViewer\nGCEasy\n\n城通网盘提取码：800763\n总结\n针对幸存者s0，s1区的总结：复制之后有交换，谁空谁是to\n关于垃圾回收：频繁在新生区收集，很少在老年代收集，几乎不再永久代和元空间进行收集\n新生代采用复制算法的目的：是为了减少内碎片\n\nMinor GC，MajorGC、Full GC\nMinor GC：新生代的GC\nMajor GC：老年代的GC\nFull GC：整堆收集，收集整个Java堆和方法区的垃圾收集\n\n\n我们都知道，JVM的调优的一个环节，也就是垃圾收集，我们需要尽量的避免垃圾回收，因为在垃圾回收的过程中，容易出现STW的问题\n而 Major GC 和 Full GC出现STW的时间，是Minor GC的10倍以上\n\nJVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。针对Hotspot VM的实现，它里面的GC按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC）\n部分收集：不是完整收集整个Java堆的垃圾收集。其中又分为：\n\n新生代收集（MinorGC&#x2F;YoungGC）：只是新生代的垃圾收集\n老年代收集（MajorGC&#x2F;oldGC）：只是老年代的圾收集。\n目前，只有CMSGC会有单独收集老年代的行为。\n注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。\n\n\n混合收集（MixedGC）：收集整个新生代以及部分老年代的垃圾收集。\n目前，只有G1 GC会有这种行为\n\n\n\n整堆收集（FullGC）：收集整个java堆和方法区的垃圾收集。\nMinor GC当年轻代空间不足时，就会触发MinorGC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC。（每次Minor GC会清理年轻代的内存。）\n因为Java对象大多都具备 朝生夕灭 的特性，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。\nMinor GC会引发STW，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行\n\nSTW：stop the word\n\n\n\nMajor GC指发生在老年代的GC，对象从老年代消失时，我们说 “Major Gc” 或 “Full GC” 发生了\n出现了MajorGc，经常会伴随至少一次的Minor GC（但非绝对的，在Paralle1 Scavenge收集器的收集策略里就有直接进行MajorGC的策略选择过程）\n\n也就是在老年代空间不足时，会先尝试触发MinorGc。如果之后空间还不足，则触发Major GC\n\nMajor GC的速度一般会比MinorGc慢1e倍以上，STW的时间更长，如果Major GC后，内存还不足，就报OOM了\nFull GC触发FullGC执行的情况有如下五种：\n\n调用System.gc()时，系统建议执行FullGC，但是不必然执行\n老年代空间不足\n方法区空间不足\n通过Minor GC后进入老年代的平均大小大于老年代的可用内存\n由Eden区、survivor spacee（From Space）区向survivor spacel（To Space）区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小\n\n说明：Full GC 是开发或调优中尽量要避免的。这样暂时时间会短一些\nGC 举例我们编写一个OOM的异常，因为我们在不断的创建字符串，是存放在元空间的\npublic class GCTest &#123;    public static void main(String[] args) &#123;        int i = 0;        try &#123;            List&lt;String&gt; list = new ArrayList&lt;&gt;();            String a = &quot;sicmatr1x&quot;;            while(true) &#123;                list.add(a);                a = a + a;                i++;            &#125;        &#125;catch (Exception e) &#123;            e.getStackTrace();        &#125;    &#125;&#125;\n\n设置JVM启动参数\n-Xms10m -Xmx10m -XX:+PrintGCDetails\n\n运行结果：\n[GC (Allocation Failure) [PSYoungGen: 2005K-&gt;508K(2560K)] 2005K-&gt;832K(9728K), 0.0013790 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (Allocation Failure) [PSYoungGen: 2512K-&gt;496K(2560K)] 2836K-&gt;1953K(9728K), 0.0016054 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (Allocation Failure) [PSYoungGen: 1757K-&gt;482K(2560K)] 6670K-&gt;5991K(9728K), 0.0010749 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC (Allocation Failure) [PSYoungGen: 482K-&gt;498K(2560K)] 5991K-&gt;6015K(9728K), 0.0007589 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 498K-&gt;0K(2560K)] [ParOldGen: 5517K-&gt;4061K(7168K)] 6015K-&gt;4061K(9728K), [Metaspace: 3219K-&gt;3219K(1056768K)], 0.0064008 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 34K-&gt;128K(2560K)] 6399K-&gt;6493K(9728K), 0.0016660 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Ergonomics) [PSYoungGen: 128K-&gt;0K(2560K)] [ParOldGen: 6365K-&gt;5237K(7168K)] 6493K-&gt;5237K(9728K), [Metaspace: 3225K-&gt;3225K(1056768K)], 0.0046603 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] [GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(1536K)] 5237K-&gt;5237K(8704K), 0.0003621 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC (Allocation Failure) [PSYoungGen: 0K-&gt;0K(1536K)] [ParOldGen: 5237K-&gt;5216K(7168K)] 5237K-&gt;5216K(8704K), [Metaspace: 3225K-&gt;3225K(1056768K)], 0.0086411 secs] [Times: user=0.05 sys=0.02, real=0.01 secs] Heap PSYoungGen      total 1536K, used 70K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)  eden space 1024K, 6% used [0x00000000ffd00000,0x00000000ffd11ac8,0x00000000ffe00000)  from space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)  to   space 1024K, 0% used [0x00000000ffe00000,0x00000000ffe00000,0x00000000fff00000) ParOldGen       total 7168K, used 5216K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000)  object space 7168K, 72% used [0x00000000ff600000,0x00000000ffb180c0,0x00000000ffd00000) Metaspace       used 3257K, capacity 4496K, committed 4864K, reserved 1056768K  class space    used 353K, capacity 388K, committed 512K, reserved 1048576KException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space\tat java.util.Arrays.copyOfRange(Arrays.java:3664)\tat java.lang.String.&lt;init&gt;(String.java:207)\tat java.lang.StringBuilder.toString(StringBuilder.java:407)\tat com.sicmatr1x.java.GCTest.main(GCTest.java:14)Process finished with exit code 1\n\n触发OOM的时候，一定是进行了一次Full GC，因为只有在老年代空间不足时候，才会爆出OOM异常\n堆空间分代思想 为什么要把Java堆分代？不分代就不能正常工作了吗？经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。\n\n新生代：有Eden、两块大小相同的survivor（又称为from&#x2F;to，s0&#x2F;s1）构成，to总为空。老年代：存放新生代中经历多次GC仍然存活的对象。\n\n\n\n其实不分代完全可以，分代的唯一理由就是优化GC性能。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。\n\n\n\n内存分配策略如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到survivor空间中，并将对象年龄设为1。对象在survivor区中每熬过一次MinorGC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，其实每个JVM、每个GC都有所不同）时，就会被晋升到老年代\n对象晋升老年代的年龄阀值，可以通过选项-xx:MaxTenuringThreshold来设置\n针对不同年龄段的对象分配原则如下所示：\n\n优先分配到Eden\n开发中比较长的字符串或者数组，会直接存在老年代，但是因为新创建的对象 都是 朝生夕死的，所以这个大对象可能也很快被回收，但是因为老年代触发Major GC的次数比 Minor GC要更少，因此可能回收起来就会比较慢\n\n\n大对象直接分配到老年代\n尽量避免程序中出现过多的大对象\n\n\n长期存活的对象分配到老年代\n动态对象年龄判断\n如果survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无须等到MaxTenuringThreshold 中要求的年龄。\n\n\n\n空间分配担保： -Xx:HandlePromotionFailure\n\n也就是经过Minor GC后，所有的对象都存活，因为Survivor比较小，所以就需要将Survivor无法容纳的对象，存放到老年代中。\n\n为对象分配内存：TLAB问题：堆空间都是共享的么？不一定，因为还有TLAB这个概念，在堆中划分出一块区域，为每个线程所独占\n为什么有TLAB？TLAB：Thread Local Allocation Buffer，也就是为每个线程单独分配了一个缓冲区\n堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据\n由于对象实例的创建在JVM中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的\n为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度。\n什么是TLAB从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，它包含在Eden空间内。\n多线程同时分配内存时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为快速分配策略。\n所有OpenJDK衍生出来的JVM都提供了TLAB的设计。\n\n\n尽管不是所有的对象实例都能够在TLAB中成功分配内存，但JVM确实是将TLAB作为内存分配的首选。\n在程序中，开发人员可以通过选项-Xx:UseTLAB设置是否开启TLAB空间。\n默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%，当然我们可以通过选项-Xx:TLABWasteTargetPercent设置TLAB空间所占用Eden空间的百分比大小。\n一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在Eden空间中分配内存。\nTLAB分配过程对象首先是通过TLAB开辟空间，如果不能放入，那么需要通过Eden来进行分配\n\n\n小结：堆空间的参数设置官方文档：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html\n\n-XX：+PrintFlagsInitial：查看所有的参数的默认初始值\n\n-XX：+PrintFlagsFinal：查看所有的参数的最终值（可能会存在修改，不再是初始值）\n\n-Xms：初始堆空间内存（默认为物理内存的1&#x2F;64）\n\n-Xmx：最大堆空间内存（默认为物理内存的1&#x2F;4）\n\n-Xmn：设置新生代的大小。（初始值及最大值）\n\n-XX:NewRatio：配置新生代与老年代在堆结构的占比\n\n-XX:SurvivorRatio：设置新生代中Eden和S0&#x2F;S1空间的比例\n\n-XX:MaxTenuringThreshold：设置新生代垃圾的最大年龄\n\n-XX：+PrintGCDetails：输出详细的GC处理日志\n\n打印gc简要信息：\n-Xx：+PrintGC\nverbose:gc\n\n\n\n\n-XX:HandlePromotionFalilure：是否设置空间分配担保\n\n\n在发生Minor GC之前，虚拟机会检查老年代最大可用的连续空间是否大于新生代所有对象的总空间。I\n\n如果大于，则此次Minor GC是安全的\n如果小于，则虚拟机会查看-xx:HandlePromotionFailure设置值是否允担保失败。\n如果HandlePromotionFailure&#x3D;true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小。\n如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；\n如果小于，则改为进行一次FullGC。\n如果HandlePromotionFailure&#x3D;false，则改为进行一次Ful1 Gc。\n\n\n\n在JDK6 Update24之后，HandlePromotionFailure参数不会再影响到虚拟机的空间分配担保策略，观察openJDK中的源码变化，虽然源码中还定义了HandlePromotionFailure参数，但是在代码中已经不会再使用它。JDK6 Update 24之后的规则变为只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC，否则将进行FullGC。\n堆是分配对象的唯一选择么？逃逸分析在《深入理解Java虚拟机》中关于Java堆内存有这样一段描述：\n随着JIT编译期的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。\n在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是如果经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。\n此外，前面提到的基于openJDk深度定制的TaoBaovm，其中创新的GCIH（GC invisible heap）技术实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。\n如何将堆上的对象分配到栈，需要使用逃逸分析手段。\n这是一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。逃逸分析的基本行为就是分析对象动态作用域：\n\n当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。\n当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中。\n\n逃逸分析举例没有发生逃逸的对象，则可以分配到栈上，随着方法执行的结束，栈空间就被移除，每个栈里面包含了很多栈帧，也就是发生逃逸分析\npublic void my_method() &#123;    V v = new V();    // use v    // ....    v = null;&#125;\n\n针对下面的代码\npublic static StringBuffer createStringBuffer(String s1, String s2) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    return sb;&#125;\n\n如果想要StringBuffer sb不发生逃逸，可以这样写\npublic static String createStringBuffer(String s1, String s2) &#123;    StringBuffer sb = new StringBuffer();    sb.append(s1);    sb.append(s2);    return sb.toString();&#125;\n\n完整的逃逸分析代码举例\n/** * 逃逸分析 * 如何快速的判断是否发生了逃逸分析，大家就看new的对象是否在方法外被调用。 */public class EscapeAnalysis &#123;    public EscapeAnalysis obj;    /**     * 方法返回EscapeAnalysis对象，发生逃逸     * @return     */    public EscapeAnalysis getInstance() &#123;        return obj == null ? new EscapeAnalysis():obj;    &#125;    /**     * 为成员属性赋值，发生逃逸     */    public void setObj() &#123;        this.obj = new EscapeAnalysis();    &#125;    /**     * 对象的作用于仅在当前方法中有效，没有发生逃逸     */    public void useEscapeAnalysis() &#123;        EscapeAnalysis e = new EscapeAnalysis();    &#125;    /**     * 引用成员变量的值，发生逃逸     */    public void useEscapeAnalysis2() &#123;        EscapeAnalysis e = getInstance();        // getInstance().XXX  发生逃逸    &#125;&#125;\n\n参数设置在JDK 1.7 版本之后，HotSpot中默认就已经开启了逃逸分析\n如果使用的是较早的版本，开发人员则可以通过：\n\n选项-xx：+DoEscapeAnalysis显式开启逃逸分析\n通过选项-xx：+PrintEscapeAnalysis查看逃逸分析的筛选结果\n\n结论开发中能使用局部变量的，就不要使用在方法外定义。\n使用逃逸分析，编译器可以对代码做如下优化：\n\n栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会发生逃逸，对象可能是栈上分配的候选，而不是堆上分配\n同步省略：如果一个对象被发现只有一个线程被访问到，那么对于这个对象的操作可以不考虑同步。\n分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。\n\n栈上分配JIT编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无须进行垃圾回收了。\n常见的栈上分配的场景\n\n在逃逸分析中，已经说明了。分别是给成员变量赋值、方法返回值、实例引用传递。\n\n举例我们通过举例来说明 开启逃逸分析 和 未开启逃逸分析时候的情况\n/** * 栈上分配 */class User &#123;    private String name;    private String age;    private String gender;    private String phone;&#125;public class StackAllocation &#123;    public static void main(String[] args) throws InterruptedException &#123;        long start = System.currentTimeMillis();        for (int i = 0; i &lt; 100000000; i++) &#123;            alloc();        &#125;        long end = System.currentTimeMillis();        System.out.println(&quot;花费的时间为：&quot; + (end - start) + &quot; ms&quot;);        // 为了方便查看堆内存中对象个数，线程sleep        Thread.sleep(10000000);    &#125;    private static void alloc() &#123;        User user = new User();    &#125;&#125;\n\n设置JVM参数，表示未开启逃逸分析\n-Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n\n运行结果，同时还触发了GC操作\n花费的时间为：664 ms\n\n然后查看内存的情况，发现有大量的User存储在堆中\n\n\n\n我们在开启逃逸分析\n-Xmx1G -Xms1G -XX:+DoEscapeAnalysis -XX:+PrintGCDetails\n\n然后查看运行时间，我们能够发现花费的时间快速减少，同时不会发生GC操作\n花费的时间为：5 ms\n\n然后在看内存情况，我们发现只有很少的User对象，说明User发生了逃逸，因为他们存储在栈中，随着栈的销毁而消失\n\n\n\n同步省略线程同步的代价是相当高的，同步的后果是降低并发性和性能。\n在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。如果没有，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫锁消除。\n例如下面的代码\npublic void f() &#123;    Object hellis = new Object();    synchronized(hellis) &#123;        System.out.println(hellis);    &#125;&#125;\n\n代码中对hellis这个对象加锁，但是hellis对象的生命周期只在f()方法中，并不会被其他线程所访问到，所以在JIT编译阶段就会被优化掉，优化成：\npublic void f() &#123;    Object hellis = new Object();\tSystem.out.println(hellis);&#125;\n\n我们将其转换成字节码\n\n\n\n分离对象和标量替换标量（scalar）是指一个无法再分解成更小的数据的数据。Java中的原始数据类型就是标量。\n相对的，那些还可以分解的数据叫做聚合量（Aggregate），Java中的对象就是聚合量，因为他可以分解成其他聚合量和标量。\n在JIT阶段，如果经过逃逸分析，发现一个对象不会被外界访问的话，那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替。这个过程就是标量替换。\npublic static void main(String args[]) &#123;    alloc();&#125;class Point &#123;    private int x;    private int y;&#125;private static void alloc() &#123;    Point point = new Point(1,2);    System.out.println(&quot;point.x&quot; + point.x + &quot;;point.y&quot; + point.y);&#125;\n\n以上代码，经过标量替换后，就会变成\nprivate static void alloc() &#123;    int x = 1;    int y = 2;    System.out.println(&quot;point.x = &quot; + x + &quot;; point.y=&quot; + y);&#125;\n\n可以看到，Point这个聚合量经过逃逸分析后，发现他并没有逃逸，就被替换成两个聚合量了。那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。标量替换为栈上分配提供了很好的基础。\n参数设置：-XX:+EliminateAllocations开启标量替换(默认打开)，允许将对象打散分配在栈上\n代码优化之标量替换上述代码在主函数中进行了1亿次alloc。调用进行对象创建，由于User对象实例需要占据约16字节的空间，因此累计分配空间达到将近1.5GB。如果堆空间小于这个值，就必然会发生GC。使用如下参数运行上述代码：\n-server -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations\n\n这里设置参数如下：\n\n参数-server：启动Server模式，因为在server模式下(64bit下默认启动的是server模式，可用java -version查看)，才可以启用逃逸分析。\n参数-XX:+DoEscapeAnalysis：启用逃逸分析\n参数-Xmx10m：指定了堆空间最大为10MB\n参数-XX:+PrintGC：将打印Gc日志。\n参数一xx：+EliminateAllocations：开启了标量替换（默认打开），允许将对象打散分配在栈上，比如对象拥有id和name两个字段，那么这两个字段将会被视为两个独立的局部变量进行分配\n\n逃逸分析的不足关于逃逸分析的论文在1999年就已经发表了，但直到JDK1.6才有实现，而且这项技术到如今也并不是十分成熟的。\n其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。\n虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JvM设计者的选择。据我所知，oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。\n目前很多书籍还是基于JDK7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。\n小结年轻代是对象的诞生、成长、消亡的区域，一个对象在这里产生、应用，最后被垃圾回收器收集、结束生命。\n老年代放置长生命周期的对象，通常都是从survivor区域筛选拷贝过来的Java对象。当然，也有特殊情况，我们知道普通的对象会被分配在TLAB上；如果对象较大，JVM会试图直接分配在Eden其他位置上；如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM就会直接分配到老年代。当GC只发生在年轻代中，回收年轻代对象的行为被称为MinorGc。\n当GC发生在老年代时则被称为MajorGc或者FullGC。一般的，MinorGc的发生频率要比MajorGC高很多，即老年代中垃圾回收发生的频率将大大低于年轻代。\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"Java NIO","url":"/2022/07/25/Java/Java-NIO/","content":"Java NIO(New IO或Non Bloking IO)是从Java1.4版本开始引入的一个新的IO API，NIO支持面向缓冲区的、基于通道的IO操作，读写文件更加高效。\nJava NIO区别\nIO\n面向流(Stream Oriented)：相当于水管，一个steam一个方向出水的水管\n阻塞IO(Blocking IO)\n无选择器\n\n\nNIO\n面向缓冲区(Buffer Oriented)：相当于铁路，一条铁路上面有一个缓冲区可以装数据然后双向运输\n非阻塞IO(Non Blocking IO)\n选择器(Selectors)\n\n\n\nNIO系统的核心：通道表示打开到IO设备的连接。若需要使用NIO系统，需要获取用于连接IO设备的通道以及用于容纳数据的缓冲区，然后操作缓冲区，对数据进行处理。\n缓冲区(Buffer)\n缓冲区(Buffer):在NIO中复制数据的春秋，缓冲区就是数组。\n\n\n根据数据类型的不同可以分配对应的缓冲区，boolean类型除外\n\n\n缓冲区存取数据的两个核心方法：\n\n\nput()\nget()\n\n\n缓冲区四个核心属性\nint capacity(容量): 表示缓冲区中最大存储数据的容量。一旦声明不能改变。\nlimit: 界限，表示缓冲区中可以操作数据的大小，即limit后的数据不能进行读写\nposition: 位置，表示缓冲区中正在操作数据的位置，且需满足(position &lt;&#x3D; limit &lt;&#x3D; capacity)\nmark: 标记，标记当前position的位置，可以通过reset()恢复到mark的位置\n\n\n\n这几个属性位于java.nio.Buffer类里\npublic abstract class Buffer &#123;    /**     * The characteristics of Spliterators that traverse and split elements     * maintained in Buffers.     */    static final int SPLITERATOR_CHARACTERISTICS =        Spliterator.SIZED | Spliterator.SUBSIZED | Spliterator.ORDERED;    // Invariants: mark &lt;= position &lt;= limit &lt;= capacity    private int mark = -1;    private int position = 0;    private int limit;    private int capacity;\n\n实例代码public void test1() &#123;    String str = &quot;abcde&quot;;    // 分配一个指定大小的缓冲区    ByteBuffer buf = ByteBuffer.allocate(1024);    System.out.println(buf.position()); // 0    System.out.println(buf.limit()); // 1024    System.out.println(buf.capacity()); // 1024    // 写数据    buf.put(str.getBytes());    System.out.println(buf.position()); // 5    System.out.println(buf.limit()); // 1024    System.out.println(buf.capacity()); // 1024    // 切换读取数据模式    buf.flip();    System.out.println(buf.position()); // 0    System.out.println(buf.limit()); // 5    System.out.println(buf.capacity()); // 1024    // 读数据    byte[] dst = new byte[buf.limit()];    buf.get(dst);    System.out.println(new String(dst, 0, dst.length)); // abcd    System.out.println(buf.position()); // 5    System.out.println(buf.limit()); // 5    System.out.println(buf.capacity()); // 1024    // rewind() 可重复读数据    buf.rewind();    System.out.println(buf.position()); // 0    System.out.println(buf.limit()); // 5    System.out.println(buf.capacity()); // 1024    // clear() 清空缓冲区，但是数据依然存在且处于被遗忘状态    buf.clear();    System.out.println(buf.position()); // 0    System.out.println(buf.limit()); // 1024    System.out.println(buf.capacity()); // 1024&#125;\n\npublic void test2() &#123;    String str = &quot;abcde&quot;;    ByteBuffer buf = ByteBuffer.allocate(1024);    buf.put(str.getBytes());    buf.flip();    byte[] dst = new byte[buf.limit()];    buf.get(dst, 0, 2);    System.out.println(new String(dst, 0, 2));    System.out.println(buf.position()); // 2    buf.mark();    buf.get(dst, 2, 2);    System.out.println(new String(dst, 0, 2));    System.out.println(buf.position()); // 4    buf.reset();    System.out.println(buf.position()); // 2&#125;\n\n\n直接缓冲区与非直接缓冲区\n\n\n非直接缓冲区：通过allocate()方法分配的缓冲区，缓冲区建立在JVM的内存中\n直接缓冲区：通过allocateDirect()方法分配的直接缓冲区或者使用FileChannel的map()方法返回MappedByteBuffer对象，将缓冲区建立在物理内存中。可以提高效率\n\n通道(Channel)用于源节点和目标节点间的连接，在NIO中复制缓冲区中数据的传输。Channel本身不存储数据，需要配合缓冲区使用。\n通道主要实现类\njava.nio.channels.CHannel\nFileChannel\nSocketChannel\nServerSocketChannel\nDatagramChannel\n\n\n\n获取通道的几种方式\nJava针对支持通道的类提供了getChannel()方法用于获取对应的通道\n\n\n本地IO\nFileInputStream\nFileOutputStream\nRandomAccessFile\n\n\n网络IO\nSocket\nServerSocket\nDatagramSocket\n\n\n\n\nJDK1.7提供的NIO.2针对各个通道提供了静态方法open()\nJDK1.7中的NIO.2的Files工具类的newByteChannel()方法\n\n通道使用案例/** * 直接缓冲区：利用通道实现本地文件复制(内存映射文件) */@Testpublic void test2() throws IOException &#123;    FileChannel inChannel = FileChannel.open(Paths.get(&quot;1.png&quot;), StandardOpenOption.READ);    FileChannel outChannel = FileChannel.open(Paths.get(&quot;3.png&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW);    // 内存映射文件    MappedByteBuffer inMappedBuffer = inChannel.map(FileChannel.MapMode.READ_ONLY, 0, inChannel.size());    MappedByteBuffer outMappedBuffer = outChannel.map(FileChannel.MapMode.READ_WRITE, 0, inChannel.size());    // 直接对缓冲区进行数据的读写操作    byte[] dst = new byte[inMappedBuffer.limit()];    inMappedBuffer.get(dst);    outMappedBuffer.put(dst);    inChannel.close();    outChannel.close();&#125;@Testpublic void test3() throws IOException &#123;    FileChannel inChannel = FileChannel.open(Paths.get(&quot;1.png&quot;), StandardOpenOption.READ);    FileChannel outChannel = FileChannel.open(Paths.get(&quot;3.png&quot;), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW);    inChannel.transferTo(0, inChannel.size(), outChannel);    inChannel.close();    outChannel.close();&#125;\n\n\n分散(Scatter)于聚集(Gather)\n分散读取(Scattering Reads): 将通道中的数据分散到多个缓冲区中\n聚集写入(Gathering Writes): 将多个缓冲区中的数据聚集到通道中\n\npublic void test4() throws IOException &#123;    RandomAccessFile raf1 = new RandomAccessFile(&quot;1.txt&quot;, &quot;r&quot;);    // 获取通道    FileChannel fileChannel1 = raf1.getChannel();    // 分配多个缓冲区    ByteBuffer buf1 = ByteBuffer.allocate(100);    ByteBuffer buf2 = ByteBuffer.allocate(1024);    // 分散读取    ByteBuffer[] bufs = &#123;buf1, buf2&#125;;    fileChannel1.read(bufs);    for (ByteBuffer byteBuffer : bufs) &#123;        byteBuffer.flip();    &#125;    System.out.println(new String(bufs[0].array(), 0, bufs[0].limit()));    // 聚集写入    RandomAccessFile raf2 = new RandomAccessFile(&quot;2.txt&quot;, &quot;rw&quot;);    FileChannel fileChannel2 = raf2.getChannel();    fileChannel2.write(bufs);    fileChannel1.close();    fileChannel2.close();&#125;\n\n字符集(Charset)public void test6() throws CharacterCodingException &#123;    Charset cs1 = Charset.forName(&quot;GBK&quot;);    // 获取编码器与解码器    CharsetEncoder ce = cs1.newEncoder();    CharsetDecoder cd = cs1.newDecoder();    CharBuffer buffer = CharBuffer.allocate(1024);    buffer.put(&quot;获取编码器与&quot;);    buffer.flip();    // 编码    ByteBuffer bBuf = ce.encode(buffer);    for (int i = 0; i &lt; 12; i++) &#123;        System.out.println(bBuf.get());    &#125;    // 解码    bBuf.flip();    CharBuffer cBuf = cd.decode(bBuf);    System.out.println(cBuf.toString());&#125;\n\n阻塞式网络通信使用NIO完成网络通信需要：\n\n通道(Channel): 负责连接\njava.nio.channels.Channel接口\nSelectableChannel\nSocketChannel\nServerSocketChannel\nDatagramChannel\nPipe.SinkChannel\nPipe.SourceChannel\n\n\n\n\n\n\n缓冲区(Buffer): 负责数据的存取\n选择器(Selector): 是SelectableChannel的多路复用器。用于监控SelectableChannel的IO状况\n\n非阻塞式网络通信使用ServerSocketChannelpackage com.sicmatr1x.nio;import org.junit.Test;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.time.LocalDateTime;import java.util.Iterator;import java.util.Scanner;public class TestNonBlockingNIO &#123;    @Test    public void client() throws IOException &#123;        SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(&quot;127.0.0.1&quot;, 9898));        // 切换成非阻塞模式        sChannel.configureBlocking(false);        // 分配缓冲区        ByteBuffer buf = ByteBuffer.allocate(1024);        // 发送数据        Scanner scanner = new Scanner(System.in);        while(scanner.hasNext())&#123;            String str = scanner.next();            buf.put((LocalDateTime.now().toString() + &quot;:&quot; + str).getBytes());            buf.flip();            sChannel.write(buf);            buf.clear();        &#125;        sChannel.close();    &#125;    @Test    public void server() throws IOException &#123;        ServerSocketChannel ssChannel = ServerSocketChannel.open();        // 切换成非阻塞模式        ssChannel.configureBlocking(false);        // 绑定连接        ssChannel.bind(new InetSocketAddress(9898));        // 获取选择器        Selector selector = Selector.open();        // 将通道注册到选择器，并且指定监听事件        ssChannel.register(selector, SelectionKey.OP_ACCEPT);        // 轮询式的获取选择器上已经准备就绪的事件        while (selector.select() &gt; 0) &#123;            // 获取当前选择器中所有注册的且已就绪的选择键            Iterator&lt;SelectionKey&gt; iterator = selector.selectedKeys().iterator();            // 迭代            while(iterator.hasNext()) &#123;                // 获取准备就绪的事件                SelectionKey key = iterator.next();                // 判断是什么事件就绪                if (key.isAcceptable()) &#123; // 若为接收就绪                    SocketChannel sChannel = ssChannel.accept();                    sChannel.configureBlocking(false);                    sChannel.register(selector, SelectionKey.OP_READ);                &#125; else if (key.isReadable()) &#123;                    // 获取当前选择器上读就绪的通道                    SocketChannel sChannel = (SocketChannel)key.channel();                    ByteBuffer buffer = ByteBuffer.allocate(1024);                    int len = 0;                    while((len = sChannel.read(buffer)) &gt; 0) &#123;                        buffer.flip();                        System.out.println(new String(buffer.array(), 0, len));                        buffer.clear();                    &#125;                &#125;                // 取消选择键                iterator.remove();            &#125;        &#125;    &#125;&#125;\n\n使用DatagramChannelpackage com.sicmatr1x.nio;import org.junit.Test;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.DatagramChannel;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.util.Date;import java.util.Iterator;import java.util.Scanner;public class TestNonBlockingNIO2 &#123;    @Test    public void send() throws IOException &#123;        DatagramChannel dc = DatagramChannel.open();        dc.configureBlocking(false);        ByteBuffer buffer = ByteBuffer.allocate(1024);        Scanner scan = new Scanner(System.in);        while(scan.hasNext()) &#123;            String str = scan.next();            buffer.put((new Date().toString() + &quot;:&quot; + str).getBytes());            dc.send(buffer, new InetSocketAddress(&quot;127.0.0.1&quot;, 9898));            buffer.clear();        &#125;        dc.close();    &#125;    @Test    public void receive() throws IOException &#123;        DatagramChannel dc = DatagramChannel.open();        dc.configureBlocking(false);        dc.bind(new InetSocketAddress(9898));        Selector selector = Selector.open();        dc.register(selector, SelectionKey.OP_READ);        while(selector.select() &gt; 0) &#123;            Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();            while(it.hasNext()) &#123;                SelectionKey key = it.next();                if(key.isReadable()) &#123;                    ByteBuffer buffer = ByteBuffer.allocate(1024);                    dc.receive(buffer);                    buffer.flip();                    System.out.println(new String(buffer.array(), 0, buffer.limit()));                &#125;            &#125;            it.remove();        &#125;    &#125;&#125;\n\n管道package com.sicmatr1x.nio;import org.junit.Test;import java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.Pipe;public class TestPip &#123;    @Test    public void test1() throws IOException &#123;        // 获取管道        Pipe pipe = Pipe.open();        // 将缓冲区中的数据写入管道        ByteBuffer buffer = ByteBuffer.allocate(1024);        Pipe.SinkChannel sinkChannel = pipe.sink();        buffer.put(&quot;通过管道发送数据&quot;.getBytes());        buffer.flip();        sinkChannel.write(buffer);        // 读取数据        ByteBuffer buffer1 = ByteBuffer.allocate(1024);        Pipe.SourceChannel sourceChannel = pipe.source();        int len = sourceChannel.read(buffer1);        System.out.println(new String(buffer1.array(), 0, len));        sourceChannel.close();        sinkChannel.close();    &#125;&#125;","categories":["Java"],"tags":["Back-end"]},{"title":"Java后端速查表","url":"/2023/01/20/Java/Java%E5%90%8E%E7%AB%AF%E9%80%9F%E6%9F%A5%E8%A1%A8/","content":"Index\n\nJava\nDatabase\n分布式\nSpring &amp; SpringBoot\n微服务\n高并发\n高可用\n其它\n\n\n\nJavaJava语言特性\nJDK(Java Development Kit)\nJRE(Java Runtime Environment)\n\n面向对象三大特征:\n\n封装: 封装是指把一个对象的状态信息隐藏在对象内部，不允许外部对象直接访问对象的内部信息。但是可以提供一些可以被外界访问的方法来操作属性。\n继承: 继承是使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。提高代码的重用，程序的可维护性\n多态: 表示一个对象具有多种的状态。具体表现为父类的引用指向子类的实例。\n\nJava 和 C++的区别\n\n都是面向对象的语言，都支持封装、继承和多态\nJava 不提供指针来直接访问内存，程序内存更加安全\nJava 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。\nJava 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存\n\n为什么说 Java 语言编译与解释并存？\n\n编译型语言: 是指编译器针对特定的操作系统将源代码一次性翻译成可被该平台执行的机器码\n解释型语言: 是指解释器对源程序逐行解释成特定平台的机器码并立即执行。\nJava 程序要经过先编译，后解释两个步骤，由 Java 编写的程序需要先经过编译步骤，生成字节码（*.class 文件），这种字节码必须由 Java 解释器来解释执行。\n\n为什么重写equals()时必须重写hashCode()方法？\n\n两个对象调用 equals 方法返回 true, 那么调用 hashCode 返回的值也必须一样\n反之 hashCode 返回值一样 equals 可以返回 false，这种情况为哈希碰撞\n\n重载(Overload)和重写(@Override)的\n\n重载就是同样的一个方法能够根据输入数据的不同，做出不同的处理\n重写就是当子类继承自父类的相同方法，输入数据一样，但要做出有别于父类的响应时，你就要覆盖父类方法\n\n深拷贝 vs 浅拷贝\n\n浅拷贝：对基本数据类型进行值传递，对引用数据类型进行引用传递般的拷贝，此为浅拷贝。\n深拷贝：对基本数据类型进行值传递，对引用数据类型，创建一个新的对象，并复制其内容，此为深拷贝。\n\nJava基本类异常(Throwable)： \n\nException（异常）：是程序本身可以处理的异常。Exception 类有一个重要的子类 RuntimeException。\nRuntimeException\n例如：ArithmeticException（算术运算异常，一个整数除以 0 时，抛出该异常）\n\n\n\n\nError（错误）：是程序无法处理的错误，表示运行应用程序中较严重问题。表示代码运行时 JVM（Java 虚拟机）出现的问题。\n例如：当 JVM 不再有继续执行操作所需的内存资源时，将出现 OutOfMemoryError。这些异常发生时，Java 虚拟机（JVM）一般会选择线程终止。\n\n\n\njava.util.HashMap\n\nJDK1.7: 数组+单链表+链表(链地址法)(头插法)\nJDK1.8: 数组+单链表+红黑树(当链表(尾插法)的深度达到8的时候，就会自动扩容把链表转成红黑树的数据结构来把时间复杂度从O(n)变成O(logN)提高了效率)\nput操作的流程：\nkey.hashcode()，时间复杂度O(1)\n找到桶以后，判断桶里是否有元素，如果没有，直接new一个entey节点插入到数组中。时间复杂度O(1)\n如果桶里有元素，并且元素个数小于6，则调用equals方法，比较是否存在相同名字的key，不存在则new一个entry插入都链表尾部。时间复杂度O(n)\n如果桶里有元素，并且元素个数大于6，则调用equals方法，比较是否存在相同名字的key，不存在则new一个entry插入都链表尾部。时间复杂度O(logn)\n\n\n如果new HashMap()不传值，默认大小是 16，负载因子是 0.75，如果自己传入初始大小 k，初始化大小为 大于 k 的 2 的整数次方，例如如果传 10，大小为 16\nHashMap 的哈希函数怎么设计的吗？\nhash 函数是先拿到通过 key 的 hashcode，是 32 位的 int 值，然后让 hashcode 的高 16 位和低 16 位进行异或操作。哈希函数也叫扰动函数，一定要尽可能降低 hash 碰撞，越分散越好；算法一定要尽可能高效，因为这是高频操作, 因此采用位运算；\n\n\n为什么采用 hashcode 的高 16 位和低 16 位异或能降低 hash 碰撞？hash 函数能不能直接用 key 的 hashcode？\n因为 key.hashCode()函数调用的是 key 键值对象自带的哈希函数，返回 int 型散列值(int 值范围为-2147483648~2147483647)，前后加起来大概 40 亿的映射空间。只要哈希函数映射得比较均匀松散，一般应用是很难出现碰撞的。但问题是一个 40 亿长度的数组，内存是放不下的。你想，如果 HashMap 数组的初始大小才 16，用之前需要对数组的长度取模运算，得到的余数才能用来访问数组下标。\n\n\n\njava.util.concurrent.ConcurrentHashMap\n\n采用了分段锁技术\n构造方法(Segment数组里面的Entry数组全部加起来的初始化大小, Segment数组的大小)\n理论上 ConcurrentHashMap 支持 CurrencyLevel (Segment 数组数量)的线程并发。每当一个线程占用锁访问一个 Segment 时，不会影响到其他的 Segment\n这里给Segment加锁采用的机制是CAS，否则自旋，同时还用到了ReentrantLock(可重入锁)\nJDK1.8中，ConcurrentHashMap摒弃了Segment，而是采用synchronized+CAS+红黑树来实现的。锁的粒度也从段锁缩小为结点(Node)锁\n\n1.7\n\nput(): \n通过 key 定位到 Segment，之后在对应的 Segment 中进行具体的 put\n尝试获取锁，如果获取失败肯定就有其他线程存在竞争，则利用 scanAndLockForPut() 自旋获取锁\n重试的次数达到了 MAX_SCAN_RETRIES 则改为阻塞锁获取\n将当前 Segment 中的 table 通过 key 的 hashcode 定位到 HashEntry\n遍历该 HashEntry，如果不为空则判断传入的 key 和当前遍历的 key 是否相等，相等则覆盖旧的 value\n不为空则需要新建一个 HashEntry 并加入到 Segment 中，同时会先判断是否需要扩容\n释放当前 Segment 的锁\n\n\nget():\nKey 通过 Hash 之后定位到具体的 Segment ，再通过一次 Hash 定位到具体的元素上\n由于 HashEntry 中的 value 属性是用 volatile 关键词修饰的，保证了内存可见性，所以每次获取时都是最新值\n\n\n\n1.8与1.7的区别\n\nput(): \n直接定位到桶，拿到 first 节点后进行判断:\n为空则 CAS 插入\n为 -1 则说明在扩容，则跟着一起扩容；else 则加锁 put(类似1.7)\n\n\nget():\n由于 value 声明为 volatile，保证了修改的可见性，因此不需要加锁\n\n\n\n面试题:\n\nHashMap数据结构及扩容机制\nHashMap 1.7和1.8区别，红黑树怎么遍历的.\nHashMap尾插法和头插法区别: 就是插入时，如果数组位置上已经有元素，1.7 将新元素放到数组中，原始节点作为新节点的后继节点，1.8 遍历链表，将元素放置到链表的最后。这样做可以避免多线程操作时头插法可能会出现环形链表。\n\n红黑树红黑树(Red-Black Tree，简称R-B Tree)，它一种特殊的二叉查找树。红黑树是特殊的二叉查找树，意味着它满足二叉查找树的特征：任意一个节点所包含的键值，大于等于左孩子的键值，小于等于右孩子的键值。在自平衡二叉搜索树的基础上，有颜色。即通过与颜色相关的《红黑树5性质》限定了红黑树自平衡的程度，使其不是严格意义上的平衡二叉树。平衡二叉树过于严格的限制了高度差不得超过1，会使树的结构调整过于频繁。这也是为什么要有红黑树。\n\n性质1.(红黑)节点是红色或黑色。\n性质2.(黑根)根节点是黑色。\n性质3.(黑叶)所有叶子都是黑色。(叶子是NULL节点)\n性质4.(二黑)每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)\n性质5.(黑高)从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。\n\nI&#x2F;O传统拷贝流程(下载文件为例):\n\n磁盘 -&gt; 内核缓冲区 -&gt; 用户缓冲区 -&gt; 网络堆栈相关的内核缓冲区 -&gt; 网卡\nDMA从磁盘读取文件到内核缓冲区 -&gt; CPU从内核缓冲区拷贝到用户缓冲区 -&gt; 应用程序调write系统调用把用户缓冲区的内容拷贝到网络堆栈相关的内核缓冲区 -&gt; socket把内核缓冲区的内容发送到网卡上\n\n零拷贝(下载文件为例):\n\n磁盘 -&gt; 内核缓冲区 -&gt; 网络堆栈相关的内核缓冲区 -&gt; 网卡\n磁盘上的数据会通过DMA被拷贝的内核缓冲区 -&gt; 操作系统把内核缓冲区与应用程序共享 -&gt; 应用程序调write系统调用将内核缓冲区的内容拷贝到socket缓冲区中 -&gt; socket把内核缓冲区的内容发送到网卡上\n\nBIO(Blocked I&#x2F;O): 面向流(单向); 同步阻塞I&#x2F;O\n\n服务端: 通过ServerSocket注册端口\n服务端: 调用accept()监听客户端Socket请求\n客户端: 调用connect()连接服务端\n服务端&#x2F;客户端: 从Socket中获取字节输入流或输出流对数据进行读写操作\n\nNIO(Non-blocked I&#x2F;O): 面向缓冲区(双向); 非阻塞I&#x2F;O\n\n一个线程对应一个Selector选择器\n一个Selector对应多个Channel通道\n一个Channel对应一个Buffer(底层是一个数组)\n直接缓冲区与非直接缓冲区\n直接缓冲区(非堆内存): 本地IO -&gt; 直接内存 -&gt; 本地IO\n非直接缓冲区(堆内存): 本地IO -&gt; 直接内存 -&gt; 非直接内存 -&gt; 直接内存 -&gt; 本地IO\n\n\n\nSelector选择器\n\n可以通过Selector来实现一个I&#x2F;O线程并发处理N个客户端连接和读写操作\nSelector接多个Channel并监听这些Channel上的事件，使用选择器的事件迭代器遍历获取选择器监听到的事件并判断事件类型分别处理，处理完后清除事件\n\nAIO(Async-Blocked I&#x2F;O): 异步非阻塞I&#x2F;O\n多线程多线程\n\n进程(资源分配的基本单位): 是程序的一次执行过程，是系统运行程序的基本单位。系统运行一个程序即是一个进程从创建，运行到消亡的过程。\n线程(执行调度的基本单位): 与进程相似，但线程是一个比进程更小的执行单位。一个进程在其执行的过程中可以产生多个线程。与进程不同的是多个线程可以共享同一块内存空间和一组系统资源(堆)，所以系统在产生一个线程，或是在各个线程之间作切换工作时，负担要比进程小得多。但是频繁的切换线程可能会消耗大量的CPU资源，因为需要频繁的保存和恢复线程运行上下文。\n特性\n可见性\n有序性\n原子性\n\n\n\n\n纤程: Java不涉及\n\n线程撕裂者: 一个核里面可以跑多个线程\n\n一颗CPU可以有多个核，正常的CPU一个核可以同时跑一个线程\n线程撕裂者就是一个核里面有一个ALU(arithmetic and logic unit)和2寄存器组，ALU可以在2个寄存器组之间快速切换，一个寄存器组存一个线程的工作数据，这样一个核看起来就是同时跑2个线程。例如4核8线程\n\n并行与并发\n\n并行：多个cpu实例或者多台机器同时执行一段处理逻辑，是真正的同时。\n并发：通过cpu调度算法，让用户看上去同时执行，实际上从cpu操作层面不是真正的同时。并发往往在场景中有公用的资源，那么针对这个公用的资源往往产生瓶颈，我们会用TPS(Transaction per Second 事物数&#x2F;秒)或者QPS(Queries Per Second 查询数&#x2F;秒)来反应这个系统的处理能力\n\n线程安全:经常用来描绘一段代码。指在并发的情况之下，该代码经过多线程使用，线程的调度顺序不影响任何结果。这个时候使用多线程，我们只需要关注系统的内存，cpu是不是够用即可。\n死锁:产生死锁的四个必要条件\n\n互斥条件：进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。\n不可剥夺条件: 进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放(只能是主动释放)。\n请求与保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。\n循环等待条件: 存在一种进程资源的循环等待链，链中每一个进程已获得的资源同时被 链中下一个进程所请求。即存在一个处于等待状态的进程集合{Pl, P2, …, pn}，其中Pi等 待的资源被P(i+1)占有(i&#x3D;0, 1, …, n-1)，Pn等待的资源被P0占有\n\n同步:Java中的同步指的是通过人为的控制和调度，保证共享资源的多线程访问成为线程安全，来保证结果的准确。常见的解决方法是使用synchronized关键字。\nsynchronized关键字\nsynchronized(expression) &#123;// 同步代码块&#125;: 对表达式expresssion求值(值的类型须是引用类型reference type)，获取它所代表的对象，然后尝试获取这个对象的锁 -&gt; 如果能获取锁，则进入同步块执行，执行完后退出同步块，并归还对象的锁(异常退出也会归还); 如果不能获取锁，则阻塞在这里，直到能够获取锁;\n\n特性:\n\n原子性: 同步代码块中的内容要么全部执行要么都不执行\n可见性: 多个线程访问一个资源时，该资源的状态、值信息等对于其他线程都是可见的。一个线程如果要访问该类或对象必须先获得它的锁，而这个锁的状态对于其他任何线程都是可见的，并且在释放锁之前会将对变量的修改刷新到主存当中，保证资源变量的可见性。这点和volatile的实现类似，被volatile修饰的变量，每当值需要修改时都会立即更新主存，主存是共享的，所有线程可见，所以确保了其他线程读取到的变量永远是最新值，保证可见性\n有序性: 程序执行的顺序按照代码先后执行，每个时刻都只有一个线程访问同步代码块，也就确定了线程执行同步代码块是分先后顺序的，保证了有序性\n可重入性: synchronized关键字属于可重入锁。当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁。通俗一点讲就是说一个线程拥有了锁仍然还可以重复申请锁。\n\n\n源码解读\n\n反编译使用了synchronized关键字的类的class文件可以看到两种实现方法:\n字节码指令(monitorenter,monitorexit): 修饰同步代码块\n\n\nsynchronized修饰在方法块: 通过 monitorenter 和 monitorexit 这两个字节码指令获取线程的执行权的。当方法执行完毕退出以后或者出现异常的情况下会自动释放锁\nJVM执行到monitorenter指令时它会尝试获取对象的锁，如果该对象没有锁，或者当前线程已经拥有了这个对象的锁时，它会把计数器+1；然后当执行到monitorexit 指令时就会将计数器-1；然后当计数器为0时，锁就释放了。如果获取锁失败，那么当前线程就要阻塞等待，直到对象锁被另一个线程释放为止。\n反编译后可以看到一个monitorenter和两个monitorexit: 这是因为第二个monitorexit是给异常处理释放锁用的\nmonitor到底是什么: monitor它就是个监视器，底层源码是C++编写的\n\n\nflag=ACC_SYNCHRONIZED: 修饰同步方法\n\n\n这标志用来告诉JVM这是一个同步方法，在进入该方法之前先获取相应的锁，锁的计数器加1，方法结束后计数器-1，如果获取失败就阻塞住，知道该锁被释放。\n\n\n\n\n可重入锁: 就是一个线程不用释放，可以重复的获取一个锁n次，只是在释放的时候，也需要相应的释放n次。(简单来说：A线程在某上下文中或得了某锁，当A线程想要在次获取该锁时，不会应为锁已经被自己占用，而需要先等到锁的释放)假使A线程即获得了锁，又在等待锁的释放，就会造成死锁。\n\n\nmonitorenter, monitorexit的指令解析是通过InterpreterRuntime.cpp中的两个方法实现\n// monitorenter(JavaThread 当前获取锁的线程, BasicObjectLock 基础对象锁)IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT  thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif  if (PrintBiasedLockingStatistics) &#123;    Atomic::inc(BiasedLocking::slow_path_entry_count_addr());  &#125;  Handle h_obj(thread, elem-&gt;obj());  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),         &quot;must be NULL or an object&quot;);  if (UseBiasedLocking) &#123; // UseBiasedLocking是在JVM启动的时候，是否启动偏向锁的标识    // Retry fast entry if bias is revoked to avoid unnecessary inflation    // 当处于不安全点时，通过 revoke_and_rebias尝试获取偏向锁，如果成功则直接返回，如果失败则进入轻量级锁获取过程    ObjectSynchronizer::fast_enter(h_obj, elem-&gt;lock(), true, CHECK);  &#125; else &#123;// 如果偏向锁未开启，则进入 slow_enter获取轻量级锁的流程    // BasicObjectLock对象的lock属性的地址用于实现轻量级锁，即所谓的Thread ID    ObjectSynchronizer::slow_enter(h_obj, elem-&gt;lock(), CHECK);  &#125;  assert(Universe::heap()-&gt;is_in_reserved_or_null(elem-&gt;obj()),         &quot;must be NULL or an object&quot;);#ifdef ASSERT  thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END// monitorexit(JavaThread 当前获取锁的线程, BasicObjectLock 基础对象锁)IRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorexit(JavaThread* thread, BasicObjectLock* elem))#ifdef ASSERT  thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endif  Handle h_obj(thread, elem-&gt;obj());  assert(Universe::heap()-&gt;is_in_reserved_or_null(h_obj()),         &quot;must be NULL or an object&quot;);  if (elem == NULL || h_obj()-&gt;is_unlocked()) &#123;    THROW(vmSymbols::java_lang_IllegalMonitorStateException());  &#125;  ObjectSynchronizer::slow_exit(h_obj(), elem-&gt;lock(), thread);  // Free entry. This must be done here, since a pending exception might be installed on  // exit. If it is not cleared, the exception handling code will try to unlock the monitor again.  elem-&gt;set_obj(NULL);#ifdef ASSERT  thread-&gt;last_frame().interpreter_frame_verify_monitor(elem);#endifIRT_END\n\n// slow_entervoid ObjectSynchronizer::slow_enter(Handle obj, BasicLock* lock, TRAPS) &#123;  markOop mark = obj-&gt;mark();  assert(!mark-&gt;has_bias_pattern(), &quot;should not see bias pattern here&quot;);  if (mark-&gt;is_neutral()) &#123;// 如果当前是无锁状态, markword的    // 直接把mark保存到BasicLock对象的_displaced_header字段    lock-&gt;set_displaced_header(mark);    // 通过CAS将mark word更新为指向BasicLock对象的指针，更新成功表示获得了轻量级锁    // BasicObjectLock对象的lock属性为Thread ID    if (mark == (markOop) Atomic::cmpxchg_ptr(lock, obj()-&gt;mark_addr(), mark)) &#123;      TEVENT (slow_enter: release stacklock) ;      return ;    &#125;    // Fall through to inflate() ...  &#125;   // 如果markword处于加锁状态、且markword中的ptr指针指向当前线程的栈帧，表示为重入操作，不需要争抢锁  else  if (mark-&gt;has_locker() &amp;&amp; THREAD-&gt;is_lock_owned((address)mark-&gt;locker())) &#123;    assert(lock != mark-&gt;locker(), &quot;must not re-lock the same lock&quot;);    assert(lock != (BasicLock*)obj-&gt;mark(), &quot;don&#x27;t relock with same BasicLock&quot;);    lock-&gt;set_displaced_header(NULL);    return;  &#125;#if 0  // The following optimization isn&#x27;t particularly useful.  if (mark-&gt;has_monitor() &amp;&amp; mark-&gt;monitor()-&gt;is_entered(THREAD)) &#123;    lock-&gt;set_displaced_header (NULL) ;    return ;  &#125;#endif\t// 代码执行到这里，说明有多个线程竞争轻量级锁，轻量级锁通过`inflate`进行膨胀升级为重量级锁  lock-&gt;set_displaced_header(markOopDesc::unused_mark());  ObjectSynchronizer::inflate(THREAD, obj())-&gt;enter(THREAD);&#125;\n\n\n深入理解synchronized底层源码HotSpot 三种锁实现总结\n\n锁锁的实现本质上都对应着一个入口的等待队列\n公平锁和非公平锁\n\n公平锁: 多个线程按照申请锁的顺序去获得锁，线程会按顺序进入队列，永远是队列第一位先获得锁\n非公平锁: 多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接获取到锁\n\nReentrantLock 中就有公平锁和非公平锁的实现。默认是采用非公平锁的策略来实现锁的竞争逻辑，它内部是使用AQS来实现所资源的竞争，没有竞争到锁资源的线程，会加入到AQS的同步队列里，这个队列是一个FIFO的双向链表。\nJDK6之前: 无锁、有锁(重量级锁)JDK6之后: 无锁 -&gt; 偏向锁 -&gt; 轻量级锁(CAS) -&gt; 重量级锁\n\n偏向锁\n\n\n如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word的结构也就变为偏向锁结构，当该线程再次请求锁时，无需再做任何同步操作，即获取锁的过程只需要检查Mark Word的锁标记位为偏向锁以及当前线程ID等于Mark Word的ThreadID即可，这样就省去了大量有关锁申请的操作\n\n\n轻量级锁\n\n\n当存在第二个线程申请同一个锁对象时，偏向锁就会立即升级为轻量级锁。注意这里的第二个线程只是申请锁，不存在两个线程同时竞争锁，可以是一前一后地交替执行同步块\n只需要将lock属性地址(ThreadID)通过CAS写入对象头即视为加锁成功，因为BasicLock只有一个8字节属性。当存在多个线程抢占轻量级锁的时候，只有一个能够抢占成功，获取轻量级锁恢复正常执行，其他线程都会尝试将该轻量级锁膨胀成重量级锁，也只有一个线程完成锁膨胀。\n\n\n重量级锁\n\n\n当同一时间有多个线程竞争锁时，锁就会被升级成重量级锁，此时其申请锁带来的开销也就变大\n\nQ: synchronized什么时候是偏向锁，轻量级锁以级重量级锁.\n\n一个线程获得了锁，那么锁就进入偏向模式。第二个线程申请同一个锁对象时，偏向锁就会立即升级为轻量级锁。如果还有第三个或以上的线程竞争锁时，锁就会被升级成重量级锁。\n\nJVM中对象实例的组成:\n\n对象头:\n\n\nMark Word:\n对象的hashCode\n锁信息: 记录对象锁当前的状态，在申请锁、锁升级等过程中JVM都需要读取对象的Mark Word数据\n分代年龄\nGC标志\n\n\nClass Metadata Address: 类型指针指向对象的类元数据，JVM通过该指针确定该对象是哪个类的实例\n\n\n实例数据: 存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐\n对其填充\n\n先行发生原则(happens-before): 在发生操作B之前，操作A产生的影响能被操作B观察到。先行发生原则是判断数据是否存在竞争、线程是否安全的主要依据\nvolatile关键字volatile关键字: 当一个变量定义为volatile之后，它将具备两种特性\n\n保证此变量对所有线程的可见性，即当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的\n禁止指令重排序优化\n\n\nCPU指令重排序遵循2个原则:\nas-if-serial: 不管怎么重排序，(单线程)程序的执行结果不能被改变，即重排序前和排序后的执行结果应该是一样的\nhappens-before: JDK5后引入，用于保证程序执行的原子性、可见性和有序性\n\n\n\n\n保证不指令重排序的机制:\n\n\n字节码层面: 生成的字节码不会重排序\nCPU层面: 内存屏障: 屏障指令(汇编指令)加载需要保证不重排序的指令之间起到屏障的作用\n\n内存屏障在介绍内存屏障前，需要知道编译器和 CPU 会在保证程序输出结果一致的情况下，会对代码进行重排序，从指令优化角度提升性能。而指令重排序可能会带来一个不好的结果，导致 CPU 的高速缓存和内存中数据的不一致，而内存屏障（Memory Barrier）就是通过阻止屏障两边的指令重排序从而避免编译器和硬件的不正确优化情况。在硬件层面上，内存屏障是 CPU 为了防止代码进行重排序而提供的指令，不同的硬件平台上实现内存屏障的方法可能并不相同。在 Java8 中，引入了 3 个内存屏障的函数，它屏蔽了操作系统底层的差异，允许在代码中定义、并统一由 JVM 来生成内存屏障指令，来实现内存屏障的功能。内存屏障可以看做对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。以loadFence方法为例，它会禁止读操作重排序，保证在这个屏障之前的所有读操作都已经完成，并且将缓存数据设为无效，重新从主存中进行加载。Unsafe 中提供了下面三个内存屏障相关方法：\n\npublic native void loadFence();: 内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前\npublic native void storeFence();: 内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前\npublic native void fullFence();: 内存屏障，禁止load、store操作重排序\n\nReentrantLock(可重入锁):\n\n指的是一个线程能够对一个临界资源重复加锁\n\nLongAdder\n\n采用分段CAS: 除了真正记录数值的base属性外，还有与base相同的数据类型的cell数组，如果存在多个线程同时对Lang做自增操作，则new一个cell元素放到cell数组里供新增的线程做操作(这里会根据线程数自动扩容或缩容cell数组)，使得同时对base做自增操作的线程数变少，自旋占用的CPU变少，最后再用sum求和操作对所有cell属性和base属性做求和操作并返回，这个求出来的和就是所有线程做的操作的总和\n\nJava线程Java 中实现多线程的方法\n\n继承 Thread 类\n实现 Runnable 接口: 如果一个类继承 Thread类，则不适合于多个线程共享资源，而实现了 Runnable 接口，就可以方便的实现资源的共享\n\n线程的状态变化:\n\nNew(创建状态): 在程序中用构造方法创建了一个线程对象后，新的线程对象便处于新建状态，此时它已经有了相应的内存空间和其他资源(程序计数器、本地方法栈、虚拟机栈)，但还处于不可运行状态。新建一个线程对象可采用Thread 类的构造方法来实现，例如 Thread thread=new Thread()\nReady(就绪状态): 新建线程对象后，调用该线程的 start() 方法就可以启动线程。当线程启动时，线程进入就绪状态。此时，线程将进入线程队列排队，等待 CPU 调度，这表明它已经具备了运行条件\nRunning(运行状态): 当就绪状态被调用并获得处理器资源时，线程就进入了运行状态。此时，自动调用该线程对象的 run() 方法。run() 方法定义该线程的操作和功能\nBlocked(阻塞状态): 一个正在执行的线程遇到synchronized，会进入阻塞状态。线程都将进入阻塞状态，阻塞的线程进入调度队列entry set排队，获取到锁的线程才可以转入就绪状态\nWaiting(等待): 调用Object.wait(), Thread.join()方法可使一个线程进入不带时限的等待状态，直到其它线程调用了方法Object.notify()或Object.notifyAll()唤醒了等待状态的线程，被唤醒后可能进入调度队列entry set继续等待获取锁(Blocked状态)或直接获取到锁(Runnable状态)\nTime_Waiting(超时等待): 调用Object.wait(long), Thread.join(long), Thread.sleep(long)方法可使一个线程进入带时限的等待状态，直到其它线程调用了方法Object.notify()或Object.notifyAll()唤醒了等待状态的线程\nTerminated(死亡状态): 线程调用 stop() 方法时或 run() 方法执行结束后，即处于死亡状态。\n\n\nJava 线程状态之 WAITING\n\n常用的线程池java.util.concurrent.Executors类下静态方法:\n\nnewSingleThreadExecutor(): 创建了一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。\nnewFixedThreadPool(int nThreads): 创建了一个固定大小的线程池，每次提交一个任务就创建一个线程，直到线程达到线程池的最大值nThreads。线程池的大小一旦达到最大值后，再有新的任务提交时则放入无界阻塞队列中，等到有线程空闲时，再从队列中取出任务继续执行。\nnewCachedThreadPool(): 创建了一个可缓存的线程池。当有新的任务提交时，有空闲线程则直接处理任务，没有空闲线程则创建新的线程处理任务，队列中不储存任务。线程池不对线程池大小做限制，线程池大小完全依赖于操作系统（或者说JVM）能够创建的最大线程大小。如果线程空闲时间超过了60秒就会被回收。\n\npublic ThreadPoolExecutor(int corePoolSize, // 核心线程数                          int maximumPoolSize, // 线程池最大线程数                          long keepAliveTime, // 超出核心线程数的线程等待new task的时间，超过则terminated                          TimeUnit unit, // keepAliveTime时间的单位                          BlockingQueue&lt;Runnable&gt; workQueue, // 用于保存等待执行的任务的阻塞队列: 用于存放等待线程执行的task的队列只存放由execute方法提交的Runnable任务                          RejectedExecutionHandler handler // 线程池对拒绝任务的处理策略                          ); public static ExecutorService newSingleThreadExecutor() &#123;        return new FinalizableDelegatedExecutorService            (new ThreadPoolExecutor(1, 1,                                    0L, TimeUnit.MILLISECONDS,                                    new LinkedBlockingQueue&lt;Runnable&gt;())); // 本身是有界队列但是这里未设置其大小限制，默认Integer.MAX_VALUE，此时相当于无界队列&#125;public static ExecutorService newFixedThreadPool(int nThreads) &#123;        return new ThreadPoolExecutor(nThreads, nThreads,                                      0L, TimeUnit.MILLISECONDS,                                      new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newCachedThreadPool() &#123;        return new ThreadPoolExecutor(0, Integer.MAX_VALUE,                                      60L, TimeUnit.SECONDS,                                      new SynchronousQueue&lt;Runnable&gt;()); // 这个阻塞队列没有存储空间，这意味着只要有请求到来，就必须要找到一条工作线程处理他，如果当前没有空闲的线程，那么就会再创建一条新的线程&#125;\n\nExecutors存在什么问题\n\nSingleThreadPool和FixedThreadPool使用的是无界队列，其请求队列长度为Integer.MAX_VALUE，可能会堆积大量的请求而导致OOM\nCachedThreadPool和ScheduledThreadPool允许创建的线程数量为Integer.MAX_VALUE，可能会大量创建线程而导致OOM\n\n创建线程池的正确姿势，直接使用java.util.concurrent.ThreadPoolExecutor类的构造方法来创建\nExecutorService executor = new ThreadPoolExecutor(10, 10, // 10个线程，最大也支持10个        60L, TimeUnit.SECONDS, // 超时时间60秒        new ArrayBlockingQueue(10), // 有界队列，容量为10，最多容纳10个task        new ThreadFactoryBuilder().setNameFormat(&quot;my-pool-%d&quot;).build(), // 线程名称        new ThreadPoolExecutor.AbortPolicy()); // 拒绝策略(默认)\n\nQ: 线程池怎么设置核心线程数?\n\n如果是CPU密集型服务线程数量等于CPU核心数\n如果是I&#x2F;O密集型服务: 线程数 &#x3D; ((工作时间+休息时间)&#x2F;工作时间) * CPU核心数 * CPU利用率\n\nworkQueue(工作队列): \n\nArrayBlockingQueue: 基于数组结构的有界阻塞队列，按FIFO（先进先出）原则对任务进行排序。使用该队列，线程池中能创建的最大线程数为maximumPoolSize。 \nLinkedBlockingQueue: 基于链表结构的无界阻塞队列，按FIFO（先进先出）原则对任务进行排序，吞吐量高于ArrayBlockingQueue。使用该队列，线程池中能创建的最大线程数为corePoolSize。\nSynchronousQueue: 一个不存储元素的阻塞队列。添加任务的操作必须等到另一个线程的移除操作，否则添加操作一直处于阻塞状态。\nPriorityBlockingQueue: 一个支持优先级的无界阻塞队列。使用该队列，线程池中能创建的最大线程数为corePoolSize。\n\n线程池(ThreadPoolExecutor)处理流程:\n\n提交任务 execute(Runnable)\n核心线程池是否已满? N: 创建线程执行任务\n队列是否已满? N: 将任务存储在队列中\n线程池是否已满? N: 创建非核心线程执行任务\n经过以上步骤还是有新任务则执行拒绝策略\n\nhandler(饱和策略，或者又称拒绝策略): 当队列和线程池都满了，即线程池饱和了，必须采取一种策略处理提交的新任务。\n\nAbortPolicy: 无法处理新任务时，直接抛出异常，这是默认策略。 \nCallerRunsPolicy: 用调用者所在的线程来执行任务。\nDiscardOldestPolicy: 丢弃阻塞队列中最靠前的一个任务，并执行当前任务。\nDiscardPolicy: 直接丢弃任务。\n\n线程池的状态:\n\nRUNNING: 该状态的线程池既能接受新提交的任务，又能处理阻塞队列中任务。\nSHUTDOWN: 该状态的线程池不能接收新提交的任务，但是能处理阻塞队列中的任务。处于 RUNNING 状态时，调用shutdown()方法会使线程池进入到该状态。 注意： finalize()方法在执行过程中也会隐式调用shutdown()方法。 \nSTOP: 该状态的线程池不接受新提交的任务，也不处理在阻塞队列中的任务，还会中断正在执行的任务。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态\nTIDYING: 如果所有的任务都已终止，workerCount(有效线程数)&#x3D;0 。线程池进入该状态后会调用 terminated() 钩子方法进入TERMINATED 状态。\nTERMINATED: 在terminated()钩子方法执行完后进入该状态，默认terminated()钩子方法中什么也没有做。\n\n线程池的关闭可通过shutdown()或者shutdownNow()方法 \n\nshutdown()将线程池的状态设置为SHUTDOWN状态，只会中断空闲的工作线程\nshutdownNow()将线程池的状态设置为STOP状态，会中断所有工作线程，不管工作线程是否空闲\n调用两者中任何一种方法，都会使isShutdown()方法的返回值为true；\n线程池中所有的任务都关闭后，isTerminated()方法的返回值为true\n\nQ: 新的任务提交到线程池，线程池是怎样处理的？步骤：\n\n线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。如果核心线程池里的线程都在执行任务，则执行第二步。\n线程池判断工作队列是否已经满。如果没有满，则将新提交的任务存储在这个工作队列里进行等待。如果工作队列满了，则执行第三步。\n线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。\n\nQ: 父线程子线程怎么共享数据?\n\n可以使用InheritableThreadLocals可继承线程变量这个类来实现，ThreadLocals是线程变量，相当于一个map，每个线程是map的key，value是set()进去的值，一个线程使用get()只能get到它自己set进去的值，所以不可用于获取父线程的数据。而InheritableThreadLocals会在子线程new出来的时候就把自己的value复制进去，所以子线程可以使用这个来共享获取父线程的数 据\n\nQ: 线程池怎么维护线程状态，怎么处理线程异常.什么时候task需要queued\n\nTODO\n\nAQS(AbstractQueuedSynchronized)\n抽象队列同步器AQS: 是一个同步框架，它提供通用机制来原子性管理同步状态、阻塞和唤醒线程，以及维护被阻塞线程的队列. AQS定义了一套多线程访问共享资源的同步器框架，许多同步类实现都依赖于它，如常用的ReentrantLock&#x2F;Semaphore&#x2F;CountDownLatch\n底层实现为: volatile + CAS\nAQS内部维护了一个volatile修饰的共享变量，state主要用来标记锁的状态。\nAQS通过自定义Node节点来维护一个队列，完成资源获取线程的排队工作。\nAQS通过park和unParkSuccessor方法来实现阻塞和唤醒线程。\nAQS内部的compareAndSetState方法保证了锁状态设置的原子性。\n\n默认ReentrantLock采用的是非公平锁实现，下面来分析一次ReebtrantLock加锁的过程吧，整体的过程描述如下：\n\n当线程A访问时，先判断state所标记值是否为0\n发现state标识为0，接着将state的值通过compareAndSetState()方法修改为1\n设置当前拥有独占访问权的线程A为自己当前线程\n其他线程B再次访问，也是一上来先去判断了一下state状态，发现是1，自然CAS失败了，只能乖乖进入等待队列\n经过一段时间，线程A访问资源结束，准备释放锁，修改state状态为0，准备去唤醒B线程\n这时候线程C也过来了，他也来抢占锁资源，发现state为0，线程C果断CAS成功，抢占了锁资源，还修改当前线程为自己\n线程B被A唤醒准备去获取锁，发现state已经是1了，锁资源已经被抢占，结果线程B又只能默默回去等等队列继续等待了\n\nCAS原理\nCAS有3个操作数，内存值V，旧的预期值A，要修改的新值B。当且仅当预期值A和内存值V相同时，将内存值V修改为B，否则什么都不做。\nCAS操作都是通过sun包下Unsafe类实现，而Unsafe类中的方法都是native方法CAS通过调用JNI(Java Native Interface)的c++代码实现的\nunsafe 的cas 依赖了的是 jvm 针对不同的操作系统实现的 Atomic::cmpxchg\nAtomic::cmpxchg 的实现使用了汇编的 cas 操作，并使用 cpu 硬件提供的 lock信号保证其原子性\nAtomic类中的value是volatile的，volatile可以保证可见性和有序性\nAtomic类中设置值使用自旋锁，不断取内存中的value值，然后CAS更新，若失败则持续自旋重试更新操作\n缺点:\nABA问题:\n\n\nCAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。AtomicStampedReference类具有版本号功能\n\n\n只能保证一个共享变量的原子操作: 多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者把多个共享变量合并成一个共享变量来操作(JDK1.5之后提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作)\n\n\n\nAtomic::cmpxchg\n#define LOCK_IF_MP(mp) &quot;cmp $0, &quot; #mp &quot;; je 1f; lock; 1: &quot;// 判断mp是否为多核CPU是则返回LOCK指令inline jlong Atomic::cmpxchg (jlong exchange_value, volatile jlong* dest, jlong compare_value) &#123;  bool mp = os::is_MP(); //   __arm__ __volatile__ (LOCK_IF_MP(%4) &quot;cmpxchgq %1,(%3)&quot; // MP=mult prosser LOCK_IF_MP返回lock指令 汇编指令cmpxchgq执行原子的CAS                        : &quot;=a&quot; (exchange_value)                        : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp)                        : &quot;cc&quot;, &quot;memory&quot;);  return exchange_value;&#125;\n\n\n乐观锁底层实现: lock + cmpxchg 指令\n悲观锁底层实现: lock 指令\nvolatile的底层实现也是用的: lock指令\n\n缓存一致性协议: 硬件级别的协议\n作用: 多核CPU有多个一级缓存，保证缓存内部数据的一致,不让系统数据混乱\nIntel CPU对缓存一致性协议的实现(MESI &#x3D; modified + exclusive + shared + invalid)\nMESI中每个缓存行(Cache line:CPU中缓存存储数据的单元，一般为64字节)都有四个状态(假设线程 A 和线程 B 同时对一个变量执行 i++)\n核心 A 从内存中加载变量 i，并将缓存行设置为 E（独享），随后通过总线嗅探检查内存中对变量 i 的操作；\n核心 B 从内存中加载变量 i，总线嗅探机制会将核心 A 与核心 B 的缓存行设置为 S（共享）\n核心 A 对变量 i 进行修改，缓存行设置为 M（修改），而核心 B 被通知修改缓存行为 I（无 效）。如果存在高并发，则交给总线裁决\n核心 A 将修改后数据同步回内存，并将变量设置为 E（独享）\n核心 B 重新刷新缓存行，并将缓存行核心 A 和核心 B 的缓存行设置为 S（共享）\n\n\nCPU 是通过总线和内存进行数据传输的。在多核心时代下，多个核心通过同一条总线和内存以及其他硬件进行通信\n通过在 inc 指令前添加 lock 前缀，即可让该指令具备原子性。多个核心同时执行同一条 inc 指令时，会以串行的方式进行\n伪共享问题: 伪共享是指多个线程同时读写同一个缓存行中的变量，而导致缓存行失效的问题。尽管多个线程分别访问的是不同的数据，但由于它们存在同一个缓存行中，只要任何一方修改都会使得缓存失效，降低了运算效率。\n解决方案: \n字节填充，在变量前后填充多个字节使得 变量大小+填充的字节&#x3D;64字节，这样这个变量肯定会独占一个缓存行。\nJDK8以及之后的版本 Java 提供了sun.misc.Contended 注解，通过@Contented注解就可以解决伪共享的问题。使用@Contented注解后会增加128字节的padding，并且需要开启-XX:-RestrictContended选项后才能生效。\n\n\nQ: 你工作中遇到的一个比较大的问题是什么\nA: 钻石突击队抢单，\n\n\nCPU缓存一致性协议MESI缓存行与MESI\n\n用户态内核态\nLinux操作系统的体系架构分为用户态和内核态\n内核态: 本质上是一种软件，控制计算机硬件资源(CPU资源、存储资源、I&#x2F;O资源等)\n用户态: 上层应用程序的活动空间\n上层应用想要访问计算机硬件资源需要通过内核提供的访问接口(系统调用)来调用\n系统调用是操作系统的最小功能单位\n从用户态到内核态切换可以通过三种方式:\n系统调用\n异常: 如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常\n外设中断: 当外设完成用户的请求时，会向CPU发送中断信号\n\n\n\n多线程框架Disruptor 框架\n\n英国外汇交易公司LMAX开发的一个高性能队列。主要用于线程与线程之间的消息传递\nQPS: 600w\n为什么快:\nCAS: ArrayBlockingQueue使用了重量级锁(lock锁)，而Disruptor采用CAS操作\n消除伪共享: 解决方案: 字节填充，在变量前后填充多个字节使得 变量大小+填充的字节&#x3D;64字节，这样这个变量肯定会独占一个缓存行。\nRingBuffer: 环形数组，没有删除操作，超过容量会直接覆盖原有数据，避免了垃圾回收。大小必须为2的n次方，因为取余运算直接使用的是位运算，使得元素定位更快。\n\n\n\nJVM类加载类加载子系统: 根据给定的全限定名类名(如java.lang.Object)来装载class文件的内容到方法区(Method Area)\n\nBootstrap ClassLoader(启动类加载器): $JAVA_HOME中jre/lib/rt.jar里所有的class，由C++实现\nExtension ClassLoader(扩展类加载器): 负责加载java平台中扩展功能的一些jar包，包括$JAVA_HOME中jre/lib/*.jar或-D java.ext.dirs指定目录下的jar包\nApp ClassLoader(系统类加载器): 负责加载classpath中指定的jar包及目录中class\nCustom ClassLoader(用户自定义类加载器): 属于应用程序根据自身需要自定义的ClassLoader，如tomcat、jboss都会根据j2ee规范自行实现ClassLoader\n\n双亲委派机制: JVM对class文件采用按需加载的方式，在加载时JVM采用的是双亲委派机制，即把请求交由父类处理，它是一种任务委派模式\n\n如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行\n如果父类加载器还存在其父类加载器，则进一步向上委托，一次递归，请求最终将到达顶层的启动类加载器\n如果父类加载器可以完成类加载任务，就成功返回，若无法完成，子类加载器才会去加载。\n\nJVM 内存模型运行时数据区(Runtime Data Area)\n\n程序计数器(Program Counter Register) &lt;- 线程不共享\n本地方法栈(Native Method Stack) &lt;- 线程不共享\n虚拟机栈(Java Virtual Machine Stack) &lt;- 线程不共享\n方法区(Method Area) &lt;- 线程共享\n堆(Heap) &lt;- 线程共享\n\n本地内存\n\n直接内存(Direct Memory)\n方法区(Method Area): 1.8之后挪到了本地内存\n\n1. 程序计数器(Program Counter Register)每个线程都要它自己的程序计数器，是线程私有的，生命周期与线程的生命周期保持一致。程序计数器会存储当前线程正在执行的Java方法的JVM指令地址，若为native方法则为undefined\n2. 本地方法栈(Native Method Stack)本地方法栈用于管理本地方法的调用\n3. 虚拟机栈(Java Virtual Machine Stack)\n线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame)\n栈帧的内部结构：\n局部变量表(Local Variables): 最基本的存储单元是Slot(变量槽)，容量大小是在编译期确定下来的，并保存在方法的Code属性的maximum local variables数据项中。JVM会为局部变量表中的每一个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值。\n操作数栈(operand Stack)(或表达式栈): 用于保存计算过程的中间结果\n动态链接(DynamicLinking)(或指向运行时常量池的方法引用): 每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用，包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(Dynamic Linking)\n方法返回地址(Return Address)(或方法正常退出或者异常退出的定义): 存放调用该方法的pc寄存器的值\n\n\n\n4. 方法区(Method Area)方法区包含运行时常量池(Runtime Constant Pool)元空间(Metaspace)是其实现，元空间并不在虚拟机中，而是使用本地内存1.8之前方法区在运行时数据区，1.8之后挪到了本地内存\n5. 堆(Heap)年青代:老年代&#x3D;1:2\n\n年青代(Young): Eden:From:To&#x3D;8:1:1\nEden: 新创建的对象绝大部分会分配在Eden区。当Eden区内存不够的时候，就会触发MinorGC\nSurvivor 0(From): 在GC开始的时候，对象只会存在于Eden区和名为From的Survivor区，To区是空的，一次MinorGc过后，Eden区和SurvivorFrom区存活的对象会移动到SurvivorTo区中，然后会清空Eden区和SurvivorFrom区，并对存活的对象的年龄+1，如果对象的年龄到15，则直接分配到老年代。\nSurvivor 1(To)\n\n\n老年代(Tenured): 老年代存放从年轻代存活的对象。一般来说老年代存放的都是生命期较长的对象\n\nGC(Generational Collecting)垃圾回收:\nMinor GC: 当伊甸园的空间满时，程序又需要创建对象，触发Minor GC\nFull GC: 当老年代内存不足时，对老年代进行垃圾回收。这时可能会伴随着STW(Stop The World)\nSTW(Stop The World): 停止所有线程，进行垃圾回收，这时候线程会被阻塞，直到垃圾回收完成\nQ: 为什么要STW？-&gt; A: 如果不执行STW的话在Full GC的过程中如果有一个线程执行完毕，那么这个线程的局部变量表里面所指向的在堆里的对象都会变成垃圾，但是此时Full GC还没执行完，那么这次Full GC执行所得到的结果是不准确的\n\n\n\n判断对象是否需要回收\n\n引用计数法: 给对象添加一个引用计数器。但是难以解决循环引用问题。\n可达性分析法: 通过一系列的 GC Roots 的对象作为起始点，从这些节点出发所走过的路径称为引用链。当一个对象到 GC Roots 没有任何引用链相连的时候说明对象不可用。\n\n垃圾回收算法\n\n标记-清除算法(Mark-Sweep):\n\n\n分为两个阶段：标记阶段(标记出所有需要被回收的对象) -&gt; 清除阶段(回收被标记的对象所占用的空间)\n缺点: 效率不高、空间会产生大量碎片\n\n\n复制算法(Copying): 将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用的内存空间一次清理掉，这样一来就不容易出现内存碎片的问题。Eden:From:To&#x3D;8:1:1\n标记-整理算法(Mark-Compact): 在完成标记之后，它不是直接清理可回收对象，而是将存活对象都向一端移动，然后清理掉端边界以外的内存\n分代收集(Generational Collection): 根据对象的生命周期划分几块内存区，一般是分为新生代和老年代。新生代:老年代&#x3D;1:2\n\n垃圾收集器:\n\nSerial&#x2F;Serial Old收集器: 单线程收集器，进行垃圾收集时，必须暂停所有用户线程\n\n\nSerial: 新生代 Copying算法\nSerial Old: 老年代 Mark-Compact算法\n\n\nParNew收集器: Serial收集器的多线程版本\nParallel Scavenge收集器: 新生代的多线程收集器回收期间不需要暂停其他用户线程 Copying算法\nParallel Old收集器: 多线程 Mark-Compact算法\nCMS(Concurrent Mark Sweep)收集器: 并发收集器，优点是最短回收停顿时间 Mark-Sweep算法\nG1收集器: 并行与并发收集器，并且它能建立可预测的停顿时间模型\n\nJVM虚拟机调优:\n主要是减少STW发生的频率，因为发生STW的时候会阻塞全部的用户线程，在用户看来就是应用程序卡顿\n能不能通过调整JVM参数是的几乎发生Full GC?\n默认年青代:老年代&#x3D;1:2，改成2:1，那么当年轻代满的时候绝大部分昭生夕死的对象会被干掉，只有实在干不掉的才会挪到老年代\n\n\njVisualVM: 可视化工具，可以查看JVM的内存使用情况，安装插件可以观察到堆分代模型的整个GC过程\n\nJava 定时任务单机定时任务技术选型java.util.TimerTimer 内部使用一个叫做 TaskQueue 的类存放定时任务，它是一个基于最小堆实现的优先级队列。TaskQueue 会按照任务距离下一次执行时间的大小将任务排序，保证在堆顶的任务最先执行。这样在需要执行任务时，每次只需要取出堆顶的任务运行即可\n// 示例代码：TimerTask task = new TimerTask() &#123;    public void run() &#123;        System.out.println(&quot;当前时间: &quot; + new Date() + &quot;n&quot; +                &quot;线程名称: &quot; + Thread.currentThread().getName());    &#125;&#125;;System.out.println(&quot;当前时间: &quot; + new Date() + &quot;n&quot; + &quot;线程名称: &quot; + Thread.currentThread().getName());Timer timer = new Timer(&quot;Timer&quot;);long delay = 1000L;timer.schedule(task, delay);//输出：//当前时间: Fri May 28 15:18:47 CST 2021n线程名称: main//当前时间: Fri May 28 15:18:48 CST 2021n线程名称: Timer\n\n不过其缺陷较多，比如一个 Timer 一个线程，这就导致 Timer 的任务的执行只能串行执行，一个任务执行时间过长的话会影响其他任务（性能非常差），再比如发生异常时任务直接停止(Timer 只捕获了 InterruptedException)。ScheduledThreadPoolExecutor 支持多线程执行定时任务并且功能更强大，是 Timer 的替代品。\nScheduledExecutorService// 示例代码：TimerTask repeatedTask = new TimerTask() &#123;    @SneakyThrows    public void run() &#123;        System.out.println(&quot;当前时间: &quot; + new Date() + &quot;n&quot; +                &quot;线程名称: &quot; + Thread.currentThread().getName());    &#125;&#125;;System.out.println(&quot;当前时间: &quot; + new Date() + &quot;n&quot; + &quot;线程名称: &quot; + Thread.currentThread().getName());ScheduledExecutorService executor = Executors.newScheduledThreadPool(3);long delay  = 1000L;long period = 1000L;executor.scheduleAtFixedRate(repeatedTask, delay, period, TimeUnit.MILLISECONDS);Thread.sleep(delay + period * 5);executor.shutdown();//输出：//当前时间: Fri May 28 15:40:46 CST 2021n线程名称: main//当前时间: Fri May 28 15:40:47 CST 2021n线程名称: pool-1-thread-1//当前时间: Fri May 28 15:40:48 CST 2021n线程名称: pool-1-thread-1//当前时间: Fri May 28 15:40:49 CST 2021n线程名称: pool-1-thread-2//当前时间: Fri May 28 15:40:50 CST 2021n线程名称: pool-1-thread-2//当前时间: Fri May 28 15:40:51 CST 2021n线程名称: pool-1-thread-2//当前时间: Fri May 28 15:40:52 CST 2021n线程名称: pool-1-thread-2\n\n缺点: 不论是使用 Timer 还是 ScheduledExecutorService 都无法使用 Cron 表达式指定任务执行的具体时间\nSpring TaskSpring 自带的定时调度只支持单机，并且提供的功能比较单一。底层是基于 JDK 的 ScheduledThreadPoolExecutor 线程池来实现的\n/** * cron：使用Cron表达式。　每分钟的1，2秒运行 */@Scheduled(cron = &quot;1-2 * * * * ? &quot;)public void reportCurrentTimeWithCronExpression() &#123;  log.info(&quot;Cron Expression: The time is now &#123;&#125;&quot;, dateFormat.format(new Date()));&#125;\n\n分布式定时任务技术选型通常情况下，一个定时任务的执行往往涉及到下面这些角色：\n\n任务: 首先肯定是要执行的任务，这个任务就是具体的业务逻辑比如定时发送文章\n调度器: 其次是调度中心，调度中心主要负责任务管理，会分配任务给执行器\n执行器: 最后就是执行器，执行器接收调度器分派的任务并执行\n\nQuartz优缺点总结：\n\n优点: 可以与 Spring 集成，并且支持动态添加任务和集群。\n缺点: 分布式支持不友好，没有内置 UI 管理控制台、使用麻烦（相比于其他同类型框架来说）\n\nElastic-Job基于Quartz和ZooKeeper的分布式调度解决方案ElasticJob 支持任务在分布式场景下的分片和高可用、任务可视化管理等功能Elastic-Job 没有调度中心这一概念，而是使用 ZooKeeper 作为注册中心，注册中心负责协调分配任务到不同的节点上。Elastic-Job 中的定时调度都是由执行器自行触发，这种设计也被称为去中心化设计（调度和处理都是执行器单独完成）\n\nDatabaseSQL常见编写SQL性能建议\n充分利用表上已经存在的索引\n避免使用双%号的查询条件。如：a like &#39;%123%&#39;，（如果无前置%,只有后置%，是可以用到列上的索引的）\n禁止使用 SELECT * 必须使用 SELECT &lt;字段列表&gt; 查询\nSELECT * 消耗更多的 CPU 和 IO 以网络带宽资源\nSELECT &lt;字段列表&gt; 可减少表结构变更带来的影响\nSELECT * 无法使用覆盖索引\n\n\n禁止使用不含字段列表的 INSERT 语句\n建议使用预编译语句进行数据库操作\n预编译语句可以重复使用这些计划，减少 SQL 编译所需要的时间，还可以解决动态 SQL 所带来的 SQL 注入的问题。\n只传参数，比传递 SQL 语句更高效\n相同语句可以一次解析，多次使用，提高处理效率。\n\n\n避免使用子查询，可以把子查询优化为 join 操作\n避免使用 JOIN 关联太多的表\n减少同数据库的交互次数\n对应同一列进行 or 判断时，使用 in 代替 or\nWHERE 从句中禁止对列进行函数转换和计算\n\n数据库操作规范\n超 100 万行的批量写 (UPDATE,DELETE,INSERT) 操作,要分批多次进行操作\n大批量操作可能会造成严重的主从延迟\n避免产生大事务操作\n\n\n程序连接不同的数据库使用不同的账号，禁止跨库查询\n为数据库迁移和分库分表留出余地\n降低业务耦合度\n避免权限过大而产生的安全风险\n\n\n\nMySQL存储引擎MyISAM\n\n非聚集索引: 索引文件与数据文件分开; .MYI文件存索引, .MYD文件存数据\n底层数据结构: B+Tree 作为索引结构，叶节点的 data 域存放的是数据记录的地址\n主键: 可以没有\n辅助索引(Secondary key): 结构上与主索引没有任何区别，辅助索引的 key 可以重复\n\nInnoDB\n\n聚集索引: 数据文件本身就是索引文件\n底层数据结构: B+Tree 作为索引结构，叶节点的 data 域保存了完整的数据记录。索引的 key 是数据表的主键，因此InnoDB 要求表必须有主键\n主键: 必须有主键。如果没有显式指定，则会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则自动为 InnoDB 表生成一个隐含字段作为主键，类型为长整形。尽量在采用自增字段做表的主键，非单调的主键会造成在插入新记录时数据文件为了维持 B+Tree 的特性而频繁的分裂调整\n辅助索引(Secondary key): 辅助索引 data 域存储相应记录主键的值而不是地址。这使得辅助索引搜索需要检索两遍索引(回表):首先检索辅助索引获得主键,然后用主键到主索引中检索获得记录。\n\n索引 &amp; 优化mysql索引数据结构为什么选择B+Tree?\n\n二叉排序树: 无平衡机制，插入递增元素，退化成链表\n红黑树(是一种二叉平衡树): 数据量大时树的深度也会很深\nB Tree: 多叉，从左到右依次递增，叶子节点都在同一层\nB+ Tree: 非叶子节点不存储data，叶子节点包含所有索引字段并用指针从左往右链接成链表。\n\nB+ Tree: 每个节点大小16kb限制，16kb&#x2F;每个节点大小(8字节索引元素+6字节孩子节点磁盘文件地址指针)&#x3D;1170个索引\n\n索引全部加载到内存，找到后根据磁盘文件地址进行一次磁盘I&#x2F;O读取对应的数据\n只用3层的B+ Tree就支持上千万行数据的查找\n\n索引优化\n\n限制每张表上的索引数量,建议单张表索引不超过 5 个\n每个 InnoDB 表必须有个主键\nInnoDB 是一种索引组织表：数据的存储的逻辑顺序和索引的顺序是相同的。每个表都可以有多个索引，但是表的存储顺序只能有一种。\nInnoDB 是按照主键索引的顺序来组织表的\n不要使用更新频繁的列作为主键\n不要使用 UUID,MD5,HASH,字符串列作为主键（无法保证数据的顺序增长），主键建议使用自增 ID 值\n\n\n设置索引字段推荐\n出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列、包含在 ORDER BY、GROUP BY、DISTINCT 中的字段\n并不要将符合 1 和 2 中的字段的列都建立一个索引， 通常将 1、2 中的字段建立联合索引效果更好\n多表 join 的关联列\n\n\n建立索引的目的是：希望通过索引进行数据查找，减少随机 IO，增加查询性能 ，索引能过滤出越少的数据，则从磁盘中读入的数据也就越少\n尽量避免使用外键约束\n\n事务ACID\n\n原子性(Atomicity): 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部都执行，要么都不执行\n一致性(Consistency): 指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的\n隔离性(Isolation): 多个事务并发访问时，事务之间是相互隔离的，一个事务不应该被其他事务干扰，多个并发事务之间要相互隔离\n持久性(Durability): 表示事务完成提交后，该事务对数据库所作的操作更改，将持久地保存在数据库之中\n\n事务并发存在的问题\n\n脏读: 如果一个事务读取到了另一个未提交事务修改过的数据，我们就称发生了脏读现象\n不可重复读: 同一个事务内，前后多次读取，读取到的数据内容不一致\n幻读: 如果一个事务先根据某些搜索条件查询出一些记录，在该事务未提交时，另一个事务写入了一些符合那些搜索条件的记录(如insert、delete、update)，就意味着发生了幻读\n\n事务隔离级别\n\nREAD-UNCOMMITTED(读未提交): 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。\nREAD-COMMITTED(读已提交): 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。\nREPEATABLE-READ(可重复读): 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。\nSERIALIZABLE(可串行化): 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。\n\nInnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）。我们可以通过SELECT @@tx_isolation;命令来查看，MySQL 8.0 该命令改为SELECT @@transaction_isolation;InnoDB 存储引擎在分布式事务的情况下一般会用到 SERIALIZABLE 隔离级别\nInnoDB 实现的 REPEATABLE-READ 隔离级别其实是可以解决幻读问题发生的，主要有下面两种情况：\n\n快照读: 由 MVCC 机制来保证不出现幻读。\n当前读: 使用 Next-Key Lock 进行加锁来保证不出现幻读，Next-Key Lock 是行锁(Record Lock)和间隙锁(Gap Lock)的结合，行锁只能锁住已经存在的行，为了避免插入新行，需要依赖间隙锁。\n\nMVCC(Multi-Version Concurrency Control)多版本并发控制一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。数据库隔离级别读已提交、可重复读 都是基于MVCC实现的\n查询一条记录，基于MVCC，是怎样的流程\n\n获取事务自己的版本号，即事务ID\n获取Read View\n查询得到的数据，然后Read View中的事务版本号进行比较。\n如果不符合Read View的可见性规则， 即就需要Undo log中历史快照;\n最后返回符合规则的数据\n\nInnoDB 实现MVCC，是通过 Read View + Undo Log 实现的，Undo Log 保存了历史快照，Read View可见性规则帮助判断当前版本的数据是否可见。\n\nRead View: \n事务执行SQL语句时，产生的读视图。实际上在innodb中，每个SQL语句执行前都会得到一个Read View\n主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据\n\n\nUndo Log:\n回滚日志，用于记录数据被修改前的信息。在表记录修改之前，会先把数据拷贝到undo log里，如果事务回滚，即可以通过undo log来还原数据\n当delete一条记录时，undo log 中会记录一条对应的insert记录\n用途: \n事务回滚时，保证原子性和一致性\n用于MVCC快照读\n\n\n\n\n快照读: 读取的是记录数据的可见版本（有旧的版本）。不加锁,普通的select语句都是快照读\n当前读: 读取的是记录数据的最新版本，显式加锁的都是当前读\n\nTODO:\n\n分布式Redisredis单线程为什么快?\n\n纯内存操作: 数据存放在内存中，内存的响应时间大约是100纳秒\n单线程: Redis是基于内存的操作，CPU不是Redis的瓶颈。Redis的瓶颈最有可能是机器内存或者网络带宽，同时避免了线程切换和竞态产生的消耗 \n非阻塞I&#x2F;O: Redis采用epoll做为I&#x2F;O多路复用技术的实现 ，再加上Redis自身的事件处理模型将epoll中的连接，读写，关闭都转换为了时间，不在I&#x2F;O上浪费过多的时间\n全局哈希表: \n客户端调服务端:\n发送命令\n执行命令: 每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个队列中，然后逐个被执行。并且多个客户端发送的命令的执行顺序是不确定的。但是可以确定的是不会有两条命令被同时执行，不会产生并发问题\n返回结果\n\nRedis数据结构底层实现\n\nString: Simple dynamic string(SDS)\nbuf[]字节数组，用于保存字符串, len保存字符串的长度, freebuf 数组中未使用字节的数量\n优点: 不用担心字符串变更造成的内存溢出问题\n\n\n链表: 双向链表上扩展了头、尾节点、元素数等属性\n优点: 可以直接获得头、尾节点\n\n\n字典(Hash): 数组+链表的基础上，进行了一些rehash优化\n采用链地址法来处理冲突，然后它没有使用红黑树优化\n哈希表节点采用单链表结构\nrehash优化: 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子(load factor)维持在一个合理的范围之内， 程序需要对哈希表的大小进行相应的扩展或者收缩\n\n\n有序集合:\n底层实现为跳跃表: 跳表其实就是一种可以进行二分查找的有序链表。跳表在原有的有序链表上面增加了多级索引，通过索引来实现快速查找。首先在最高级索引上查找最后一个小于当前查找元素的位置，然后再跳到次高级索引继续查找，直到跳到最底层为止，这时候以及十分接近要查找的元素的位置了(如果查找元素存在的话)。由于根据索引可以一次跳过多个元素，所以跳查找的查找速度也就变快了\n\n\n\n分布式锁\n使用setnx命令(SET if Not eXists)实现: 在Redis中，setnx命令的作用是，如果key不存在，则设置key-value并返回true，如果key存在，则不做任何操作并返回false; 利用这一机制在获取锁为设置key，设置成功返回true表示获取到锁了，执行完业务逻辑之后删除掉设置的key即可\n可以在使用setnx命令的同时设置超时时间，假设值key的那个服务器挂了，没有删除key，那么key会在超时后自动删除以释放锁\n生产案例: 钻石突击队抢单，使用setnx实现分布式锁，锁机构库update，抢到保单的线程抢锁来update机构库对应保单数据的督导工号。没有设置过期时间，一个微服务实例在运行完setnx db-update superId之后没有运行del key来删除key，即设置了锁之后挂了，没有释放锁，导致一个机构库的update被锁住，无法抢单。那么为什么要设置key过期时间呢？如果请求执行因为某些原因意外退出了，导致创建了锁但是没有删除锁，那么这个锁将一直存在（redis不设置key的过期时间，默认是永久的），以至于一直处于加锁状态。\n\nepoll: linux内核下的一个高效的处理大批量的文件操作符的一个实现\n缓存雪崩、缓存穿透、缓存击穿\n缓存雪崩: 缓存同一时间大面积失效，后面的请求都会落到数据库上，造成数据库短时间内无法承受大量请求而崩溃\n解决方案: \n每个key的失效时间加个随机值，避免同一时间大量的key失效\n集群部署，可以将热点数据分布到各个不同的库\n\n\n\n\n缓存穿透: 大量请求的key不存在于缓存中，例如某个黑客制造缓存中不存在的key发起大量请求，导致大量请求落到数据库\n解决方案:\n入参校验，将不合法的参数直接拦截\n缓存和数据库都查不到某个key的数据，就将key写入到redis，value为null，并设置过期时间，避免下次请求落到数据库上\n布隆过滤器: 布隆过滤器可以非常方便的判定一个给定的数据是否存在与海量数据中.可以将所有可能存在的请求的值存到布隆过滤器，当请求过来先判断用户发来的请求是否存在于布隆过滤器，不存在就直接拦截\n\n\n\n\n缓存击穿: 一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key失效瞬间，持续的大并发就穿破缓存，直接请求到数据库\n解决方案:\n定时任务主动刷新缓存设计\njvm缓存+redis缓存的多级缓存: 两个缓存同时失效概率低，JVM缓存时间设随机值,比如 10秒~30秒\n利用redis实现的分布式锁setnx 来实现互斥的数据库操作: 如果缓存中没有则拿到锁的去查数据库\n如果缓存没有,则尝试获取分布式锁(有超时设置)\n如果没有拿到锁,则阻塞当前线程,n秒,之后再次尝试获取分布式锁(自旋)\n拿到锁之后检查数据是否已经被其他线程放到redis缓存中,如果redis缓存已有,直接返回redis中的数据,释放分布式锁\n如果缓存没有被刷新,则查数据库\n将数据库查询的结果保存到redis缓存中\n返回查询结果\n\n\n\n\n\n\n\nCAP 理论起源于 2000 年，由加州大学伯克利分校的 Eric Brewer 教授在分布式计算原理研讨会（PODC）上提出，因此 CAP 定理又被称作 布鲁尔定理（Brewer’s theorem）\nCAP: 分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP 架构\n\nConsistency(一致性): 所有节点访问同一份最新的数据副本\nAvailability(可用性): 非故障的节点在合理的时间内返回合理的响应（不是错误或者超时的响应）\nPartition Tolerance(分区容错性): 分布式系统出现网络分区的时候，仍然能够对外提供服务\n\n\n网络分区: 分布式系统中，多个节点之前的网络本来是连通的，但是因为某些故障（比如部分节点网络出了问题）某些节点之间不连通了，整个网络就分成了几块区域，这就叫 网络分区\n\nZooKeeper 保证的是 CP。 任何时刻对 ZooKeeper 的读请求都能得到一致性的结果，但是， ZooKeeper 不保证每次请求的可用性比如在 Leader 选举过程中或者半数以上的机器不可用的时候服务就是不可用的。\n\nEureka 保证的则是 AP。 Eureka 在设计的时候就是优先保证 A （可用性）。在 Eureka 中不存在什么 Leader 节点，每个节点都是一样的、平等的。因此 Eureka 不会像 ZooKeeper 那样出现选举过程中或者半数以上的机器不可用的时候服务就是不可用的情况。 Eureka 保证即使大部分节点挂掉也不会影响正常提供服务，只要有一个节点是可用的就行了。只不过这个节点上的数据可能并不是最新的。\n\nNacos 不仅支持 CP 也支持 AP。\n\n\nBASE 理论BASE 理论起源于 2008 年， 由 eBay 的架构师 Dan Pritchett 在 ACM 上发表。\nBASE: BASE 理论是对 CAP 中一致性 C 和可用性 A 权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求\n\nBasically Available(基本可用): 分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用\n\n\n损失部分可用性: 1.响应时间上的损失; 2.系统功能上的损失(eg:系统的部分非核心功能无法使用)\n\n\nSoft-state(软状态): 软状态指允许系统中的数据存在中间状态（CAP 理论中的数据不一致），并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时\nEventually Consistent(最终一致性): 最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性\n\n分布式一致性的 3 种级别: \n\n强一致性: 系统写入了什么，读出来的就是什么\n弱一致性: 不一定可以读取到最新写入的值，也不保证多少时间之后读取到的数据是最新的，只是会尽量保证某个时刻达到数据一致的状态\n最终一致性: 弱一致性的升级版，系统会保证在一定时间内达到数据一致的状态\n\n实现最终一致性的具体方式:\n\n读时修复: 在读取数据时，检测数据的不一致，进行修复。比如 Cassandra 的 Read Repair 实现，具体来说，在向 Cassandra 系统查询数据的时候，如果检测到不同节点的副本数据不一致，系统就自动修复数据\n写时修复: 在写入数据，检测数据的不一致时，进行修复。比如 Cassandra 的 Hinted Handoff 实现。具体来说，Cassandra 集群的节点之间远程写数据的时候，如果写失败 就将数据缓存下来，然后定时重传，修复数据的不一致性\n异步修复: 这个是最常用的方式，通过定时对账检测副本数据的一致性，并修复\n\nBASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充:如果系统没有发生“分区”的话，节点间的网络连接通信正常的话，也就不存在 P 了。这个时候，我们就可以同时保证 C 和 A 了。因此，如果系统发生“分区”，我们要考虑选择 CP 还是 AP。如果系统没有发生“分区”的话，我们要思考如何保证 CA 。因此，AP 方案只是在系统发生分区的时候放弃一致性，而不是永远放弃一致性。在分区故障恢复后，系统应该达到最终一致性。这一点其实就是 BASE 理论延伸的地方。\n缓存一致性如果是要求强一致性，那就不能使用缓存，因为保证不了强一致性，只能保证最终一致性TODO:\nSpringCloud-EurekaKafka\nPartition: topic中的数据分割为一个或多个partition。每个topic至少有一个partition。每个partition中的数据使用多个segment文件存储。\n\n消息传递模式\n\n点对点传递模式: 消息持久化到一个队列中，一个或多个消费者消费队列中的数据，一条消息只能被消费一次\n发布-订阅模式: 消息被持久化到一个topic中，消费者可以订阅一个或多个topic，消费者可以消费该topic中所有的数据，同一条数据可以被多个消费者消费，数据被消费后不会立马删除\n\nRocketMQ与Kafka的区别\n\nrocketMQ的NameServer和kafka的zookeeper对比\n\n\nkafka具备选举功能: Master&#x2F;Slave的选举，有2步\n先通过ZK在所有机器中，选举出一个KafkaController\n再由这个Controller，决定每个partition的Master是谁，Slave是谁\n\n\n因为有了选举功能，所以kafka某个partition的master挂了，该partition对应的某个slave会升级为主对外提供服务\nrocketMQ不具备选举，Master&#x2F;Slave的角色也是固定的。当一个Master挂了之后，你可以写到其他Master上，但不能让一个Slave切换成Master\nrocketMq的所有broker节点的角色都是一样，上面分配的topic和对应的queue的数量也是一样的，Mq只能保证当一个broker挂了，把原本写到这个broker的请求迁移到其他broker上面\n\n\nkafka为什么比RocketMQ有更大的吞吐量\n\n\nkafka在消息存储过程中会根据topic和partition的数量创建物理文件，也就是说我们创建一个topic并指定了3个partition，那么就会有3个物理文件目录，也就说说partition的数量和对应的物理文件是一一对应的\nRocketMQ在消息存储方式是采用commitLog，RocketMQ的queue的数量其实是在consumeQueue里面体现的，在真正存储消息的commitLog其实就只有一个物理文件\nkafka的多文件并发写入 VS RocketMQ的单文件写入，性能差异kafka完胜可想而知\nkafka的大量文件存储会导致一个问题，也就说在partition特别多的时候，磁盘的访问会发生很大的瓶颈，毕竟单个文件看着是append操作，但是多个文件之间必然会导致磁盘的寻道\n\nRocketMQ组成:\n\nName Server: 名称服务充当路由消息的提供者，可集群部署，节点之间无任何信息同步，提供命名服务，更新和发现 Broker 服务\nProducer(生产者): \nBroker: 消息中转角色，负责存储消息，转发消息。Broker 在实际部署过程中对应一台服务器，每个 Broker 可以存储多个Topic的消息，每个Topic的消息也可以分片存储于不同的 Broker\nConsumer(消费者):\n\n\nTopic: 表示消息的第一级类型，一条消息必须有一个Topic\nQueue: Queue是Topic在一个Broker上的分片，在分片基础上再等分为若干份（可指定份数）后的其中一份，是负载均衡过程中资源分配的基本单元\ntags: Tags是Topic下的次级消息类型&#x2F;二级类型，可以在同一个Topic下基于Tags进行消息过滤。Tags的过滤需要经过两次比对，首先会在Broker端通过Tag hashcode进行一次比对过滤，匹配成功传到consumer端后再对具体Tags进行比对，以防止Tag hashcode重复的情况\ncommitLog: 用于存储消息的文件。顺序写入，随机读写。消息只要被写入 commitlog 那么该消息就不会丢失。\nConsumeQueue: ConsumeQueue中并不需要存储消息的内容，而存储的是消息在CommitLog中的offset。通过broker保存的offset可以在ConsumeQueue中获取消息，从而快速的定位到commitLog的消息位置\n\n集群: 推荐多主多从\n\n多个master节点多个slave节点，一个master节点配一个slave节点，slave是master节点的备份\n\nslave节点不接受生产者的消息，生产者的消息发给master节点\n\n消费者一般从master节点消费消息\n\n若master节点宕机，则消费者从对应的slave节点消费消息，注意：这里slave即使master宕机也不会升级，依然是slave节点\n\n同步复制: 生产者发送同步消息需主节点和从节点都写入文件或内存(异步刷盘是内存，一般选择异步刷盘)之后才会返回确认信息给生产者\n\n异步刷盘(高性能): 注意这里因为消息同时存在于主节点和从节点所以这里可以采用异步刷盘，丢失的概率不大\n\nTopic: 表示消息的第一级类型，一条消息必须有一个Topic\n\nQueue: Queue是Topic在一个Broker上的分片，在分片基础上再等分为若干份（可指定份数）后的其中一份，是负载均衡过程中资源分配的基本单元\n\ntags: Tags是Topic下的次级消息类型&#x2F;二级类型，可以在同一个Topic下基于Tags进行消息过滤。Tags的过滤需要经过两次比对，首先会在Broker端通过Tag hashcode进行一次比对过滤，匹配成功传到consumer端后再对具体Tags进行比对，以防止Tag hashcode重复的情况\n\ncommitLog: 用于存储消息的文件。顺序写入，随机读写。消息只要被写入 commitLog 那么该消息就不会丢失。\n\nConsumeQueue: ConsumeQueue中并不需要存储消息的内容，而存储的是消息在CommitLog中的offset。通过broker保存的offset可以在ConsumeQueue中获取消息，从而快速的定位到commitLog的消息位置\n\n\n消息类型\n\n同步消息: 消息发送方发出数据后，生产者会阻塞直到MQ服务方发回响应消息，表示已经写入数据到queue里了\n异步消息: MQ 的异步发送，需要用户实现异步发送回调接口(SendCallback)，在执行消息的异步发送时，应用不需要等待服务器响应即可直接返回，通过回调接口接收服务器响应\n单向(one-way)消息: 只负责发送消息，不等待服务器回应且没有回调函数触发，即只发送请求不等待应答。此方式发送消息的过程耗时非常短，一般在微秒级别\n\n消息丢失分析:\n\n生产者发送时丢失: 同步复制+重试\nRocketMQ自身丢失: 主从架构+持久化\n消费者消费消息丢失: 重试+死信队列\n\n消息重复消费问题:\n\nMVCC(Multi-Version Concurrency Control多版本并发控制): 生产者发送到queue的消息需要带上这个版本号，消费者在执行业务逻辑的同时带上版本号，sql的update语句的where带上version号保证语句的幂等性。\n缺点: 这意味着生产者在发送消息之前就需要查表拿到最新的版本号，增加了生产者和消费者的耦合度\n\n\n去重表方案: 每个消息带唯一id，然后消费者维护消息表，id设成唯一，消费消息的同时insert这张表，如果抛异常就把异常吃了直接返回，后续业务逻辑不继续进行了\n\n顺序消息消费问题:\n\n一个topic对应一个queue，这样需要顺序消费的消息就在同一条queue里\n重试参数改成0\n\n\nSpring &amp; SpringBootSpring Framework 它是很多模块的集合，使用这些模块可以很方便地协助我们进行开发Spring 提供的核心功能主要是 IoC 和 AOP\nCore Container: Spring 框架的核心模块，主要提供 IoC 依赖注入功能的支持\n\nspring-core: Spring 框架基本的核心工具类\nspring-beans: 提供对 bean 的创建、配置和管理等功能的支持\nspring-context: 提供对国际化、事件传播、资源加载等功能的支持\nspring-expression: 提供对表达式语言(Spring Expression Language)SpEL 的支持，只依赖于 core 模块，不依赖于其他模块，可以单独使用\n\nIoC(Inversion of Control:控制反转)IoC 的思想就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理\n\n控制: 指的是对象创建(实例化、管理)的权力\n反转: 控制权交给外部环境(Spring 框架、IoC 容器)\n\nIoC 容器是 Spring 用来实现 IoC 的载体， IoC 容器实际上就是个 Map(key，value)，Map 中存放的是各种对象\nSpring Bean: 代指的就是那些被 IoC 容器所管理的对象org.springframework.beans 和 org.springframework.context 这两个包是 IoC 实现的基础\n将一个类声明为 Bean 的注解\n\n@Component: 通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注\n@Repository: 对应持久层即 Dao 层，主要用于数据库相关操作\n@Service: 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。\n@Controller: 对应 Spring MVC 控制层，主要用户接受用户请求并调用 Service 层返回数据给前端页面\n\n@Component 和 @Bean 的区别\n\n@Component 注解作用于类，而@Bean注解作用于方法。\n@Component通常是通过类路径扫描来自动侦测以及自动装配到 Spring 容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。\n@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了 Spring 这是某个类的实例，当我需要用它的时候还给我。\n@Bean 注解比 @Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册 bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现\n\n@Configurationpublic class AppConfig &#123;    @Bean    public TransferService transferService() &#123;        return new TransferServiceImpl();    &#125;&#125;\n\n注入 Bean 的注解Spring 内置的 @Autowired 以及 JDK 内置的 @Resource 和 @Inject 都可以用于注入 Bean\n\n@Autowired: org.springframework.bean.factory\n@Resource: javax.annotation\n@Inject: javax.inject\n\n@Autowired 和 @Resource 的区别\n\n@Autowired 是 Spring 提供的注解，@Resource 是 JDK 提供的注解。\nAutowired 默认的注入方式为byType（根据类型进行匹配），@Resource默认注入方式为 byName（根据名称进行匹配）。\n当一个接口存在多个实现类的情况下，@Autowired 和@Resource都需要通过名称才能正确匹配到对应的 Bean。Autowired 可以通过 @Qualifier 注解来显式指定名称，@Resource可以通过 name 属性来显式指定名称\n\nAOP\nspring-aspects: 该模块为与 AspectJ 的集成提供支持。\nspring-aop: 提供了面向切面的编程实现。\nspring-instrument: 提供了为 JVM 添加代理(agent)的功能。 具体来讲，它为 Tomcat 提供了一个织入代理，能够为 Tomcat 传递类文件，就像这些文件是被类加载器加载的一样，这个模块的使用场景非常有限\n\nSpring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理\nSpring AOP 和 AspectJ AOP 有什么区别\n\nSpring AOP 属于运行时增强，而 AspectJ 是编译时增强。\nSpring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)\n\nAOP常见术语\n\n目标(Target): 被通知的对象\n代理(Proxy): 向目标对象应用通知之后创建的代理对象\n连接点(JoinPoint): 目标对象的所属类中，定义的所有方法均为连接点\n切入点(Pointcut): 被切面拦截 &#x2F; 增强的连接点（切入点一定是连接点，连接点不一定是切入点）\n通知(Advice): 增强的逻辑 &#x2F; 代码，也即拦截到目标对象的连接点之后要做的事情\n切面(Aspect): 切入点(Pointcut)+通知(Advice)\nWeaving(织入): 将通知应用到目标对象，进而生成代理对象的过程动作\n\nSpring MVCMVC 是模型(Model)、视图(View)、控制器(Controller)的简写，其核心思想是通过将业务逻辑、数据、显示分离来组织代码Spring MVC 下我们一般把后端项目分为 Service 层（处理业务）、Dao 层（数据库操作）、Entity 层（实体类）、Controller 层(控制层，返回数据给前台页面)\nSpring MVC 的核心组件\n\nDispatcherServlet: 核心的中央处理器，负责接收请求、分发，并给予客户端响应。\nHandlerMapping: 处理器映射器，根据 uri 去匹配查找能处理的 Handler ，并会将请求涉及到的拦截器和 Handler 一起封装。\nHandlerAdapter: 处理器适配器，根据 HandlerMapping 找到的 Handler ，适配执行对应的 Handler；\nHandler: 请求处理器，处理实际请求的处理器。\nViewResolver: 视图解析器，根据 Handler 返回的逻辑视图 &#x2F; 视图，解析并渲染真正的视图，并传递给 DispatcherServlet 响应客户端\n\nData Access&#x2F;Integration\nspring-jdbc: 提供了对数据库访问的抽象 JDBC。不同的数据库都有自己独立的 API 用于操作数据库，而 Java 程序只需要和 JDBC API 交互，这样就屏蔽了数据库的影响。\nspring-tx: 提供对事务的支持。\nspring-orm: 提供对 Hibernate、JPA 、iBatis 等 ORM 框架的支持。\nspring-oxm: 提供一个抽象层支撑 OXM(Object-to-XML-Mapping)，例如：JAXB、Castor、XMLBeans、JiBX 和 XStream 等。\nspring-jms: 消息服务。自 Spring Framework 4.1 以后，它还提供了对 spring-messaging 模块的继承\n\nSpring Web\nspring-web: 对 Web 功能的实现提供一些最基础的支持。\nspring-webmvc: 提供对 Spring MVC 的实现。\nspring-websocket: 提供了对 WebSocket 的支持，WebSocket 可以让客户端和服务端进行双向通信。\nspring-webflux: 提供对 WebFlux 的支持。WebFlux 是 Spring Framework 5.0 中引入的新的响应式框架。与 Spring MVC 不同，它不需要 Servlet API，是完全异步\n\nSpring TestSpring 团队提倡测试驱动开发(TDD)。有了控制反转 (IoC)的帮助，单元测试和集成测试变得更简单。\nSpring 的测试模块对 JUnit(单元测试框架)、TestNG(类似 JUnit)、Mockito(主要用来 Mock 对象)、PowerMock(解决 Mockito 的问题比如无法模拟 final, static， private 方法)等等常用的测试框架支持的都比较好\nSpring 框架中用到了哪些设计模式\n工厂设计模式: Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。\n代理设计模式: Spring AOP 功能的实现。\n单例设计模式: Spring 中的 Bean 默认都是单例的。\n模板方法模式: Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。\n包装器设计模式: 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源\n观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。\n适配器模式: Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller\n\nSpring 事务\n编程式事务: 在代码中硬编码(不推荐使用): 通过 TransactionTemplate或者 TransactionManager 手动管理事务，实际应用中很少使用，但是对于你理解 Spring 事务管理原理有帮助。\n声明式事务: 在 XML 配置文件中配置或者直接基于注解（推荐使用）: 实际是通过 AOP 实现（基于@Transactional 的全注解方式使用最多）\n\n事务传播行为\n\nTransactionDefinition.PROPAGATION_REQUIRED: 使用的最多的一个事务传播行为，我们平时经常使用的@Transactional注解默认使用就是这个事务传播行为。如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务\nTransactionDefinition.PROPAGATION_REQUIRES_NEW: 创建一个新的事务，如果当前存在事务，则把当前事务挂起。也就是说不管外部方法是否开启事务，Propagation.REQUIRES_NEW修饰的内部方法会新开启自己的事务，且开启的事务相互独立，互不干扰\nTransactionDefinition.PROPAGATION_NESTED: 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED\nTransactionDefinition.PROPAGATION_MANDATORY: 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常(mandatory强制性,使用的很少)\n\n若是错误的配置以下 3 种事务传播行为，事务将不会发生回滚\n\nTransactionDefinition.PROPAGATION_SUPPORTS: 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行\nTransactionDefinition.PROPAGATION_NOT_SUPPORTED: 以非事务方式运行，如果当前存在事务，则把当前事务挂起\nTransactionDefinition.PROPAGATION_NEVER: 以非事务方式运行，如果当前存在事务，则抛出异常\n\n事务中的隔离级别\npublic enum Isolation &#123;    // 使用后端数据库默认的隔离级别，MySQL 默认采用的 REPEATABLE_READ 隔离级别 Oracle 默认采用的 READ_COMMITTED 隔离级别    DEFAULT(TransactionDefinition.ISOLATION_DEFAULT),    // 低的隔离级别，使用这个隔离级别很少，因为它允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读    READ_UNCOMMITTED(TransactionDefinition.ISOLATION_READ_UNCOMMITTED),    // 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生    READ_COMMITTED(TransactionDefinition.ISOLATION_READ_COMMITTED),    // 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生    REPEATABLE_READ(TransactionDefinition.ISOLATION_REPEATABLE_READ),    // 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别    SERIALIZABLE(TransactionDefinition.ISOLATION_SERIALIZABLE);    private final int value;    Isolation(int value) &#123;        this.value = value;    &#125;    public int value() &#123;        return this.value;    &#125;&#125;\n\n@Transactional(rollbackFor = Exception.class)注解当 @Transactional 注解作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。如果类或者方法加了这个注解，那么这个类里面的方法抛出异常，就会回滚，数据库里面的数据也会回滚在 @Transactional 注解中如果不配置rollbackFor属性,那么事务只会在遇到RuntimeException的时候才会回滚，加上 rollbackFor=Exception.class,可以让事务在遇到非运行时异常时也回滚\nSpring JPA实体之间的关联关系注解\n@OneToOne // 一对一。@ManyToMany // 多对多。@OneToMany // 一对多。@ManyToOne // 多对一\n\n在数据库中非持久化一个字段\nstatic String transient1; // not persistent because of staticfinal String transient2 = &quot;Satish&quot;; // not persistent because of finaltransient String transient3; // not persistent because of transient@TransientString transient4; // not persistent because of @Transient\n\nJPA 的审计功能\n@Data@AllArgsConstructor@NoArgsConstructor@MappedSuperclass@EntityListeners(value = AuditingEntityListener.class)public abstract class AbstractAuditBase &#123;    @CreatedDate // 表示该字段为创建时间字段，在这个实体被 insert 的时候，会设置值    @Column(updatable = false)    @JsonIgnore    private Instant createdAt;    @LastModifiedDate    @JsonIgnore    private Instant updatedAt;    @CreatedBy // 表示该字段为创建人，在这个实体被 insert 的时候，会设置值    @Column(updatable = false)    @JsonIgnore    private String createdBy;    @LastModifiedBy    @JsonIgnore    private String updatedBy;&#125;\n\nSpring SecuritySpring Security 重要的是实战\n加密算法工具类这些加密算法实现类的父类是 PasswordEncoder ，如果你想要自己实现一个加密算法的话，也需要继承 PasswordEncoder\npublic interface PasswordEncoder &#123;    // 加密也就是对原始密码进行编码    String encode(CharSequence var1);    // 比对原始密码和数据库中保存的密码    boolean matches(CharSequence var1, String var2);    // 判断加密密码是否需要再次进行加密，默认返回 false    default boolean upgradeEncoding(String encodedPassword) &#123;        return false;    &#125;&#125;\n\n批量更换系统使用的加密算法推荐的做法是通过 DelegatingPasswordEncoder 兼容多种不同的密码加密方案，以适应不同的业务需求从名字也能看出来，DelegatingPasswordEncoder 其实就是一个代理类，并非是一种全新的加密算法，它做的事情就是代理上面提到的加密算法实现类。在 Spring Security 5.0之后，默认就是基于 DelegatingPasswordEncoder 进行密码加密的\nSpring 启动原理SpringBoot 自动装配原理通过 Spring Boot 的全局配置文件 application.properties或application.yml即可对项目进行设置比如更换端口号，配置 JPA 属性等等Spring Boot 中，我们直接引入一个 starter 即可。比如你想要在项目中使用 redis 的话，直接在项目中引入对应的 starter 即可\n&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;\n\nSpringBoot 的核心注解 SpringBootApplication:@SpringBootApplication &#x3D; @Configuration + @EnableAutoConfiguration + @ComponentScan\n\n@EnableAutoConfiguration： 启用 SpringBoot 的自动配置机制\n@Configuration： 允许在上下文中注册额外的 bean 或导入其他配置类\n@ComponentScan： 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类 ，可以自定义不扫描某些 bean。容器中将排除TypeExcludeFilter和AutoConfigurationExcludeFilter@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@ComponentScan // 扫描被@Component (@Service,@Controller)注解的 bean，注解默认会扫描启动类所在的包下所有的类@EnableAutoConfiguration // 启用 SpringBoot 的自动配置机制public @interface SpringBootApplication &#123;&#125;@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Configuration //实际上它也是一个配置类public @interface SpringBootConfiguration &#123;&#125;\n\n@EnableAutoConfiguration: 实现自动装配的核心注解\n@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage //作用：将main包下的所有组件注册到容器中// 自动装配核心功能的实现实际是通过 AutoConfigurationImportSelector类@Import(&#123;AutoConfigurationImportSelector.class&#125;) //加载自动装配类 xxxAutoconfigurationpublic @interface EnableAutoConfiguration &#123;    String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;;    Class&lt;?&gt;[] exclude() default &#123;&#125;;    String[] excludeName() default &#123;&#125;;&#125;\n\nAutoConfigurationImportSelector: 加载自动装配类继承关系如下:\npublic class AutoConfigurationImportSelector implements DeferredImportSelector, BeanClassLoaderAware, ResourceLoaderAware, BeanFactoryAware, EnvironmentAware, Ordered &#123;&#125;public interface DeferredImportSelector extends ImportSelector &#123;&#125;public interface ImportSelector &#123;    // 该方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中    String[] selectImports(AnnotationMetadata var1);&#125;\n\nselectImports方法主要用于获取所有符合条件的类的全限定类名，这些类需要被加载到 IoC 容器中\nprivate static final String[] NO_IMPORTS = new String[0];public String[] selectImports(AnnotationMetadata annotationMetadata) &#123;        // &lt;1&gt;.判断自动装配开关是否打开        if (!this.isEnabled(annotationMetadata)) &#123;            return NO_IMPORTS;        &#125; else &#123;          //&lt;2&gt;.获取所有需要装配的bean            AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader);            // getAutoConfigurationEntry主要负责加载自动配置类的            AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata);            return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());        &#125;    &#125;\n\ngetAutoConfigurationEntry()的源码:\nprivate static final AutoConfigurationEntry EMPTY_ENTRY = new AutoConfigurationEntry();AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123;        //&lt;1&gt;. isEnabled: 判断自动装配开关是否打开。默认spring.boot.enableautoconfiguration=true，可在 application.properties 或 application.yml 中设置        if (!this.isEnabled(annotationMetadata)) &#123;            return EMPTY_ENTRY;        &#125; else &#123;            //&lt;2&gt;. 用于获取EnableAutoConfiguration注解中的 exclude 和 excludeName            AnnotationAttributes attributes = this.getAttributes(annotationMetadata);            //&lt;3&gt;. 获取需要自动装配的所有配置类，读取spring-boot/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring.factories            // 一般名称为XXXAutoConfiguration的作用就是按需加载组件            // 不光是这个依赖下的META-INF/spring.factories被读取到，所有 Spring Boot Starter 下的META-INF/spring.factories都会被读取到            // eg: druid 数据库连接池的 Spring Boot Starter 就创建了META-INF/spring.factories文件            List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes);            //&lt;4&gt;. 筛选，@ConditionalOnXXX 中的所有条件都满足，该类才会生效            configurations = this.removeDuplicates(configurations);            Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes);            this.checkExcludedClasses(configurations, exclusions);            configurations.removeAll(exclusions);            configurations = this.filter(configurations, autoConfigurationMetadata);            this.fireAutoConfigurationImportEvents(configurations, exclusions);            return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions);        &#125;    &#125;\n\n@Configuration// 检查相关的类：RabbitTemplate 和 Channel是否存在// 存在才会加载@ConditionalOnClass(&#123; RabbitTemplate.class, Channel.class &#125;)@EnableConfigurationProperties(RabbitProperties.class)@Import(RabbitAnnotationDrivenConfiguration.class)public class RabbitAutoConfiguration &#123;&#125;\n\nautoconfig原理@Autowired实现原理SpringBoot 注解字典@SpringBootApplication\n@SpringBootApplication // 创建 SpringBoot 项目之后会默认在主类加上public class SpringSecurityJwtGuideApplication &#123;      public static void main(java.lang.String[] args) &#123;        SpringApplication.run(SpringSecurityJwtGuideApplication.class, args);    &#125;&#125;\n\n@SpringBootApplication看作是 @Configuration、@EnableAutoConfiguration、@ComponentScan 注解的集合\npackage org.springframework.boot.autoconfigure;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration // 启用 SpringBoot 的自动配置机制// 扫描被@Component (@Repository,@Service,@Controller)注解的 bean，注解默认会扫描该类所在的包下所有的类@ComponentScan(excludeFilters = &#123;\t\t@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\t\t@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123;   ......&#125;package org.springframework.boot;@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Configuration // 允许在 Spring 上下文中注册额外的 bean 或导入其他配置类public @interface SpringBootConfiguration &#123;&#125;\n\n@Autowired: 自动导入对象到类中，被注入进的类同样要被 Spring 容器管理\n@Servicepublic class UserService &#123;  //......&#125;@RestController@RequestMapping(&quot;/users&quot;)public class UserController &#123;   @Autowired   private UserService userService;   //......&#125;\n\n@Component, @Repository, @Service, @Controller: \n\n@Component: 通用的注解，可标注任意类为 Spring 组件。如果一个 Bean 不知道属于哪个层，可以使用@Component 注解标注。\n@Repository: 对应持久层即 Dao 层，主要用于数据库相关操作。\n@Service: 对应服务层，主要涉及一些复杂的逻辑，需要用到 Dao 层。\n@Controller: 对应 Spring MVC 控制层，主要用于接受用户请求并调用 Service 层返回数据给前端页面。\n\n@RestController: @Controller+@ResponseBody, 表示这是个控制器 bean,并且是将函数的返回值直接填入 HTTP 响应体中,是 REST 风格的控制器。单独使用 @Controller 不加 @ResponseBody的话一般是用在要返回一个视图的情况，这种情况属于比较传统的 Spring MVC 的应用，对应于前后端不分离的情况。@Controller + @ResponseBody 返回 JSON 或 XML 形式数据\n@Scope: 声明 Spring Bean 的作用域四种常见的 Spring Bean 的作用域：\n\nsingleton: 唯一 bean 实例，Spring 中的 bean 默认都是单例的。\nprototype: 每次请求都会创建一个新的 bean 实例。\nrequest: 每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP request 内有效。\nsession: 每一个 HTTP Session 会产生一个新的 bean，该 bean 仅在当前 HTTP session 内有效。@Bean@Scope(&quot;singleton&quot;)public Person personSingleton() &#123;    return new Person();&#125;\n\n@Configuration: 一般用来声明配置类，可以使用 @Component注解替代，不过使用@Configuration注解声明配置类更加语义化\n@Configurationpublic class AppConfig &#123;    @Bean    public TransferService transferService() &#123;        return new TransferServiceImpl();    &#125;&#125;\n\n前后端传值\n@PathVariable: 用于获取路径参数\n@RequestParam: 用于获取查询参数@GetMapping(&quot;/klasses/&#123;klassId&#125;/teachers&quot;)public List&lt;Teacher&gt; getKlassRelatedTeachers(         @PathVariable(&quot;klassId&quot;) Long klassId,         @RequestParam(value = &quot;type&quot;, required = false) String type ) &#123;    // 前端调/klasses/123456/teachers?type=web    // klassId=123456,type=web&#125;\n\n@RequestBody: 用于读取 Request 请求（可能是 POST,PUT,DELETE,GET 请求）的 body 部分并且Content-Type 为 application/json 格式的数据，接收到数据之后会自动将数据绑定到 Java 对象上去。系统会使用HttpMessageConverter或者自定义的HttpMessageConverter将请求的 body 中的 json 字符串转换为 java 对象\n@PostMapping(&quot;/sign-up&quot;)public ResponseEntity signUp(@RequestBody @Valid UserRegisterRequest userRegisterRequest) &#123;  userService.save(userRegisterRequest);  return ResponseEntity.ok().build();&#125;\n\nUserRegisterRequest对象:\n@Data@AllArgsConstructor@NoArgsConstructorpublic class UserRegisterRequest &#123;    @NotBlank    private String userName;    @NotBlank    private String password;    @NotBlank    private String fullName;&#125;\n\n我们发送 post 请求到这个接口，并且 body 携带 JSON 数据:\n&#123;&quot;userName&quot;:&quot;coder&quot;,&quot;fullName&quot;:&quot;shuangkou&quot;,&quot;password&quot;:&quot;123456&quot;&#125;\n\n后端就可以直接把 json 格式的数据映射到我们的 UserRegisterRequest 类上。一个请求方法只可以有一个@RequestBody，但是可以有多个@RequestParam和@PathVariable\n读取配置信息数据源application.yml内容如下:\ntest2020: 2020年my-profile:  name: David  email: nobodynowhere@163.comlibrary:  location: 中国  books:    - name: 天才基本法      description: 二十二岁的林朝夕在父亲确诊阿尔茨海默病这天，得知自己暗恋多年的校园男神裴之即将出国深造的消息——对方考取的学校，恰是父亲当年为她放弃的那所。    - name: 时间的秩序      description: 为什么我们记得过去，而非未来？时间“流逝”意味着什么？是我们存在于时间之内，还是时间存在于我们之中？卡洛·罗韦利用诗意的文字，邀请我们思考这一亘古难题——时间的本质。    - name: 了不起的我      description: 如何养成一个新习惯？如何让心智变得更成熟？如何拥有高质量的关系？ 如何走出人生的艰难时刻？\n\n@Value(常用)\n@Value(&quot;$&#123;wuhan2020&#125;&quot;)String wuhan2020;\n\n@ConfigurationProperties(常用): 读取配置信息并与 bean 绑定\n@Component@ConfigurationProperties(prefix = &quot;library&quot;)class LibraryProperties &#123;    @NotEmpty    private String location;    private List&lt;Book&gt; books;    @Setter    @Getter    @ToString    static class Book &#123;        String name;        String description;    &#125;  //省略getter/setter  //......&#125;\n\n@PropertySource(不常用): 读取指定 properties 文件\n@Component@PropertySource(&quot;classpath:website.properties&quot;)class WebSite &#123;    @Value(&quot;$&#123;url&#125;&quot;)    private String url;  //省略getter/setter  //......&#125;\n\n参数校验JSR(Java Specification Requests) 是一套 JavaBean 参数校验的标准，它定义了很多常用的校验注解，我们可以直接将这些注解加在我们 JavaBean 的属性上面SpringBoot 项目的 spring-boot-starter-web 依赖中已经有 hibernate-validator 包，不需要引用相关依赖更新版本的 spring-boot-starter-web 依赖中不再有 hibernate-validator 包（如2.3.11.RELEASE），需要自己引入 spring-boot-starter-validation 依赖所有的注解，推荐使用 JSR 注解，即javax.validation.constraints，而不是org.hibernate.validator.constraints\n常用的字段验证的注解\n\n@NotEmpty 被注释的字符串的不能为 null 也不能为空\n@NotBlank 被注释的字符串非 null，并且必须包含一个非空白字符\n@Null 被注释的元素必须为 null\n@NotNull 被注释的元素必须不为 null\n@AssertTrue 被注释的元素必须为 true\n@AssertFalse 被注释的元素必须为 false\n@Pattern(regex&#x3D;,flag&#x3D;)被注释的元素必须符合指定的正则表达式\n@Email 被注释的元素必须是 Email 格式。\n@Min(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@Max(value)被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@DecimalMin(value)被注释的元素必须是一个数字，其值必须大于等于指定的最小值\n@DecimalMax(value) 被注释的元素必须是一个数字，其值必须小于等于指定的最大值\n@Size(max&#x3D;, min&#x3D;)被注释的元素的大小必须在指定的范围内\n@Digits(integer, fraction)被注释的元素必须是一个数字，其值必须在可接受的范围内\n@Past被注释的元素必须是一个过去的日期\n@Future 被注释的元素必须是一个将来的日期\n\n验证请求体(RequestBody)\n@Data@AllArgsConstructor@NoArgsConstructorpublic class Person &#123;    @NotNull(message = &quot;classId 不能为空&quot;)    private String classId;    @Size(max = 33)    @NotNull(message = &quot;name 不能为空&quot;)    private String name;    @Pattern(regexp = &quot;((^Man$|^Woman$|^UGM$))&quot;, message = &quot;sex 值不在可选范围&quot;)    @NotNull(message = &quot;sex 不能为空&quot;)    private String sex;    @Email(message = &quot;email 格式不正确&quot;)    @NotNull(message = &quot;email 不能为空&quot;)    private String email;&#125;@RestController@RequestMapping(&quot;/api&quot;)public class PersonController &#123;    // 需要验证的参数上加上了@Valid注解，如果验证失败，它将抛出MethodArgumentNotValidException    @PostMapping(&quot;/person&quot;)    public ResponseEntity&lt;Person&gt; getPerson(@RequestBody @Valid Person person) &#123;        return ResponseEntity.ok().body(person);    &#125;&#125;\n\n验证请求参数(Path Variables 和 Request Parameters)\n@RestController@RequestMapping(&quot;/api&quot;)@Validated // 这个参数可以告诉 Spring 去校验方法参数public class PersonController &#123;    @GetMapping(&quot;/person/&#123;id&#125;&quot;)    public ResponseEntity&lt;Integer&gt; getPersonByID(@Valid @PathVariable(&quot;id&quot;) @Max(value = 5,message = &quot;超过 id 的范围了&quot;) Integer id) &#123;        return ResponseEntity.ok().body(id);    &#125;&#125;\n\n全局处理 Controller 层异常\n@ControllerAdvice: 注解定义全局异常处理类\n@ExceptionHandler: 注解声明异常处理方法\n\n@ControllerAdvice@ResponseBodypublic class GlobalExceptionHandler &#123;    /**     * 请求参数异常处理     */    @ExceptionHandler(MethodArgumentNotValidException.class)    public ResponseEntity&lt;?&gt; handleMethodArgumentNotValidException(MethodArgumentNotValidException ex, HttpServletRequest request) &#123;       //......    &#125;&#125;\n\nJPA 相关暂时跳过，现在多使用MyBatis，很少用Bean和表结构对应的强结构的设计\nJson 数据处理@JsonIgnoreProperties 作用在类上用于过滤掉特定字段不返回或者不解析\n//生成json时将userRoles属性过滤@JsonIgnoreProperties(&#123;&quot;userRoles&quot;&#125;)public class User &#123;    private String userName;    private String fullName;    private String password;    private List&lt;UserRole&gt; userRoles = new ArrayList&lt;&gt;();&#125;\n\n@JsonIgnore一般用于类的属性上，作用和上面的@JsonIgnoreProperties 一样\npublic class User &#123;    private String userName;    private String fullName;    private String password;   //生成json时将userRoles属性过滤    @JsonIgnore    private List&lt;UserRole&gt; userRoles = new ArrayList&lt;&gt;();&#125;\n\n格式化 json 数据: @JsonFormat一般用来格式化 json 数据\n@JsonFormat(shape=JsonFormat.Shape.STRING, pattern=&quot;yyyy-MM-dd&#x27;T&#x27;HH:mm:ss.SSS&#x27;Z&#x27;&quot;, timezone=&quot;GMT&quot;)private Date date;\n\n扁平化对象\n@Getter@Setter@ToStringpublic class Account &#123;    private Location location;    private PersonInfo personInfo;  @Getter  @Setter  @ToString  public static class Location &#123;     private String provinceName;     private String countyName;  &#125;  @Getter  @Setter  @ToString  public static class PersonInfo &#123;    private String userName;    private String fullName;  &#125;&#125;\n\n未扁平化之前\n&#123;    &quot;location&quot;: &#123;        &quot;provinceName&quot;:&quot;湖北&quot;,        &quot;countyName&quot;:&quot;武汉&quot;    &#125;,    &quot;personInfo&quot;: &#123;        &quot;userName&quot;: &quot;coder1234&quot;,        &quot;fullName&quot;: &quot;shaungkou&quot;    &#125;&#125;\n\n使用@JsonUnwrapped 扁平对象之后\n@Getter@Setter@ToStringpublic class Account &#123;    @JsonUnwrapped    private Location location;    @JsonUnwrapped    private PersonInfo personInfo;    //......&#125;\n\n&#123;  &quot;provinceName&quot;:&quot;湖北&quot;,  &quot;countyName&quot;:&quot;武汉&quot;,  &quot;userName&quot;: &quot;coder1234&quot;,  &quot;fullName&quot;: &quot;shaungkou&quot;&#125;\n\n测试相关@SpringBootTest(webEnvironment = RANDOM_PORT)@ActiveProfiles(&quot;test&quot;) // 一般作用于测试类上， 用于声明生效的 Spring 配置文件@Slf4jpublic abstract class TestBase &#123;  //......&#125;\n\n@Test //声明一个方法为测试方法@Transactional //被声明的测试方法的数据会回滚，避免污染测试数据@WithMockUser(username = &quot;user-id-18163138155&quot;, authorities = &quot;ROLE_TEACHER&quot;) //Spring Security 提供的，用来模拟一个真实用户，并且可以赋予权限void should_import_student_success() throws Exception &#123;    //......&#125;\n\n\n微服务RPC(Remote Procedure Call)远程过程调用: RPC 可以帮助我们调用远程计算机上某个服务的方法，这个过程就像调用本地方法一样简单\n\n客户端(服务消费端): 调用远程方法的一端。\n客户端 Stub(桩): 这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。\n网络传输: 网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最近基本的 Socket或者性能以及封装更加优秀的 Netty(推荐)。\n服务端 Stub(桩): 这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去指定对应的方法然后返回结果给客户端的类。\n服务端(服务提供端): 提供远程方法的一端。\n\n\n服务消费端(client)以本地调用的方式调用远程服务；\n客户端 Stub(client stub) 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体(序列化)：RpcRequest；\n客户端 Stub(client stub) 找到远程服务的地址，并将消息发送到服务提供端；\n服务端 Stub(桩)收到消息将消息反序列化为Java对象: RpcRequest；\n服务端 Stub(桩)根据RpcRequest中的类、方法、方法参数等信息调用本地的方法；\n服务端 Stub(桩)得到方法执行结果并将组装成能够进行网络传输的消息体：RpcResponse(序列化)发送至消费方；\n客户端 Stub(client stub)接收到消息并将消息反序列化为Java对象:RpcResponse ，这样也就得到了最终结果。over!\n\nSpring Cloud Gateway配置中心 &amp; bus高并发一致性哈希算法\n假设你需要对文件进行缓存，你有缓存集群，对每个文件根据哈希对服务器数量取模，将每一张文件映射到一台缓存服务器上面。缺点: 如果你要增加一台服务器，那么需要对所有的文件都重新计算一遍，这样就会导致缓存雪崩，全部缓存到文件失效\n为解决这个问题可以采用一致性哈希算法: 将服务器映射到一个环上面，然后根据哈希值取模，将文件映射到环上某个位置，然后这个文件存储的服务器就是映射位置顺时针遇到的第一个服务器，这样如果增加一台服务器也只会使得环上的一部分文件缓存失效，避免了缓存雪崩\n缺点: 有时候可能会出现缓存不均匀的情况，即服务器映射到环上的位置是不均匀的，可以通过增加虚拟节点解决，文件顺时针遇到虚拟节点就放到虚拟节点对应的那个真实节点对应的服务器上\n\n常用高并发相关工具Apache JMeter\n高可用常见限流算法固定窗口计数器算法固定窗口其实就是时间窗口。固定窗口计数器算法 规定了我们单位时间处理的请求数量\n\n给定一个变量 counter 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。\n1 分钟之内每处理一个请求之后就将 counter+1 ，当 counter&#x3D;33 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。\n等到 1 分钟结束后，将 counter 重置 0，重新开始计数\n\n缺点: 这种限流算法无法保证限流速率，因而无法保证突然激增的流量就比如说我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了\n滑动窗口计数器算法固定窗口计数器算法的升级版，优化点：把时间以一定比例分片例如我们的接口限流每分钟处理 60 个请求，我们可以把 1 分钟分为 60 个窗口。每隔 1 秒移动一次，每个窗口一秒只能处理 不大于 60(请求数)&#x2F;60（窗口数） 的请求， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。\n漏桶算法我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。如果想要实现这个算法的话也很简单，准备一个队列用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰&#x2F;限流的思想是一样的）\n令牌桶算法令牌桶算法也比较简单。和漏桶算法算法一样，还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了\n单机限流Google Guava 自带的限流工具类 RateLimiter 。 RateLimiter 基于令牌桶算法，可以应对突发流量\n分布式限流\n借助中间件架限流 ：可以借助 Sentinel 或者使用 Redis 来自己实现对应的限流逻辑。\n网关层限流 ：比较常用的一种方案，直接在网关层把限流给安排上了。不过，通常网关层限流通常也需要借助到中间件&#x2F;框架。就比如 Spring Cloud Gateway 的分布式限流实现RedisRateLimiter就是基于 Redis+Lua 来实现的，再比如 Spring Cloud Gateway 还可以整合 Sentinel 来做限流\n\n为什么建议 Redis+Lua 的方式\n\n减少了网络开销: 我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。\n原子性: 一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰\n\n超时&amp;重试超时超时机制说的是当一个请求超过指定的时间（比如 1s）还没有被处理的话，这个请求就会直接被取消并抛出指定的异常或者错误\n\n连接超时(ConnectTimeout): 客户端与服务端建立连接的最长等待时间。\n读取超时(ReadTimeout): 客户端和服务端已经建立连接，客户端等待服务端处理完请求的最长时间。实际项目中，我们关注比较多的还是读取超时。\n\n超时时间应该如何设置: 超时值设置太高或者太低都有风险。\n\n如果设置太高的话，会降低超时机制的有效性，比如你设置超时为 10s 的话，那设置超时就没啥意义了，系统依然可能会出现大量慢请求堆积的问题。\n如果设置太低的话，就可能会导致在系统或者服务在某些处理请求速度变慢的情况下（比如请求突然增多），大量请求重试（超时通常会结合重试）继续加重系统或者服务的压力，进而导致整个系统或者服务被拖垮的问题\n\n建议读取超时设置为 1500ms ,这是一个比较普适的值。如果你的系统或者服务对于延迟比较敏感的话，那读取超时值可以适当在 1500ms 的基础上进行缩短。反之，读取超时值也可以在 1500ms 的基础上进行加长，不过，尽量还是不要超过 1500ms 。连接超时可以适当设置长一些，建议在 1000ms ~ 5000ms 之内\n重试机制重试机制一般配合超时机制一起使用，指的是多次发送相同的请求来避免瞬态故障和偶然性故障\n\n瞬态故障可以简单理解为某一瞬间系统偶然出现的故障，并不会持久。偶然性故障可以理解为哪些在某些情况下偶尔出现的故障，频率通常较低\n\n重试的次数如何设置: 重试的次数通常建议设为 3 次。并且，我们通常还会设置重试的间隔，比如说我们要重试 3 次的话，第 1 次请求失败后，等待 1 秒再进行重试，第 2 次请求失败后，等待 2 秒再进行重试，第 3 次请求失败后，等待 3 秒再进行重试\n重试幂等: 需要注意保证同一个请求没有被多次执行\n其它SSO 单点登录SSO 英文全称 Single Sign On，单点登录。SSO 是在多个应用系统中，用户只需要登录一次就可以访问所有相互信任的应用系统\n核心功能:\n\n单点登录\n单点登出\n支持跨域单点登录\n支持跨域单点登出\n\n常见的 Web 框架对于 Session 的实现都是生成一个 SessionId 存储在浏览器 Cookie 中。然后将 Session 内容存储在服务器端内存中\n\n用户登录成功之后，生成 AuthToken 交给客户端保存。如果是浏览器，就保存在 Cookie 中。如果是手机 App 就保存在 App 本地缓存中\n用户在浏览需要登录的页面时，客户端将 AuthToken 提交给 SSO 服务校验登录状态&#x2F;获取用户登录信息\n\n对于登录信息的存储，建议采用 Redis，使用 Redis 集群来存储登录信息，既可以保证高可用，又可以线性扩充。同时也可以让 SSO 服务满足负载均衡&#x2F;可伸缩的需求\n","categories":["Java"],"tags":["Java","JVM"]},{"title":"Java复习笔记","url":"/2017/10/10/Java/Java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/","content":"索引\n Java运行环境 \n Java语言 \n Java语法 \n Java数组 \n 集合框架 \n Java I&#x2F;O 输入&#x2F;输出流 \n 反射 \n Java网络编程 \n Java Web 开发相关技术 \n 算法题 \n\n Java运行环境 JDK和JRE的作用JRE(Java Runtime Environment)是Java程序的运行环境。包含JVM在%JRE安装目录%&#x2F;bin&#x2F;client&#x2F;jvm.dll，所有的Java类库的class文件，在lib目录下打包成jar包。JKD(Java Development Kit)是Java开发工具包。在%JDK安装目录%&#x2F;bin&#x2F;client&#x2F;jvm.dll与在%JKD安装目录%&#x2F;bin&#x2F;server&#x2F;jvm.dll下含有两个JVM虚拟机。同时只有JDK下才有javac。\n配置JDK环境\n我的电脑-&gt;属性-&gt;系统属性-&gt;高级-&gt;环境变量-&gt;系统环境变量，新建JAVA_HOME环境变量，值为 %jdk安装目录%，例：C:\\Program Files\\Java\\jkd1.6.1_13\n配置path环境变量：在path后加上;%JAVA_HOME%\\bin\n编译java代码：\n\npublic class HelloWorld &#123;    public static void main(String[] args)&#123;        System.out.println(&quot;Hello world!&quot;);    &#125;&#125;\n\n保存为HelloWorld.java，命令行进入当前目录使用命令：javac HelloWorld.java编译上传HelloWorld.class文件(class文件是字节码文件，字节码需要在JVM虚拟机里面运行)\n\n使用命令java HelloWorld 运行\n\n如果类指定了包名则需用命令javac -d HelloWorld.java来进行编译\n.class文件.class文件是字节码文件，字节码需要在JVM虚拟机里面运行。对一个.java文件进行编译可以产生一个同名的.class文件。若对一个含有内部类的.java文件进行编译会产生 外部类名$内部类名.class的文件。\n类的加载机制Java提供两种类的装载方式：\n\n预先装载\n按需装载(大部分类延迟到使用时才动态加载被称为Java的运行时动态装载机制)\n\nJava的运行时动态装载机制：使得Java可以在动态运行时装载软件部件，修改代码无需全盘编译，为软件系统的开发提供了极大的灵活性。\n\n预先装载\n\n当启动一个程序时：Java首先在JDK目录下找到并载入jvm.dll-&gt;启动虚拟机-&gt;虚拟机进行初始化操作(设置操作系统参数等)-&gt;创建Bootstrap Loader对象(启动类装载器，由C++编写)-&gt;Bootstrap Loader一次性加载JVM的所有基础类\nBootstrap Loader还会装载定义在sun.misc命名空间下的Launcher类，Launcher类拥有两个内部类：ExtClassLoader, AppClassLoader. 其继承关系如下：Bootstrap Loader&lt;-ExtClassLoader&lt;-AppClassLoader(拥有main()函数的入口类)\n\n按需装载\n\n装载条件：1)静态方法2)静态属性3)构造方法除外：1)当访问静态常量属性时，JVM加载类的过程中不会进行类的初始化工作，只会进行到解析阶段2)构造方法没有被显示的声明为静态方法，但它仍作为内地 静态成员特例\n按需装载流程：当需要使用一个类时JVM会检查这个类的Class对象是否已经加载，若未加载则开始装载：\n\n加载：查找并导入类的二进制字节码文件，根据这些字节码文件创建一个Class对象\n链接：分为校验、准备、解析\n校验：检查导入的二进制字节码的完整性、正确性、安全性\n准备：为静态域分配存储空间\n解析：将符号引用转折为直接引用\n初始化：初始化静态变量并执行静态域代码\n\n类加载器：JVM使用类加载器来加载类，Java加载器在Java核心类库和CLASSPATH环境下面的所有类中查找类，若找不到则会抛出java.lang.ClassNotFoundException异常\n从J2SE1.2开始：JVM使用了3中加载器：bootstrap、extension、system类加载器，依次为父子关系。\n环境变量CLASSPATH的作用环境变量CLASSPATH是在编译Java源码和运行程序时使用的，用于为Java程序指定所依赖的接口、类等搜索路径。\n.;c:\\jar\\log4j.jar;d:\\work\\java\n\n如何为Java程序动态的指定类搜索路径使用-cp选项，此时JVM会把指定的jar文件作为CLASSPATH的一部分\njavac -cp D:\\work\\java\\log4j.jar HelloWorld.java\n\n如何使用cmd把Java程序打包成jar文件jar包一般包含class文件、配置文件和清单文件manifest.mf\n格式如下：\njar &#123;c t x u f&#125;[v m e 0 M i][-C 目录]文件名&#123;c t x u f&#125;四个参数必须选其一[v m e 0 m i]为可选参数-c 创建一个jar包-t 显示jar包中内容列表-x 解压jar包-u 添加文件到jar包-f 指定jar包的文件名-v 生成详细报告并输出到标准设备-m 指定manifest.mf文件-0 产生jar包时不对内容进行压缩-M 不产生所有文件的清单文件manifest.mf-i 为指定的jar文件创建索引文件-C 表示转到相应的目录下指定jar命令\n\n生成hello.jar包jar cf hello.jar HelloWorld.class显示打包过程jar vcf hello.jar HelloWorld.class\n\nJava Web项目生成(Build)、部署(Deploy)、配置(Configuration)目录结构：\njavaweb    |- META-INF    |- resource    |- WEB-INF        |- classes        |- lib\n\nweb.xml是整个Web应用程序的配置文件，通过它来定义Servlet、过滤器、监听器等，Web容器通过该文件的配置来控制整个Web应用程序的行为方式。须放在WEB-INF目录下\nServlet是服务器端处理HTTP请求的基本组成单元。JSP、过滤器都由其实现。Servlet存活在Web容器中，由Web容器来控制其生命周期。JSP的脚本语言是Java，其本质是Servlet。\n打包出来的文件为.war后缀，Java Web容器是符合Java EE规范的，所以每个Java Web应用程序都可以部署到任何平台的任何Java EE容器中。\n\n Java语言 Java与C++程序的区别C、C++：由编译器把源码直接编译成计算机可识别的机器码(exe、dll等)，再直接运行。Java：由javac命令把源文件编译成class文件，在Java程序启动时先启动Java虚拟机再由虚拟机去加载class文件。\n简述JCM及其工作原理JVM是一种用软件模拟出来的计算机，它用于执行Java程序，有一套非常严格的技术规范，是Java程序实现跨平台特性的基础。Java虚拟机有虚拟出来的计算机硬件如：处理器、寄存器、堆栈等，还具有与之配套的指令系统。它运行Java程序就行普通计算机运行C、C++程序一样。\nJava程序为什么无需delete语句进行内存回收(JVM的垃圾回收机制)JVM把程序创建的对象存放在堆空间中\n堆(Heap)：是一个运行时的数据存储区。分配和释放由程序中显示分配，没有垃圾自动回收机制，且须由程序代码显示释放这些实体。类似于C中的malloc()和free()。JVM会把程序创建的对象放在堆中，在Java中则由JVM自动释放(一般是垃圾回收器检测出一个对象不再被引用就就行回收)。栈(Stack)：一般存放非static的自动变量、函数参数、表达式的临时结果和函数返回值。分配和释放均由系统自动完成。\n\n Java语法 变量及其作用域全局变量：可以被所有函数在任何地址使用的变量局部变量：在某一特定的代码范围才能看见的变量\n根据生存周期来分：\n\n静态变量：类中由static修饰的变量，当类加载时就生成并初始化\n成员变量：类中没有使用static修饰的变量，当对象加载时就生成并初始化，随着垃圾回收器回收而消失\n局部变量：定义在方法中的变量或方法的参数或定义在代码块中(用大括号包括的)的变量\n\nJava变量数据类型分为：\n基本数据类型和引用数据类型\nJava包含哪些基本数据类型及其包装类基本数据类型：byte, short, int, long, float, double, boolean, char包装类：Byte, Short, Integer, Long, Float, Double, Boolean, Character\nint取值范围：int长度为4字节，共4*8&#x3D;32位，第一位为符号位，最大值为2^31-1，最小值为-2^31\nint otc = 0123; // 八进制int hex = 0x123; // 十六进制\n\nlong取值范围：长度为8字节，共8*8&#x3D;64位，[-2^63, 2^63-1]\nfloat取值范围：长度为4字节，共4*8&#x3D;32位，[3.4E+10^-38, 3.4E+10^38]\ndouble取值范围：长度为8字节，共8*8&#x3D;64位，[1.7E+10^-308, 1.7E+10^308]\n类型转换：分为显示转换和隐式转换\nboolean存于栈空间，Boolean对象存放在堆空间中\nchar采用Unicode编码，用2字节表示一个字符，char长度为2字节，16位，[0, 2^16-1]\nJVM启动时会实例化9个对象池，分别用来存储8种基本类型和String对象：对象池的作用是为了避免频繁的创建和销毁对象影响系统性能\nStringBuffer线程安全，StringBuilder线程不安全。\n使用指定的字符集创建String对象：String str &#x3D; new String(“中午”.getBytes(), “GBK”)，可用”GBK”, “UTF-8”, “ISO-8859-1”\n装箱与拆箱Java5.0提供的功能，用于打包基本数据类型，同时隐藏一些细节。自动装箱与拆箱是在编译阶段进行的。\n转义字符\\a:响铃\\b:退格BS\\f:换页FF\\n:换行LF\\r:回车CR\\t:水平制表HT\\v:垂直制表VT\\\\:反斜杠\\?:问号字符\\&#x27;:单引号字符\\&quot;:双引号字符\\0:空字符NULL\\ddd:任意字符 三位八进制\\xhh:任意字符 二位十六进制\n\nJava的引用与C++的指针的区别相同：都是指向一块内存地址的，通过引用指针来完成对内存数据的操作。区别：\n\n类型：引用的值为地址的数据元素，Java封装了的地址，可以转成字符查看，不必关心长度。C++指针是一个装地址的变量。\n所占内存：引用声明没有实体，不占空间，C++指针用到才会赋值\n初始值：java初始值为null，C++为原内存里所保存的值\n计算：引用不可计算，C++相当于int可计算\n控制：引用不可控制，C++可以使用计算来控制指针指向\n内存泄漏：java不会，C++容易产生内存泄漏\n\nJava中的main()方法public static void main(String[] args)&#123;&#125;\n\n作为程序的入口函数，可以通过args接受外部参数。\nequal与&#x3D;&#x3D;&#x3D;&#x3D;为直接比较值，若为基本数据类型则比较是否相同，若为引用则比较引用是否指向同一个对象。\nequal则是调用java.lang.Object里的equal()方法或对象里面重写的equal方法来比较\nJava中的三元运算符tmp = a &gt; b ? &quot;a&gt;b&quot; : &quot;a&lt;b&quot;;\n\n注释// 行注释/*块注释*//***文档注释*/public int test(String arg0)&#123;&#125;\n\n静态成员的特点在类中通过static关键字修饰，包括：静态成员变量、静态方法、静态代码块\n\n在类加载的时候就进行创建、初始化或执行代码\n一个类只有一个\n类的所有实例都可以访问\n\n子类构造方法调用父类的构造方法使用super()方法，且super()方法必须放在子类构造方法的第一行，若super()无参数则可省略\n接口和抽象类的区别抽象类是功能不全的类，里面可以有非抽象方法接口是抽象方法声明和静态不能被修改数据的集合两者都不能被实例化一个类一次只能继承一个抽象类但可以实现多个接口\n内部类package abc;class A&#123;    class B&#123;    &#125;&#125;\n\nB类的全类名是abc.A.B，且B会依赖于A。\n下面分类讨论：\n根据定义结构分类：\n\n成员式：定义的方法与成员变量相似\n局部式：定义在方法体重\n\n成员内部类：\n\n静态内部类：使用static关键字修饰的内部类，当加载外部类的时候也会加载静态内部类。无法访问外部类的非静态成员。全类名：abc.A.B，class文件名：A$B.class\n\npackage abc;class A&#123;    static class B&#123;    &#125;&#125;\n\n\n成员内部类：需要等外部类创建对象以后才会被加载到JVM中，属于外部类的某个实例，可访问外部类的静态与非静态成员。\n\npackage abc;class A&#123;    class B&#123;    &#125;&#125;\n\n创建成员内部类语法：\npublic static void main(String[] args)&#123;    A a = new A();    A.B b = a.new B();&#125;\n\n局部式内部类：\n\n普通局部内部类：位于方法中\n匿名内部类：没有类名，匿名内部类的class文件命名方法按照匿名内部类的排列顺序来进行：Outter$1.class\n\n可见性private, protected, public, defaultpublic:可被所有其它类访问private:自身所在类内可见protected:自身，子类及同一个包中类可访问default:自身，同一个包中类可访问\n Java数组 Java数组的本质Java数组的本质是一个特殊的类，该类好保存了数据类型的信息。该类通过成员变量的形式保存数据，并通过[]符号来访问数据。基本数据类型的数组保存的是值(初始化为0)，而应用类型的数组保存的是对象的引用(初始化为null)。\n拷贝数组的数据通过for遍历来赋值只是复制了对象的引用，若需要复制对象则可用：\nint[] arr = new int[][1,2,3];int[] arr2 = new int[3];System.arraycopy(arr, 0, arr, 0, arr.length);\n\n–\n 集合框架 \n列表List：有序，允许重复集合Set：无序，不允许重复SortedSet：有序的Set映射Map：无序，不允许重复，键值对SortedMap：有序的Map\n迭代器迭代器(Iterator)模式，又叫游标(Cursor)模式。提供一种方法来访问一个容器对象中的各个元素。\n比较器用于比较元素，需要实现Comparable或Comparator接口。\n\nComparable接口：进行比较类需要实现的接口，仅包含一个compareTo()方法，返回值大于0时表示本对象&lt;参数对象\n\npublic class User implements Comparable&#123;    public int age;    public int compareTo(Object o)&#123;        return this.age-(User o).age;    &#125;&#125;\n\n\nComparator接口：实现该接口的类被称为比较器，包含compare()方法。\n\npublic class User&#123;    public int age;    public User(int age)&#123;        this.age = age;    &#125;    public static void main(String[] args)&#123;        User u1 = new User(16);        User u2 = new User(18);        Comparator comp = new UserComparator();        int result = comp.compare(u1, u2);        System.out.println(result);    &#125;&#125;public class UserComparator implements Comparator&#123;    public int compare(Object arg0, Object arg1)&#123;        User u1 = (User) arg0;        User u2 = (User) arg1;        return u1.age - u2.age;    &#125;&#125;\n\nVector 与 ArrayList 的区别Vector是线程安全的，它操作元素的方法都是同步方法。ArrayList不是，但效率更高。\nHashMap 与 HashTable 的区别HashTable的方法是同步的，HashMap不同步HashTable不允许null，HashMap允许nullHashTable使用Enumeration遍历，HashMap使用Iterator遍历HashTable直接使用对象的hashCode，HashMap会重新计算\n集合使用泛型可以明确集合里存储的元素的类型，避免了手动类型转换的过程\n集合元素排序使用java.util.Collections类中的sort()方法对List元素进行排序如果类中的元素全部实现了Comparable接口则可通过Collections.sort()排序\n//REVIEW:test this codepublic class User implements Comparable&lt;User&gt;&#123;    public int age;    public User(int age)&#123;        this.age = age;    &#125;    public int compareTo(Object o)&#123;        return this.age-(User o).age;    &#125;&#125;public class Test&#123;    public static void main(String[] args)&#123;        List&lt;User&gt; list = new ArrayList&lt;User&gt;();        list.add(new User(16));        list.add(new User(18));        list.add(new User(22));        // 默认排序        Collections.sort(list);        // 降序排序        // 若没有实现Comparable接口，也可以提供比较器        Comparator comp = Collections.reverseOrder();        Collections.sort(list, comp);    &#125;&#125;\n\n若没有实现Comparable接口，也可以提供比较器来进行排序\n什么集合可以使用 foreachforeach运行步骤如下：\n\n调用指定集合对象的Iterator()方法，得到迭代器\n使用迭代器的hasNext()方法判断有无下一个元素进行循环\n每次循环都用next()方法得到元素\n\n数组或实现了Iterable接口的类实例，Jav集合框架中的集合大多符合第二条\n\n Java I&#x2F;O 输入&#x2F;输出流 复制文件程序import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;public class FileCopy&#123;    public static void main(String[] args)&#123;        // 输入文件流        FileInputStream fin = new FileInputStream(&quot;d:/test/a.txt&quot;);        // 输出文件流        FileOutputStream fout = new FileOutputStream(&quot;d:/test/b.txt&quot;);        byte[] buff = new byte[256]; // 缓冲区        int len = 0; // 每次读到的数据长度        while((len = fin.read(buff)) &gt; 0)&#123;            fout.write(buff, 0, len);        &#125;        fin.close();        fout.close();    &#125;&#125;\n\n如果不关闭流，会造成资源的浪费，还可能会导致文件锁住，其他程序无法操作文件。\n字节流字节流处理的是最基本的单位byte，它可以处理任何形式的数据，主要操作byte数组。Java中可以使用java.io.FileInputStream和java.io.FileOutputStream来进行字节流的处理。\n你也可以使用包装过的具有特定功能的字节流，基本使用思路如下：\n\n获取输入或输出的流对象，从File获得或网络等\n根据特定的字符格式创建InputStreamReader或InputStreamWriter\n使用read()或readLine()方法读取数据，write()或print()\n关闭流\n\n序列化把对象内存中的数据按照规则变成一系列的字节数据并写入到流中。须Serializable，必要时还需提供serialVersionUID\n多线程线程(Thread)与进程(Process)的区别进程包含线程，每个应用程序的执行都在操作系统内核中登记一个进程标志，操作系统根据分配的标志对应用程序的执行进行调度和系统资源分配。进程是占用系统资源的基本单位。进程在执行过程中拥有独立的内存单元，而多个线程共享内存。进程拥有固定的入口、执行顺序、出口，而线程会被应用程序控制。\n并发(Concurrent)与并行(Parallel)的区别\n\n并发：交替使用一台咖啡机；并行同时使用两台咖啡机。\n并行是指两个或者多个事件在同一时刻发生；而并发是指两个或多个事件在同一时间间隔内发生。并行是并发的子集。\n在操作系统中，并发是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行，但任一个时刻点上只有一个程序在处理机上运行。\n让一个类成为线程类\n实现Runnable接口\n继承Thread类\n\n继承Thread类之后就不能继承其它类了，实现Runnable接口则可以。继承Thread类更方便。实现Runnable接口的线程类更方便访问同一个变量，而Thread则需要使用内部类。\n继承自Thread类可以通过new创建对象再调用start()方法。实现Runnable接口的线程类需要将其对象作为Thread构造方法的参数，然后调用Thread对象的start()方法\n使用sychronized让线程同步每个对象都可以有一个线程锁，sychronized可以用任何一个对象的线程锁来锁住一段代码，任何想要进入该段代码的线程必须在解锁以后才能继续执行，否则进入等待状态。只有占用锁资源的线程执行完毕后，锁资源才会被释放。\njava会为每个object对象分配一个monitor，当某个对象的同步方法（synchronized methods ）被多个线程调用时，该对象的monitor将负责处理这些访问的并发独占要求。当一个线程调用一个对象的同步方法时，JVM会检查该对象的monitor。如果monitor没有被占用，那么这个线程就得到了monitor的占有 权，可以继续执行该对象的同步方法；如果monitor被其他线程所占用，那么该线程将被挂起，直到monitor被释放。当线程退出同步方法调用时，该线程会释放monitor，这将允许其他等待的线程获得monitor以使对同步方法的调用执行下去。\n编写一个生产者消费者模型的多线程例子每个生产者在添加货物之前检查仓库是否已满，若已满则等待并通知消费者进行消费，直到消费者消费了至少一个货物以后再继续添加；消费者在消费一个货物之前检查仓库是否为空，若为空着等待并通知生产者进行生产，直到生产者添加了至少一个货物后，再进行消费。\nsleep()函数是Thread类的静态函数，不涉及到线程间同步概念，仅仅为了让一个线程自身获得一段沉睡时间。sleep可以在任何地方使用。wait函数是object类的函数，要解决的问题是线程间的同步，该过程包含了同步锁的获取和释放，调用wait方法将会将调用者的线程挂起，直到其他线程调用同一个对象的notify方法才会重新激活调用者。\npackage review.thread;public class Store &#123;\t/**\t * 仓库的最大容量\t */\tprivate final int MAX_SIZE;\t/**\t * 当前的货物数量\t */\tprivate int count;\t/**\t * 初始化最大容量的构造方法\t * @param n 仓库的最大容量\t */\tpublic Store(int n)&#123;\t\tMAX_SIZE = n;\t\tcount=0;\t&#125;\t\t/**\t * 向仓库添加货物\t */\tpublic synchronized void add()&#123;\t\twhile(count &gt;= MAX_SIZE)&#123;\t\t\tSystem.out.println(&quot;仓库已满&quot;);\t\t\ttry&#123;\t\t\t\tthis.wait(); // 进入等待池\t\t\t&#125;catch(InterruptedException e)&#123;\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t\tcount++; // 增加库存\t\tSystem.out.println(Thread.currentThread().toString() + &quot; add &quot; + count);\t\tthis.notifyAll(); // 通知所有消费者线程来拿，同时唤醒所有挂起的生产者\t&#125;\t\tpublic synchronized void remove()&#123;\t\twhile(count &lt;= 0)&#123;\t\t\tSystem.out.print(&quot;empty&quot;);\t\t\ttry &#123;\t\t\t\tthis.wait();\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t// TODO Auto-generated catch block\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t\tSystem.out.println(Thread.currentThread().toString() + &quot; remove &quot; + count);\t\tcount--;\t\tthis.notify(); // 通知生产者添加\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tStore store = new Store(5);\t\t\t\tThread pro1 = new Proceducer(store);\t\tThread pro2 = new Proceducer(store);\t\tThread con1 = new Consumer(store);\t\tThread con2 = new Consumer(store);\t\tpro1.setName(&quot;producer1&quot;);\t\tpro2.setName(&quot;producer2&quot;);\t\tcon1.setName(&quot;consumer1&quot;);\t\tcon2.setName(&quot;consumer2&quot;);\t\t\t\tpro1.start();\t\tpro2.start();\t\tcon1.start();\t\tcon2.start();\t&#125;&#125;package review.thread;public class Proceducer extends Thread&#123;\tprivate Store store;\tpublic Proceducer(Store store)&#123;\t\tthis.store = store;\t&#125;\tpublic void run()&#123;\t\twhile(true)&#123;\t\t\tthis.store.add();\t\t\ttry &#123;\t\t\t\tThread.sleep(1000);\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t// TODO Auto-generated catch block\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;&#125;package review.thread;public class Consumer extends Thread&#123;\tprivate Store store;\tpublic Consumer(Store store)&#123;\t\tthis.store = store;\t&#125;\tpublic void run()&#123;\t\twhile(true)&#123;\t\t\tthis.store.remove();\t\t\ttry &#123;\t\t\t\tThread.sleep(1500);\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t// TODO Auto-generated catch block\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\n如何使用Java线程池线程池属于对象池，其目的在于最大限度的复用对象。还可以使线程代码与业务代码分离。\njava.util.concurrent.ThreadPoolExecutor(    int corePoolSize, // 最大核心线程数    int maximumPoolSize, // 允许最大线程数    long keepAliveTime,    TimeUnit unit,    BlokingQueue&lt;Runnable&gt; workQueue, // 缓冲队列    RejectedExecutionHandler handler);\n\n一个Runnable类型的对象通过execute(Runnable)方法添加到线程池。当一个任务通过execute(Runnable)方法添加到线程池时：\n\n如果此时线程池中线程数&lt;corePoolSize，即使线程池中的线程都处于空闲状态也要添加新线程来处理任务\n如果此时线程池中线程数&#x3D;corePoolSize，但缓冲队列workQueue未满，那么任务被放入缓冲队列\n如果此时线程池中线程数&gt;corePoolSize，缓冲队列workQueue满，但线程池中线程数&lt;maximumPoolSize，创建新线程来处理任务\n如果此时线程池中线程数&gt;corePoolSize，缓冲队列workQueue满，但线程池中线程数&#x3D;maximumPoolSize，通过handler所指定的策略来处理此任务\n\nimport java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class TestThreadPool &#123;\tprivate static int produceTaskSleepTime = 2000;\tpublic static void main(String[] args)&#123;\t\t// 创建线程池\t\tThreadPoolExecutor producerPool = new ThreadPoolExecutor(\t\t\t\t1, 1, 0, TimeUnit.SECONDS, \t\t\t\tnew ArrayBlockingQueue(3), \t\t\t\tnew ThreadPoolExecutor.DiscardOldestPolicy());\t\t\t\tint i = 1;\t\twhile(true)&#123;\t\t\ttry &#123;\t\t\t\tThread.sleep(produceTaskSleepTime);\t\t\t\tString task = &quot;task@&quot; + i;\t\t\t\tSystem.out.println(&quot;put &quot; + task);\t\t\t\t// 用execute方法启动任务\t\t\t\tproducerPool.execute(new ThreadPoolTask(task));\t\t\t\ti++;\t\t\t&#125; catch (InterruptedException e) &#123;\t\t\t\t// TODO Auto-generated catch block\t\t\t\te.printStackTrace();\t\t\t&#125;\t\t&#125;\t&#125;&#125;import java.io.Serializable;public class ThreadPoolTask implements Runnable, Serializable&#123;\tprivate static final long serialVersionUID = 0;\tprivate static int consumeTaskSleepTime = 2000;\t\tprivate String threadPoolTaskData;\t\tpublic ThreadPoolTask(String tasks)&#123;\t\tthis.threadPoolTaskData = tasks;\t&#125;\t\tpublic void run() &#123;\t\tSystem.out.println(&quot;start..&quot; + threadPoolTaskData);\t\ttry &#123;\t\t\tThread.sleep(consumeTaskSleepTime);\t\t&#125; catch (InterruptedException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125;\t\tthreadPoolTaskData = null;\t&#125;\t&#125;\n\n\n 反射 反射原理反射能够动态的加载一个类，动态的调用一个方法，动态的访问一个属性。JVM会为每个类创建一个java.lang.Class类的实例，通过该对象可以获取这个类的信息，然后在通过java.lang.reflect包下的API来进行操作。\n类型信息的存储如果Java类文件存在内部类，那么编译这个文件时就会产生多个.class文件，命名规则为：外部类名$内部类名.class\n例如：\npublic class Person&#123;\tclass Tool&#123;\t&#125;\tinterface Communication&#123;\t\tpublic void speak();\t&#125;&#125;\n\n会产生 Perlon.class, Person$Tool.class, Person$Communitcation.class 三个文件\n.class 文件结构\n\n    \n        \n            \n                类型\n            \n            \n                名称\n            \n            \n                数量\n            \n            \n                长度\n            \n            \n                备注\n            \n        \n        \n            \n                u4\n            \n            \n                magic\n            \n            \n                1\n            \n            \n                4Byte\n            \n            \n                魔数：0xCAFEBABEOd -x命令可以看到，保证虚拟机可以轻松分辨Java文件和非Java文件。\n                \n            \n        \n        \n            \n                u2\n            \n            \n                minor_version\n            \n            \n                1\n            \n            \n                2Byte\n            \n            \n                主版本号，class文件格式变化而变化\n            \n        \n        \n            \n                u2\n            \n            \n                major_version\n            \n            \n                1\n            \n            \n                2Byte\n            \n            \n                主版本号，class文件格式变化而变化\n            \n        \n        \n            \n                u2\n            \n            \n                constant_pool_count\n            \n            \n                1\n            \n            \n                ?\n            \n            \n                常量个数\n            \n        \n        \n            \n                cp_info\n            \n            \n                constant_pool\n            \n            \n                constant_pool_count-1\n            \n            \n                ?\n            \n            \n                常量池：包含文件中类和接口相关常量。文字字符串、final变量值、类名和方法名的常量。通常占整个类大小的60%\n            \n        \n        \n            \n                u2\n            \n            \n                access_flags\n            \n            \n                1\n            \n            \n                2Byte\n            \n            \n                访问标志：定义了类或接口。\n            \n        \n        \n            \n                u2\n            \n            \n                this_class\n            \n            \n                1\n            \n            \n                2Byte\n            \n            \n                常量池索引，指向常量池中该类全限定名的常量池入口\n            \n        \n        \n            \n                u2\n            \n            \n                super_class\n            \n            \n                1\n            \n            \n                2Byte\n            \n            \n                指向父类全限定名\n            \n        \n        \n            \n                u2\n            \n            \n                interfaces_count\n            \n            \n                1\n            \n            \n                ?\n            \n            \n                该类实现的接口数量\n            \n        \n        \n            \n                u2\n            \n            \n                interfaces\n            \n            \n                interfaces_count\n            \n            \n                ?\n            \n            \n                由该类实现的接口的常量池引用\n            \n        \n        \n            \n                u2\n            \n            \n                fields_count\n            \n            \n                1\n            \n            \n                ?\n            \n            \n                字段数量\n            \n        \n        \n            \n                field_info\n            \n            \n                fields\n            \n            \n                fields_count\n            \n            \n                ?\n            \n            \n                字段信息表，描述字段的类型、描述符等\n            \n        \n        \n            \n                u2\n            \n            \n                methods_count\n            \n            \n                1\n            \n            \n                ?\n            \n            \n                方法数量\n            \n        \n        \n            \n                method_info\n            \n            \n                methods\n            \n            \n                methods_count\n            \n            \n                ?\n            \n            \n                方法本身，每个方法都有一个method_info表，记录了方法的方法名、字段类型、描述符等\n            \n        \n        \n            \n                u2\n            \n            \n                attributes_count\n            \n            \n                1\n            \n            \n                ?\n            \n            \n                属性数量\n            \n        \n        \n            \n                attribute_info\n            \n            \n                attributes\n            \n            \n                attributes_count\n            \n            \n                ?\n            \n            \n                属性本身\n            \n        \n    \n\n\n\n\n代理\n静态代理\npublic interface Speakable&#123;\tpublic void speak(String msg);&#125;public class Person implements Speakable&#123;\t@Override\tpublic void speak(String msg)&#123;\t\tSystem.out.println(&quot;Speak:&quot; + msg);\t&#125;&#125;public class PersonProxy implements Speakable&#123;\tprivate Person person;\tpublic PersonProxy(Person person)&#123;\t\tthis.person=person;\t&#125;\t@Override\tpublic void speak(String msg)&#123;\t\tthis.person.speak(msg);\t\tSystem.out.println(&quot;运行时间:&quot; + System.currentTimeMillis());\t&#125;&#125;public class Boostrap&#123;\tpublic static void main(String[] args)&#123;\t\tPerson person = new Person();\t\tPersonProxy proxy = new PersonProxy(person);\t\tproxy.speak(&quot;static proxy&quot;);\t&#125;&#125;\n\n动态代理\n// 调用处理器public class MyProxy implements InvocationHandler&#123;\tprivate Object proxied;\tpublic MyProxy(Object proxied)&#123;\t\tthis.proxied=proxied;\t&#125;\t// (代理对象由java动态生成, 被执行的委托方法, 执行委托方法所需要的参数)\t@Override\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable&#123;\t\tmethod.invoke(this.proxied, args);\t\tSystem.out.println(&quot;运行时间:&quot; + System.currentTimeMillis());\t\treturn null;\t&#125;&#125;public class Bootstrap&#123;\tpublic static void main(String[] args)&#123;\t\tPerson person = new Person();\t\tSpeakable speakable = (Speakable)Proxy.newProxyInstance(\t\t\tSpeakable.class.getClassLoader(),\t\t\tnew Class[] &#123;Speakable.class&#125;,\t\t\tnew MyProxy(person)\t\t);\t\tspeakable.speak(&quot;dynamic proxy&quot;);\t&#125;&#125;\n\n\n\n Java网络编程 TCP&#x2F;IP协议TCP&#x2F;IP(Transmission Control Protocel&#x2F;Internet Protocol)，传输控制协议&#x2F;因特网互联协议，网络通讯协议。由网络层的IP协议与传输层的TCP协议组成。\n\n应用层(Application Layer)\n传输层(Transport Layer)\n网络层(Network Layer)\n链接层(Link Layer)\n物理层(Physical Layer)\n\n早期的时候，每家公司都有自己的电信号分组方式。逐渐地，一种叫做”以太网”（Ethernet）的协议，占据了主导地位。以太网规定，一组电信号构成一个数据包，叫做”帧”（Frame）。每一帧分成两个部分：包头（Head）和数据（Data）。\n“传输层”的功能，就是建立”端口到端口”的通信。相比之下，”网络层”的功能是建立”主机到主机”的通信。只要确定主机和端口，我们就能实现程序之间的交流。\n\n\n\n\n Java Web 开发相关技术 javaweb // 应用程序名字    |- META-INF    |- resource    |- WEB-INF        |- classes // 存放class文件，类加载路径        |- lib // 第三方jar类库\t\t|- web.xml // 整个web应用程序的描述文件，通过它配置信息资源\n\n用户发送HTTP请求，Web容器通过http:&#x2F;&#x2F;&lt;域名或IP地址&gt;&#x2F;&lt;应用的名字&gt;&#x2F;&lt;资源的地址&gt;去定位资源\n&lt;servlet&gt;\t&lt;servlet-name&gt;&lt;/servlet-name&gt;\t&lt;servlet-class&gt;&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt;\t&lt;servlet-name&gt;&lt;/servlet-name&gt;\t&lt;servlet-pattern&gt;&lt;/servlet-pattern&gt;&lt;/servlet-mapping&gt;\n\n\n 算法题 反转字符串输出package algorithm;public class BackString &#123;\tpublic static void main(String[] args)&#123;\t\tString str = &quot;Hello world!&quot;;\t\tStringBuffer sb = new StringBuffer();\t\tfor(int i = str.length() - 1; i &gt;= 0; i--)&#123;\t\t\tsb.append(str.substring(i,i+1));\t\t&#125;\t\tSystem.out.print(sb);\t&#125;&#125;\n\n求素数package algorithm.prime;public class Prime &#123;\t\tprivate static boolean isPrime(int num)&#123;\t\tif(num &lt; 2)&#123;\t\t\treturn false;\t\t&#125;\t\tfor(int i = 2; i &lt; num; i++)&#123;\t\t\tif(num % i == 0)&#123;\t\t\t\treturn false;\t\t\t&#125;\t\t&#125;\t\treturn true;\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tint count=0;\t\tfor(int i = 0; i &lt; 1000000; i++)&#123;\t\t\tboolean flag = Prime.isPrime(i);//\t\t\tSystem.out.println(i + &quot;,&quot; + flag);\t\t\tif(flag)&#123;\t\t\t\tcount++;\t\t\t&#125;\t\t&#125;\t\tSystem.out.println(&quot;count=&quot; + count);\t&#125;&#125;\n\n改进版\npackage algorithm.prime;public class Prime &#123;\t\tprivate static final int MaxLimit=1000000;\t\tprivate static boolean[] primeList = new boolean[MaxLimit+1];\t\tprivate static boolean isPrime(int num)&#123;\t\tif(num &lt; 2)&#123;\t\t\treturn false;\t\t&#125;\t\tif(num == 2)&#123;\t\t\tprimeList[2] = true;\t\t\treturn true;\t\t&#125;\t\tif(num % 2 == 0)&#123;\t\t\treturn false;\t\t&#125;\t\tfor(int i = 3; i*i &lt; num; i+=2)&#123;\t\t\tif(primeList[num])&#123;\t\t\t\tif(num % i == 0)&#123;\t\t\t\t\treturn false;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tfor(int i = 3; i*i &lt; num; i+=2)&#123;\t\t\tif(num % i == 0)&#123;\t\t\t\treturn false;\t\t\t&#125;\t\t&#125;\t\tprimeList[num] = true;\t\treturn true;\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tint count=0;\t\tfor(int i = 0; i &lt; MaxLimit; i++)&#123;\t\t\tboolean flag = Prime.isPrime(i);//\t\t\tSystem.out.println(i + &quot;,&quot; + flag);\t\t\tif(flag)&#123;\t\t\t\tcount++;\t\t\t&#125;\t\t&#125;\t\tSystem.out.println(&quot;count=&quot; + count);\t&#125;&#125;\n\n打印回文数字package algorithm;public class MirrorNum &#123;\tpublic static boolean isMirrorNumber(int num)&#123;\t\tint temp = num;\t\tint result = 0;\t\twhile(temp &gt; 0)&#123;\t\t\tresult = result*10 + temp%10;\t\t\ttemp /= 10;\t\t&#125;\t\treturn num == result;\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tfor(int i = 10; i &lt; 1000; i++)&#123;\t\t\tif(isMirrorNumber(i))&#123;\t\t\t\tSystem.out.println(i);\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n\n冒泡排序 BubbleSortpackage demo;public class BubbleSort &#123;\t\tpublic static void bubbleSort(int[] array)&#123;\t\tfor(int i = 1; i &lt; array.length; i++)&#123;\t\t\tfor(int j = 0; j &lt; array.length-i; j++)&#123;\t\t\t\tif(array[j] &gt; array[j+1])&#123;\t\t\t\t\tint temp = array[j];\t\t\t\t\tarray[j] = array[j+1];\t\t\t\t\tarray[j+1] = temp;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tint[] array = &#123;5,3,2,1,4&#125;;\t\tbubbleSort(array);\t\tfor(int i = 0; i &lt; array.length; i++)&#123;\t\t\tSystem.out.print(array[i] + &quot;,&quot;);\t\t&#125;\t&#125;&#125;\n\n插入排序 InsertSortpackage demo;public class InsertSort &#123;\t\tpublic static void insertSort(int[] array)&#123;\t\tfor(int i = 1; i &lt; array.length; i++)&#123;\t\t\tint temp = array[i];\t\t\tint j;\t\t\tfor(j = i; j &gt; 0; j--)&#123;\t\t\t\tif(array[j-1] &gt; temp)&#123;\t\t\t\t\tarray[j]=array[j-1];\t\t\t\t&#125;else&#123;\t\t\t\t\tbreak;\t\t\t\t&#125;\t\t\t&#125;\t\t\tarray[j] = temp;\t\t&#125;\t\t\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tint[] array = &#123;5,3,2,1,4&#125;;\t\tinsertSort(array);\t\tfor(int i = 0; i &lt; array.length; i++)&#123;\t\t\tSystem.out.print(array[i] + &quot;,&quot;);\t\t&#125;\t&#125;&#125;\n\n快速排序 QuickSortpackage demo;public class QuickSort &#123;\t\tpublic static void quickSort(int[] a,int low,int high)&#123;\t\tint i,j;\t\ti=low;\t\tj=high;\t\tif(i&gt;j)\t\t\treturn;\t\tint temp=a[i];\t\twhile(i&lt;j)&#123;\t\t\twhile(i&lt;j&amp;&amp;a[j]&gt;temp)&#123;\t\t\t\tj--;\t\t\t&#125;\t\t\tif(i&lt;j)&#123;\t\t\t\ta[i]=a[j];\t\t\t\ti++;\t\t\t&#125;\t\t\twhile(i&lt;j&amp;&amp;a[i]&lt;temp)&#123;\t\t\t\ti++;\t\t\t&#125;\t\t\tif(i&lt;j)&#123;\t\t\t\ta[j]=a[i];\t\t\t\tj--;\t\t\t&#125;\t\t&#125;\t\ta[i]=temp;\t\tquickSort(a,low,i-1);\t\tquickSort(a,i+1,high);\t&#125;\t\tpublic static void main(String[] args)&#123;\t\tint[] array = &#123;5,3,2,1,4&#125;;\t\tquickSort(array, 0, 4);\t\tfor(int i = 0; i &lt; array.length; i++)&#123;\t\t\tSystem.out.print(array[i] + &quot;,&quot;);\t\t&#125;\t&#125;&#125;\n\n归并排序package demo;public class QuickSort &#123;\tpublic static void esort(int[] a,int p,int r)&#123;\t\tif(p&gt;=r)\t\t\treturn;\t\tint q= (p+r)/2;\t\tesort(a,p,q);\t\tesort(a,q+1,r);\t\tmsort(a,p,q,r);\t&#125;\tpublic static void msort(int[] a,int p,int q,int r)&#123;\t\tint n1=q-p+1;\t\tint n2=r-q;\t\tint i,j,k;\t\tint L[]=new int[n1];\t\tint R[]=new int[n2];\t\tfor(i=0,k=p;i&lt;n1;i++,k++)\t\t\tL[i]=a[k];\t\tfor(j=0;j&lt;n2;j++,k++)\t\t\tR[j]=a[k];\t\tfor(i=0,j=0,k=p;i&lt;n1&amp;&amp;j&lt;n2;k++)&#123;\t\t\tif(L[i]&lt;R[j])&#123;\t\t\t\ta[k]=L[i];\t\t\t\ti++;\t\t\t&#125;else &#123;\t\t\t\ta[k]=R[j];\t\t\t\tj++;\t\t\t&#125;\t\t&#125;\t\twhile(i&lt;n1)&#123;\t\t\ta[k]=L[i];\t\t\ti++;\t\t\tk++;\t\t&#125;\t\twhile(j&lt;n2)&#123;\t\t\ta[k]=R[j];\t\t\tj++;\t\t\tk++;\t\t&#125;\t&#125;\tpublic static void main(String[] args)&#123;\t\tint[] array = &#123;5,3,2,1,4&#125;;\t\tesort(array, 0, 4);\t\tfor(int i = 0; i &lt; array.length; i++)&#123;\t\t\tSystem.out.print(array[i] + &quot;,&quot;);\t\t&#125;\t&#125;&#125;\n\n\n\n\n","categories":["Back-end"],"tags":["Java"]},{"title":"Java复习笔记：注解","url":"/2021/05/13/Java/Java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E6%B3%A8%E8%A7%A3/","content":"Java 内置注解@Override定义在：java.lang.Override 中\n只能用于修辞方法，表示一个方法声明打算重写超类中的另一个方法。\n@Deprecated定义在：java.lang.Deprecated 中\n可以用于修辞方法、属性、类，表示不推荐程序员使用的元素，通常意味着它存在危险或有更好的选择\n@SuppressWarnings定义在：java.lang.SuppressWarnings 中\n用于抑制编译时的警告信息\n\n@SuppressWarnings(&quot;all&quot;): 抑制所有类型的警告\n@SuppressWarnings(value=&#123;&quot;unchecked&quot;, &quot;rawtypes&quot;&#125;): 抑制所多种类型的警告\n@SuppressWarnings(&quot;unchecked&quot;): 抑制unchecked类型的警告\n\n参数：\n\nall: to suppress all warnings\nboxing : to suppress warnings relative to boxing&#x2F;unboxing operations\ncast: to suppress warnings relative to cast operations\ndep-ann: to suppress warnings relative to deprecated annotation\ndeprecation: to suppress warnings relative to deprecation\nfallthrough:  to suppress warnings relative to missing breaks in switch statements\nfinally : to suppress warnings relative to finally block that don’t return\nhiding: to suppress warnings relative to locals that hide variable\nincomplete-switch:  to suppress warnings relative to missing entries in a switch statement (enum case)\nnls:  to suppress warnings relative to non-nls string literals\nnull: to suppress warnings relative to null analysis\nrawtypes: to suppress warnings relative to un-specific types when using generics on class params\nrestriction: to suppress warnings relative to usage of discouraged or forbidden references\nserial: to suppress warnings relative to missing serialVersionUID field for a serializable class\nstatic-access: o suppress warnings relative to incorrect static access\nsynthetic-access :  to suppress warnings relative to unoptimized access from inner classes\nunchecked:  to suppress warnings relative to unchecked operations\nunqualified-field-access: to suppress warnings relative to field access unqualified\nunused: to suppress warnings relative to unused code\n\n元注解(meta-annotation)用于注解其它注解的注解\n1. @Target用于描述注解的使用范围\nexample:\n@Target(value = ElementType.TYPE)\n\n可用&#123;&#125;来给value传入数组\n@Target(value = &#123;ElementType.TYPE, ElementType.METHOD&#125;)\n\nvalue参数值为枚举类型，定义如下：\npublic enum ElementType &#123;    /** Class, interface (including annotation type), or enum declaration */    TYPE,    /** Field declaration (includes enum constants) */    FIELD,    /** Method declaration */    METHOD,    /** Formal parameter declaration */    PARAMETER,    /** Constructor declaration */    CONSTRUCTOR,    /** Local variable declaration */    LOCAL_VARIABLE,    /** Annotation type declaration */    ANNOTATION_TYPE,    /** Package declaration */    PACKAGE,    /**     * Type parameter declaration     *     * @since 1.8     */    TYPE_PARAMETER,    /**     * Use of a type     *     * @since 1.8     */    TYPE_USE&#125;\n\n2. @Retention表示需要什么级别保存该注解信息，用于描述注解的生命周期\n取值：SOURCE &lt; CLASS &lt; RUNTIME\n\nSOURCE: 保留到源码\nCLASS: 保留到字节码\nRUNTIME: 保留到虚拟机\n\npublic enum RetentionPolicy &#123;    /**     * Annotations are to be discarded by the compiler.     */    SOURCE,    /**     * Annotations are to be recorded in the class file by the compiler     * but need not be retained by the VM at run time.  This is the default     * behavior.     */    CLASS,    /**     * Annotations are to be recorded in the class file by the compiler and     * retained by the VM at run time, so they may be read reflectively.     *     * @see java.lang.reflect.AnnotatedElement     */    RUNTIME&#125;\n\n3. @Document表示该注解将被包含在javadoc中\n4. @Inherited表示子类可以继承父类中的该注解\n自定义注解反射(Reflection)反射(Reflection)是Java被视为动态语言的关键，反射机制允许程序在执行期借助于Reflection API取得任何类型的内部信息，并能直接操作任意对象的内部属性及方法。\n加载完类之后，在堆内存的方法区中就产生了一个Class类型的对象（一个类只有一个Class对象），这个对象就包含了完整的类的结构信息。我们可以通过这个对象看到类的结构。\n","categories":["Design Patterns"],"tags":["JavaScript"]},{"title":"Java复习笔记：多线程与并发第一章","url":"/2022/11/13/Java/Java%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91%E7%AC%AC%E4%B8%80%E7%AB%A0/","content":"基本概念回顾进程和线程的区别进程和线程的由来\n串行：早起的计算机只能执行串行任务，并且遇到用户输入的操作时便会阻塞\n批处理：预先将用户的指令集中成清单，批量串行处理用户指令，仍无法并发执行\n进程：进程独占内存空间，保存各自运行状态，相互不干扰且可以互相切换，为并发处理任务提供了可能\n线程：共享进程的内存资源，相互间切换更便捷，支持更细粒度的任务控制，让进程内的子任务得以并发执行\n\n区别进程和线程都是一个时间段的描述，是CPU工作时间段的描述。进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。\n所有与进程相关的资源都被记录在PCB(PCB Process Control Block)中。\nPCB:\n\n描述信息\n控制信息\n资源信息\n程序段\n数据段\n\n\nCPU现场\n\n\n它是进程实体的一部分，是操作系统中最重要的记录性数据结构。它是进程管理和控制的最重要的数据结构，每一个进程均有一个PCB，在创建进程时，建立PCB，伴随进程运行的全过程，直到进程撤消而撤消。\n\n进程拥有完整的虚拟内存地址空间，而同一进程下的线程则共享该进程拥有的内存空间。\n线程的组成：\n\n堆栈寄存器\n程序计数器\nTCB\n\n进程就是包括上下文切换的程序执行时间总和 &#x3D; CPU加载上下文+CPU执行+CPU保存上下文。\n\n\n进程的颗粒度太大，每次都要有上下的调入，保存，调出。\n假设存在进程A，其实际分成 a，b，c等多个块组合而成。那么这里具体的执行就可能变成：\n进程A得到CPU-&gt;CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。\n这里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段。\n进程是资源分配的最小单位，线程是CPU调度的最小单位。\nLinux用户态和内核态转换为什么需要转换内核态的多线程是如何通过轻量级线程来实现的什么是系统中断Java中的进程和线程Java进程和线程的关系\n运行一个程序会产生一个进程，进程包含至少一个线程\n每个进程对应一个JVM实例，多个线程共享JVM里的堆\nJava采用单线程编程模型，程序会自动创建主线程\n\nThread中的start和run方法的区别使用run方法会继续使用主线程来执行重写的run方法里面的内容，而使用start方法则会开一个新线程来执行。\n我们看一下start方法源码\n\nThread.java\n\n/**     * Causes this thread to begin execution; the Java Virtual Machine     * calls the &lt;code&gt;run&lt;/code&gt; method of this thread.     * &lt;p&gt;     * The result is that two threads are running concurrently: the     * current thread (which returns from the call to the     * &lt;code&gt;start&lt;/code&gt; method) and the other thread (which executes its     * &lt;code&gt;run&lt;/code&gt; method).     * &lt;p&gt;     * It is never legal to start a thread more than once.     * In particular, a thread may not be restarted once it has completed     * execution.     *     * @exception  IllegalThreadStateException  if the thread was already     *               started.     * @see        #run()     * @see        #stop()     */    public synchronized void start() &#123;        /**         * This method is not invoked for the main method thread or &quot;system&quot;         * group threads created/set up by the VM. Any new functionality added         * to this method in the future may have to also be added to the VM.         *         * A zero status value corresponds to state &quot;NEW&quot;.         */        if (threadStatus != 0)            throw new IllegalThreadStateException();        /* Notify the group that this thread is about to be started         * so that it can be added to the group&#x27;s list of threads         * and the group&#x27;s unstarted count can be decremented. */        group.add(this);        boolean started = false;        try &#123;            start0();            started = true;        &#125; finally &#123;            try &#123;                if (!started) &#123;                    group.threadStartFailed(this);                &#125;            &#125; catch (Throwable ignore) &#123;                /* do nothing. If start0 threw a Throwable then                  it will be passed up the call stack */            &#125;        &#125;    &#125;    private native void start0();\n\n可以看到在start方法里面主要是使用到了一个native的方法start0()，该方法调用到了外部的非Java的源码。\n可以访问OpenJKD来查询\nJKD8 Thread.c源码\n\nThread.c\n\n#include &quot;jni.h&quot;#include &quot;jvm.h&quot;#include &quot;java_lang_Thread.h&quot;#define THD &quot;Ljava/lang/Thread;&quot;#define OBJ &quot;Ljava/lang/Object;&quot;#define STE &quot;Ljava/lang/StackTraceElement;&quot;#define STR &quot;Ljava/lang/String;&quot;#define ARRAY_LENGTH(a) (sizeof(a)/sizeof(a[0]))static JNINativeMethod methods[] = &#123;    &#123;&quot;start0&quot;,           &quot;()V&quot;,        (void *)&amp;JVM_StartThread&#125;,    &#123;&quot;stop0&quot;,            &quot;(&quot; OBJ &quot;)V&quot;, (void *)&amp;JVM_StopThread&#125;,    &#123;&quot;isAlive&quot;,          &quot;()Z&quot;,        (void *)&amp;JVM_IsThreadAlive&#125;,    &#123;&quot;suspend0&quot;,         &quot;()V&quot;,        (void *)&amp;JVM_SuspendThread&#125;,    &#123;&quot;resume0&quot;,          &quot;()V&quot;,        (void *)&amp;JVM_ResumeThread&#125;,    &#123;&quot;setPriority0&quot;,     &quot;(I)V&quot;,       (void *)&amp;JVM_SetThreadPriority&#125;,    &#123;&quot;yield&quot;,            &quot;()V&quot;,        (void *)&amp;JVM_Yield&#125;,    &#123;&quot;sleep&quot;,            &quot;(J)V&quot;,       (void *)&amp;JVM_Sleep&#125;,    &#123;&quot;currentThread&quot;,    &quot;()&quot; THD,     (void *)&amp;JVM_CurrentThread&#125;,    &#123;&quot;countStackFrames&quot;, &quot;()I&quot;,        (void *)&amp;JVM_CountStackFrames&#125;,    &#123;&quot;interrupt0&quot;,       &quot;()V&quot;,        (void *)&amp;JVM_Interrupt&#125;,    &#123;&quot;isInterrupted&quot;,    &quot;(Z)Z&quot;,       (void *)&amp;JVM_IsInterrupted&#125;,    &#123;&quot;holdsLock&quot;,        &quot;(&quot; OBJ &quot;)Z&quot;, (void *)&amp;JVM_HoldsLock&#125;,    &#123;&quot;getThreads&quot;,        &quot;()[&quot; THD,   (void *)&amp;JVM_GetAllThreads&#125;,    &#123;&quot;dumpThreads&quot;,      &quot;([&quot; THD &quot;)[[&quot; STE, (void *)&amp;JVM_DumpThreads&#125;,    &#123;&quot;setNativeName&quot;,    &quot;(&quot; STR &quot;)V&quot;, (void *)&amp;JVM_SetNativeThreadName&#125;,&#125;;#undef THD#undef OBJ#undef STE#undef STRJNIEXPORT void JNICALLJava_java_lang_Thread_registerNatives(JNIEnv *env, jclass cls)&#123;    (*env)-&gt;RegisterNatives(env, cls, methods, ARRAY_LENGTH(methods));&#125;\n\n可以看到start0方法调用到了JVM_StartThread方法，而该方法引自jvm.h\nJDK8 jvm.cpp源码\n在jvm.cpp下的JVM_StartThread方法里有下面这句话用于创建一个线程\n\njvm.cpp\n\nnative_thread = new JavaThread(&amp;thread_entry, sz);\n\n搜索上面用于创建线程的方法传入的参数thread_entry\nstatic void thread_entry(JavaThread* thread, TRAPS) &#123;  HandleMark hm(THREAD);  Handle obj(THREAD, thread-&gt;threadObj());  JavaValue result(T_VOID);  JavaCalls::call_virtual(&amp;result,                          obj,                          KlassHandle(THREAD, SystemDictionary::Thread_klass()),                          vmSymbols::run_method_name(),                          vmSymbols::void_method_signature(),                          THREAD);&#125;\n\n可以看到该方法最后会调用JVM虚拟机JavaCalls::call_virtual，并传入run_method_name\n综上所述：\n\n调用start方法会：Thread#start()-&gt;JVM_StartThread-&gt;thread_entry-&gt;Thread#run()\n在thread_entry时创建一个新的子线程并启动去运行Thread#run()里的方法体\n\n\n调用run方法会：Thread#run()\n当做一个普通的方法调用去调用Thread#run()里的方法体\n\n\n\nThread和 Runnable是什么关系\nThread类实现了Runnable接口，使得run支持多线程\n因为类的单一继承原则，推荐使用Runnable接口\n\n实现了Runnable接口是没有start方法的，需要把其对象作为参数去创建一个Thread对象再调用start方法启动\n如何给run()方法传参\n构造函数传参\n成员变量传参\n回调函数传参\n\n处理线程的返回值\n主线程等待法：让主线程循环等待直到子线程返回\n使用Thread类的join()阻塞当前主线程以等待子线程处理完毕public class Test implements Runnable &#123;    @Override    void run() &#123;        try &#123;            Thread.currentThread.sleep(5000);        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125;        value = &quot;data&quot;;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        Test test = new Test();        Thread t = new Thread(test);        t.start();        t.join();        System.out.println(&quot;value:&quot; + cw.value);    &#125;&#125;\n通过Callable接口实现：通过FutureTask or 线程池获取\n\n// 通过FutureTaskpublic class MyCallable implements Callable&lt;String&gt; &#123;    @Override    public String call() throws Exception&#123;        String value=&quot;test&quot;;        System.out.println(&quot;ready to work&quot;);        Thread.currentThread().sleep(5000);        System.out.println(&quot;Task down&quot;);        return value;    &#125;&#125;public class FutureTaskDemo &#123;    public static void main(String[] args) throws InterruptedException &#123;        FutureTask&lt;String&gt; task = new FutureTask&lt;&gt;(new MyCallable());        new Thread(task);        if(!task.isDone())&#123;            System.out.println(&quot;task has not finished, please wait&quot;);        &#125;        // 显示MyCallable里面的返回值        System.out.println(&quot;task return:&quot; + task.get());    &#125;&#125;\n\n// 通过线程池public class ThreadPoolDemo &#123;    public static void main(String[] args) throws InterruptedException &#123;        ExecutorService newPool = Executors.newCachedThreadPool();        Future&lt;String&gt; future = newPool.submit(new MyCallable());        if (!task.isDone()) &#123;            System.out.println(&quot;task has not finished, please wait&quot;);        &#125;        // 显示MyCallable里面的返回值        try &#123;            System.out.println(&quot;task return:&quot; + task.get());        &#125; catch (InterruptedException e) &#123;            e.printStackTrace();        &#125; catch (ExecutionException e) &#123;            e.printStackTrace();        &#125; finally &#123;            newPool.shutdown();        &#125;    &#125;&#125;\n\nsleep和wait的区别\nsleep是Thread类的方法，wait是Object类中定义的方法\nsleep方法可以在任何地方使用\nwait方法只能在synchronized方法或synchronized快中使用\nThread.sleep只会让出CPU，不会导致锁行为的改变\nObject.wait不仅会让出CPU，还会释放已经占有的同步资源\n\npublic class WaitSleepDemo &#123;  public static void main(String[] args) &#123;    final Object lock = new Object();    new Thread(new Runnable() &#123;      @Override      public void run() &#123;        System.out.println(&quot;thread A is waiting to get lock&quot;);        synchronized (lock) &#123;          try &#123;            System.out.println(&quot;thread A get lock&quot;);            Thread.sleep(20);            System.out.println(&quot;thread A do wait lock&quot;);            lock.wait(1000);            System.out.println(&quot;thread A is done&quot;);          &#125; catch (InterruptedException e) &#123;            e.printStackTrace();          &#125;        &#125;      &#125;    &#125;).start();    try &#123;      Thread.sleep(10);    &#125; catch (InterruptedException e) &#123;      e.printStackTrace();    &#125;    new Thread(new Runnable() &#123;      @Override      public void run() &#123;        System.out.println(&quot;thread B is waiting to get lock&quot;);        synchronized (lock) &#123;          try &#123;            System.out.println(&quot;thread B get lock&quot;);            System.out.println(&quot;thread B sleeping 10 ms&quot;);            Thread.sleep(10);            System.out.println(&quot;thread B is done&quot;);          &#125; catch (InterruptedException e) &#123;            e.printStackTrace();          &#125;        &#125;      &#125;    &#125;).start();  &#125;&#125;\n\nthread A is waiting to get lockthread A get lockthread B is waiting to get lockthread A do wait lockthread B get lockthread B sleeping 10 msthread B is donethread A is done\n\n观察输出可发现，在A获得锁之后B开始等待锁，而A开始wait之后B就获得了锁\nnotify和notifyAll的区别锁池 EntryList：假设线程A已经拥有了某对象的锁，而其它线程B、C想要调用这个对象的某个synchronized方法(或块)之前必须先获得该对象锁的拥有权，而恰巧该对象的锁目前正被线程A占用，此时B、C线程就会被阻塞，进入一个地方去等待锁的释放，这个地方便是该对象的锁池。\n等待池 WaitSet：假设线程A调用了某个对象的wait()方法，线程A就会释放该对象的锁，同时线程A就进入到了该对象的等待池中，进入到等待池中的线程不会去竞争该对象的锁。\n\nnotifyAll会让所有处于等待池中的线程全部进入锁池去竞争获取锁的机会\nnotify会随机选取一个处于等待池中的线程进入锁池去竞争获取锁的机会\n\npublic class WaitSleepDemo &#123;  public static void main(String[] args) &#123;    final Object lock = new Object();    new Thread(new Runnable() &#123;      @Override      public void run() &#123;        System.out.println(&quot;thread A is waiting to get lock&quot;);        synchronized (lock) &#123;          try &#123;            System.out.println(&quot;thread A get lock&quot;);            Thread.sleep(20);            System.out.println(&quot;thread A do wait lock&quot;);            lock.wait();            System.out.println(&quot;thread A is done&quot;);          &#125; catch (InterruptedException e) &#123;            e.printStackTrace();          &#125;        &#125;      &#125;    &#125;).start();    try &#123;      Thread.sleep(10);    &#125; catch (InterruptedException e) &#123;      e.printStackTrace();    &#125;    new Thread(new Runnable() &#123;      @Override      public void run() &#123;        System.out.println(&quot;thread B is waiting to get lock&quot;);        synchronized (lock) &#123;          try &#123;            System.out.println(&quot;thread B get lock&quot;);            System.out.println(&quot;thread B sleeping 10 ms&quot;);            Thread.sleep(10);            System.out.println(&quot;thread B is done&quot;);            lock.notify(); // or lock.notifyAll();          &#125; catch (InterruptedException e) &#123;            e.printStackTrace();          &#125;        &#125;      &#125;    &#125;).start();  &#125;&#125;\n\npublic class NotificationDemo &#123;  private volatile boolean go = false;  private synchronized void go() &#123;    while (go == false) &#123;      System.out.println(Thread.currentThread() + &quot; is going to notify all or one thread waiting on&quot;);      go = true;      notify();    &#125;  &#125;  private synchronized void shouldGo() throws InterruptedException &#123;    while (go != true) &#123;      System.out.println(Thread.currentThread() + &quot; is going to wait on this object&quot;);      wait();      System.out.println(Thread.currentThread() + &quot; is woken up&quot;);    &#125;    go = false;  &#125;  public static void main(String[] args) throws InterruptedException &#123;    final NotificationDemo test = new NotificationDemo();    Runnable waitTask = new Runnable() &#123;      @Override      public void run() &#123;        try &#123;          test.shouldGo();        &#125; catch (InterruptedException e) &#123;          e.printStackTrace();        &#125;        System.out.println(Thread.currentThread().getName() + &quot; finished Execution&quot;);      &#125;    &#125;;    Runnable notifyTask = new Runnable() &#123;      @Override      public void run() &#123;        test.go();        System.out.println(Thread.currentThread().getName() + &quot; finished Execution&quot;);      &#125;    &#125;;    Thread t1 = new Thread(waitTask, &quot;WT1&quot;);    Thread t2 = new Thread(waitTask, &quot;WT2&quot;);    Thread t3 = new Thread(waitTask, &quot;WT3&quot;);    Thread t4 = new Thread(notifyTask, &quot;NT1&quot;);    t1.start();    t2.start();    t3.start();    Thread.sleep(200);    t4.start();  &#125;&#125;\n\nThread[WT1,5,main] is going to wait on this objectThread[WT2,5,main] is going to wait on this objectThread[WT3,5,main] is going to wait on this objectThread[NT1,5,main] is going to notify all or one thread waiting onThread[WT1,5,main] is woken upNT1 finished ExecutionWT1 finished Execution\n\n\n从输出来看前3行是WT1、WT2、WT3依次进入等待池，\n之后NT1调用notify方法随机唤醒一个线程将其置入锁池，并修改go = true;跳出循环\n这里是WT1被置入锁池，因为上一步中go的值被修改所以跳出循环，WT1获得锁并且修改了变量go = false;，然后因为NT1线程已经结束所以剩下两个线程WT2、WT3依然处于等待池。\n\nyield当调用Thread.yield()时会给线程调度器scheduler一个当前线程愿意让出CPU的使用的信号，但是调度去可能会无视该暗示。\n\nThread.java\n\n/** * A hint to the scheduler that the current thread is willing to yield * its current use of a processor. The scheduler is free to ignore this * hint. * * &lt;p&gt; Yield is a heuristic attempt to improve relative progression * between threads that would otherwise over-utilise a CPU. Its use * should be combined with detailed profiling and benchmarking to * ensure that it actually has the desired effect. * * &lt;p&gt; It is rarely appropriate to use this method. It may be useful * for debugging or testing purposes, where it may help to reproduce * bugs due to race conditions. It may also be useful when designing * concurrency control constructs such as the ones in the * &#123;@link java.util.concurrent.locks&#125; package. */public static native void yield();\n\npublic class YieldDemo &#123;  public static void main(String[] args) &#123;    Runnable yieldTask = new Runnable() &#123;      @Override      public void run() &#123;        for (int i = 0; i &lt;= 10; i++) &#123;          System.out.println(Thread.currentThread().getName() + i);          if (i == 5) &#123;            Thread.yield();          &#125;        &#125;      &#125;    &#125;;    Thread t1 = new Thread(yieldTask, &quot;A&quot;);    Thread t2 = new Thread(yieldTask, &quot;B&quot;);    t1.start();    t2.start();  &#125;&#125;\n\n输出：\nA0B0A1B1A2B2A3B3A4B4B5A5B6B7B8B9B10A6A7A8A9A10\n\n可以看出当A线程执行到5时把CPU让给了B来执行，直到B执行到10把B让给A\n使用interrupt来中断线程已被抛弃的方法：\n\nstop()：过于暴力，被中断线程可能没有释放锁\nsuspend(), resume()\n\ninterrupt()\n\n如果线程处于被阻塞状态，那么线程将立即退出被阻塞状态，并抛出一个InterruptedException异常\n如果线程处于正常状态，那么线程会将该线程的中断标志设置为true。被设置中断标志的线程将继续正常运行，不受影响。\n\npublic class InterruptDemo &#123;  public static void main(String[] args) throws InterruptedException &#123;    Runnable interruptTask = new Runnable() &#123;      @Override      public void run() &#123;        int i = 0;        try &#123;          // 在正常运行任务时，经常检查本线程的中断标志位，如果设置了中断标志就自行停止线程          while (!Thread.currentThread().isInterrupted()) &#123;            Thread.sleep(100);            i++;            System.out.println(Thread.currentThread().getName() + &quot; (&quot; + Thread.currentThread().getState()+ &quot;) loop:i=&quot; + i);          &#125;        &#125; catch (InterruptedException e) &#123;          // 在调用阻塞方法时正确处理InterruptedException异常          System.out.println(Thread.currentThread().getName()+ &quot; (&quot; + Thread.currentThread().getState() + &quot;) catch InterruptedException&quot;);        &#125;      &#125;    &#125;;    Thread t1 = new Thread(interruptTask, &quot;t1&quot;);    System.out.println(t1.getName() + &quot; (&quot; + t1.getState() + &quot;) is new.&quot;);    t1.start();    System.out.println(t1.getName() + &quot; (&quot; + t1.getState() + &quot;) is started.&quot;);    Thread.sleep(300);    t1.interrupt();    System.out.println(t1.getName() + &quot; (&quot; + t1.getState() + &quot;) is interrupted.&quot;);    Thread.sleep(300);    System.out.println(t1.getName() + &quot; (&quot; + t1.getState() + &quot;) is interrupted now.&quot;);  &#125;&#125;\n\n输出：\nt1 (NEW) is new.t1 (RUNNABLE) is started.t1 (RUNNABLE) loop:i=1t1 (RUNNABLE) loop:i=2t1 (RUNNABLE) catch InterruptedExceptiont1 (RUNNABLE) is interrupted.t1 (TERMINATED) is interrupted now.\n\n\n线程的状态\nThread.java\n\n/** * A thread state.  A thread can be in one of the following states: * &lt;ul&gt; * &lt;li&gt;&#123;@link #NEW&#125;&lt;br&gt; *     A thread that has not yet started is in this state. *     &lt;/li&gt; * &lt;li&gt;&#123;@link #RUNNABLE&#125;&lt;br&gt; *     A thread executing in the Java virtual machine is in this state. *     &lt;/li&gt; * &lt;li&gt;&#123;@link #BLOCKED&#125;&lt;br&gt; *     A thread that is blocked waiting for a monitor lock *     is in this state. *     &lt;/li&gt; * &lt;li&gt;&#123;@link #WAITING&#125;&lt;br&gt; *     A thread that is waiting indefinitely for another thread to *     perform a particular action is in this state. *     &lt;/li&gt; * &lt;li&gt;&#123;@link #TIMED_WAITING&#125;&lt;br&gt; *     A thread that is waiting for another thread to perform an action *     for up to a specified waiting time is in this state. *     &lt;/li&gt; * &lt;li&gt;&#123;@link #TERMINATED&#125;&lt;br&gt; *     A thread that has exited is in this state. *     &lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt; * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * * @since   1.5 * @see #getState */public enum State &#123;    /**     * Thread state for a thread which has not yet started.     */    NEW,    /**     * Thread state for a runnable thread.  A thread in the runnable     * state is executing in the Java virtual machine but it may     * be waiting for other resources from the operating system     * such as processor.     */    RUNNABLE,    /**     * Thread state for a thread blocked waiting for a monitor lock.     * A thread in the blocked state is waiting for a monitor lock     * to enter a synchronized block/method or     * reenter a synchronized block/method after calling     * &#123;@link Object#wait() Object.wait&#125;.     */    BLOCKED,    /**     * Thread state for a waiting thread.     * A thread is in the waiting state due to calling one of the     * following methods:     * &lt;ul&gt;     *   &lt;li&gt;&#123;@link Object#wait() Object.wait&#125; with no timeout&lt;/li&gt;     *   &lt;li&gt;&#123;@link #join() Thread.join&#125; with no timeout&lt;/li&gt;     *   &lt;li&gt;&#123;@link LockSupport#park() LockSupport.park&#125;&lt;/li&gt;     * &lt;/ul&gt;     *     * &lt;p&gt;A thread in the waiting state is waiting for another thread to     * perform a particular action.     *     * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt;     * on an object is waiting for another thread to call     * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on     * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt;     * is waiting for a specified thread to terminate.     */    WAITING,    /**     * Thread state for a waiting thread with a specified waiting time.     * A thread is in the timed waiting state due to calling one of     * the following methods with a specified positive waiting time:     * &lt;ul&gt;     *   &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt;     *   &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt;     *   &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt;     *   &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt;     *   &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt;     * &lt;/ul&gt;     */    TIMED_WAITING,    /**     * Thread state for a terminated thread.     * The thread has completed execution.     */    TERMINATED;&#125;\n\nJava线程状态：\n\n新建(NEW)：创建后尚未启动的线程状态\n运行(RUNNABLE)：包含Running(正在执行)和Ready(正在等待CPU分配时间片)\nReady(正在等待CPU分配时间片)：其它线程调用了该对象的start()方法，该线程位于可运行线程池中，等待被线程调度选中，获取CPU使用权。\nRunning(正在执行)：就绪状态的线程在获得CPU时间片后变为运行中状态(running)\n\n\n运行(RUNNING)：可运行状态(runnable)的线程获得了cpu 时间片(timeslice)，执行程序代码\n无限期等待(WAITING)：不会被分配CPU执行时间，需要被显示唤醒，进入该状态的线程需要等待其他线程做出一些特定动作(通知或中断)\n没有设置Timeout参数的Object.wait()方法\n没有设置Timeout参数的Thread.join()方法\nLockSupport.park()方法\n\n\n限期等待(TIMED_WAITING)：在一定时间后会由系统自动唤醒\nThread.sleep()方法\n设置了Timeout参数的Object.wait()方法\n设置了Timeout参数的Thread.join()方法\nLockSupport.parkNanos()方法\nLockSupport.parkUntil()方法\n\n\n阻塞(BLOCKED)：等待获取排它锁，线程试图获取一个内部对象的Monitor（进入synchronized方法或synchronized块）但是其他线程已经抢先获取，那此线程被阻塞，知道其他线程释放Monitor并且线程调度器允许当前线程获取到Monitor，此线程就恢复到可运行状态。\n结束(TERMINATED)：已终止线程的状态，线程已经结束执行\n\n\n\n\n\n参考\n一文读懂Java线程状态转换\n\n下图为Oracle支持各个JDK版本所到的年限\n\n\n","categories":["Back-end"],"tags":["Java"]},{"title":"Java日期转换工具类","url":"/2023/03/04/Java/Java%E6%97%A5%E6%9C%9F%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7%E7%B1%BB/","content":"package util.common;import java.text.ParseException;import java.text.SimpleDateFormat;import java.time.*;import java.time.format.DateTimeFormatter;import java.util.*;import java.util.regex.Pattern;/** * DateUtil * jdk8 or higher * @author sicmatr1x@outlook.com * @date 2023/3/4 20:22 */public class DateUtil &#123;    // Empty checks    //-----------------------------------------------------------------------    public static boolean isEmpty(final CharSequence cs) &#123;        return cs == null || cs.length() == 0;    &#125;    // Date formats    //-----------------------------------------------------------------------    public static final String DEFAULT_DATETIME_FORMAT = &quot;yyyy-MM-dd HH:mm:ss&quot;;    private static final Map&lt;String, String&gt; FORMATS = new HashMap&lt;&gt;();    private static final Map&lt;String, String&gt; FORMATS_REGEX = new HashMap&lt;&gt;();    static &#123;        FORMATS.put(&quot;yyyyMMdd&quot;, &quot;^\\\\d&#123;4&#125;\\\\d&#123;1,2&#125;\\\\d&#123;1,2&#125;$&quot;);        FORMATS.put(&quot;yyyy-MM-dd&quot;, &quot;^\\\\d&#123;4&#125;-\\\\d&#123;1,2&#125;-\\\\d&#123;1,2&#125;$&quot;);        FORMATS.put(&quot;yyyy/MM/dd&quot;, &quot;^\\\\d&#123;4&#125;/\\\\d&#123;1,2&#125;/\\\\d&#123;1,2&#125;$&quot;);        FORMATS.put(&quot;yyyy.MM.dd&quot;, &quot;^\\\\d&#123;4&#125;\\\\.\\\\d&#123;1,2&#125;\\\\.\\\\d&#123;1,2&#125;$&quot;);        FORMATS.put(&quot;yyyy-MM-dd HH:mm:ss&quot;, &quot;^(?:(?!0000)[0-9]&#123;4&#125;-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]&#123;2&#125;(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29) (20|21|22|23|[0-1][0-9]):[0-5][0-9]:[0-5][0-9]$&quot;);        FORMATS_REGEX.put(&quot;^\\\\d&#123;4&#125;\\\\d&#123;1,2&#125;\\\\d&#123;1,2&#125;$&quot;, &quot;yyyyMMdd&quot;);        FORMATS_REGEX.put(&quot;^\\\\d&#123;4&#125;-\\\\d&#123;1,2&#125;-\\\\d&#123;1,2&#125;$&quot;, &quot;yyyy-MM-dd&quot;);        FORMATS_REGEX.put(&quot;^\\\\d&#123;4&#125;/\\\\d&#123;1,2&#125;/\\\\d&#123;1,2&#125;$&quot;, &quot;yyyy/MM/dd&quot;);        FORMATS_REGEX.put(&quot;^\\\\d&#123;4&#125;\\\\.\\\\d&#123;1,2&#125;\\\\.\\\\d&#123;1,2&#125;$&quot;, &quot;yyyy.MM.dd&quot;);        FORMATS_REGEX.put(&quot;^(?:(?!0000)[0-9]&#123;4&#125;-(?:(?:0[1-9]|1[0-2])-(?:0[1-9]|1[0-9]|2[0-8])|(?:0[13-9]|1[0-2])-(?:29|30)|(?:0[13578]|1[02])-31)|(?:[0-9]&#123;2&#125;(?:0[48]|[2468][048]|[13579][26])|(?:0[48]|[2468][048]|[13579][26])00)-02-29) (20|21|22|23|[0-1][0-9]):[0-5][0-9]:[0-5][0-9]$&quot;, &quot;yyyy-MM-dd HH:mm:ss&quot;);    &#125;    /**     * test date string is match the format     * @param format date format     * @param dateStr date string     * @return true: match; false: not match     */    public static boolean test(String format, String dateStr) &#123;        if (isEmpty(format) || isEmpty(dateStr)) &#123;            return false;        &#125;        if (!FORMATS.containsKey(format)) &#123;            return false;        &#125;        String formatRegex = FORMATS.get(format);        return Pattern.matches(formatRegex, dateStr);    &#125;    // Date formats: string -&gt; java.util.Date    //-----------------------------------------------------------------------    /**     * recognize the date string format     * @param dateStr date string     * @return date format     */    public static Optional&lt;String&gt; recognizeFormat(String dateStr) &#123;        if (isEmpty(dateStr)) &#123;            return Optional.empty();        &#125;        return FORMATS_REGEX.entrySet().stream()                .filter(e -&gt; Pattern.matches(e.getKey(), dateStr))                .map(Map.Entry::getValue)                .findFirst();    &#125;    /**     * recognize the date string format, if not recognize than return default string     * @param dateStr date string     * @return date format     */    public static String recognizeFormat(String dateStr, String defaultStr) &#123;        return recognizeFormat(dateStr).orElse(defaultStr);    &#125;    /**     * smart recognize the date string format, and parse to date object     *     * @param dateStr date string need to parse     * @return date object     * @throws ParseException parse error     */    public static Date smartParse(String dateStr) throws ParseException &#123;        if (isEmpty(dateStr)) &#123;            return null;        &#125;        Optional&lt;String&gt; format = recognizeFormat(dateStr);        if (format.isPresent()) &#123;            SimpleDateFormat sdf = new SimpleDateFormat(format.get());            return sdf.parse(dateStr);        &#125;        return null;    &#125;    /**     * smart recognize the date string format, and parse to support date object     *     * @param dateStr date string need to parse     * @param clazz support class: java.util.Date, java.time.LocalDate, java.time.LocalTime, java.time.LocalDateTime     * @return support date object     * @throws ParseException parse error     */    public static Object smartParse(String dateStr, Class clazz) throws ParseException &#123;        Date date = smartParse(dateStr);        if (date == null || clazz == null) &#123;            return null;        &#125;        if (clazz == Date.class) &#123;            return date;        &#125; else if (clazz == LocalDate.class) &#123;            return toLocalDate(date);        &#125; else if (clazz == LocalTime.class) &#123;            return toLocalTime(date);        &#125; else if (clazz == LocalDateTime.class) &#123;            return toLocalDateTime(date);        &#125;        return null;    &#125;    // Date formats: date object -&gt; string    //-----------------------------------------------------------------------    /**     * some support class date object convert to date string,     * if not support or illegal dateObj than return an empty string     *     * @param dateObj support class: java.util.Date, java.time.LocalDate, java.time.LocalTime, java.time.LocalDateTime     * @param formatStr date format     * @return date string     */    public static String toString(Object dateObj, String formatStr) &#123;        if (dateObj == null) &#123;            return &quot;&quot;;        &#125;        if (dateObj instanceof String) &#123;            return (String) dateObj;        &#125;        if (isEmpty(formatStr)) &#123;            formatStr = DEFAULT_DATETIME_FORMAT;        &#125;        if (dateObj instanceof Date) &#123;            SimpleDateFormat sdf = new SimpleDateFormat(formatStr);            return sdf.format(dateObj);        &#125;        if (dateObj instanceof LocalDate) &#123;            DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);            return ((LocalDate) dateObj).format(dtf);        &#125; else if (dateObj instanceof LocalTime) &#123;            DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);            return ((LocalTime) dateObj).format(dtf);        &#125; else if (dateObj instanceof LocalDateTime) &#123;            DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);            return ((LocalDateTime) dateObj).format(dtf);        &#125;        return &quot;&quot;;    &#125;    /**     * java.time.LocalDate -&gt; String     *     * @param localDate java.time.LocalDate     * @param formatStr format     * @return date string     */    public static String toString(LocalDate localDate, String formatStr) &#123;        if (localDate == null) &#123;            return &quot;&quot;;        &#125;        DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);        return localDate.format(dtf);    &#125;    /**     * java.time.LocalTime -&gt; String     *     * @param localTime java.time.LocalTime     * @param formatStr format     * @return date string     */    public static String toString(LocalTime localTime, String formatStr) &#123;        if (localTime == null) &#123;            return &quot;&quot;;        &#125;        DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);        return localTime.format(dtf);    &#125;    /**     * java.time.LocalDateTime -&gt; String     *     * @param localDateTime java.time.LocalDateTime     * @param formatStr format     * @return date string     */    public static String toString(LocalDateTime localDateTime, String formatStr) &#123;        if (localDateTime == null) &#123;            return &quot;&quot;;        &#125;        DateTimeFormatter dtf = DateTimeFormatter.ofPattern(formatStr);        return localDateTime.format(dtf);    &#125;    // java.util.Date -&gt; java.time.LocalDate    //                -&gt; java.time.LocalTime    //                -&gt; java.time.LocalDateTime    //-----------------------------------------------------------------------    /**     * java.util.Date -&gt; java.time.LocalDate     *     * @param date java.util.Date     * @param zoneId A time-zone ID, if null than use system default     * @return java.time.LocalDate     */    public static LocalDate toLocalDate(Date date, ZoneId zoneId) &#123;        Instant instant = date.toInstant();        if (zoneId == null) &#123;            zoneId = ZoneId.systemDefault();        &#125;        return instant.atZone(zoneId).toLocalDate();    &#125;    /**     * java.util.Date -&gt; java.time.LocalDate     *     * @param date java.util.Date     * @return java.time.LocalDate     */    public static LocalDate toLocalDate(Date date) &#123;        return toLocalDate(date, null);    &#125;    /**     * java.util.Date -&gt; java.time.LocalTime     *     * @param date java.util.Date     * @param zoneId A time-zone ID, if null than use system default     * @return java.time.LocalTime     */    public static LocalTime toLocalTime(Date date, ZoneId zoneId) &#123;        Instant instant = date.toInstant();        if (zoneId == null) &#123;            zoneId = ZoneId.systemDefault();        &#125;        return instant.atZone(zoneId).toLocalTime();    &#125;    /**     * java.util.Date -&gt; java.time.LocalTime     *     * @param date java.util.Date     * @return java.time.LocalTime     */    public static LocalTime toLocalTime(Date date) &#123;        return toLocalTime(date, null);    &#125;    /**     * java.util.Date -&gt; java.time.LocalDateTime     *     * @param date java.util.Date     * @param zoneId A time-zone ID, if null than use system default     * @return java.time.LocalDateTime     */    public static LocalDateTime toLocalDateTime(Date date, ZoneId zoneId) &#123;        Instant instant = date.toInstant();        if (zoneId == null) &#123;            zoneId = ZoneId.systemDefault();        &#125;        return instant.atZone(zoneId).toLocalDateTime();    &#125;    /**     * java.util.Date -&gt; java.time.LocalTime     *     * @param date java.util.Date     * @return java.time.LocalDateTime     */    public static LocalDateTime toLocalDateTime(Date date) &#123;        return toLocalDateTime(date, null);    &#125;&#125;\n\n\n","categories":["Java"],"tags":["Java","CodeCheetSheet"]},{"title":"全文搜索ElasticSearch","url":"/2020/03/15/Java/%E5%85%A8%E6%96%87%E6%90%9C%E7%B4%A2ElasticSearch/","content":"ElasticSearch是高度可扩展的开源全文搜索和分析引擎，可以快速的、近实时的对大数据进行存储、搜索和分析。\n全文搜索方法非结构化数据的检索\n顺序扫描法(Serial Scanning): 操作系统搜索文件、linux gurp命令\n全文搜索(Full-text Search): 将非结构化数据转化为结构化数据，建立索引\n\n全文搜索(Full-text Search)\n建立文本库\n建立索引\n执行搜索\n过滤结果\n\n基于Java的开源全文搜索引擎\nLucene: 全文搜索引擎\nElasticSearch: 基于Lucene，使用内建的协调分布系统。只支持json格式\nSolr: 使用了ZooKeeper的协调分布系统\n\nElasticSearch的特点\n分布式：每个索引使用可配置数量的一个分片，每个分片可以有多个副本，在任何一个副本上执行读取和搜索操作。\n高可用\n多类型\n多API：支持HTTP RESTFUL、支持Java\n面向文档：不需要定义模式，NoSQL\n异步写入：写入性能更好\n近实时\n基于Lucenne\n开源：Apache协议\n\n重要概念：\n\n近实时：如果要做到真实时需要牺牲索引的效率，因为每次搜索之后都需要刷新数据，或者牺牲查询的效率。每隔n秒进行刷新，索引不写入磁盘，根据刷新策略来写入磁盘\n集群：多个节点的集合，用来保存应用的全部数据并提供基于全部节点集成的索引的搜索功能，每个节点都有唯一的名称\n节点\n索引：在ElasticSearch中，索引为相似文档的集合，索引的内容与文档相关\n类型：对索引中包含文档的进一步细分，一般根据文档的公共属性来划分\n文档：是进行索引的基本单位，与索引中的类型是相对应的，使用json来表示\n分片：对于分片中的数据需要建立一个副本，每个索引可以建成多个分片。主要用于水平分割内容，分布在多个节点上可以提高性能\n副本：分片可以设置副本，分布在不同的节点上。\n\nMAC下环境配置下载ElasticSearchhttps://www.elastic.co/cn/downloads/elasticsearch\n解压ElasticSearch&#x2F;Users&#x2F;sicmatr1x&#x2F;Develop&#x2F;elasticsearch-7.6.1\n配置环境变量使用管理员权限打开/Users/sicmatr1x/.bash_profile\nexport PATH=$PATH:/Users/sicmatr1x/Develop/elasticsearch-7.6.1/bin\n\n运行ElasticSearchelasticsearch\n\n测试ElasticSearch服务器sicmatr1xMacBook-Pro:~ sicmatr1x$ curl http://localhost:9200&#123;  &quot;name&quot; : &quot;sicmatr1xMacBook-Pro.local&quot;,  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,  &quot;cluster_uuid&quot; : &quot;mIhriR4FTWquZLqg_7UBiA&quot;,  &quot;version&quot; : &#123;    &quot;number&quot; : &quot;7.6.1&quot;,    &quot;build_flavor&quot; : &quot;default&quot;,    &quot;build_type&quot; : &quot;tar&quot;,    &quot;build_hash&quot; : &quot;aa751e09be0a5072e8570670309b1f12348f023b&quot;,    &quot;build_date&quot; : &quot;2020-02-29T00:15:25.529771Z&quot;,    &quot;build_snapshot&quot; : false,    &quot;lucene_version&quot; : &quot;8.4.0&quot;,    &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;,    &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot;  &#125;,  &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;\n\nElasticSearch与Spring Boot集成\nElasticSearch 2.4.4\nSpring Data ElasticSearch 2.1.3.RELEASE\nJNA 4.0.3 用于访问操作系统原生应用\n\nbuild.gradle\n// 添加  Spring Data Elasticsearch 的依赖compile(&#x27;org.springframework.boot:spring-boot-starter-data-elasticsearch&#x27;)// 添加  JNA 的依赖compile(&#x27;net.java.dev.jna:jna:4.3.0&#x27;)\n\napplication.properties\n# Elasticsearch 服务地址spring.data.elasticsearch.cluster-nodes=localhost:9300# 设置连接超时时间spring.data.elasticsearch.properties.transport.tcp.connect_timeout=120s\n\nQ &amp; AReceived message from unsupported version: [2.0.0] minimal compatible version is: [6.8.0]java.lang.IllegalStateException: Received message from unsupported version: [2.0.0] minimal compatible version is: [6.8.0]\tat org.elasticsearch.transport.InboundMessage.ensureVersionCompatibility(InboundMessage.java:152) ~[elasticsearch-7.6.1.jar:7.6.1]\tat org.elasticsearch.transport.InboundMessage.access$000(InboundMessage.java:37) ~[elasticsearch-7.6.1.jar:7.6.1]\tat org.elasticsearch.transport.InboundMessage$Reader.deserialize(InboundMessage.java:70) ~[elasticsearch-7.6.1.jar:7.6.1]\tat org.elasticsearch.transport.InboundHandler.messageReceived(InboundHandler.java:114) ~[elasticsearch-7.6.1.jar:7.6.1]\tat org.elasticsearch.transport.InboundHandler.inboundMessage(InboundHandler.java:103) ~[elasticsearch-7.6.1.jar:7.6.1]\tat org.elasticsearch.transport.TcpTransport.inboundMessage(TcpTransport.java:667) [elasticsearch-7.6.1.jar:7.6.1]\n\n原因：spring boot是1.3.x版本，而es采用了2.x版本。在es的2.x版本去除了一些类，而这些类在spring boot的1.3.x版本中仍然被使用，导致此错误。\n解决：依照问题1中的版本对应关系，启动特定版本的es即可。\n","categories":["Back-end"],"tags":["SearchEngine"]},{"title":"Algorithm CheetSheet","url":"/2019/08/19/LeetCode/Algorithm-CheetSheet/","content":"数据结构数组&#x2F;顺序表数组遍历框架，典型的线性迭代结构：\nvoid traverse(int[] arr) &#123;    for (int i = 0; i &lt; arr.length; i++) &#123;        // 迭代访问 arr[i]    &#125;&#125;\n\n链表链表遍历框架，兼具迭代和递归结构：\n/* 基本的单链表节点 */class ListNode &#123;    int val;    ListNode next;&#125;void traverse(ListNode head) &#123;    for (ListNode p = head; p != null; p = p.next) &#123;        // 迭代访问 p.val    &#125;&#125;void traverse(ListNode head) &#123;    // 递归访问 head.val    traverse(head.next)&#125;\n\n二叉树遍历框架，典型的非线性递归遍历结构：\n/* 基本的二叉树节点 */class TreeNode &#123;    int val;    TreeNode left, right;&#125;void traverse(TreeNode root) &#123;    traverse(root.left)    traverse(root.right)&#125;\n\n你看二叉树的递归遍历方式和链表的递归遍历方式，相似不？再看看二叉树结构和单链表结构，相似不？如果再多几条叉，N 叉树你会不会遍历？\n二叉树框架可以扩展为 N 叉树的遍历框架：\n/* 基本的 N 叉树节点 */class TreeNode &#123;    int val;    TreeNode[] children;&#125;void traverse(TreeNode root) &#123;    for (TreeNode child : root.children)        traverse(child)&#125;\n\n哈希表构造哈希函数需要考虑的因素：\n计算哈希函数所需时间(包括硬件指令因素)\n关键字长度\n哈希表大小\n关键字的分布情况\n记录的查找频率\n\n常见构造哈希函数的方法：\n直接定址法\n取关键字或关键字的某个线性函数值为哈希地址，即：H(key)=key 或 H(key)=a*key+b\n\n\n数字分析法\n假设关键字是以r为基的数(如十进制)，并且哈希表中可能出现的关键字都是事先知道的，则可取关键字的若干数位组成哈希地址\n\n\n平方取中法\n取关键字平方后的中间几位为哈希地址\n\n\n折叠法(folding)\n将关键字分割成位数相同的几部分(最后一部分的位数可以不同)，然后取这几部分的叠加和(舍去进位)作为哈希地址\n\n\n除留余数法\n取关键字被某个不大于哈希表长度m的数p除后所得余数为哈希地址，即：H(key)=key % p, p&lt;=m\n\n\n随机数法\n选择一个随机函数，取关键字的随机函数值为它的哈希地址，即：H(key)=random(key)，其中random为随机函数。通常关键字长度不等时采用此方法。\n\n\n\n处理冲突的方法\n开放定址法\n再哈希法\n链地址法\n建立一个公共溢出区\n\n/** * 采用： * 除留余数法+链地址法(拉链法) */public class ZipHashTable &#123;    // 一般情况下取质数或不包含小于20的质因数的合数    private static final int N = 1023;    @SuppressWarnings(&quot;unchecked&quot;)    private final List&lt;int[]&gt;[] buckets = new List[N];    public ZipHashTable() &#123;    &#125;    public void put(int key, int value) &#123;        final int hash = key % N;        List&lt;int[]&gt; bucket = buckets[hash];        if (bucket == null) &#123;            bucket = new LinkedList&lt;&gt;();            buckets[hash] = bucket;        &#125;        boolean contains = false;        for (int[] slot : bucket) &#123;            if (slot[0] == key) &#123;                contains = true;                slot[1] = value;                break;            &#125;        &#125;        if (!contains) &#123;            bucket.add(new int[] &#123;key, value&#125;);        &#125;    &#125;    public int get(int key) &#123;        final int hash = key % N;        final List&lt;int[]&gt; bucket = buckets[hash];        if (bucket == null) &#123;            return -1;        &#125;        for (int[] slot : bucket) &#123;            if (slot[0] == key) &#123;                return slot[1];            &#125;        &#125;        return -1;    &#125;    public void remove(int key) &#123;        final int hash = key % N;        final List&lt;int[]&gt; bucket = buckets[hash];        if (bucket == null) &#123;            return;        &#125;        bucket.removeIf(slot -&gt; slot[0] == key);    &#125;&#125;\n\n二叉树二叉树算法的设计的总路线：明确一个节点要做的事情，然后剩下的事抛给框架。\nDFS(Depth First Search)深度优先搜索：\nvoid traverse(TreeNode root) &#123;    // root 需要做什么？在这做。    // 其他的不用 root 操心，抛给框架    traverse(root.left);    traverse(root.right);&#125;\n\nBFS(Breadth First Search)广度优先搜索：\n// 二叉树每层作为一个数组放到大数组里// 队列每次全部弹出到临时数组，分别获取该层所有结点的所有孩子并加入队列public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;    List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();    Queue&lt;TreeNode&gt; q = new LinkedList&lt;&gt;();    q.offer(root);    while (!q.isEmpty()) &#123;        int size = q.size();        List&lt;Integer&gt; level = new LinkedList&lt;&gt;();        for (int i = 0; i &lt; size; ++i) &#123;            TreeNode cur = q.peek();            q.poll();            if (cur == null) &#123;                continue;            &#125;            level.add(cur.val);            q.offer(cur.left);            q.offer(cur.right);        &#125;        if (!level.isEmpty()) &#123;            res.add(level);        &#125;    &#125;    return res;&#125;\n\n\n\n如何把二叉树所有的节点中的值加一？\n\nvoid plusOne(TreeNode root) &#123;    if (root == null) return;    root.val += 1;    plusOne(root.left);    plusOne(root.right);&#125;\n\n\n如何判断两棵二叉树是否完全相同？\n\nboolean isSameTree(TreeNode root1, TreeNode root2) &#123;    // 都为空的话，显然相同    if (root1 == null &amp;&amp; root2 == null) return true;    // 一个为空，一个非空，显然不同    if (root1 == null || root2 == null) return false;    // 两个都非空，但 val 不一样也不行    if (root1.val != root2.val) return false;    // root1 和 root2 该比的都比完了    return isSameTree(root1.left, root2.left)        &amp;&amp; isSameTree(root1.right, root2.right);&#125;\n\n二叉搜索树二叉搜索树（Binary Search Tree，简称 BST）是一种很常用的的二叉树。它的定义是：一个二叉树中，任意节点的值要大于等于左子树所有节点的值，且要小于等于右边子树的所有节点的值。\n零、判断 BST 的合法性:\nboolean isValidBST(TreeNode root) &#123;    return isValidBST(root, null, null);&#125;boolean isValidBST(TreeNode root, TreeNode min, TreeNode max) &#123;    if (root == null) return true;    if (min != null &amp;&amp; root.val &lt;= min.val) return false;    if (max != null &amp;&amp; root.val &gt;= max.val) return false;    return isValidBST(root.left, min, root)         &amp;&amp; isValidBST(root.right, root, max);&#125;\n\n在 BST 中查找一个数是否存在:\nboolean isInBST(TreeNode root, int target) &#123;    if (root == null) return false;    if (root.val == target)        return true;    if (root.val &lt; target)         return isInBST(root.right, target);    if (root.val &gt; target)        return isInBST(root.left, target);    // root 该做的事做完了，顺带把框架也完成了，妙&#125;\n\n于是，我们对原始框架进行改造，抽象出一套针对 BST 的遍历框架：\nvoid BST(TreeNode root, int target) &#123;    if (root.val == target)        // 找到目标，做点什么    if (root.val &lt; target)         BST(root.right, target);    if (root.val &gt; target)        BST(root.left, target);&#125;\n\n在 BST 中插入一个数:\nTreeNode insertIntoBST(TreeNode root, int val) &#123;    // 找到空位置插入新节点    if (root == null) return new TreeNode(val);    // if (root.val == val)    //     BST 中一般不会插入已存在元素    if (root.val &lt; val)         root.right = insertIntoBST(root.right, val);    if (root.val &gt; val)         root.left = insertIntoBST(root.left, val);    return root;&#125;\n\n在 BST 中删除一个数:\n\nA 恰好是末端节点，两个子节点都为空，那么它可以当场去世了。\nA 只有一个非空子节点，那么它要让这个孩子接替自己的位置。\nA 有两个子节点，麻烦了，为了不破坏 BST 的性质，A 必须找到左子树中最大的那个节点，或者右子树中最小的那个节点来接替自己。我们以第二种方式讲解。\n\n三种情况分析完毕，填入框架，简化一下代码：\nTreeNode deleteNode(TreeNode root, int key) &#123;    if (root == null) return null;    if (root.val == key) &#123;        // 这两个 if 把情况 1 和 2 都正确处理了        if (root.left == null) return root.right;        if (root.right == null) return root.left;        // 处理情况 3        TreeNode minNode = getMin(root.right);        root.val = minNode.val;        root.right = deleteNode(root.right, minNode.val);    &#125; else if (root.val &gt; key) &#123;        root.left = deleteNode(root.left, key);    &#125; else if (root.val &lt; key) &#123;        root.right = deleteNode(root.right, key);    &#125;    return root;&#125;TreeNode getMin(TreeNode node) &#123;    // BST 最左边的就是最小的    while (node.left != null) node = node.left;    return node;&#125; \n\n动态规划\n重叠子问题\n最优子结构\n\n状态转移方程\n查找二分查找int binary_search(int[] nums, int target) &#123;    int left = 0, right = nums.length - 1;     while(left &lt;= right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target) &#123;            left = mid + 1;        &#125; else if (nums[mid] &gt; target) &#123;            right = mid - 1;         &#125; else if(nums[mid] == target) &#123;            // 直接返回            return mid;        &#125;    &#125;    // 直接返回    return -1;&#125;/*比如说给你有序数组 `nums = [1,2,2,2,3]`，`target` 为 2，此算法返回的索引是 2，没错。但是如果我想得到 `target` 的左侧边界，即索引 1，或者我想得到 `target` 的右侧边界，即索引 3，这样的话此算法是无法处理的。*/// 寻找左侧边界的二分搜索int left_bound(int[] nums, int target) &#123;    int left = 0, right = nums.length - 1;    while (left &lt;= right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target) &#123;            left = mid + 1;        &#125; else if (nums[mid] &gt; target) &#123;            right = mid - 1;        &#125; else if (nums[mid] == target) &#123;            // 别返回，锁定左侧边界            right = mid - 1;        &#125;    &#125;    // 最后要检查 left 越界的情况    if (left &gt;= nums.length || nums[left] != target)        return -1;    return left;&#125;// 寻找右侧边界的二分搜索int right_bound(int[] nums, int target) &#123;    int left = 0, right = nums.length - 1;    while (left &lt;= right) &#123;        int mid = left + (right - left) / 2;        if (nums[mid] &lt; target) &#123;            left = mid + 1;        &#125; else if (nums[mid] &gt; target) &#123;            right = mid - 1;        &#125; else if (nums[mid] == target) &#123;            // 别返回，锁定右侧边界            left = mid + 1;        &#125;    &#125;    // 最后要检查 right 越界的情况    if (right &lt; 0 || nums[right] != target)        return -1;    return right;&#125;\n","categories":["LeetCode"],"tags":["DataStructure"]},{"title":"BackPackII","url":"/2023/03/26/LeetCode/BackPackII/","content":"package leetcode.problems.medium;import util.PrintUtil;public class BackPackII &#123;    /**     * 状态 dp(i, j): 前 i个物品放入大小为 j的背包中所获得的最大价值     * weight(i): 新增物品的大小     * value(i): 新增物品的价格     * 递推关系:     * 不放: dp(i, j) = dp(i-1, j) 表示不把第i个物品放入背包中，所以它的价值就是前i-1个物品放入大小为j的背包的最大价值     * 放: dp(i-1, j - weight[i]) + value[i] 表示把第i个物品放入背包中，价值增加value[i],但是需要腾出j - weight[i]的大小放     * 状态转移方程: dp(i,j) = max&#123; dp(i-1, j), dp(i-1, j - weight[i]) + value[i] &#125;     * 初始状态：dp(i, 0) = dp(0, j) = 0   第0行和第0列都为0，表示没有装物品时的价值都为0     * 返回值：dp(i, j)     * @param m 大小为 m 的背包     * @param A 每个物品的大小     * @param V 每个物品的价值     * @return 最多能装入背包的总价值是多大     */    public int backPackII(int m, int[] A, int[] V) &#123;        int itemNum = A.length;        int weight[] = A;        int value[] = V;        if (itemNum == 0 || m == 0) return 0;        // dp[最多取物品数量个][最大取背包大小]        int[][] dp = new int[itemNum][m + 1];        // 初始化        for (int i = 0; i &lt; dp.length; i++) &#123; // 可以省略            dp[i][0] = 0;        &#125;        for (int j = 0; j &lt; m + 1; j++) &#123;            if (j &lt; weight[0]) &#123;                dp[0][j] = 0;            &#125; else &#123;                dp[0][j] = value[0];            &#125;        &#125;        for (int i = 1; i &lt; itemNum; i++) &#123; // 遍历背包            for (int j = 0; j &lt;= m; j++) &#123; // 遍历重量                if (weight[i] &gt; j) &#123;                    // 新增物品质量大于当前背包，放不下                    dp[i][j] = dp[i - 1][j];                &#125; else &#123;                    // 放得下，如果放入新物品要计算出背包剩余大小，看下剩余背包大小最多能装多少然后加上新增物品价格，和不放入新物品背包最大价格对比，取最大。最大价格都在上一层                    dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - weight[i]] + value[i]);                &#125;            &#125;        &#125;        PrintUtil.printSubList(dp);        return dp[itemNum-1][m];    &#125;    /**     * 一维数组（滚动数组）实现     * 状态 F(i, j): 前 i个物品放入大小为 j的背包中所获得的最大价值     * A(i): 新增物品的大小     * V(i): 新增物品的价格     * 状态转移方程: dp(i,j) = max&#123; dp(i-1, j), dp(i-1, j - A[i-1]) + V[i-1] &#125;     * dp[i] = 前 i个物品放入大小为 j的背包中所获得的最大价值     * dp[j] = max(dp[j], dp[j - A[i-1]] + V[i-1]);     *     * @param m 大小为 m 的背包     * @param A 每个物品的大小     * @param V 每个物品的价值     * @return 最多能装入背包的总价值是多大     */    public int backPackII1(int m, int[] A, int[] V) &#123;        int itemNum = A.length;        int weight[] = A;        int value[] = V;        if (itemNum == 0 || m == 0) return 0;        // dp[最大取背包大小]        int[] dp = new int[m + 1];        // 初始化        for (int j = 0; j &lt; m + 1; j++) &#123;            if (j &lt; weight[0]) &#123;                dp[j] = 0;            &#125; else &#123;                dp[j] = value[0];            &#125;        &#125;        for (int i = 1; i &lt; itemNum; i++) &#123; // 遍历背包            for (int j = m; j &gt;= weight[i]; j--) &#123; // 遍历重量                dp[j] = Math.max(dp[j], dp[j - weight[i]] + value[i]);            &#125;        &#125;        PrintUtil.printSubList(dp);        return dp[m];    &#125;&#125;\n\n\n","categories":["LeetCode"],"tags":["Dynamic Programming"]},{"title":"No216. Combination Sum II","url":"/2022/10/30/LeetCode/No216.%20Combination%20Sum%20II/","content":"\nCombination Sum IIIFind all valid combinations of k numbers that sum up to n such that the following conditions are true:Only numbers 1 through 9 are used.Each number is used at most once.Return a list of all possible valid combinations.The list must not contain the same combination twice, and the combinations may be returned in any order.\n\nExample 1:\nInput: k = 3, n = 7Output: [[1,2,4]]\n\nExplanation:1 + 2 + 4 &#x3D; 7There are no other valid combinations.  \nExample 2:\nInput: k = 3, n = 9Output: [[1,2,6],[1,3,5],[2,3,4]]\n\nExplanation:1 + 2 + 6 &#x3D; 91 + 3 + 5 &#x3D; 92 + 3 + 4 &#x3D; 9There are no other valid combinations.  \nExample 3:\nInput: k = 4, n = 1Output: []\n\nExplanation: There are no valid combinations.Using 4 different numbers in the range [1,9], the smallest sum we can get is 1+2+3+4 &#x3D; 10 and since 10 &gt; 1, there are no valid combination.\nConstraints:2 &lt;&#x3D; k &lt;&#x3D; 91 &lt;&#x3D; n &lt;&#x3D; 60  \n给 元素重复 无序 数组，求满足条件的子数组，组合问题需要子数组满足的条件：子数组元素和等于某个数\npackage leetcode.problems.medium;import java.util.ArrayList;import java.util.List;public class CombinationSumIII &#123;    public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123;        int[] nums = &#123;1,2,3,4,5,6,7,8,9&#125;;        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();        List&lt;Integer&gt; path = new ArrayList&lt;&gt;();        backtrack(result, path, nums, 0, k, n);        return result;    &#125;    private void backtrack(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, int start, int level, int stillNeed) &#123;        if (stillNeed == 0 &amp;&amp; level == 0) &#123;            result.add(new ArrayList&lt;&gt;(path));            return;        &#125; else if (level &lt; 0 || stillNeed &lt;= 0) &#123;            return;        &#125;        for (int i = start; i &lt; nums.length; i++) &#123;            path.add(nums[i]);            backtrack(result, path, nums, i+1, level-1, stillNeed-nums[i]);            path.remove(path.size()-1);        &#125;    &#125;&#125;","categories":["LeetCode"],"tags":["Backtracking"]},{"title":"No39. Combination Sum","url":"/2022/10/30/LeetCode/No39.%20Combination%20Sum/","content":"\nCombination Sum\n\nhttps://leetcode.com/problems/combination-sum/\nGiven an array of distinct integers candidates and a target integer target, return a list of all unique combinationsof candidates where the chosen numbers sum to target. You may return the combinations in any order.The same number may be chosen from candidates an unlimited number of times.Two combinations are unique if the frequency of at least one of the chosen numbers is different.The test cases are generated such that the number of unique combinations that sum up to target is less than 150combinations for the given input.\nExample 1:\nInput: candidates = [2,3,6,7], target = 7Output: [[2,2,3],[7]]\n\nExplanation:2 and 3 are candidates, and 2 + 2 + 3 &#x3D; 7. Note that 2 can be used multiple times.7 is a candidate, and 7 &#x3D; 7.These are the only two combinations.  \nExample 2:\nInput: candidates = [2,3,5], target = 8Output: [[2,2,2,2],[2,3,3],[3,5]]\n\nExample 3:\nInput: candidates = [2], target = 1Output: []\n\n给 元素不重复 无序 数组，求满足条件的子数组，组合问题需要子数组满足的条件：子数组元素和等于某个数\npackage leetcode.problems.medium;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class CombinationSum &#123;    public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123;        Arrays.sort(candidates);        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();        List&lt;Integer&gt; path = new ArrayList&lt;&gt;();        backtrack(result, candidates, path, 0, target);        return result;    &#125;    /**     * 1. 画出递归树，找到状态变量(回溯函数的参数)，这一步非常重要※     * 2. 根据题意，确立结束条件     * 3. 找准选择列表(与函数参数相关),与第一步紧密关联※     * 4. 判断是否需要剪枝     * 5. 作出选择，递归调用，进入下一层     * 6. 撤销选择 返回上一层     * @param result     * @param candidates     * @param start     * @param stillNeed     */    private void backtrack(List&lt;List&lt;Integer&gt;&gt; result, int[] candidates, List&lt;Integer&gt; path, int start, int stillNeed) &#123;        if (stillNeed &lt; 0) &#123;            return;        &#125; else if (stillNeed == 0) &#123;            result.add(new ArrayList&lt;&gt;(path));            return;        &#125;        for (int i = start; i &lt; candidates.length; i++) &#123;            path.add(candidates[i]);            backtrack(result, candidates, path, i, stillNeed-candidates[i]);            path.remove(path.size()-1);        &#125;    &#125;&#125;\n","categories":["LeetCode"],"tags":["Backtracking"]},{"title":"No78. Subsets","url":"/2022/10/07/LeetCode/No78.Subsets/","content":"Given an integer array nums of unique elements, return all possible subsets (the power set).\nThe solution set must not contain duplicate subsets. Return the solution in any order.\nExample 1:\nInput: nums = [1,2,3]Output: [[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]\n\nExample 2:\nInput: nums = [0]Output: [[],[0]]\nConstraints:\n1 &lt;&#x3D; nums.length &lt;&#x3D; 10-10 &lt;&#x3D; nums[i] &lt;&#x3D; 10  \nAll the numbers of nums are unique.\n\n给 元素不重复 无序 数组，求所有的子数组，组合问题\npackage leetcode.problems.medium;import java.util.ArrayList;import java.util.Arrays;import java.util.List;public class Subsets &#123;    public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123;        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;List&lt;Integer&gt;&gt;();        List&lt;Integer&gt; path = new ArrayList&lt;&gt;();        Arrays.sort(nums);        backtrack(result, path, nums, 0);        return result;    &#125;    /**     * 回溯法 求不重复元素数组的全组合 子集     * @param result 全部子集列表     * @param path 尝试选择元素的可能性树的从根节点开始到当前节点的路径     * @param nums 不重复元素数组     * @param start 当前准备开始尝试start index后的全部数组     */    private void backtrack(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, int start) &#123;        // 因为是求全部子数组，所以需要遍历完整棵树，递归出口就是 start == nums.length 可省略        result.add(new ArrayList&lt;&gt;(path));        for (int i = start; i &lt; nums.length; i++) &#123;            // 不需要剪枝，不存在重复元素            path.add(nums[i]);            backtrack(result, path, nums, i+1);            path.remove(path.size() - 1);        &#125;    &#125;&#125;\n","categories":["LeetCode"],"tags":["Backtracking"]},{"title":"算法-递归","url":"/2020/10/07/LeetCode/%E7%AE%97%E6%B3%95-%E9%80%92%E5%BD%92/","content":"迭代转递归我们先看个例子\n/** * 使用树来进行迭代 * 当然在没有分叉的情况下树迭代与简单递归是一样的 * 对一个数组循环求和，以下使用迭代与递归两种方式来实现 */public class TreeIteration &#123;    public static void main(String[] args) &#123;        int[] arr = &#123;1,2,3,4,5,6,7,8,9&#125;;        TreeIteration binaryTree = new TreeIteration();        System.out.println(binaryTree.getSum(arr));        System.out.println(binaryTree.getSumByRecursion(arr));    &#125;    public int getSum(int[] arr) &#123;        int sum = 0;        for (int i = 0; i &lt; arr.length; i++) &#123;            sum += arr[i];        &#125;        return sum;    &#125;    public int getSumByRecursion(int[] arr) &#123;        return dfs(arr, 0);    &#125;    int dfs(int[] arr, int i) &#123;        // 递归出口，相当于迭代的for循环里面的结束条件        if (i == arr.length - 1) &#123;            return arr[i];        &#125;        // 递归调用dfs函数，在传入数组下标参数时+1，相当于迭代的i++        return arr[i] + dfs(arr, i+1);    &#125;&#125;\n\n尾递归尾递归和一般的递归不同在对内存的占用，普通递归创建stack累积而后计算收缩，尾递归只会占用恒量的内存（和迭代一样）。尾递归是把变化的参数传递给递归函数的变量了。\n怎么写尾递归？形式上只要最后一个return语句是单纯函数就可以。如：return dfs(arr, i+1);\n简单来讲，尾递归是指在一个方法内部，递归调用后直接return，没有任何多余的指令了。\nint dfs(int[] arr, int i) &#123;    // 递归出口，相当于迭代的for循环里面的结束条件    if (i == arr.length - 1) &#123;        return arr[i];    &#125;    // 递归调用dfs函数，在传入数组下标参数时+1，相当于迭代的i++    return arr[i] + dfs(arr, i+1);&#125;\n\n请问这个是尾递归么？答案是否定的。可能有的人会说，明明最后一个步骤就是调用dfs，为啥不是尾递归？实际上，你看到的最后一个步骤不代表从指令层面来讲的最后一步。这个方法的return先拿到dfs(n-1)的值，然后再将n与其相加，所以求dfs(n-1)并不是最后一步，因为最后还有一个add操作。\n采用尾递归优化一下：\npublic int getSumByTailRecursion(int[] arr) &#123;    return dfs1(arr, 0, 0);&#125;int dfs1(int[] arr, int i, int sum) &#123;    if (i == arr.length - 1) &#123;        return arr[i] + sum;    &#125;    return dfs1(arr, i+1, arr[i] + sum);&#125;\n\n尾递归由于将外层方法的结果传递给了内层方法，那外层方法实际上没有任何利用价值了，直接从栈里踢出去就行了，所以可以保证同时只有一个栈帧在栈里存活，节省了大量栈空间。\n递归的实现递归和循环是等价的\n如果定义一个概念需要用到这个概念本身，我们称它的定义是递归的（Recursive）\n递归和循环是等价的，用循环能做的事用递归都能做，反之亦然。\n尾调用 (tail call) 和尾递归 (tail recursion)\n非尾递归算法，需要O(n)的调用栈空间\n尾递归是尾调用的特殊情形，尾调用并不要求 callee 和 caller 是同一个函数。\n尾递归太特殊了，太容易优化了，所以在源码层面就能做递归到迭代的变换。\n\n任何的递归，都可以转换成尾调用，然后优化。\n\n如果算法本身就是尾递归的，那么，可以直接改写成迭代，这是尾调用优化的一种特例。\n如果算法本身是非尾递归的，那么，CPS 变换可以将算法改写成尾调用形式，从而可以进行尾调用优化。改写过后的空间复杂度仍然是 O(n)，只不过是从 O(n) 的栈变成了 O(n) 的 continuation chain，这个改变对支持尾调用优化的简单解释器是有意义的。\n\n剪枝从一个集合中选择符合条件的真子集的递归二叉树DFS剪枝模板先看题目：\n\n18.  四数之和\n给定一个包含 n 个整数的数组 nums 和一个目标值 target，判断 nums 中是否存在四个元素 a，b，c 和 d ，使得 a + b + c + d 的值与 target 相等？找出所有满足条件且不重复的四元组。\n\n注意：答案中不可以包含重复的四元组。\n示例：\n给定数组 nums &#x3D; [1, 0, -1, 0, -2, 2]，和 target &#x3D; 0。\n满足要求的四元组集合为：[  [-1,  0, 0, 1],  [-2, -1, 1, 2],  [-2,  0, 0, 2]]通过次数127,257提交次数325,331 *链接：https://leetcode-cn.com/problems/4sum/来源：力扣（LeetCode）著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n\n\n这道题不考虑时间复杂度的迭代解法\npublic List&lt;List&lt;Integer&gt;&gt; fourSum1(int[] nums, int target) &#123;    List&lt;Integer&gt; oneSolution = null;    List&lt;List&lt;Integer&gt;&gt; output = new ArrayList&lt;List&lt;Integer&gt;&gt;();    Arrays.sort(nums);    for (int i = 0; i &lt; nums.length - 3; i++) &#123;        for (int j = i + 1; j &lt; nums.length - 2; j++) &#123;            for (int m = j + 1; m &lt; nums.length - 1; m++) &#123;                for (int n = m + 1; n &lt; nums.length; n++) &#123;                    if (target == nums[i] + nums[j] + nums[m] + nums[n]) &#123;                        oneSolution = new ArrayList&lt;Integer&gt;();                        oneSolution.add(nums[i]);                        oneSolution.add(nums[j]);                        oneSolution.add(nums[m]);                        oneSolution.add(nums[n]);                        output.add(oneSolution);                    &#125;                &#125;            &#125;        &#125;    &#125;    return output;&#125;\n\npublic class FourSum &#123;    public static void main(String[] args) &#123;        int[] nums = &#123;1, 0, -1, 0, -2, 2&#125;;        int target = 0;        FourSum1 fourSum = new FourSum1();        List&lt;List&lt;Integer&gt;&gt; result = fourSum.fourSum(nums, target);        for (List&lt;Integer&gt; list : result) &#123;            System.out.println(list);        &#125;    &#125;    public List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) &#123;        ArrayList&lt;Integer&gt; notSelected = new ArrayList&lt;Integer&gt;();        List&lt;Integer&gt; oneSolution = new ArrayList&lt;Integer&gt;();        List&lt;List&lt;Integer&gt;&gt; output = new ArrayList&lt;List&lt;Integer&gt;&gt;();        Arrays.sort(nums);        Search(0, target, oneSolution, notSelected, nums, output);        return output;    &#125;    public static void Search(int i, int target, List&lt;Integer&gt; oneSolution, ArrayList&lt;Integer&gt; notSelected, int[] nums, List&lt;List&lt;Integer&gt;&gt; output) &#123;        // 递归出口，当前选择的子数组达到4个且符合等于target的要求        if ((target == 0) &amp;&amp; (oneSolution.size() == 4)) &#123;            List&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(oneSolution);            output.add(temp);            return;        &#125;        // 递归出口，i超过数组长度或者一个解选择的数多于4个        if ((i &gt; nums.length - 1) || (oneSolution.size() &gt; 4)) &#123;            return;        &#125;        // 若当前数在不选的列表里跳过当前数判断下一个        if (Inside(notSelected, nums[i])) &#123;            Search(i + 1, target, oneSolution, notSelected, nums, output);            return;        &#125;        // ========剪枝========        // 剪枝条件一：若target &gt; 当前数+剩余选择个数*剩下数组里最大的那个数 则表示对于已经选择的子数组而言当前选择的数太小需要向下找一个更大的数        if ((target &gt; nums[i] + (3 - oneSolution.size()) * nums[nums.length - 1])) &#123;            Search(i + 1, target, oneSolution, notSelected, nums, output);            return;        &#125;        // 剪枝条件二：若target &lt; 剩余选择个数*当前数 则表示对于已经选择的子数组而言当前选择的数太大，且接下来选择的数只会更大，放弃当前选择的子数组        if (target &lt; (4 - oneSolution.size()) * nums[i]) &#123;            return;        &#125;        // ====================        // 假设选择当前数        oneSolution.add(nums[i]);        Search(i + 1, target - nums[i], oneSolution, notSelected, nums, output);        oneSolution.remove(oneSolution.size() - 1);        // 假设不选择当前数        notSelected.add(nums[i]);        Search(i + 1, target, oneSolution, notSelected, nums, output);        notSelected.remove(notSelected.size() - 1);    &#125;    public static boolean Inside(ArrayList&lt;Integer&gt; notSelected, int num) &#123;        for (int i : notSelected) &#123;            if (i == num) &#123;                return true;            &#125;        &#125;        return false;    &#125;&#125;\n\n根据上述代码可以总结出模板，这里的元素类型用int&#x2F;Integer为例：\n// nums为给定条件集合, target为符合要求的子集public List&lt;List&lt;Integer&gt;&gt; fourSum(int[] nums, int target) &#123;    ArrayList&lt;Integer&gt; notSelected = new ArrayList&lt;Integer&gt;();    List&lt;Integer&gt; oneSolution = new ArrayList&lt;Integer&gt;();    List&lt;List&lt;Integer&gt;&gt; output = new ArrayList&lt;List&lt;Integer&gt;&gt;();    Arrays.sort(nums);    Search(0, target, oneSolution, notSelected, nums, output);    return output;&#125;/** * DFS搜索 * @param i 迭代用的下标 * @param target 判断子集符合要求的条件 * @param oneSolution 其中一个子集 * @param notSelected 不选择的元素 * @param nums 条件给出的父集合 * @param output 符合要求的子集组成的列表 */public static void Search(int i, int target, List&lt;Integer&gt; oneSolution, ArrayList&lt;Integer&gt; notSelected, int[] nums, List&lt;List&lt;Integer&gt;&gt; output) &#123;    // 递归出口，    if (/*判断当前子集符合条件的代码*/) &#123;        // 若符合则把当前子集加入答案列表        List&lt;Integer&gt; temp = new ArrayList&lt;Integer&gt;(oneSolution);        output.add(temp);        return;    &#125;    // 递归出口，i超过数组长度    if ((i &gt; nums.length - 1)) &#123;        return;    &#125;    // 若当前判断的元素在不选的列表里跳过当前元素判断下一个    if (Inside(notSelected, nums[i])) &#123;        Search(i + 1, target, oneSolution, notSelected, nums, output);        return;    &#125;    // ========剪枝========    // 剪枝(剪掉当前元素的枝)：当前元素加入就会导致当前判断的子集不符合要求则跳过当前元素继续判断    if (/**/) &#123;        Search(i + 1, target, oneSolution, notSelected, nums, output);        return;    &#125;    // 剪枝(剪掉接下来判断的所有元素的枝，即剪掉当前枝)：若当前元素和以后的元素全部会导致当前子集不符合要求    if (/**/) &#123;        return;    &#125;    // ====================    // 假设选择当前元素    oneSolution.add(nums[i]);    Search(i + 1, target - nums[i], oneSolution, notSelected, nums, output);    oneSolution.remove(oneSolution.size() - 1);    // 假设不选择当前元素    notSelected.add(nums[i]);    Search(i + 1, target, oneSolution, notSelected, nums, output);    notSelected.remove(notSelected.size() - 1);&#125;// 用来判断当前元素是否在不选择的列表里面public static boolean Inside(ArrayList&lt;Integer&gt; notSelected, int num) &#123;    for (int i : notSelected) &#123;        if (i == num) &#123;            return true;        &#125;    &#125;    return false;&#125;\n\n","categories":["LeetCode"],"tags":["递归","DFS","剪枝"]},{"title":"No90. Subsets II","url":"/2022/10/20/LeetCode/No90.%20Subsets%20II/","content":"https://leetcode.com/problems/subsets-ii/\nGiven an integer array nums that may contain duplicates, return all possible subsets (the power set).The solution set must not contain duplicate subsets. Return the solution in any order.\nExample 1:\nInput: nums = [1,2,2]Output: [[],[1],[1,2],[1,2,2],[2],[2,2]]\n\nExample 2:\nInput: nums = [0]Output: [[],[0]]\n\nConstraints:1 &lt;&#x3D; nums.length &lt;&#x3D; 10-10 &lt;&#x3D; nums[i] &lt;&#x3D; 10  \n给 元素重复 无序 数组，求所有的子数组，组合问题\npackage leetcode.problems.medium;import java.util.ArrayList;import java.util.Arrays;import java.util.Collections;import java.util.List;public class SubsetsII &#123;    public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123;        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();        List&lt;Integer&gt; path = new ArrayList&lt;&gt;();        Arrays.sort(nums);        backtrack(result, path, nums, 0);        return result;    &#125;    /**     * 回溯法 选择可能性的N叉树，每个叉代表基于当前节点的一种选择可能性(数值一样的选择可能性视作同一种可能性要进行剪枝操作)     * 怎么样写回溯算法(回溯法通用解题模板)     * 1. 画出递归树，找到状态变量(回溯函数的参数)，这一步非常重要※: 状态变量start，用来标识当前的选择列表的起始位置。也就是标识每一层的状态     * 2. 根据题意，确立结束条件: 因为每条路径都要加入结果集，所以是统计全路径。start越过数组边界的时候即是结束条件     * 3. 找准选择列表(与函数参数相关),与第一步紧密关联※: 路径即子集     * 4. 判断是否需要剪枝: 需要，因为存在同样的元素所以对于同一个节点往下分别选择一样的元素算同一种可能性     * 5. 作出选择，递归调用，进入下一层     * 6. 撤销选择 返回上一层     * 参考：https://leetcode.cn/problems/subsets/solution/c-zong-jie-liao-hui-su-wen-ti-lei-xing-dai-ni-gao-/     *     * @param result 用来记录全部可能的路径的结果 list     * @param path 从树的根节点开始往下走到全部叶子节点的路径     * @param nums 题目给的集合     * @param start 当前节点起始下标     */    private void backtrack(List&lt;List&lt;Integer&gt;&gt; result, List&lt;Integer&gt; path, int[] nums, int start) &#123;        result.add(new ArrayList&lt;&gt;(path)); // 记得要深拷贝不然传引用的话result list里面全是存的同一个path list的地址        for (int i = start; i &lt; nums.length; i++) &#123;            if (i &gt; start &amp;&amp; nums[i-1] == nums[i]) &#123; // 剪枝: 同样的数字不必再进入子树了                continue;            &#125;            path.add(nums[i]);            backtrack(result, path, nums, i+1);            path.remove(path.size()-1);        &#125;    &#125;    public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup2(int[] nums) &#123;        List&lt;List&lt;Integer&gt;&gt; result = new ArrayList&lt;&gt;();        result.add(new ArrayList&lt;&gt;());        for (int i = 0; i &lt; nums.length; i++) &#123;            for (int j = i; j &lt; nums.length; j++) &#123;                List&lt;Integer&gt; subset = new ArrayList&lt;&gt;();                for (int index = i; index &lt;= j; index++) &#123;                    subset.add(nums[index]);                &#125;                result.add(subset);            &#125;        &#125;        return result;    &#125;    public static void print(List&lt;List&lt;Integer&gt;&gt; subsets) &#123;        for (List&lt;Integer&gt; subset : subsets) &#123;            System.out.print(&quot;[&quot;);            for (int i = 0; i &lt; subset.size(); i++) &#123;                System.out.print(subset.get(i));                if (i != subset.size()-1)                    System.out.print(&quot;,&quot;);            &#125;            System.out.println(&quot;]&quot;);        &#125;    &#125;&#125;\n","categories":["LeetCode"],"tags":["Backtracking"]},{"title":"(Tor) Set up an obfs4 bridge","url":"/2018/08/16/Network/(Tor)-Set-up-an-obfs4-bridge/","content":"Bridge set up guideThis guide will help you set up an obfs4 bridge to help censored users connect to the Tor network. The requirements are:\n24/7 Internet connectivity\nThe ability to expose TCP ports to the Internet (make sure that NAT doesn&#39;t get in the way)\n\nNote: If you’re running a platform that is not listed on this page, you can compile obfs4 from source.\n\nDebian &#x2F; Ubuntu: How to deploy an obfs4 bridge on Debian &#x2F; Ubuntu\nWindows: How to deploy an obfs4 bridge on Windows\nFedora: How to deploy an obfs4 bridge on Fedora\nCentOS &#x2F; RHEL &#x2F; OpenSUSE: How to deploy an obfs4 bridge on CentOS &#x2F; RHEL &#x2F; OpenSUSE\nDragonflyBSD: How to deploy an obfs4 bridge on DragonflyBSD\nDocker: How to deploy an obfs4 bridge using a docker container\nPost-install: How to find your bridge in Relay Search and connect manually\nNetBSD: How to deploy an obfs4 bridge on NetBSD\n\nSet up bridge by using Docker1. Deploy a containerWe provide a docker-compose file that helps you deploy the container. First, download docker-compose.yml: \n# This file assists operators in (re-)deploying an obfs4 bridge Docker# container.  You need the tool &#x27;docker-compose&#x27; to use this file.  You# can find it in the Debian package &#x27;docker-compose&#x27;.## First, you need to create a configuration file, &quot;.env&quot;, in the same directory# as this file, &quot;docker-compose.yml&quot;.  Add the following environment variables# to this configuration file.  EMAIL is your email address; OR_PORT is your# onion routing port; and PT_PORT is your obfs4 port:##   EMAIL=you@example.com#   OR_PORT=XXX#   PT_PORT=XXX## Next, pull the Docker image, by running:##   docker-compose pull obfs4-bridge## And finally, to (re-)deploy the container, run:##   docker-compose up -d obfs4-bridgeversion: &quot;3.4&quot;services:  obfs4-bridge:    image: thetorproject/obfs4-bridge:latest    environment:      # Exit with an error message if OR_PORT is unset or empty.      - OR_PORT=$&#123;OR_PORT:?Env var OR_PORT is not set.&#125;      # Exit with an error message if PT_PORT is unset or empty.      - PT_PORT=$&#123;PT_PORT:?Env var PT_PORT is not set.&#125;      # Exit with an error message if EMAIL is unset or empty.      - EMAIL=$&#123;EMAIL:?Env var EMAIL is not set.&#125;    volumes:      - data:/var/lib/tor    ports:      - $&#123;OR_PORT&#125;:$&#123;OR_PORT&#125;      - $&#123;PT_PORT&#125;:$&#123;PT_PORT&#125;    restart: unless-stoppedvolumes:  data:    name: tor-datadir-$&#123;OR_PORT&#125;-$&#123;PT_PORT&#125;\n\nand then write your bridge configuration to a new file, .env, which is in the same directory as docker-compose.yml. Here’s a template:\n# Your bridge&#x27;s Tor port.OR_PORT=X# Your bridge&#x27;s obfs4 port.PT_PORT=Y# Your email address.EMAIL=Z\n\nReplace X with your desired OR port, Y with your obfs4 port (make sure that both ports are forwarded in your firewall), and Z with your email address, which allows us to get in touch with you if there are problems with your bridge. With your bridge configuration in place, you can now deploy the container by running:\ndocker-compose up -d obfs4-bridge\n\nThis command will automatically load your docker-compose.yml file while considering the environment variables in .env.\nYou should now see output similar to the following:\nStarting docker-obfs4-bridge_obfs4-bridge_1 ... done\n\nThat’s it! Your container is now bootstrapping your new obfs4 bridge.\n2. Upgrade your containerUpgrading to the latest version of our image is as simple as running:\ndocker-compose up -d obfs4-bridge\n\nNote that your bridge’s data directory (which includes its key material) is stored in a docker volume, so you won’t lose your bridge’s identity when upgrading to the latest docker image. If you are running multiple bridges on your computer, you need to repeat this step for each bridge. We will announce new image versions on the tor-dev mailing list.\n3. Monitor your logsYou can inspect your bridge’s logs by running:\ndocker logs CONTAINER_ID\n\nTo use your new bridge in Tor Browser, you need its “bridge line”. Here’s how you can get your bridge line:\ndocker exec CONTAINER_ID get-bridge-line\n\nThis will return a string similar to the following:\nobfs4 1.2.3.4:1234 B0E566C9031657EA7ED3FC9D248E8AC4F37635A4 cert=OYWq67L7MDApdJCctUAF7rX8LHvMxvIBPHOoAp0+YXzlQdsxhw6EapaMNwbbGICkpY8CPQ iat-mode=0\n\nMake sure to check out the post-install notes. If you are having troubles setting up your bridge, have a look at our help section.\npost-install notesCongrats!If you get to this point, it means that your obfs4 bridge is running and is being distributed by BridgeDB to censored users. Note that it can take several days or weeks until you see a consistent set of users, so don&#x27;t get discouraged if you don&#x27;t see user connections right away. BridgeDB uses four buckets for bridge distribution: HTTPS, Moat, Email, and manual. Some buckets are used more than others, which also affects the time until your bridge sees users. Finally, there aren&#x27;t many bridge users out there, so you cannot expect your bridge to be as popular as a relay.If you want to connect to your bridge manually, you will need to know the bridge&#x27;s obfs4 certificate. See the file /var/lib/tor/pt_state/obfs4_bridgeline.txt and paste the entire bridge line into Tor Browser:Bridge obfs4 &lt;IP ADDRESS&gt;:&lt;PORT&gt; &lt;FINGERPRINT&gt; cert=&lt;CERTIFICATE&gt; iat-mode=0You&#x27;ll need to replace &lt;IP ADDRESS&gt;, &lt;PORT&gt;, and &lt;FINGERPRINT&gt; with the actual values, which you can find in the tor log. Make sure to use &lt;FINGERPRINT&gt;, not &lt;HASHED FINGERPRINT&gt;; and that &lt;PORT&gt; is the obfs4 port you chose - and not the OR port.Finally, you can monitor your obfs4 bridge&#x27;s usage on Relay Search. Just enter your bridge&#x27;s &lt;HASHED FINGERPRINT&gt; in the form and click &quot;Search&quot;. After having set up the bridge, it takes approximately three hours for the bridge to show up in Relay Search.\n\nour help sectionIf you run into problems while setting up your relay, you can ask your questions on the public tor-relays mailing list. The list is a great resource for asking (and answering) questions, and for getting to know other relay operators. Make sure to check out the archives!\nYou can also get help by joining the IRC channel #tor-relays in the network irc.oftc.net.\n","categories":["Network"],"tags":["Tor"]},{"title":"(Tor)-All-about-tor-full-pack","url":"/2018/07/16/Network/Tor-All-about-tor-full-pack/","content":"All About TorVersion 2019 - 02\nAgenda\nFill in this section\nWith your agenda for the day\nTo help your audience stay focused!\n\nLet’s begin\nDo you use Tor?\nIf not, why not?\nIf yes, do you have any questions, concerns, issues, or doubts about using it?\nDo you teach others about Tor?\n\nWhat is Tor?\nFree software and an open network\nMitigates against tracking, surveillance and censorship\nRun by a US non-profit and volunteers from all over the world\nIt’s Tor, not TOR\n\nWhy do we need Tor?\nGovernment mass and targeted surveillance\nThe business model of the Internet: big data, advertising, non-consensual tracking\nSurveillance threats from family, bosses, bad people on the Internet\n\nWhy do you need Tor?\nLet’s discuss the work you do \nAdversaries and challenges \nMitigations\nHow Tor can help\n\nlittle-t Tor or core tor\nTor the network daemon (a computer program)\nPresents a SOCKS or http proxy\nLocation and source anonymity, similar to a VPN or regular proxy (but better!)\nNetwork of relays in many parts of the world\n\nWho can see your activity without Tor or HTTPS?Who can see your activity with Tor and HTTPS?Tor Browser\nlittle-t tor plus patched Firefox\nAnyone snooping can’t see the websites you visit\nWebsites can’t track you or see other sites you visit (cross-tracking)\nPrevents other privacy violations like fingerprinting or 3rd party cookies\nWrites nearly nothing to disk\nNo browser history\nCross platform: Windows, macOS, Linux and Android\n\nTor Browser in other languages\nGo to https://torproject.org\nSelect the language  on dropdown menu \nOr select “Download in another language or platform”\n\nDownloading Tor Browser\nThe safest way to download is from https://torproject.org\n\nIf https://torproject.org is blocked, try mirrors\n\nhttp://tor.calyxinstitute.org/\n\nhttps://tor.eff.org/\n\nOr try GetTor - email &#103;&#101;&#x74;&#116;&#x6f;&#114;&#x40;&#x74;&#x6f;&#114;&#112;&#114;&#x6f;&#106;&#x65;&#x63;&#x74;&#46;&#x6f;&#114;&#x67; and in the message write “windows”, “osx” or “linux” (no quotes, no subject line)\n\n\nRunning Tor Browser the first timeUsing Tor Browser\nDefault search engine: DuckDuckGo\nBundled with NoScript, HTTPS Everywhere\nYou should not add any other extensions nor enable any plugins (eg Flash)!\nBest practices:Websites won’t know anything about you unless you login and tell them\n\n\n\nClicking on the site information menu will show your current circuit (and “New Circuit for this site” option)Updating Tor BrowserUninstalling Tor BrowserUninstalling Tor Browser is as easy as moving the folder to the trash! Then, empty the trash.\nDefault Tor Browser folder locations:\n\nWindows: desktop\nmacOS: move the Tor Browser application to Trash and also the TorBrowser-Data folder  (~&#x2F;Library&#x2F;Application Support&#x2F;)\nLinux: home, or look for a name like “tor-browser_en-US”\n\nTroubleshooting Tor Browser\nIs your system clock correct?\nIs the browser already running?\nAre you being censored?\nIs your antivirus or firewall blocking Tor?\nDo you have a very old operating system?\nTry uninstalling and reinstalling\nGet help at https://support.torproject.org\n\nMore Tor BrowserThe “onion” menu\nNew Identity: completely refreshes Tor Browser and its circuits; wipes all history; closes all tabs\nTor network settings: censorship mitigation options; access to Tor log\nCheck for Tor Browser update\n\nSecurity SliderNoScript\nIt’s not advisable to change settings in the “options” menu\nFor example, adding sites to the “whitelist” can result in fingerprinting\nInstead, only “temporarily trust” blocked objects\n\nDuckDuckGo\nDuckDuckGo is the default search engine in Tor Browser\nUsing Tor Browser prevents DDG from tracking users, even if they wanted to (they claim not to)\nDuckduckgo.com or https://3g2upl4pq6kufc4m.onion/\n\nPlugins, add-ons, Javascript\nDo not add any new add-ons&#x2F;extensions to Tor, and don’t enable any plugins\nFor example, Flash plugin can reveal your real location \nJavascript is enabled by default, but is sanitized to preserve anonymity\nTo prevent possible Javascript vulnerabilities, use the “safest” setting in the security slider\n\nMobile TorThings to know about mobile Tor\nThe design of mobile devices makes full privacy impossible\nMobile Tor is best for censorship prevention\nCan also provide better privacy for some threat models\nWe’re making it better all the time and better options for mobile devices are coming out soon\n\nTor Browser for Android\nYou don’t need to install two APPs (Orbot and Orfox) anymore\nFind it in the Play Store\nOr Guardian Project repository in F-Droid\nOr download .apk\n\nOnion Browser\nTor Browser for iOS\nFind it in the App Store\nLots of fake Tor Browsers for iOS\nVery rudimentary\nCrashes on sleep\n\nUsing Orbot\nTor proxy for Android\nFind it on the Play Store or F-Droid\nUse it to run other Apps through Tor (like Twitter)\nClick start to run \nYou can choose your exit country if you want (some countries don’t have exits!)\n\nUsing Orbot\nToggle “VPN mode” on main screen\nThen click “Orbot-enabled apps”\nThen select the apps you want to proxy with Tor\n\nHow do I get help using Tor?Help using Tor\nTor Browser Manual: tb-manual.torproject.org\nSupport Portal: https://support.torproject.org\nOpen mailing lists: https://lists.torproject.org \nChat: IRC OFTC network - easy access through https://webchat.oftc.net channel #tor\nhttps://tor.stackexchange.com\n\nIf you find a bug in Tor\nhttps://trac.torproject.org\nCreate a login\nSearch for your issue to find any existing tickets\nIf no ticket opened, open a new ticket with detailed description of the problem\n\nCircumventing censorship with TorWhat do you do when  Tor is blocked?I downloaded Tor Browser, but it won’t connect\nIf this screen takes a long time and does not connect, you may need a bridge or pluggable transport\n\nWhen torproject.org is blocked\nMirrors\nhttps://tor.eff.org/ \nhttp://tor.calyxinstitute.org/ (if https is blocked)\nGetTor email: &#103;&#x65;&#116;&#116;&#x6f;&#x72;&#x40;&#x74;&#x6f;&#114;&#112;&#114;&#x6f;&#x6a;&#101;&#99;&#x74;&#x2e;&#111;&#x72;&#x67;\nContact from a Gmail or Riseup account\nFlash drive with Tor on it from someone you trust\nGet the EXE, DMG, tar.xz, don’t copy the installed folder\nDownloading Tor from a random website is dangerous!\n\nBridges and pluggable transports\nBridges are relays that are not listed publicly\nGet bridges directly from Tor Browser (moat)\nOr from the website https://bridges.torproject.org or send an email to &#x62;&#x72;&#x69;&#100;&#103;&#x65;&#x73;&#x40;&#x74;&#111;&#x72;&#x70;&#x72;&#111;&#106;&#x65;&#99;&#x74;&#x2e;&#111;&#x72;&#x67; from a Gmail, or Riseup.net account\nOr get a bridge address from a trusted person\nPluggable transports can be used like bridges to disguise Tor traffic (also called “built-in bridges”)\n\nBridges and pluggable transportsRequest a bridge\nmoat method\n\nOr select a built-in bridgePluggable transports\nobfs4: makes Tor traffic look random; works in many situations including China (if not, try meek)\nfte: makes Tor traffic look like regular HTTP traffic\nmeek-azure: makes it look like Microsoft traffic; works in China\nsnowflake: proxies traffic through temporary proxies using WebRTC (under development) https://snowflake.torproject.org\n\nOONI\nOpen Observatory of Network Interference:https://ooni.torproject.org\nCountry-level reports of specific censorship tools in use on certain websites\nView their reports:https://explorer.ooni.torproject.org\nOr use your own OONI Probe to test websites: available in App Store and PlayStore\n\nSharing content anonymously with TorWhat are Onion Services?The regular internet allows adversaries to see what you are sharing and with whom, whether you’re using Dropbox etc, downloading it from email or through your browser…\n…so Tor devised a sneaky way to hide both the file data and the related metadata!\nOnion Services\nProtection for both the user and the server\nUser learns about xyz.onion\nClient and service meet at rendezvous point in the Tor cloud\nEnd-to-end encrypted without HTTPS\nConnections never go out to the “vanilla” internet\n\nOnionShare\nSecure, private, anonymous file sharing done easy, built on top of the Tor network\nUses onion services to securely send files\nCreates an onion service where the file can be downloaded\nNo need to trust third parties like Dropbox\nDownload from https://onionshare.org\n\nConnection\nOnionShare connects to Tor network\nClick “add” then find the file you want to share.\n\nSharingOnce the file is added, click “start sharing”\nSharing\nCopy the xyz.onion link and send it to your contact\nContact installs Tor Browser\nWhen they finish downloading you’ll see this →\n\nHelp LinkIp hidden and TOR network configured: Visit https://check.torproject.org, you should see a message like: “Congratulations. This Browser is configured to use Tor.”\nChecking DNS Leaks: Visit https://dnsleaktest.com and make a extended test to see what are your DNS.\n","categories":["Network"],"tags":["Tor"]},{"title":"Nginx","url":"/2020/04/10/Network/Nginx/","content":"Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP&#x2F;POP3&#x2F;SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的。\n基本概念反向代理正向代理在客户端(浏览器)中配置代理服务器，通过代理服务器进行互联网访问。\n反向代理负载均衡动静分离高可用installhttp://nginx.org/en/download.html\n安装依赖pcre解压pcre压缩包，进入目录执行\n./configuremake &amp;&amp; make install\n\n查看版本号\npcre-config --version\n\nzlib与opensslyum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel\n\n或者使用yum一键安装上述3个依赖yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel\n\n安装 nginx解压nginx压缩包，进入目录执行\n./configuremake &amp;&amp; make install\n\n使用cd /usr/local/nginx\n\nnginx的启动脚本在nginx/sbin文件夹下面\n测试cd /usr/local/nginx/sbin./nginxps -ef | grep nginx\n\n配置防火墙查看防火墙规则：\nfirewall-cmd --list-all\n\n添加规则：\nfirewall-cmd --add-service=http =permanentsudo firewall-cmd --add-port=80/tcp --permanent\n\n重启防火墙：\nfirewall-cmd -reload\n\nnginx 常用命令进入nginx根目录或者将其添加到PATH\ncd /usr/local/nginx/sbin\n\n查看nginx版本号./nginx -v\n\n启动nginx./nginx\n\n关闭nginx./nginx -s stop\n\n重新加载nginxnginx.conf文件内容修改后需要重新加载才能生效，此命令可以使得在不重启nginx情况下应用修改\n./nginx -s reload\n\n配置文件nginx.confcd /usr/local/nginx/conf\n\n配置文件由3部分组成：\n\n全局块：从配置文件开始到events块之间的内容，主要会设置一些影响nginx服务器整体运行的配置指令\nevents块：主要影响nginx服务器与用户的网络连接，常用的设置包括是否开启对多worker processes下的网络连接进行序列化，是否允许同时接受多个网络连接，选取暗中事件驱动模型来处理连接请求，每个word process可以同时支持的最大连接数等\nhttp块：包含http全局块和server块，代理、缓存和日志等绝大多数功能和第三方模块的配置都在这里\nhttp全局块：包括文件引入、MIME-TYPE协议、日志自定义、连接超时时间、单链接请求数上限等\nserver块：包含全局server块和location块，和虚拟主机有密切关系，虚拟主机从用户角度看和一台独立的硬件主机完全一样，该技术主要用于节省互联网服务器硬件成本\n全局server块：最常见的配置是虚拟主机的监听配置和本虚拟主机的名称或IP配置\nlocation块：一个server块可以配置多个location块，这个块的主要作用是基于nginx服务器收到的请求字符串(例如：server_name&#x2F;uri-string)，对虚拟主机名称(或IP别名)之外的字符串(例如：&#x2F;uri-string)进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里。\n\n\n\n\n\n全局块#user  nobody;worker_processes  1; #nginx服务器并发处理关键配置，worker_processes值越大，可以支持的并发处理量越多，但是受硬件、软件等设备制约#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;\n\nevents块events &#123;    worker_connections  1024; #表示每个worker processes支持的最大连接数为1024&#125;\n\nhttp块http &#123;    # http全局块    include       mime.types;    default_type  application/octet-stream;    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    #access_log  logs/access.log  main;    sendfile        on;    #tcp_nopush     on;    #keepalive_timeout  0;    keepalive_timeout  65;    #gzip  on;    server &#123; # server块        listen       80; # 目前监听端口号        server_name  localhost; # 主机名称        #charset koi8-r;        #access_log  logs/host.access.log  main;        location / &#123;            root   html;            index  index.html index.htm;        &#125;        #error_page  404              /404.html;        # redirect server error pages to the static page /50x.html        #        error_page   500 502 503 504  /50x.html;        location = /50x.html &#123;            root   html;        &#125;        # proxy the PHP scripts to Apache listening on 127.0.0.1:80        #        #location ~ \\.php$ &#123;        #    proxy_pass   http://127.0.0.1;        #&#125;        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000        #        #location ~ \\.php$ &#123;        #    root           html;        #    fastcgi_pass   127.0.0.1:9000;        #    fastcgi_index  index.php;        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;        #    include        fastcgi_params;        #&#125;        # deny access to .htaccess files, if Apache&#x27;s document root        # concurs with nginx&#x27;s one        #        #location ~ /\\.ht &#123;        #    deny  all;        #&#125;    &#125;    # another virtual host using mix of IP-, name-, and port-based configuration    #    #server &#123;    #    listen       8000;    #    listen       somename:8080;    #    server_name  somename  alias  another.alias;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;    # HTTPS server    #    #server &#123;    #    listen       443 ssl;    #    server_name  localhost;    #    ssl_certificate      cert.pem;    #    ssl_certificate_key  cert.key;    #    ssl_session_cache    shared:SSL:1m;    #    ssl_session_timeout  5m;    #    ssl_ciphers  HIGH:!aNULL:!MD5;    #    ssl_prefer_server_ciphers  on;    #    location / &#123;    #        root   html;    #        index  index.html index.htm;    #    &#125;    #&#125;&#125;\n\nlocation指令说明该指令用于匹配URL\n语法如下：\n\n=: 用于不含正则表达式的URI前，要求请求字符串与URI严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求\n~: 用于表示URI包含正则表达式，并且区分大小写\n~*: 用于表示URI包含正则表达式，并且不区分大小写\n^~: 用于不含正则表达式的URI前，要求Nginx服务器找到标识URI和请求字符串匹配度最高的location后，立即使用此location处理请求，而不再使用location块中的正则URI和请求字符串做匹配\n\n操作实例反向代理实例实例一实现效果：浏览器输入网址www.123.com跳转到本地Tomcat页面\n下载并解压Tomcat，进入bin目录启动Tomcat\n./startup.sh\n\n开放端口\nsudo firewall-cmd --add-port=8080/tcp --permanentfirewall-cmd -reloadfirewall-cmd --list-all\n\n修改配置文件\nserver &#123;    listen 80;    server_name www.123.com;    location / &#123;        proxy_pass http://www.123.com:8080;        index index.html index.htm index.jsp;    &#125;&#125;\n\n实例二实现效果：根据访问的路径跳转到不同端口的服务中\n\n访问http://127.0.0.1:9001/edu 直接跳转到127.0.0.1:8080\n访问http://127.0.0.1:9001/vod 直接跳转到127.0.0.1:8081\n\nserver &#123;    listen 9001;    server_name localhost;    location ~ /edu/ &#123; # ~符号表示后接正则表达式，表示访问的路径中包含edu字符串就跳转到8080        proxy_pass http://localhost:8080;    &#125;    location ~ /vod/ &#123;        proxy_pass http://localhost:8081;    &#125;&#125;\n\n\n负载均衡实例实现效果：通过浏览器的地址栏输入地址(http://localhost/edu/a.html)，使得请求平均分配到8080与8081端口中\n关键配置：\nhttp &#123;    #.....    upstream myserver &#123;        ip_hash;        server 192.168.17.129:8080 weight=1;        server 192.168.17.129:8081 weight=1;    &#125;    #.....    server &#123;        location / &#123;            #.....            proxy_pass http://myserver;            proxy_connect_timeout 10;        &#125;    &#125;&#125;\n\n配置案例：\nworker_processes  1;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    sendfile        on;    keepalive_timeout  65;    upstream myserver &#123;        ip_hash;        server 192.168.17.129:8080 weight=1;        server 192.168.17.129:8081 weight=1;    &#125;    server &#123;        listen       80;        server_name  192.168.17.129;        location / &#123;            proxy_pass http://myserver;            proxy_connect_timeout 10;            root   html            index index.html index.htm        &#125;    &#125;&#125;\n\n负载均衡的分配方式\n轮询(默认)：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。\nweight：权重，weight和访问比率成正比，用于后端服务器性能不均的情况，例如：\nA服务器weight=5，B服务器weight=10，则B会收到的流量为A的一倍，即A会收到全部流量的1&#x2F;3，B为2&#x2F;3\n\n\nip_hash：每个请求按IP的hash结果分配，每个访客固定访问一个后端服务器，可以解决session的问题\nfair: 按照后端服务器的访问时间来分配，时间短的优先分配\n\nupstream myserver &#123;    server 192.168.17.129:8080;    server 192.168.17.129:8081;&#125;\n\nupstream myserver &#123;    server 192.168.17.129:8080 weight=5;    server 192.168.17.129:8081 weight=10;&#125;\n\nupstream myserver &#123;    ip_hash;    server 192.168.17.129:8080;    server 192.168.17.129:8081;&#125;\n\nupstream myserver &#123;    server 192.168.17.129:8080;    server 192.168.17.129:8081;    fair;&#125;\n\n动静分离实例通过location指定不同的后缀名实现不同的请求转发。通过expires参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。\nExpores：给一个资源设定一个过期时间，无需服务器端验证，而是由浏览器去确认该资源是否过期，不会产生额外的流量。适用于不经常变动的资源。比如设置为3d表示3天之内访问这个URL，浏览器会发送一个请求来对比服务器该文件最后更新时间有无变化，若无则不会从服务器抓取，返回状态码304，如果有修改则直接从服务器下载，返回状态码200\n实现效果：\n\n浏览器中输入地址http://192.168.17.129/image/01.jpg\n浏览器中输入地址http://192.168.17.129/www/a.html\n\n文件结构：\n\ndata\nimage\n01.jpg\n\n\nwww\na.html\n\n\n\n\n\nworker_processes  1;events &#123;    worker_connections  1024;&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    sendfile        on;    keepalive_timeout  65;    server &#123;        listen       80;        server_name  192.168.17.129;        location /www/ &#123;            root /data/;            index index.html index.htm        &#125;        location /image/ &#123;            root /data/;            autoindex on; # 在浏览器中列出当前文件夹中的内容        &#125;    &#125;&#125;\n\n高可用集群多台Nginx同时工作，若其中一台宕机服务不会中断。\n需要：\n\n2台服务器192.168.17.129, 192.168.17.131\n两台服务器安装Nginx\n两台服务器安装keepalived\n\nyum install keepalived -y\n\n配置文件/etc/keepalive.conf：\n#全局配置global_defs &#123;     notification_email &#123;        acassen@firewall.loc        failover@firewall.loc        sysadmin@firewall.loc    &#125;    notification_email from Alexandre.Cassen@firewall.loc    smtp_server 192.168.17.129    smtp_connect timeout 30    router_id LVS_DEVEL # 唯一取值，可写服务器名字(配置在hosts里的domian)也可写IP&#125;# 脚本配置vrrp_script chk_http_port &#123;    script &quot;/usr/local/src/nginx_check.sh&quot; # 检测脚本路径    interval 2 # 检测脚本执行间隔    weight 2 # 权重参数&#125;vrrp_instance VI_1 &#123;    state BACKUP # 备份服务器上将MASTER改为BACKUP    interface ens33 # 网卡    virtual_router_id 51 # 主、备机的virtual_router_id 必须相同    priority 100 # 主、备机取不同的优先级，主机值较大，备份机值较小    advert_int 1 # 时间间隔，每隔多久发送一个心跳，单位秒    authentication &#123; # 权限校验方式        auth_type PASS # 类型：密码        auth_pass 1111 # 密码值    &#125;    virtual_ipaddress &#123;        192.168.17.50 # VRRP H虚拟地址    &#125;&#125;\n\n检测脚本/usr/local/src/nginx_check.sh：\n#!/bin/bashA=`ps -C nginx -no-header |wc -l`if [ $A -eq 0 ]; then    /usr/local/nginx/sbin/nginx    sleep 2    if [ `ps -C nginx -no-header |wc -l` -eq 0 ]; then        killall keepalived    fifi\n\n查看网卡名：\nifconfig\n\nNginx原理分析master 和 workerNginx启动之后在Linux系统中其实有两个进程，分别叫nginx: master, nginx: worker\n当客户端发送一条请求给master之后，然后由worker来争抢该条请求，当worker抢到之后变进行请求转发或反向代理给Tomcat来响应请求\n一个master和多个worker的好处：\n\n可以使用nginx -s reload热部署。在进行热部署时，已经在执行任务的worker继续执行，没有任务的worker重新加载，有任务的worker任务执行完毕后再加载新配置文件。\n对于每个worker进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销。\n独立的进程互相之间不会相互影响，一个进程退出后，其它的进程还在工作，服务不会中断。若单个worker进程遇到异常退出了，会导致当前worker上的所有请求失败，不会影响到其它worker在处理的请求。\n\n需要设置多少个workerNginx和redis类似都采用了io多路复用机制，每个worker都是一个独立的进程，但每个进程只有一个主线程，通过异步非阻塞的方式来处理请求。每个worker的线程可以把一个cpu的性能发挥到极致。所以worker数和服务器的cpu核数相等是最为适宜的。设少了浪费cpu，设多了会造成cpu频繁切换上下文带来的损耗。\n反向代理配置文件案例#user  nobody;worker_processes  1; # nginx服务器并发处理关键配置，worker_processes值越大，可以支持的并发处理量越多，但是受硬件、软件等设备制约#error_log  logs/error.log;#error_log  logs/error.log  notice;#error_log  logs/error.log  info;#pid        logs/nginx.pid;events &#123;    worker_connections  1024; # 表示每个worker processes支持的最大连接数为1024&#125;http &#123;    include       mime.types;    default_type  application/octet-stream;    #log_format  main  &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;    #                  &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;    #                  &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;    #access_log  logs/access.log  main;    sendfile        on;    #tcp_nopush     on;    #keepalive_timeout  0;    keepalive_timeout  65;        server_names_hash_max_size 512;    server_names_hash_bucket_size 1024;    #gzip  on;        # upstream 负载均衡关键配置    # The ngx_http_upstream_module module is used to define groups of servers that can be referenced by the proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, and grpc_pass directives.    # 定义server用于给后面的proxy_pass使用    # 参考：https://blog.csdn.net/caijunsen/article/details/83002219    upstream www-pixiv-net &#123;         # 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除        server 210.140.131.223:443;        server 210.140.131.225:443;        server 210.140.131.220:443;    &#125;        upstream sketch-pixiv-net &#123;         server 210.140.174.37:443;        server 210.140.170.179:443;        server 210.140.175.130:443;    &#125;        upstream sketch-hls-server &#123;        server 210.140.214.211:443;        server 210.140.214.212:443;        server 210.140.214.213:443;    &#125;        upstream imgaz-pixiv-net &#123;         server 210.140.131.145:443;        server 210.140.131.144:443;        server 210.140.131.147:443;        server 210.140.131.153:443;    &#125;        upstream i-pximg-net &#123;         server 210.140.92.140:443;        server 210.140.92.137:443;        server 210.140.92.139:443;        server 210.140.92.142:443;        server 210.140.92.134:443;        server 210.140.92.141:443;        server 210.140.92.143:443;        server 210.140.92.136:443;         server 210.140.92.138:443;\t    server 210.140.92.144:443;\t    server 210.140.92.145:443;    &#125;        server &#123;        listen 80 default_server; # default_server 指令可以定义默认的 server 去处理一些没有匹配到 server_name 的请求，如果没有显式定义，则会选取第一个定义的 server 作为 default_server        rewrite ^(.*) https://$host$1 permanent; # 网站添加了https证书后，当http方式访问网站时就会报404错误，所以需要做http到https的强制跳转设置        # rewrite语法：        # rewrite    &lt;regex&gt;    &lt;replacement&gt;    [flag];        # 关键字      正则        替代内容          flag标记        # 关键字：其中关键字error_log不能改变        # 正则：perl兼容正则表达式语句进行规则匹配        # 替代内容：将正则匹配的内容替换成replacement        # flag标记：rewrite支持的flag标记        # flag标记说明：        # last: 本条规则匹配完成后，继续向下匹配新的location URI规则        # break: 本条规则匹配完成即终止，不再匹配后面的任何规则        # redirect: 返回302临时重定向，浏览器地址会显示跳转后的URL地址        # permanent: 返回301永久重定向，浏览器地址栏会显示跳转后的URL地址        # rewrite的组要功能是实现URL地址的重定向。Nginx的rewrite功能需要PCRE软件的支持，即通过perl兼容正则表达式语句进行规则匹配的。默认参数编译nginx就会支持rewrite的模块，但是也必须要PCRE的支持    &#125;    server &#123;        listen 443 ssl; # 443是https的默认端口        server_name pixiv.net; # server name 为虚拟服务器的识别路径。因此不同的域名会通过请求头中的HOST字段，匹配到特定的server块，转发到对应的应用服务器中去        server_name www.pixiv.net;        server_name ssl.pixiv.net;        server_name accounts.pixiv.net;        server_name touch.pixiv.net;        server_name oauth.secure.pixiv.net;        ssl on; # 使用HTTPS，需要安装OpenSSL        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key; # HTTPS私钥                client_max_body_size 50M; # 用nginx作代理服务器，上传大文件的大小有限制(限制请求体的大小，若超过所设定的大小，返回413错误)            \tlocation / &#123;            proxy_pass https://www-pixiv-net;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off; # 主要是实现被代理服务器的数据和客户端的请求异步            # A为客户端，B为代理服务器，C为被代理服务器。            # 当proxy_buffering开启，A发起请求到B，B再到C，C反馈的数据先到B的buffer上，            # 然后B会根据proxy_busy_buffer_size来决定什么时候开始把数据传输给A。            # 在此过程中，如果所有的buffer被写满，数据将会写入到temp_file中。            # 相反，如果proxy_buffering关闭，C反馈的数据实时地通过B传输给A。        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name i.pximg.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://i-pximg-net;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name sketch.pixiv.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;    \tlocation / &#123;            proxy_pass https://sketch-pixiv-net;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;                # Proxying WebSockets        location /ws/ &#123;            proxy_pass https://sketch-pixiv-net;            proxy_http_version 1.1;            proxy_set_header Upgrade $http_upgrade;            proxy_set_header Connection &quot;upgrade&quot;;            proxy_set_header Host $host;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name *.pixivsketch.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;    \tlocation / &#123;            proxy_pass https://sketch-hls-server;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name factory.pixiv.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;    \tlocation / &#123;            proxy_pass https://210.140.131.180/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name dic.pixiv.net;        server_name en-dic.pixiv.net;        server_name sensei.pixiv.net;        server_name fanbox.pixiv.net;        server_name payment.pixiv.net.pixiv.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://210.140.131.222/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name imgaz.pixiv.net;        server_name comic.pixiv.net;        server_name novel.pixiv.net;        server_name source.pixiv.net;        server_name i1.pixiv.net;        server_name i2.pixiv.net;        server_name i3.pixiv.net;        server_name i4.pixiv.net;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://imgaz-pixiv-net;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;    upstream wikipedia-server &#123;         server 198.35.26.96:443;        server 103.102.166.224:443;    &#125;        server &#123;        listen 443 ssl;        server_name *.wikipedia.org;        server_name *.m.wikipedia.org;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://wikipedia-server/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name *.steamcommunity.com;        server_name steamcommunity.com;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://23.61.176.149/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;        server &#123;        listen 443 ssl;        server_name *.steampowered.com;        server_name steampowered.com;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://104.112.84.145/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;\t    server &#123;        listen 443 ssl;        server_name *.archiveofourown.org;        server_name archiveofourown.org;        ssl on;        ssl_certificate ca/pixiv.net.crt;        ssl_certificate_key ca/pixiv.net.key;            \tlocation / &#123;            proxy_pass https://104.153.64.122/;            proxy_set_header Host $http_host;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Real_IP $remote_addr;            proxy_set_header User-Agent $http_user_agent;            proxy_set_header Accept-Encoding &#x27;&#x27;;             proxy_buffering off;        &#125;\t&#125;    &#125;\n\n链接\nThe easiest way to configure a performant, secure, and stable NGINX server.\nPIXIV网页版及客户端访问恢复指南\nMAC本地nginx反向代理访问Pixiv指北\nNginx 真·反代P站 恢复直接访问\nNGINX Config The easiest way to configure a performant, secure, and stable NGINX server.\n\n\n","categories":["Back-end"],"tags":["高并发","Nginx"]},{"title":"Node.js Unit Test Framework","url":"/2019/10/28/Nodejs/Node.js%20Unit%20Test%20Framework/","content":"基于Node.js的 Unit Test Framework，用到了如下几个工具：\n\nmocha: Mocha is a feature-rich JavaScript test framework.\nsinon.js: Standalone test spies, stubs and mocks for JavaScript.\nchai.js: Chai is a BDD &#x2F; TDD assertion library.\nsupertest: Super-agent driven library for testing node.js HTTP servers using a fluent API.\nistanbul.js: JavaScript test coverage made simple.\n\n安装与配置安装npm install mocha -Snpm install sinon -Snpm install chai -Snpm install supertest -Snpm install istanbul -S\n\n配置\n在项目的根目录下创建test文件夹，如果项目是分层结构的话可以在test下创建子目录\n添加mocha启动命令，参数为需要扫描的含有unit test文件的文件夹\n\nmocha test/controller test/routes test/common test/service\n\n为方便起见可以将命令添加到package.json\n&quot;scripts&quot;: &#123;  &quot;unit-test&quot;: &quot;mocha test/controller test/routes test/common test/service&quot;&#125;\n\n编写 Unit Test为方便查看unit test运行结果，可以采用每一个js文件对应一个Unit Test文件，每一个function对应一个组的结构来编写\nGiven-When-Then的case命名法Definition\nThe Given-When-Then formula is a template intended to guide the writing of acceptance tests for a User Story:\n\nGiven: Set of preconditions\nWhen: When an event occurs, or some action is carried out\nThen: What outcome is achieved, or a particular set of observable consequences should obtain\n\nExample：测试对象是人\n\nGiven：人的上下文预设：这是一个诗人\nWhen：对人的操作：把这个人放在太平盛世中\nThen：对人产生的结果：这个人将获得富足的生活\n则test case命名为：Given_一个人职业是诗人_When_活在太平盛世_Then_这个人生活富足\n\n一个 test case的结构一个test case分为3部分：\n\nmock函数部分\nGiven步骤: 准备测试数据部分\nWhen步骤：调用测试函数\nThen步骤：断言返回结果\n\nmocha中Unit Test的结构describe(&#x27;userController&#x27;, function() &#123;  describe(&#x27;#findUserByPaging()&#x27;, function() &#123;    // 准备测试数据    ...    // mock or stub function if need    let sandbox;    beforeEach(function() &#123;      sandbox = sinon.createSandbox();    &#125;);    afterEach(function() &#123;      sandbox.restore()    &#125;);    // test case    it(&#x27;should return limit user list when given offset limit&#x27;, (done) =&gt; &#123;      userController.findUserByPaging(searchCriteria).then((result) =&gt; &#123;        // Then        assert.equal(result.success, true) // assert断言        done() // 表示一个Test Case结束      &#125;).catch((err) =&gt; &#123;        done(err) // 表示一个Test Case结束      &#125;)    &#125;)  &#125;)&#125;)\n\n若断言不通过或者运行中抛出一个异常则会显示测试失败\nTest Case Example本例中用到的方法：\n\nmocha:\ndescribe()\ndone()\n\n\nsinon.js\ncreateSandbox()\nstub\n\n\nchai.js\nassert.equal()\nassert.deepEqual()\n\n\n\ndescribe(&#x27;#findUserByPaging()&#x27;, function() &#123;  let sandbox;  // Given  const searchResult = &#123;    &quot;totalCount&quot;: 1,    &quot;data&quot;: [      &#123;        &quot;userId&quot;: 1,        &quot;userDomain&quot;: &quot;TESTUSER&quot;,        &quot;userEmail&quot;: &quot;test.user@outlook.com&quot;,        &quot;userTel&quot;: &quot;1234567890&quot;,        &quot;userTeam&quot;: &quot;MBC&quot;,        &quot;roleId&quot;: 1,        &quot;roleName&quot;: &quot;Super Admin&quot;      &#125;    ]  &#125;  const searchCriteria = &#123;    userDomain: &#x27;TESTUSER&#x27;,    offset: 0,    limit: 10  &#125;  const expectData = &#123;    &quot;data&quot;: [      &#123;        &quot;role&quot;: [          &#123;            &quot;roleId&quot;: 1,            &quot;roleName&quot;: &quot;Super Admin&quot;          &#125;        ],        &quot;userDomain&quot;: &quot;TESTUSER&quot;,        &quot;userEmail&quot;: &quot;test.user@outlook.com&quot;,        &quot;userId&quot;: 1,        &quot;userTeam&quot;: &quot;MBC&quot;,        &quot;userTel&quot;: &quot;1234567890&quot;      &#125;    ],    &quot;limit&quot;: 10,    &quot;offset&quot;: 0,    &quot;totalCount&quot;: 1  &#125;  // mock function  beforeEach(function() &#123;    sandbox = sinon.createSandbox();    sandbox.stub(UserRepo, &quot;findUserByPaging&quot;).withArgs(sinon.match.any).returns(searchResult)  &#125;);  afterEach(function() &#123;    sandbox.restore()  &#125;);  it(&#x27;should return limit user list when given offset limit&#x27;, (done) =&gt; &#123;    // When    userController.findUserByPaging(searchCriteria).then((result) =&gt; &#123;      // Then      assert.equal(result.success, true)      assert.deepEqual(result.data, expectData)      done()    &#125;).catch((err) =&gt; &#123;      done(err)    &#125;)  &#125;)&#125;)\n\n对应上述代码：\n\nGiven部分给出了提供的数据，searchCriteria和searchResult对象\nWhen部分调用了findUserByPaging方法\nThen对返回结果进行了断言，判断了是否与预期结果expectData符合\n本例中对findUserByPaging方法所调用到的UserRepo对象的findUserByPaging方法进行了打桩并使其返回了我们对其预期的返回数据searchResult\n\nmock or stub如上述代码所示，使用到了sinon.js的createSandbox和stub方法\n\nsandbox\nstub\n\n\nDefault sandbox: Since &#x73;&#105;&#x6e;&#111;&#110;&#64;&#53;&#x2e;&#x30;&#x2e;&#48;, the sinon object is a default sandbox. Unless you have a very advanced setup or need a special configuration, you probably want to just use that one.\n\n与直接使用sinon.stub()比起来使用sandbox要更安全，而且在部分情况下前者会出现stub不掉的情况，而后者则不会\n&quot;test should call all subscribers, even if there are exceptions&quot; : function()&#123;    var message = &#x27;an example message&#x27;;    var stub = sinon.stub().throws();    var spy1 = sinon.spy();    var spy2 = sinon.spy();    PubSub.subscribe(message, stub);    PubSub.subscribe(message, spy1);    PubSub.subscribe(message, spy2);    PubSub.publishSync(message, undefined);    assert(spy1.called);    assert(spy2.called);    assert(stub.calledBefore(spy1));&#125;\n\n// Creates a new sandbox object with spies, stubs, and mocks.var sandbox = sinon.createSandbox();beforeEach(function() &#123;    sandbox = sinon.createSandbox();    sandbox.stub(UserRepo, &quot;findUserByPaging&quot;).withArgs(sinon.match.any).returns(searchResult)&#125;);afterEach(function() &#123;    sandbox.restore()&#125;);\n\n使用 supertest来编写模拟HTTP请求的 Unit Testdescribe(&#x27;/nj_dom_notification/users/page&#x27;, function() &#123;  let sandbox;  const data = [    &#123;      &quot;userId&quot;: 1,      &quot;userDomain&quot;: &quot;TESTUSER&quot;,      &quot;userEmail&quot;: &quot;test.user@outlook.com&quot;,      &quot;userTel&quot;: &quot;1234567890&quot;,      &quot;userTeam&quot;: &quot;MBC&quot;,      &quot;role&quot;: [        &#123;          &quot;roleId&quot;: 1,          &quot;roleName&quot;: &quot;Super Admin&quot;        &#125;      ]    &#125;  ]  beforeEach(function() &#123;    sandbox = sinon.createSandbox();    sandbox.stub(userController, &quot;findUserByPaging&quot;).callsFake(() =&gt; &#123;      return responseHelper.responsePageSuccess(data)    &#125;)  &#125;);  afterEach(function() &#123;    sandbox.restore();  &#125;);  it(&#x27;should get user list json when call findUserByPaging&#x27;, (done) =&gt; &#123;    request(app)      .get(&#x27;/nj_dom_notification/users/page?userDomain=TESTUSER&amp;limit=10&amp;offset=0&#x27;)      .set(&#x27;Accept&#x27;, &#x27;application/json&#x27;)      .expect(&#x27;Content-Type&#x27;, &#x27;application/json; charset=utf-8&#x27;)      .expect(200, done)      .expect(function(res) &#123;        assert.equal(res.body.success, true);      &#125;)  &#125;)&#125;)\n\n使用 Istanbul.js来统计 Unit Test的代码覆盖率&#123; &quot;scripts&quot;: &#123;   &quot;unit-test-cov&quot;: &quot;istanbul cover node_modules/mocha/bin/_mocha -- test/controller test/routes test/common test/service&quot; &#125;&#125;\n\n只需要在istanbul cover命令后面加上mocha的命令即可\n若有不想统计的代码可以使用/* istanbul ignore next */注释来忽略掉，但是istanbul不支持文件忽略，只支持函数、选择条件级别的忽略。\n","categories":["Back-end"],"tags":["Node.js","Unit test"]},{"title":"Oracle PL","url":"/2017/07/30/Nodejs/Node.js%E4%B8%AD%E4%BD%BF%E7%94%A8Authenticator(%E4%B8%A4%E9%83%A8%E9%AA%8C%E8%AF%81%E5%99%A8)/","content":"Node.js Authenticator：https://www.npmjs.com/package/authenticator\nTwo- and Multi- Factor Authenication (2FA &#x2F; MFA) for node.js\n关于验证器Google现在也推荐用户启用两步验证（Two-step verification）功能（Youtube上的视频介绍），并且除了以短信或者电话的方式发送一次性密码之外，还提供了另一种基于时间的一次性密码（Time-based One-time Password，简称TOTP），只需要在手机上安装密码生成应用程序，就可以生成一个随着时间变化的一次性密码，用于帐户验证，而且这个应用程序不需要连接网络即可工作。仔细看了看这个方案的实现原理，发现挺有意思的。下面简单介绍一下。\nGoogle的两步验证算法源自另一种名为HMAC-Based One-Time Password的算法，简称HOTP。HOTP的工作原理如下：\n客户端和服务器事先协商好一个密钥K，用于一次性密码的生成过程，此密钥不被任何第三方所知道。此外，客户端和服务器各有一个计数器C，并且事先将计数值同步。\n进行验证时，客户端对密钥和计数器的组合(K,C)使用HMAC（Hash-based Message Authentication Code）算法计算一次性密码，公式如下：\nHOTP(K,C) = Truncate(HMAC-SHA-1(K,C))\n\n上面采用了HMAC-SHA-1，当然也可以使用HMAC-MD5等。HMAC算法得出的值位数比较多，不方便用户输入，因此需要截断（Truncate）成为一组不太长十进制数（例如6位）。计算完成之后客户端计数器C计数值加1。用户将这一组十进制数输入并且提交之后，服务器端同样的计算，并且与用户提交的数值比较，如果相同，则验证通过，服务器端将计数值C增加1。如果不相同，则验证失败。\n这里的一个比较有趣的问题是，如果验证失败或者客户端不小心多进行了一次生成密码操作，那么服务器和客户端之间的计数器C将不再同步，因此需要有一个重新同步（Resynchronization）的机制。这里不作具体介绍，详情可以参看RFC 4226。\n介绍完了HOTP，Time-based One-time Password（TOTP）也就容易理解了。TOTP将HOTP中的计数器C用当前时间T来替代，于是就得到了随着时间变化的一次性密码。非常有趣吧！\nGoogle选择了30秒作为时间片，T的数值为从Unix epoch（1970年1月1日 00:00:00）来经历的30秒的个数。事实上，这个方法还有一个另外的功能。我们知道如果客户端和服务器的时钟有偏差，会造成与上面类似的问题，也就是客户端生成的密码和服务端生成的密码不一致。但是，如果服务器通过计算前n个时间片的密码并且成功验证之后，服务器就知道了客户端的时钟偏差。因此，下一次验证时，服务器就可以直接将偏差考虑在内进行计算，而不需要进行n次计算。\nInstallnpm install authenticator --save\n\nUsage&#x27;use strict&#x27;; var authenticator = require(&#x27;authenticator&#x27;); var formattedKey = authenticator.generateKey();// &quot;acqo ua72 d3yf a4e5 uorx ztkh j2xl 3wiz&quot;// 这个formattedKey就是客户端或令牌在手动输入模式下需要输入的密钥 var formattedToken = authenticator.generateToken(formattedKey);// &quot;957 124&quot;// 这个是根据密钥和时间动态生成的验证码用于和来自用户输入的验证码比较 authenticator.verifyToken(formattedKey, formattedToken);// &#123; delta: 0 &#125;// 验证验证码是否匹配 authenticator.verifyToken(formattedKey, &#x27;000 000&#x27;);// null// 验证验证码是否匹配 authenticator.generateTotpUri(formattedKey, &quot;john.doe@email.com&quot;, &quot;ACME Co&quot;, &#x27;SHA1&#x27;, 6, 30);// 生成otpauth用于生成二维码给客户端扫码// otpauth://totp/ACME%20Co:john.doe@email.com?secret=HXDMVJECJJWSRB3HWIZR4IFUGFTMXBOZ&amp;issuer=ACME%20Co&amp;algorithm=SHA1&amp;digits=6&amp;period=30\n","categories":["Back-end"],"tags":["Node.js","Authenticator","Security"]},{"title":"SpringBoot-原理初探","url":"/2020/03/23/SpringBoot/SpringBoot-%E5%8E%9F%E7%90%86%E5%88%9D%E6%8E%A2/","content":"自动配置启动器&lt;dependency&gt;\t&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\t&lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;\n\n是SpringBoot的启动场景\n比如使用spring-boot-starter-web，他会帮我们自动导入web环境所有的依赖\nSpringBoot会将所有的场景都变成一个个的启动器，我们要使用什么功能就只需要引入对应的启动器即可\nStarters 启动器列表\n注解@SpringBootConfiguration: springboot的配置  @Configuration: Spring的配置类    @Component: 是Spring的组件@EnableAutoConfiguration: 自动配置  @AutoConfigurationPackage: 自动配置包    @Import(AutoConfigurationPackages.Registrar.class): 自动配置包注册  @Import(AutoConfigurationImportSelector.class): 自动配置导入选择\n\norg&#x2F;springframework&#x2F;boot&#x2F;autoconfigure&#x2F;AutoConfigurationImportSelector.java\nprotected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata,\t\tAnnotationMetadata annotationMetadata) &#123;\t//...   // 获取所有配置\tList&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes);\t//...&#125; protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123;\tList&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(),\t\t\tgetBeanClassLoader());\tAssert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot;\t\t\t+ &quot;are using a custom packaging, make sure that file is correct.&quot;);\treturn configurations; &#125;\n\nMETA-INF&#x2F;spring.factories: 自动配置的核心文件\n\n\norg&#x2F;springframework&#x2F;core&#x2F;io&#x2F;support&#x2F;SpringFactoriesLoader.java\npublic static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryType, @Nullable ClassLoader classLoader) &#123;\tString factoryTypeName = factoryType.getName();\treturn loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList());&#125;private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123;\tMultiValueMap&lt;String, String&gt; result = cache.get(classLoader);\tif (result != null) &#123;\t\treturn result;\t&#125;\ttry &#123;\t\tEnumeration&lt;URL&gt; urls = (classLoader != null ?\t\t\t\tclassLoader.getResources(FACTORIES_RESOURCE_LOCATION) : // FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;\t\t\t\tClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION));\t\tresult = new LinkedMultiValueMap&lt;&gt;();\t\twhile (urls.hasMoreElements()) &#123; // 判断有没有更多的元素\t\t\tURL url = urls.nextElement();\t\t\tUrlResource resource = new UrlResource(url);\t\t\tProperties properties = PropertiesLoaderUtils.loadProperties(resource); // 所有的资源加载到配置类中\t\t\tfor (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123;\t\t\t\tString factoryTypeName = ((String) entry.getKey()).trim();\t\t\t\tfor (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123;\t\t\t\t\tresult.add(factoryTypeName, factoryImplementationName.trim());\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tcache.put(classLoader, result);\t\treturn result;\t&#125;\tcatch (IOException ex) &#123;\t\tthrow new IllegalArgumentException(&quot;Unable to load factories from location [&quot; +\t\t\t\tFACTORIES_RESOURCE_LOCATION + &quot;]&quot;, ex);\t&#125;&#125;\n\n结论：springboot所有的自动配置都是在启动的时候扫描并加载：spring.factories中的所有的自动配置类，但是不一定全部都生效，要判断条件是否成立，只要导入了对应的start，就有对应的启动器了，有了启动器，我们自动装配就会生效，然后就配置成功了\n\nspringboot在启动的时候从类路径下META-INF/spring.factories获取指定的值\n将这些配置的类导入容器，自动配置就会生效，帮我们进行自动配置\n以前需要我们配置的东西，现在springboot帮我们做了\n整合javaEE，解决方案和自动配置的东西都在spring-boot-test-autoconfigure-2.2.5.RELEASE.jar这个包下\n它会把所有需要导入的组件，以类名的方式返回，这些组件就会被添加到容器了\nspring.factories中存在许多xxxAutoConfiguration的文件(@Bean)，就是这些类给容器中导入类这个场景需要的所有组件，并自动配置\n有了自动配置类(@Configuration)，免去了我们手动配置\n\napplication配置文件如何知道可以在配置文件中配置哪些项目？\n\nMETA-INF/spring.factories下存在被加载的配置类\n以HttpEncodingAutoConfiguration为例，进入HttpEncodingAutoConfiguration.java\n@EnableConfigurationProperties(HttpProperties.class)可以看到该类关联了HttpProperties.class做为Properties\n该类里面的属性为@ConfigurationProperties(prefix = &quot;spring.http&quot;)配置的前缀后的属性\n\n//从配置文件中获取指定的值和bean的属性进行绑定@ConfigurationProperties(prefix = &quot;spring.http&quot;)public class HttpProperties &#123;\t//...&#125;\n\n主启动类运行原理@SpringBootApplication // 标志该类为springboot启动类public class SpringBootDemoApplication &#123;\tpublic static void main(String[] args) &#123;    // 该方法返回一个ConfigurableApplicationContext对象\t\tSpringApplication.run(SpringBootDemoApplication.class, args);\t&#125;&#125;\n\n类SpringApplication做了以下事情：\n\n推动应用的类型是普通项目还是web项目\n查找并加载所有可用的初始化器，设置到initializers属性中\n找出所有的应用程序监听器，设置到listeners属性中\n推断并设置main方法的定义类，找到运行的主类\n\n静态资源加载WebMvcAutoConfiguration.java\n@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123;\tif (!this.resourceProperties.isAddMappings()) &#123; // 判断是否有自定义静态文件路径\t\tlogger.debug(&quot;Default resource handling disabled&quot;);\t\treturn;\t&#125;\tDuration cachePeriod = this.resourceProperties.getCache().getPeriod();\tCacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl();\tif (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) &#123;\t\tcustomizeResourceHandlerRegistration(registry.addResourceHandler(&quot;/webjars/**&quot;)\t\t\t\t.addResourceLocations(&quot;classpath:/META-INF/resources/webjars/&quot;)\t\t\t\t.setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\t&#125;\tString staticPathPattern = this.mvcProperties.getStaticPathPattern();\tif (!registry.hasMappingForPattern(staticPathPattern)) &#123;\t\tcustomizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern)\t\t\t\t.addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations()))\t\t\t\t.setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\t&#125;&#125;\n\nWebMvcProperties.java\nprivate String staticPathPattern = &quot;/**&quot;;public String getStaticPathPattern() &#123;\treturn this.staticPathPattern;&#125;\n\nResourceProperties.java\nprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; &quot;classpath:/META-INF/resources/&quot;,\t\t&quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &#125;;/** * Locations of static resources. Defaults to classpath:[/META-INF/resources/, * /resources/, /static/, /public/]. */private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS;\n\n静态资源加载方法\nwebjars\n映射到：localhost:8080/webjars/\n\n\npublic, static, &#x2F;**, resources目录下\n映射到：localhost:8080/\n\n\n\n静态资源加载路径优先级resources &gt; static(默认) &gt; public\n自定义静态资源路径application.properties\nspring.mvc.static-path-pattern=/hello,classpath:/test/\n\n国际化WebMvcAutoConfiguration.java:\n@Bean@ConditionalOnMissingBean@ConditionalOnProperty(prefix = &quot;spring.mvc&quot;, name = &quot;locale&quot;)public LocaleResolver localeResolver() &#123;\t// 用户配了就用用户配置，否则使用默认配置\tif (this.mvcProperties.getLocaleResolver() == WebMvcProperties.LocaleResolver.FIXED) &#123;\t\treturn new FixedLocaleResolver(this.mvcProperties.getLocale());\t&#125;\tAcceptHeaderLocaleResolver localeResolver = new AcceptHeaderLocaleResolver();\tlocaleResolver.setDefaultLocale(this.mvcProperties.getLocale());\treturn localeResolver;&#125;\n\n可以看到这里使用到了AcceptHeaderLocaleResolver这个类来进行国际化解析\npublic class AcceptHeaderLocaleResolver implements LocaleResolver &#123;\t//...\t@Override\tpublic Locale resolveLocale(HttpServletRequest request) &#123;\t\tLocale defaultLocale = getDefaultLocale();\t\tif (defaultLocale != null &amp;&amp; request.getHeader(&quot;Accept-Language&quot;) == null) &#123;\t\t\treturn defaultLocale;\t\t&#125;\t\tLocale requestLocale = request.getLocale();\t\tList&lt;Locale&gt; supportedLocales = getSupportedLocales();\t\tif (supportedLocales.isEmpty() || supportedLocales.contains(requestLocale)) &#123;\t\t\treturn requestLocale;\t\t&#125;\t\tLocale supportedLocale = findSupportedLocale(request, supportedLocales);\t\tif (supportedLocale != null) &#123;\t\t\treturn supportedLocale;\t\t&#125;\t\treturn (defaultLocale != null ? defaultLocale : requestLocale);\t&#125;\t//...&#125;\n\n配置自己的国际化解析器和AcceptHeaderLocaleResolver一样需要继承LocaleResolver类，并实现resolveLocale和setLocale这两个方法\ncom/sicmatr1x/config/MyLocaleResolver.java:\npackage com.sicmatr1x.config;import java.util.Locale;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import org.springframework.util.StringUtils;import org.springframework.web.servlet.LocaleResolver;public class MyLocaleResolver implements LocaleResolver &#123;  // 解析请求  @Override  public Locale resolveLocale(HttpServletRequest request) &#123;    // 获取请求中的语言参数    String language = request.getParameter(&quot;l&quot;);    Locale locale = Locale.getDefault(); // 如果没有就使用默认的    // 若请求链接携带了国际化参数    if (!StringUtils.isEmpty(language)) &#123;      String[] split = language.split(&quot;_&quot;); // zh_CN      // 国家，地区      locale = new Locale(split[0], split[1]);    &#125;    return locale;  &#125;  @Override  public void setLocale(HttpServletRequest request, HttpServletResponse response, Locale locale) &#123;  &#125;&#125;\n\n然后需要到MyMvcConfig中去注册即可\ncom/sicmatr1x/config/MyMvcConfig.java:\n@Configurationpublic class MyMvcConfig implements WebMvcConfigurer &#123;  @Override  public void addViewControllers(ViewControllerRegistry registry) &#123;    registry.addViewController(&quot;/&quot;).setViewName(&quot;index&quot;);    registry.addViewController(&quot;/index.html&quot;).setViewName(&quot;index&quot;);  &#125;  @Bean  public LocaleResolver localeResolver() &#123;    return new MyLocaleResolver();  &#125;&#125;\n\n\n\n","categories":["Back-end"],"tags":["SpringBoot"]},{"title":"SpringCloud Alibaba","url":"/2020/07/13/SpringBoot/SpringCloud-Alibaba/","content":"\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n\n\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n\nGitHub: alibaba&#x2F;spring-cloud-alibaba 官方中文文档\n主要功能\n服务限流降级：默认支持 WebServlet、WebFlux, OpenFeign、RestTemplate、Spring Cloud Gateway, Zuul, Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。\n服务注册与发现：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。\n分布式配置管理：支持分布式系统中的外部化配置，配置更改时自动刷新。\n消息驱动能力：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。\n分布式事务：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。。\n阿里云对象存储：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。\n分布式任务调度：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。\n阿里云短信服务：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。\n\n组件\nSentinel：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\nNacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\nRocketMQ：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。\nDubbo：Apache Dubbo™ 是一款高性能 Java RPC 框架。\nSeata：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\nAlibaba Cloud ACM：一款在分布式架构环境中对应用配置进行集中管理和推送的应用配置中心产品。\nAlibaba Cloud OSS: 阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。\nAlibaba Cloud SchedulerX: 阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。\nAlibaba Cloud SMS: 覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。\n\nNacosNacos：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\nNacos 配置中心核心概念：\n命名空间：用于进行配置隔离，不同命名空间下可以存着相同的Group或Data ID的配置。默认为public(保留空间)\n\n命名空间可以用于做环境隔离，注意：需要在bootstrap.properties里配置需要使用哪个命名空间下的配置\nspring.cloud.nacos.config.namespace=72d7c7bf-e241-49be-b0bf-73faace102b9\n\n细节也可以用于对每一个微服务之间互相隔离，每一个微服务创建一个命名空间，只加载自己命名空间下配置\n\n配置集：所有的配置的集合\n配置集ID(Data ID)：类似于配置文件名\n配置分组：在一个命名空间下相同的配置集ID可以在不同的分组里面创建多个，可用于批量切换配置即切换一下分组就完成了每个微服务的配置文件切换，默认所有的配置集都属于DEFAULT_GROUP\n\n项目中的使用：每个微服务创建自己的命名空间，使用配置分组区分环境，dev，test，prod\n同时加载多个配置集\n微服务任何配置信息，任何配置文件都可以放在配置中心中\n只需要在bootstrap.properties说明加载配置中心中哪些配置文件即可\n@Value，@ConfigurationProperties\n\n\n以前SpringBoot任何方法从配置文件中获取值，都能使用。\n配置中心有的优先使用配置中心中的，\n\nSpringCloud Gateway\n开启服务注册发现 (配置nacos的注册中心地址)\n编写网关配置文件\n\n","categories":["Back-end"],"tags":["踩坑","SpringCloud"]},{"title":"SpringBoot-踩坑","url":"/2020/02/10/SpringBoot/SpringBoot-%E8%B8%A9%E5%9D%91/","content":"常用功能多环境切换yml方式可将多个环境的配置放在一个application.yml文件里，使用---来进行分割:\nserver:  port: 8090spring:  profiles:    active: dev---server:  port: 8092spring:  profiles: dev---server:  port: 8091spring:  profiles: prd\n\n使用active属性来进行环境切换\n\nQ &amp; AMySQL 相关java.sql.SQLException: Unable to load authentication plugin &#39;caching_sha2_password&#39;.出错原因：\nmysql 8.0 默认使用 caching_sha2_password 身份验证机制，而之前的版本默认使用 mysql_native_password 身份验证机制\n解决办法：\n修改加密规则 ：\nALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;password&#x27; PASSWORD EXPIRE NEVER;ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED WITH mysql_native_password BY &#x27;password&#x27;;\n\n刷新权限：\nFLUSH PRIVILEGES;\n\n重置密码：\nALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;Friday13&#x27;;\n\nUnknown system variable &#39;query_cache_size&#39;出错原因：\nmysql-connecter-java的版本过低，很显然是数据库驱动程序与数据库版本不对应\n解决办法：\n如 mybatis使用 mysql-5.1.14的驱动程序，而mybatis配置的数据源连接的是 mysql-8.0.11 ，修改 pom文件即可\n&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt;\n\n// 依赖关系dependencies &#123;\t// 添加 MySQL连接驱动 的依赖\tcompile(&#x27;mysql:mysql-connector-java:8.0.11&#x27;)&#125;\n\n官方的说法是 :\nThe query cache is deprecated as of MySQL 5.7.20, and is removed in MySQL 8.0. Deprecation includes query_cache_size.\n意思是query cache在MySQL5.7.20就已经过时了，而在MySQL8.0之后就已经被移除了。\n下表从官网总结了可用的Connector &#x2F; JDBC版本，以及JDBC驱动程序类型的详细信息，支持的JDBC API版本，支持的MySQL服务器版本，支持的JRE，构建所需的JDK以及每个连接器的支持状态&#x2F; JDBC版本\n\n运行程序不报错，单元测试报错java.lang.IllegalStateException: Failed to load ApplicationContextFailed to load ApplicationContextjava.lang.IllegalStateException: Failed to load ApplicationContext\tat org.springframework.test.context.cache.DefaultCacheAwareContextLoaderDelegate.loadContext(DefaultCacheAwareContextLoaderDelegate.java:124)\tat org.springframework.test.context.support.DefaultTestContext.getApplicationContext(DefaultTestContext.java:83)\tat org.springframework.test.context.web.ServletTestExecutionListener.setUpRequestContextIfNecessary(ServletTestExecutionListener.java:189)\tat org.springframework.test.context.web.ServletTestExecutionListener.prepareTestInstance(ServletTestExecutionListener.java:131)\tat org.springframework.test.context.TestContextManager.prepareTestInstance(TestContextManager.java:230)    ...Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &#x27;entityManagerFactory&#x27; defined in class path resource [org/springframework/boot/autoconfigure/orm/jpa/HibernateJpaAutoConfiguration.class]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: javax/xml/bind/JAXBException\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1628)\n\n出错原因：\n有bean没有加上jpa注解\nSpringBoot无法访问&#x2F;static下静态资源出错原因：\n@EnableWebMvc注解导致了WebMvcAutoConfiguration类没有生效\n原因分析：\nSpringBoot 访问静态资源的规则，都在WebMvcAutoConfiguration自动配置类中\nWebMvcAutoConfiguration.java:\n  @Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123;\tif (!this.resourceProperties.isAddMappings()) &#123;\t\tlogger.debug(&quot;Default resource handling disabled&quot;);\t\treturn;\t&#125;\tDuration cachePeriod = this.resourceProperties.getCache().getPeriod();\tCacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl();\tif (!registry.hasMappingForPattern(&quot;/webjars/**&quot;)) &#123;\t\tcustomizeResourceHandlerRegistration(registry.addResourceHandler(&quot;/webjars/**&quot;)\t\t\t\t.addResourceLocations(&quot;classpath:/META-INF/resources/webjars/&quot;)\t\t\t\t.setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\t&#125;\tString staticPathPattern = this.mvcProperties.getStaticPathPattern();\tif (!registry.hasMappingForPattern(staticPathPattern)) &#123;\t\tcustomizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern)\t\t\t\t.addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations()))\t\t\t\t.setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl));\t&#125;&#125;\n\nResourceProperties.java:\nprivate static final String[] CLASSPATH_RESOURCE_LOCATIONS = &#123; &quot;classpath:/META-INF/resources/&quot;,\t\t&quot;classpath:/resources/&quot;, &quot;classpath:/static/&quot;, &quot;classpath:/public/&quot; &#125;;/** * Locations of static resources. Defaults to classpath:[/META-INF/resources/, * /resources/, /static/, /public/]. */private String[] staticLocations = CLASSPATH_RESOURCE_LOCATIONS; //...public String[] getStaticLocations() &#123;\treturn this.staticLocations;&#125;\n\n默认按照该(CLASSPATH_RESOURCE_LOCATIONS)加载顺序，加载静态资源文件\n继续看WebMvcAutoConfiguration.java:\n@Configuration(proxyBeanMethods = false)@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, TaskExecutionAutoConfiguration.class,\t\tValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123;  //...&#125;\n\n发现有以下注解@ConditionalOnMissingBean(WebMvcConfigurationSupport.class): 在WebMvcConfigurationSupport.class这个类没有的情况下，才会走SpringBoot的Web自动配置\n@EnableWebMvc.java:\n@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documented@Import(DelegatingWebMvcConfiguration.class)public @interface EnableWebMvc &#123;&#125;\n\nDelegatingWebMvcConfiguration.java:\n@Configuration(proxyBeanMethods = false)public class DelegatingWebMvcConfiguration extends WebMvcConfigurationSupport &#123;  //...&#125;\n\n可以看到@EnableWebMvc注解加载了DelegatingWebMvcConfiguration.class类，而这个类又继承了WebMvcConfigurationSupport类\n解决办法：去掉@EnableWebMvc注解\n\n\nIf you want to keep Spring Boot MVC features and you want to add additional MVC configuration (interceptors, formatters, view controllers, and other features), you can add your own @Configuration class of type WebMvcConfigurer but without @EnableWebMvc. If you wish to provide custom instances of RequestMappingHandlerMapping, RequestMappingHandlerAdapter, or ExceptionHandlerExceptionResolver, you can declare a WebMvcRegistrationsAdapter instance to provide such components.\nIf you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc.\n\n\n官方解释：https://docs.spring.io/spring-boot/docs/2.1.7.RELEASE/reference/html/boot-features-developing-web-applications.html#boot-features-spring-mvc-auto-configuration\n","categories":["Back-end"],"tags":["踩坑","SpringBoot"]},{"title":"Spring注解驱动开发","url":"/2020/05/12/SpringBoot/Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/","content":"容器组件注册@Configuration &amp; @Bean 给容器中注册组件配置类相当于以前的配置文件beans.xml\n配置类：\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;import org.springframework.stereotype.Controller;@Configuration // 告诉Spring这是一个配置类@ComponentScan(value = &quot;com.sicmatr1x&quot;, excludeFilters = &#123;        @Filter(type = FilterType.ANNOTATION, classes = &#123;Controller.class&#125;)&#125;) // 手动配置包扫描，扫描com.sicmatr1x包下的内容，exclude可以排除不想注入的类，这里按照注解排除了使用到Controller注解的类// @ComponentScan value:指定要扫描的包// excludeFilters = Filter[] 指定扫描的时候按照什么规则排除哪些组件// includeFilters = Filter[] 指定扫描的时候按照什么规则包含哪些组件// useDefaultFilters = false 可以关闭默认的filterpublic class MainConfig &#123;    @Bean(&quot;person&quot;) // 给容器中注册一个bean，类型为返回值的类型，id默认为方法名，也可自定义    public Person person()&#123;        return new Person(&quot;Abby&quot;, 20);    &#125;&#125;\n\n测试配置类：\npackage com.sicmatr1x.test;import com.sicmatr1x.bean.Person;import com.sicmatr1x.config.MainConfig;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainTest &#123;    public static void main(String[] args) &#123;        // 传统xml方式//        ApplicationContext applicationContext = new ClassPathXmlApplicationContext(&quot;bean.xml&quot;);//        Person bean = (Person) applicationContext.getBean(&quot;person&quot;);//        System.out.println(bean);        // 以前传配置文件，现在传配置类        ApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfig.class);        Person bean = applicationContext.getBean(Person.class);        System.out.println(bean);    &#125;&#125;\n\n@ComponentScan 自动扫描组件&amp;指定扫描规则查看IOT容器里面有哪些对象：\nimport com.sicmatr1x.config.MainConfig;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class IOCTest &#123;    @SuppressWarnings(&quot;resource&quot;)    @Test    public void test01()&#123;        AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfig.class);        String[] beanNames = annotationConfigApplicationContext.getBeanDefinitionNames();        for (String beanName : beanNames) &#123;            System.out.println(beanName);        &#125;    &#125;&#125;\n\n运行结果：\norg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaobookServiceperson\n\n因为上面使用了excludeFilters = &#123;@Filter(type = FilterType.ANNOTATION, classes = &#123;Controller.class&#125;所以IOT容器中注入了除了BookController以外的其它位于包com.sicmatr1x下的类的对象\n我们再看下其它的Filter，进入到FilterType.class里面\nFilterType.java:\n/* * Copyright 2002-2013 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *      http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.context.annotation;/** * Enumeration of the type filters that may be used in conjunction with * &#123;@link ComponentScan @ComponentScan&#125;. * * @author Mark Fisher * @author Juergen Hoeller * @author Chris Beams * @since 2.5 * @see ComponentScan * @see ComponentScan#includeFilters() * @see ComponentScan#excludeFilters() * @see org.springframework.core.type.filter.TypeFilter */public enum FilterType &#123;\t/**\t * Filter candidates marked with a given annotation.\t * @see org.springframework.core.type.filter.AnnotationTypeFilter\t */\tANNOTATION,\t/**\t * Filter candidates assignable to a given type.\t * @see org.springframework.core.type.filter.AssignableTypeFilter\t */\tASSIGNABLE_TYPE,\t/**\t * Filter candidates matching a given AspectJ type pattern expression.\t * @see org.springframework.core.type.filter.AspectJTypeFilter\t */\tASPECTJ,\t/**\t * Filter candidates matching a given regex pattern.\t * @see org.springframework.core.type.filter.RegexPatternTypeFilter\t */\tREGEX,\t/** Filter candidates using a given custom\t * &#123;@link org.springframework.core.type.filter.TypeFilter&#125; implementation.\t */\tCUSTOM&#125;\n\n\nANNOTATION: 按照注解来进行过滤\neg: @Filter(type = FilterType.ANNOTATION, classes = &#123;Controller.class&#125;\n\n\nASSIGNABLE_TYPE: 按照给定的类型来进行过滤\neg: @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = &#123;BookController.class&#125;\n\n\nASPECTJ: 按照AspectJ表达式来进行过滤\nREGEX: 按照正则表达式来进行过滤\nCUSTOM: 按照自定义规则来进行过滤，需要自定义一个org.springframework.core.type.filter.TypeFilter的实现类\n\n自定义TypeFilter指定过滤规则实现org.springframework.core.type.filter.TypeFilter类：\npackage com.sicmatr1x.config;import org.springframework.core.io.Resource;import org.springframework.core.type.AnnotationMetadata;import org.springframework.core.type.ClassMetadata;import org.springframework.core.type.classreading.MetadataReader;import org.springframework.core.type.classreading.MetadataReaderFactory;import org.springframework.core.type.filter.TypeFilter;import java.io.IOException;public class MyTypeFilter implements TypeFilter &#123;    /**     *     * @param metadataReader the metadata reader for the target class 读取到当前正在扫描的类的信息     * @param metadataReaderFactory a factory for obtaining metadata readers 可以获取到其它任何类信息的     * @return true: 匹配成功; false: 匹配失败     * @throws IOException     */    @Override    public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123;        // 获取当前类注解的信息        AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata();        // 获取当前正在扫描的类的类信息        ClassMetadata classMetadata = metadataReader.getClassMetadata();        // 获取当前类资源(类路径等)信息        Resource resource = metadataReader.getResource();        String className = classMetadata.getClassName();        System.out.println(&quot;className:&quot; + className);        return false;    &#125;&#125;\n\n在Config类里面使用我们的Filter类：\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.ComponentScan.Filter;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.FilterType;@Configuration@ComponentScan(value = &quot;com.sicmatr1x&quot;, excludeFilters = &#123;        @Filter(type = FilterType.CUSTOM, classes = &#123;MyTypeFilter.class&#125;)&#125;)public class MainConfig &#123;    @Bean(&quot;person&quot;)    public Person person()&#123;        return new Person(&quot;Abby&quot;, 20);    &#125;&#125;\n\n输出：\nclassName:com.sicmatr1x.bean.PersonclassName:com.sicmatr1x.config.MyTypeFilterclassName:com.sicmatr1x.controller.BookControllerclassName:com.sicmatr1x.dao.BookDaoclassName:com.sicmatr1x.service.BookServiceclassName:com.sicmatr1x.test.MainTestorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookControllerbookDaobookServiceperson\n\n这里没有类被排除是因为我们的自定义规则里面总是返回false，所以一个都没有被排除\n修改一下代码：\npackage com.sicmatr1x.config;import org.springframework.core.io.Resource;import org.springframework.core.type.AnnotationMetadata;import org.springframework.core.type.ClassMetadata;import org.springframework.core.type.classreading.MetadataReader;import org.springframework.core.type.classreading.MetadataReaderFactory;import org.springframework.core.type.filter.TypeFilter;import java.io.IOException;public class MyTypeFilter implements TypeFilter &#123;    /**     *     * @param metadataReader the metadata reader for the target class 读取到当前正在扫描的类的信息     * @param metadataReaderFactory a factory for obtaining metadata readers 可以获取到其它任何类信息的     * @return true: 匹配成功; false: 匹配失败     * @throws IOException     */    @Override    public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException &#123;        // 获取当前类注解的信息        AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata();        // 获取当前正在扫描的类的类信息        ClassMetadata classMetadata = metadataReader.getClassMetadata();        // 获取当前类资源(类路径等)信息        Resource resource = metadataReader.getResource();        String className = classMetadata.getClassName();        System.out.println(&quot;className:&quot; + className);        if(className.contains(&quot;er&quot;)) &#123;            return true;        &#125;        return false;    &#125;&#125;\n\n输出：\nclassName:com.sicmatr1x.bean.PersonclassName:com.sicmatr1x.config.MyTypeFilterclassName:com.sicmatr1x.controller.BookControllerclassName:com.sicmatr1x.dao.BookDaoclassName:com.sicmatr1x.service.BookServiceclassName:com.sicmatr1x.test.MainTestorg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfigbookDaoperson\n\n与之前相比少了bookController, bookService，其实这里还排除了MyTypeFilter，不过这个类本来就用annotationConfigApplicationContext.getBeanDefinitionNames()获取不出来所以看不出效果\n@Scope 设置组件作用域众所周知，在spring里面注册一个bean并托管到IOT容器中之后该bean是单实例的，无论你get几次都是获得的同一个对象\n可以使用@Scope注解来限定对象范围\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Scope;@Configurationpublic class MainConfig2 &#123;    @Scope    @Bean(&quot;person&quot;)    public Person person()&#123;        return new Person(&quot;Bob&quot;, 30);    &#125;&#125;\n\n点进@Scope注解里面看一下：\n/* * Copyright 2002-2015 the original author or authors. * * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * *      http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an &quot;AS IS&quot; BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.springframework.context.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.beans.factory.config.ConfigurableBeanFactory;import org.springframework.core.annotation.AliasFor;/** * When used as a type-level annotation in conjunction with * &#123;@link org.springframework.stereotype.Component @Component&#125;, * &#123;@code @Scope&#125; indicates the name of a scope to use for instances of * the annotated type. * * &lt;p&gt;When used as a method-level annotation in conjunction with * &#123;@link Bean @Bean&#125;, &#123;@code @Scope&#125; indicates the name of a scope to use * for the instance returned from the method. * * &lt;p&gt;In this context, &lt;em&gt;scope&lt;/em&gt; means the lifecycle of an instance, * such as &#123;@code singleton&#125;, &#123;@code prototype&#125;, and so forth. Scopes * provided out of the box in Spring may be referred to using the * &#123;@code SCOPE_*&#125; constants available in the &#123;@link ConfigurableBeanFactory&#125; * and &#123;@code WebApplicationContext&#125; interfaces. * * &lt;p&gt;To register additional custom scopes, see * &#123;@link org.springframework.beans.factory.config.CustomScopeConfigurer * CustomScopeConfigurer&#125;. * * @author Mark Fisher * @author Chris Beams * @author Sam Brannen * @since 2.5 * @see org.springframework.stereotype.Component * @see org.springframework.context.annotation.Bean */@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Scope &#123;\t/**\t * Alias for &#123;@link #scopeName&#125;.\t * @see #scopeName\t */\t@AliasFor(&quot;scopeName&quot;)\tString value() default &quot;&quot;;\t/**\t * Specifies the name of the scope to use for the annotated component/bean.\t * &lt;p&gt;Defaults to an empty string (&#123;@code &quot;&quot;&#125;) which implies\t * &#123;@link ConfigurableBeanFactory#SCOPE_SINGLETON SCOPE_SINGLETON&#125;.\t * @since 4.2\t * @see ConfigurableBeanFactory#SCOPE_PROTOTYPE\t * @see ConfigurableBeanFactory#SCOPE_SINGLETON\t * @see org.springframework.web.context.WebApplicationContext#SCOPE_REQUEST\t * @see org.springframework.web.context.WebApplicationContext#SCOPE_SESSION\t * @see #value\t */\t@AliasFor(&quot;value&quot;)\tString scopeName() default &quot;&quot;;\t/**\t * Specifies whether a component should be configured as a scoped proxy\t * and if so, whether the proxy should be interface-based or subclass-based.\t * &lt;p&gt;Defaults to &#123;@link ScopedProxyMode#DEFAULT&#125;, which typically indicates\t * that no scoped proxy should be created unless a different default\t * has been configured at the component-scan instruction level.\t * &lt;p&gt;Analogous to &#123;@code &lt;aop:scoped-proxy/&gt;&#125; support in Spring XML.\t * @see ScopedProxyMode\t */\tScopedProxyMode proxyMode() default ScopedProxyMode.DEFAULT;&#125;\n\n这里的@AliasFor注解是别名的意思，就是给其注解的字段一个别名，比如这里value就和scopeName等价了\n我们看下value能取哪些值，注释中就说了可以取以下类中的以下的值\n类名#值：\n\nConfigurableBeanFactory#SCOPE_PROTOTYPE\nConfigurableBeanFactory#SCOPE_SINGLETON\norg.springframework.web.context.WebApplicationContext#SCOPE_REQUEST\norg.springframework.web.context.WebApplicationContext#SCOPE_SESSION\n\n点进ConfigurableBeanFactory中：\npublic interface ConfigurableBeanFactory extends HierarchicalBeanFactory, SingletonBeanRegistry &#123;    String SCOPE_SINGLETON = &quot;singleton&quot;;    String SCOPE_PROTOTYPE = &quot;prototype&quot;;    //...&#125;\n\n可知：SCOPE_PROTOTYPE的值为prototype，其它以此类推\nvalue能取：\n\nsingleton: 单实例（默认值），IOC容器启动时会调用方法创建对象并托管到IOC容器中，以后每次获取直接从容器中拿\nprototype: 多实例，IOC容器启动时并不会调用方法创建对象，而是每次获取的时候才会调用方法创建对象，每次获取都会调一遍方法\nrequest: 同一次请求创建一个实例\nsession: 同一个session创建一个实例\n\n我们使用prototype试下：\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Scope;@Configurationpublic class MainConfig2 &#123;    @Scope(&quot;prototype&quot;)    @Bean(&quot;person&quot;)    public Person person()&#123;        return new Person(&quot;Bob&quot;, 30);    &#125;&#125;\n\n测试方法：\n@SuppressWarnings(&quot;resource&quot;)@Testpublic void test02()&#123;    AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfig2.class);    String[] beanNames = annotationConfigApplicationContext.getBeanDefinitionNames();    for (String beanName : beanNames) &#123;        System.out.println(beanName);    &#125;    Object bean = annotationConfigApplicationContext.getBean(&quot;person&quot;);    Object bean2 = annotationConfigApplicationContext.getBean(&quot;person&quot;);    System.out.println(&quot;bean == bean2: &quot; + (bean == bean2));&#125;\n\n输出：\norg.springframework.context.annotation.internalConfigurationAnnotationProcessororg.springframework.context.annotation.internalAutowiredAnnotationProcessororg.springframework.context.annotation.internalRequiredAnnotationProcessororg.springframework.context.annotation.internalCommonAnnotationProcessororg.springframework.context.event.internalEventListenerProcessororg.springframework.context.event.internalEventListenerFactorymainConfig2personbean == bean2: false\n\n可以看到已经不是单例了\n@Lazy-bean 懒加载懒加载主要针对单实例bean，单实例通常情况下IOC容器启动时会调用方法创建对象并托管到IOC容器中，以后每次获取直接从容器中拿。如果启用懒加载则会使得容器在启动时不创建对象，而是在第一次使用(获取)bean时创建对象\n@Lazy@Bean(&quot;person&quot;)public Person person()&#123;    return new Person(&quot;Bob&quot;, 30);&#125;\n\n@Conditional 按照条件注册bean该注解在spring底层大量使用，主要作用是按照一定的条件进行判断满足条件给容器中注册bean\n那么该如何使用@Conditional注解呢，我们点进去看到需要提供一个实现了Condition接口的类\npackage org.springframework.context.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Conditional &#123;\t/**\t * All &#123;@link Condition&#125;s that must &#123;@linkplain Condition#matches match&#125;\t * in order for the component to be registered.\t */\tClass&lt;? extends Condition&gt;[] value();&#125;\n\n@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;), 显然@Conditional注解可以用于方法和类\n点进去看下Condition接口：\npublic interface Condition &#123;\t/**\t * Determine if the condition matches.\t * @param context the condition context\t * @param metadata metadata of the &#123;@link org.springframework.core.type.AnnotationMetadata class&#125;\t * or &#123;@link org.springframework.core.type.MethodMetadata method&#125; being checked.\t * @return &#123;@code true&#125; if the condition matches and the component can be registered\t * or &#123;@code false&#125; to veto registration.\t */\tboolean matches(ConditionContext context, AnnotatedTypeMetadata metadata);&#125;\n\n显然需要实现matches方法，并且若返回为true则表示条件匹配成功\n假设我们需要做一个根据操作系统来判断并注入对应的bean的功能\npackage com.sicmatr1x.condition;import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;import org.springframework.beans.factory.support.BeanDefinitionRegistry;import org.springframework.context.annotation.Condition;import org.springframework.context.annotation.ConditionContext;import org.springframework.core.env.Environment;import org.springframework.core.type.AnnotatedTypeMetadata;public class LinuxCondition implements Condition &#123;    /**     * 判断是否为Linux系统     * @param context 判断条件能使用的上下文环境     * @param metadata 注解信息     * @return     */    @Override    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;        // 能获取到IOC使用的beanFactory        ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();        // 能获取到类加载器        ClassLoader classLoader = context.getClassLoader();        // 能获取到当前环境信息        Environment environment = context.getEnvironment();        // 能获取到bean定义的注册类(可用于查某个bean的定义或者注册bean)        BeanDefinitionRegistry registry = context.getRegistry();        String property = environment.getProperty(&quot;os.name&quot;);        if(property.contains(&quot;Linux&quot;)) &#123;            return true;        &#125;        return false;    &#125;&#125;\n\npackage com.sicmatr1x.condition;import org.springframework.context.annotation.Condition;import org.springframework.context.annotation.ConditionContext;import org.springframework.core.env.Environment;import org.springframework.core.type.AnnotatedTypeMetadata;public class WindowsCondition implements Condition &#123;    @Override    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) &#123;        // 能获取到当前环境信息        Environment environment = context.getEnvironment();        String property = environment.getProperty(&quot;os.name&quot;);        if(property.contains(&quot;Windows&quot;)) &#123;            return true;        &#125;        return false;    &#125;&#125;\n\n然后使用@Conditional注解\n@Conditional(&#123;WindowsCondition.class&#125;)@Bean(&quot;bill&quot;)public Person person01()&#123;    return new Person(&quot;Bill&quot;, 60);&#125;@Conditional(&#123;LinuxCondition.class&#125;)@Bean(&quot;Linus&quot;)public Person person02()&#123;    return new Person(&quot;Linus&quot;, 50);&#125;\n\n测试一下效果：\n@SuppressWarnings(&quot;resource&quot;)@Testpublic void test03()&#123;    AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfig2.class);    ConfigurableEnvironment environment = annotationConfigApplicationContext.getEnvironment();    String property = environment.getProperty(&quot;os.name&quot;);    System.out.println(property);    String[] namesForType = annotationConfigApplicationContext.getBeanNamesForType(Person.class);    for (String name : namesForType) &#123;        System.out.println(name);    &#125;    Map&lt;String, Person&gt; persons = annotationConfigApplicationContext.getBeansOfType(Person.class);&#125;\n\n输出：\nWindows 10personbill\n\n这里打印出了我们当前的操作系统为Windows 10，然后正确的注入了bill这个bean到IOT容器\n测试Linux可以在VM arguments里面配置虚拟机参数：\n-Dos.name=Linux\n\n输出：\nLinuxpersonLinus\n\n@Conditional注解还可以放在类上，作用是满足当前条件后这个类中配置的所有bean才能生效\n容器中注册组件方法\n包扫描+组件标注注解(@Controller, @Service, @Component)\n缺点：只能作用在自己写的类上，即需要修改需要注册的类的代码，导入的第三方包不可以采用此种方法\n\n\n@Bean注解，手动注册\n@Import注解，快速导入组件到容器，id默认是全类名\n\n@Import 给容器中快速导入一个组件package com.sicmatr1x.config;import com.sicmatr1x.bean.Color;import org.springframework.context.annotation.*;@Configuration@Import(Color.class)public class MainConfig2 &#123;&#125;\n\n批量导入：\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Color;import com.sicmatr1x.bean.Red;import org.springframework.context.annotation.*;@Configuration@Import(&#123;Color.class, Red.class&#125;)public class MainConfig2 &#123;&#125;\n\n@Import 使用ImportSelector这种方法在spring源码用用到的较多\n查看@Import的源码发现除了通常的组件类(regular component classes)作为参数传入以外还可以传入Configuration, ImportSelector, ImportBeanDefinitionRegistrar\n@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Import &#123;\t/**\t * &#123;@link Configuration&#125;, &#123;@link ImportSelector&#125;, &#123;@link ImportBeanDefinitionRegistrar&#125;\t * or regular component classes to import.\t */\tClass&lt;?&gt;[] value();&#125;\n\n查看ImportSelector源码: \npublic interface ImportSelector &#123;\t/**\t * Select and return the names of which class(es) should be imported based on\t * the &#123;@link AnnotationMetadata&#125; of the importing @&#123;@link Configuration&#125; class.\t */\tString[] selectImports(AnnotationMetadata importingClassMetadata);&#125;\n\n\nSelect and return the names of which class(es) should be imported\n\n显然selectImports方法会返回需要导入的类的全类名组成的数组\n在本项目中只有MainConfig2类里面使用到了@Import注解\n@Configuration@Import(&#123;Color.class, MyImportSelector.class&#125;)public class MainConfig2 &#123;    //...&#125;\n\n我们打个断点到selectImports方法上看看传入的参数：\n\n\n可以看到importingClassMetadata对象包含的：\n\nannotations对象数组里面获取到了MainConfig2类上面的2个注解\nintrospectedClass对象则获取到了MainConfig2类的类信息\n\n继续debug就可发现：若返回为null则会抛出空指针异常\n/** * Factory method to obtain &#123;@link SourceClass&#125;s from class names. */private Collection&lt;SourceClass&gt; asSourceClasses(String[] classNames) throws IOException &#123;\tList&lt;SourceClass&gt; annotatedClasses = new ArrayList&lt;SourceClass&gt;(classNames.length); // 这里调到了classNames.length，若返回为空，显然null没有length属性\tfor (String className : classNames) &#123;\t\tannotatedClasses.add(asSourceClass(className));\t&#125;\treturn annotatedClasses;&#125;\n\n推荐在没有class返回的情况下返回一个空数组\n实践一下：\npackage com.sicmatr1x.condition;import org.springframework.context.annotation.ImportSelector;import org.springframework.core.type.AnnotationMetadata;public class MyImportSelector implements ImportSelector &#123;    /**     *     * @param importingClassMetadata 当前标注@Import注解的类的所有的类的信息     * @return 返回需要导入的类的全类名     */    @Override    public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123;        return new String[]&#123;&quot;com.sicmatr1x.bean.Blue&quot;, &quot;com.sicmatr1x.bean.Yellow&quot;&#125;;    &#125;&#125;\n\n运行unit test，可以看到已经注册进来了\nmainConfig2com.sicmatr1x.bean.Colorcom.sicmatr1x.bean.Bluecom.sicmatr1x.bean.Yellowpersonbill\n\n@Import 使用ImportBeanDefinitionRegistrar从@Import源码里面继续点进去看ImportBeanDefinitionRegistrar的源码：\npublic interface ImportBeanDefinitionRegistrar &#123;\t/**\t * Register bean definitions as necessary based on the given annotation metadata of\t * the importing &#123;@code @Configuration&#125; class.\t * &lt;p&gt;Note that &#123;@link BeanDefinitionRegistryPostProcessor&#125; types may &lt;em&gt;not&lt;/em&gt; be\t * registered here, due to lifecycle constraints related to &#123;@code @Configuration&#125;\t * class processing.\t * @param importingClassMetadata annotation metadata of the importing class\t * @param registry current bean definition registry\t */\tpublic void registerBeanDefinitions(\t\t\tAnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry);&#125;\n\n\nimportingClassMetadata: 当前类的一些注解信息\nregistry: bean定义的注册类，可用于给程序中注册bean\n\n现在实现一下这个接口：\npackage com.sicmatr1x.condition;import com.sicmatr1x.bean.RainBow;import org.springframework.beans.factory.support.BeanDefinitionRegistry;import org.springframework.beans.factory.support.RootBeanDefinition;import org.springframework.context.annotation.ImportBeanDefinitionRegistrar;import org.springframework.core.type.AnnotationMetadata;public class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar &#123;    /**     * 把所有需要添加到容器中的bean，可以通过BeanDefinition注册类的registerBeanDefinition方法注册进IOT容器     * @param importingClassMetadata 当前类的注解信息     * @param registry BeanDefinition注册类，可用于给程序中注册bean     */    @Override    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;        // 判断IOT容器中是否已经注册了red和blue        boolean isRegisteredYellowClass = registry.containsBeanDefinition(&quot;com.sicmatr1x.bean.Yellow&quot;);        boolean isRegisteredBlueClass = registry.containsBeanDefinition(&quot;com.sicmatr1x.bean.Blue&quot;);        if(isRegisteredYellowClass &amp;&amp; isRegisteredBlueClass) &#123;            // 指定Bean定义信息(如Bean的类型、作用域等)            RootBeanDefinition beanDefinition = new RootBeanDefinition(RainBow.class);            // 注册bean，同时指定bean名            registry.registerBeanDefinition(&quot;rainBow&quot;, beanDefinition);        &#125;    &#125;&#125;\n\n使用方法同前面的MyImportSelector类：\n@Configuration@Import(&#123;Color.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class&#125;)public class MainConfig2 &#123;    //...&#125;\n\n运行unit test：\nmainConfig2com.sicmatr1x.bean.Colorcom.sicmatr1x.bean.Bluecom.sicmatr1x.bean.YellowpersonbillrainBow\n\n使用FactoryBean注册组件使用前先看FactoryBean源码：\npublic interface FactoryBean&lt;T&gt; &#123;\t/**\t * Return an instance (possibly shared or independent) of the object\t * managed by this factory.\t * &lt;p&gt;As with a &#123;@link BeanFactory&#125;, this allows support for both the\t * Singleton and Prototype design pattern.\t * &lt;p&gt;If this FactoryBean is not fully initialized yet at the time of\t * the call (for example because it is involved in a circular reference),\t * throw a corresponding &#123;@link FactoryBeanNotInitializedException&#125;.\t * &lt;p&gt;As of Spring 2.0, FactoryBeans are allowed to return &#123;@code null&#125;\t * objects. The factory will consider this as normal value to be used; it\t * will not throw a FactoryBeanNotInitializedException in this case anymore.\t * FactoryBean implementations are encouraged to throw\t * FactoryBeanNotInitializedException themselves now, as appropriate.\t * @return an instance of the bean (can be &#123;@code null&#125;)\t * @throws Exception in case of creation errors\t * @see FactoryBeanNotInitializedException\t */\tT getObject() throws Exception;\t/**\t * Return the type of object that this FactoryBean creates,\t * or &#123;@code null&#125; if not known in advance.\t * &lt;p&gt;This allows one to check for specific types of beans without\t * instantiating objects, for example on autowiring.\t * &lt;p&gt;In the case of implementations that are creating a singleton object,\t * this method should try to avoid singleton creation as far as possible;\t * it should rather estimate the type in advance.\t * For prototypes, returning a meaningful type here is advisable too.\t * &lt;p&gt;This method can be called &lt;i&gt;before&lt;/i&gt; this FactoryBean has\t * been fully initialized. It must not rely on state created during\t * initialization; of course, it can still use such state if available.\t * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; Autowiring will simply ignore FactoryBeans that return\t * &#123;@code null&#125; here. Therefore it is highly recommended to implement\t * this method properly, using the current state of the FactoryBean.\t * @return the type of object that this FactoryBean creates,\t * or &#123;@code null&#125; if not known at the time of the call\t * @see ListableBeanFactory#getBeansOfType\t */\tClass&lt;?&gt; getObjectType();\t/**\t * Is the object managed by this factory a singleton? That is,\t * will &#123;@link #getObject()&#125; always return the same object\t * (a reference that can be cached)?\t * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; If a FactoryBean indicates to hold a singleton object,\t * the object returned from &#123;@code getObject()&#125; might get cached\t * by the owning BeanFactory. Hence, do not return &#123;@code true&#125;\t * unless the FactoryBean always exposes the same reference.\t * &lt;p&gt;The singleton status of the FactoryBean itself will generally\t * be provided by the owning BeanFactory; usually, it has to be\t * defined as singleton there.\t * &lt;p&gt;&lt;b&gt;NOTE:&lt;/b&gt; This method returning &#123;@code false&#125; does not\t * necessarily indicate that returned objects are independent instances.\t * An implementation of the extended &#123;@link SmartFactoryBean&#125; interface\t * may explicitly indicate independent instances through its\t * &#123;@link SmartFactoryBean#isPrototype()&#125; method. Plain &#123;@link FactoryBean&#125;\t * implementations which do not implement this extended interface are\t * simply assumed to always return independent instances if the\t * &#123;@code isSingleton()&#125; implementation returns &#123;@code false&#125;.\t * @return whether the exposed object is a singleton\t * @see #getObject()\t * @see SmartFactoryBean#isPrototype()\t */\tboolean isSingleton();&#125;\n\n可以看到有三个方法：\n\nT getObject() throws Exception: 返回需要放到容器中的对象，这里是泛型也就是说工厂接口在实现时就已经确定了其只能返回某种类型的对象了\nClass&lt;?&gt; getObjectType(): 返回对象类型\nboolean isSingleton();: 是否为单例模式\n\n我们实现一下这个接口：\npackage com.sicmatr1x.bean;import org.springframework.beans.factory.FactoryBean;/** * 实现一个spring定义的工厂Bean */public class ColorFactoryBean implements FactoryBean&lt;Color&gt; &#123;    /**     *     * @return 返回Color对象，并添加到容器中     * @throws Exception     */    @Override    public Color getObject() throws Exception &#123;        System.out.println(&quot;ColorFactoryBean:getObject()&quot;);        return new Color();    &#125;    @Override    public Class&lt;?&gt; getObjectType() &#123;        return Color.class;    &#125;    /**     * true表明为单例，容器中只保存一份     * @return     */    @Override    public boolean isSingleton() &#123;        return true;    &#125;&#125;\n\n配置类里注册一下ColorFactoryBean工厂\n@Configurationpublic class MainConfig2 &#123;    //...    @Bean    public ColorFactoryBean colorFactoryBean()&#123;        return new ColorFactoryBean();    &#125;&#125;\n\nunit test里从IOT容器中获取并打印一下我们的工厂的类型：\n// 工厂Bean获取的是调用getObject创建的对象Object factoryBean = annotationConfigApplicationContext.getBean(&quot;colorFactoryBean&quot;);Object factoryBean2 = annotationConfigApplicationContext.getBean(&quot;colorFactoryBean&quot;);System.out.println(&quot;ColorFactoryBean class is &quot; + factoryBean.getClass());System.out.println(factoryBean == factoryBean2);\n\n输出：\nColorFactoryBean:getObject()ColorFactoryBean class is class com.sicmatr1x.bean.Colortrue\n\n可以发现我们的工厂Bean的类型居然是Color，说明我们从IOT容器中getBean结果其实get到的是调用ColorFactoryBean.getObject()返回的对象，再用getBean获取一下发现两次获取到的对象是一样的，这表明我们重写isSingleton()方法的返回值被spring用于判断是否为单例模式了\n如果想获取到ColorFactoryBean本身的话可以通过在bean的id前增加一个&amp;字符来实现：\nObject factoryBean = annotationConfigApplicationContext.getBean(&quot;&amp;colorFactoryBean&quot;);\n\n至于为什么是这个字符，可以去BeanFactory接口里面定义了&amp;字符\npublic interface BeanFactory &#123;\t/**\t * Used to dereference a &#123;@link FactoryBean&#125; instance and distinguish it from\t * beans &lt;i&gt;created&lt;/i&gt; by the FactoryBean. For example, if the bean named\t * &#123;@code myJndiObject&#125; is a FactoryBean, getting &#123;@code &amp;myJndiObject&#125;\t * will return the factory, not the instance returned by the factory.\t */\tString FACTORY_BEAN_PREFIX = &quot;&amp;&quot;;    //...&#125;\n\n\n生命周期@Bean指定初始化和销毁方法Bean的生命周期：\n\nbean创建\n初始化\n销毁\n\nBean的生命周期现在是由容器来管理的，我们可以自定义初始化和销毁方法，容器在bean进行到当前生命周期的时候会调用我们自定义的初始化或销毁方法\n以下会讲4种实现方式：\n\n指定初始化和销毁方法\n\n以前是在beans.xml文件中指定初始化和销毁方法init-method=&quot;&quot; destroy-method=&quot;&quot;\npackage com.sicmatr1x.bean;public class Car &#123;    public Car()&#123;        System.out.println(&quot;Car:constructor&quot;);    &#125;    public void init() &#123;        System.out.println(&quot;Car:init()&quot;);    &#125;    public void destroy() &#123;        System.out.println(&quot;Car:destroy()&quot;);    &#125;&#125;\n\n现在可以通过@Bean注解配置对应的方法\n\n初始化：对象创建完成并赋值好，调用初始化方法\n销毁：容器关闭的时候，进行销毁\n\n写一个配置类：\npackage com.sicmatr1x.condition;import com.sicmatr1x.bean.Car;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class MainConfigLifeCycle &#123;    @Bean(initMethod = &quot;init&quot;, destroyMethod = &quot;destroy&quot;)    public Car car() &#123;        return new Car();    &#125;&#125;\n\nunit test：\n@Testpublic void test01()&#123;    // 创建IOC容器    AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfigLifeCycle.class);    System.out.println(&quot;容器创建完成&quot;);    annotationConfigApplicationContext.close();    System.out.println(&quot;容器销毁完成&quot;);&#125;\n\n输出：\nCar:constructorCar:init()容器创建完成Car:destroy()容器销毁完成\n\n在单实例模式下对象的初始化在容器创建完之后进行，销毁在容器销毁前完成\n在多实例模式下对象的初始化在你获取时进行，容器不会管理这个bean，容器不会调用其销毁方法\nInitializingBean &amp; DisposableBean\n实现InitializingBean &amp; DisposableBean接口\n\n用于在bean初始化时执行自定义初始化逻辑的接口\n当BeanFactory创建好对象并且给bean里所有的属性设置完成后会调用InitializingBean.afterPropertiesSet()\npublic interface InitializingBean &#123;\t/**\t * Invoked by a BeanFactory after it has set all bean properties supplied\t * (and satisfied BeanFactoryAware and ApplicationContextAware).\t * &lt;p&gt;This method allows the bean instance to perform initialization only\t * possible when all bean properties have been set and to throw an\t * exception in the event of misconfiguration.\t * @throws Exception in the event of misconfiguration (such\t * as failure to set an essential property) or if initialization fails.\t */\tvoid afterPropertiesSet() throws Exception;&#125;\n\n与之相对的在bean销毁时也有对应的接口：\npublic interface DisposableBean &#123;\t/**\t * Invoked by a BeanFactory on destruction of a singleton.\t * @throws Exception in case of shutdown errors.\t * Exceptions will get logged but not rethrown to allow\t * other beans to release their resources too.\t */\tvoid destroy() throws Exception;&#125;\n\n给bean实现一下对应接口：\npackage com.sicmatr1x.bean;import org.springframework.beans.factory.DisposableBean;import org.springframework.beans.factory.InitializingBean;import org.springframework.stereotype.Component;@Componentpublic class Cat implements InitializingBean, DisposableBean &#123;    public Cat() &#123;        System.out.println(&quot;Cat:constructor()&quot;);    &#125;    @Override    public void destroy() throws Exception &#123;        System.out.println(&quot;Cat:destroy()&quot;);    &#125;    @Override    public void afterPropertiesSet() throws Exception &#123;        System.out.println(&quot;Cat:afterPropertiesSet()&quot;);    &#125;&#125;\n\n运行一下unit test：\nCat:constructor()Cat:afterPropertiesSet()Car:constructorCar:init()容器创建完成Car:destroy()Cat:destroy()容器销毁完成\n\n@PostConstruct &amp; @PreDestroy\n实现@PostConstruct &amp; @PreDestroy注解\n\n@PostConstruct &amp; @PreDestroy注解在JSR250规范中被定义\n话不多说，先看源码：\npackage javax.annotation;import java.lang.annotation.*;import static java.lang.annotation.ElementType.*;import static java.lang.annotation.RetentionPolicy.*;/** * The PostConstruct annotation is used on a method that needs to be executed * after dependency injection is done to perform any initialization. This * method MUST be invoked before the class is put into service. This * annotation MUST be supported on all classes that support dependency * injection. The method annotated with PostConstruct MUST be invoked even * if the class does not request any resources to be injected. Only one * method can be annotated with this annotation. The method on which the * PostConstruct annotation is applied MUST fulfill all of the following * criteria: * &lt;p&gt; * &lt;ul&gt; * &lt;li&gt;The method MUST NOT have any parameters except in the case of * interceptors in which case it takes an InvocationContext object as * defined by the Interceptors specification.&lt;/li&gt; * &lt;li&gt;The method defined on an interceptor class MUST HAVE one of the * following signatures: * &lt;p&gt; * void &amp;#060;METHOD&amp;#062;(InvocationContext) * &lt;p&gt; * Object &amp;#060;METHOD&amp;#062;(InvocationContext) throws Exception * &lt;p&gt; * &lt;i&gt;Note: A PostConstruct interceptor method must not throw application * exceptions, but it may be declared to throw checked exceptions including * the java.lang.Exception if the same interceptor method interposes on * business or timeout methods in addition to lifecycle events. If a * PostConstruct interceptor method returns a value, it is ignored by * the container.&lt;/i&gt; * &lt;/li&gt; * &lt;li&gt;The method defined on a non-interceptor class MUST HAVE the * following signature: * &lt;p&gt; * void &amp;#060;METHOD&amp;#062;() * &lt;/li&gt; * &lt;li&gt;The method on which PostConstruct is applied MAY be public, protected, * package private or private.&lt;/li&gt; * &lt;li&gt;The method MUST NOT be static except for the application client.&lt;/li&gt; * &lt;li&gt;The method MAY be final.&lt;/li&gt; * &lt;li&gt;If the method throws an unchecked exception the class MUST NOT be put into * service except in the case of EJBs where the EJB can handle exceptions and * even recover from them.&lt;/li&gt;&lt;/ul&gt; * @since Common Annotations 1.0 * @see javax.annotation.PreDestroy * @see javax.annotation.Resource */@Documented@Retention (RUNTIME)@Target(METHOD)public @interface PostConstruct &#123;&#125;\n\n\nThe PostConstruct annotation is used on a method that needs to be executed after dependency injection is done to perform any initialization.\n\n显然这个注解的作用是用于在dependency injection(也就是bean创建完成且属性赋值完成)之后运行一个初始化方法\npackage javax.annotation;import java.lang.annotation.*;import static java.lang.annotation.ElementType.*;import static java.lang.annotation.RetentionPolicy.*;/** * The PreDestroy annotation is used on methods as a callback notification to * signal that the instance is in the process of being removed by the * container. The method annotated with PreDestroy is typically used to * release resources that it has been holding. This annotation MUST be * supported by all container managed objects that support PostConstruct * except the application client container in Java EE 5. The method on which * the PreDestroy annotation is applied MUST fulfill all of the following * criteria: * &lt;p&gt; * &lt;ul&gt; * &lt;li&gt;The method MUST NOT have any parameters except in the case of * interceptors in which case it takes an InvocationContext object as * defined by the Interceptors specification.&lt;/li&gt; * &lt;li&gt;The method defined on an interceptor class MUST HAVE one of the * following signatures: * &lt;p&gt; * void &amp;#060;METHOD&amp;#062;(InvocationContext) * &lt;p&gt; * Object &amp;#060;METHOD&amp;#062;(InvocationContext) throws Exception * &lt;p&gt; * &lt;i&gt;Note: A PreDestroy interceptor method must not throw application * exceptions, but it may be declared to throw checked exceptions including * the java.lang.Exception if the same interceptor method interposes on * business or timeout methods in addition to lifecycle events. If a * PreDestroy interceptor method returns a value, it is ignored by * the container.&lt;/i&gt; * &lt;/li&gt; * &lt;li&gt;The method defined on a non-interceptor class MUST HAVE the * following signature: * &lt;p&gt; * void &amp;#060;METHOD&amp;#062;() * &lt;/li&gt; * &lt;li&gt;The method on which PreDestroy is applied MAY be public, protected, * package private or private.&lt;/li&gt; * &lt;li&gt;The method MUST NOT be static.&lt;/li&gt; * &lt;li&gt;The method MAY be final.&lt;/li&gt; * &lt;li&gt;If the method throws an unchecked exception it is ignored except in the * case of EJBs where the EJB can handle exceptions.&lt;/li&gt; * &lt;/ul&gt; * * @see javax.annotation.PostConstruct * @see javax.annotation.Resource * @since Common Annotations 1.0 */@Documented@Retention (RUNTIME)@Target(METHOD)public @interface PreDestroy &#123;&#125;\n\n\nThe PreDestroy annotation is used on methods as a callback notification to signal that the instance is in the process of being removed by the container.\n\n显然被注解方法会在 being removed by the container之前做为callback notification to signal被调用，即容器销毁bean之前调用该方法\n创建一个bean来试验一下：\npackage com.sicmatr1x.bean;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;@Componentpublic class Dog &#123;    public Dog() &#123;        System.out.println(&quot;Dog:constructor()&quot;);    &#125;    /**     * 对象创建并赋值之后调用     */    @PostConstruct    public void init() &#123;        System.out.println(&quot;Dog:init() by @PostConstruct&quot;);    &#125;    /**     * 容器移除对象之前调用     */    @PreDestroy    public void destroy() &#123;        System.out.println(&quot;Dog:destroy() by @PreDestroy&quot;);    &#125;&#125;\n\nrun unit test看一下输出：\nCat:constructor()Cat:afterPropertiesSet()Dog:constructor()Dog:init() by @PostConstructCar:constructorCar:init()容器创建完成Car:destroy()Dog:destroy() by @PreDestroyCat:destroy()容器销毁完成\n\nBeanPostProcessor bean的后置处理器\nBeanPostProcessor bean的后置处理器\n\n在bean初始化前后进行处理\n按照惯例，看源码先：\npublic interface BeanPostProcessor &#123;\t/**\t * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;before&lt;/i&gt; any bean\t * initialization callbacks (like InitializingBean&#x27;s &#123;@code afterPropertiesSet&#125;\t * or a custom init-method). The bean will already be populated with property values.\t * The returned bean instance may be a wrapper around the original.\t * @param bean the new bean instance\t * @param beanName the name of the bean\t * @return the bean instance to use, either the original or a wrapped one;\t * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked\t * @throws org.springframework.beans.BeansException in case of errors\t * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet\t */\tObject postProcessBeforeInitialization(Object bean, String beanName) throws BeansException;\t/**\t * Apply this BeanPostProcessor to the given new bean instance &lt;i&gt;after&lt;/i&gt; any bean\t * initialization callbacks (like InitializingBean&#x27;s &#123;@code afterPropertiesSet&#125;\t * or a custom init-method). The bean will already be populated with property values.\t * The returned bean instance may be a wrapper around the original.\t * &lt;p&gt;In case of a FactoryBean, this callback will be invoked for both the FactoryBean\t * instance and the objects created by the FactoryBean (as of Spring 2.0). The\t * post-processor can decide whether to apply to either the FactoryBean or created\t * objects or both through corresponding &#123;@code bean instanceof FactoryBean&#125; checks.\t * &lt;p&gt;This callback will also be invoked after a short-circuiting triggered by a\t * &#123;@link InstantiationAwareBeanPostProcessor#postProcessBeforeInstantiation&#125; method,\t * in contrast to all other BeanPostProcessor callbacks.\t * @param bean the new bean instance\t * @param beanName the name of the bean\t * @return the bean instance to use, either the original or a wrapped one;\t * if &#123;@code null&#125;, no subsequent BeanPostProcessors will be invoked\t * @throws org.springframework.beans.BeansException in case of errors\t * @see org.springframework.beans.factory.InitializingBean#afterPropertiesSet\t * @see org.springframework.beans.factory.FactoryBean\t */\tObject postProcessAfterInitialization(Object bean, String beanName) throws BeansException;&#125;\n\n\nApply this BeanPostProcessor to the given new bean instance before any bean initialization callbacks.\n\n运行这个BeanPostProcessor在一个新的bean的实例调用任何initialization callbacks之前，也就是说会在一个bean的实例初始化时的所有的初始化调用方法之前调用该方法，相当于最早调用的bean的实例的初始化方法\n\npostProcessBeforeInitialization: 在任何初始化方法之前进行处理工作\npostProcessAfterInitialization: 在任何初始化方法之后进行处理工作\n\n\n@return the bean instance to use, either the original or a wrapped one;\n\n你可以返回一个原本的bean(通过参数传进来的)，也可以包装一下再返回\n我们实现一下这个接口来做一个自己的BeanPostProcessor：\npackage com.sicmatr1x.bean;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanPostProcessor;import org.springframework.stereotype.Component;/** * 后置处理器，初始化前后进行处理 * 讲后置处理器假如到容器 */@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;MyBeanPostProcessor:postProcessBeforeInitialization():bean=&quot; + bean + &quot;, beanName=&quot; + beanName);        return bean;    &#125;    @Override    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;MyBeanPostProcessor:postProcessAfterInitialization():bean=&quot; + bean + &quot;, beanName=&quot; + beanName);        return bean;    &#125;&#125;\n\n运行一下unit test：\nMyBeanPostProcessor:postProcessBeforeInitialization():bean=org.springframework.context.event.EventListenerMethodProcessor@c8e4bb0, beanName=org.springframework.context.event.internalEventListenerProcessorMyBeanPostProcessor:postProcessAfterInitialization():bean=org.springframework.context.event.EventListenerMethodProcessor@c8e4bb0, beanName=org.springframework.context.event.internalEventListenerProcessorMyBeanPostProcessor:postProcessBeforeInitialization():bean=org.springframework.context.event.DefaultEventListenerFactory@4206a205, beanName=org.springframework.context.event.internalEventListenerFactoryMyBeanPostProcessor:postProcessAfterInitialization():bean=org.springframework.context.event.DefaultEventListenerFactory@4206a205, beanName=org.springframework.context.event.internalEventListenerFactoryMyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.condition.MainConfigLifeCycle$$EnhancerBySpringCGLIB$$883e25cf@57175e74, beanName=mainConfigLifeCycleMyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.condition.MainConfigLifeCycle$$EnhancerBySpringCGLIB$$883e25cf@57175e74, beanName=mainConfigLifeCycleCat:constructor()MyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.bean.Cat@770c2e6b, beanName=catCat:afterPropertiesSet()MyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.bean.Cat@770c2e6b, beanName=catDog:constructor()MyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.bean.Dog@1a38c59b, beanName=dogDog:init() by @PostConstructMyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.bean.Dog@1a38c59b, beanName=dogCar:constructorMyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.bean.Car@105fece7, beanName=carCar:init()MyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.bean.Car@105fece7, beanName=car容器创建完成Car:destroy()Dog:destroy() by @PreDestroyCat:destroy()容器销毁完成\n\n可以看到我们之前的Cat, Dog类的init方法被夹在MyBeanPostProcessor的两个方法之间运行了\nMyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.bean.Cat@770c2e6b, beanName=catCat:afterPropertiesSet()MyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.bean.Cat@770c2e6b, beanName=cat\n\nMyBeanPostProcessor:postProcessBeforeInitialization():bean=com.sicmatr1x.bean.Dog@1a38c59b, beanName=dogDog:init() by @PostConstructMyBeanPostProcessor:postProcessAfterInitialization():bean=com.sicmatr1x.bean.Dog@1a38c59b, beanName=dog\n\n再看BeanPostProcessor的注释，里面举例子提到了afterPropertiesSet和custom init-method就正好对应我们的Cat.afterPropertiesSet()和Car.init()\n\nApply this BeanPostProcessor to the given new bean instance before any bean initialization callbacks (like InitializingBean’s {@code afterPropertiesSet} or a custom init-method)\n\nBeanPostProcessor 原理我们还是用上个例子来看，在MyBeanPostProcessor.postProcessBeforeInitialization方法里面打个断点\n\n\n看一下上图的方法调用栈，我们从创建IOC容器开始按照上面那个调用栈一个一个往上看：\n用// &lt;=========来表明断点的位置\npublic class IOCTest_LifeCycle &#123;    @Test    public void test01()&#123;        // 创建IOC容器        AnnotationConfigApplicationContext annotationConfigApplicationContext = new AnnotationConfigApplicationContext(MainConfigLifeCycle.class);// &lt;=========        System.out.println(&quot;容器创建完成&quot;);        annotationConfigApplicationContext.close();        System.out.println(&quot;容器销毁完成&quot;);    &#125;&#125;\n\n使用AnnotationConfigApplicationContext构造方法创建IOC容器\npublic AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123;\tthis();\tregister(annotatedClasses);\trefresh();// &lt;=========&#125;\n\nAnnotationConfigApplicationContext构造方法调用了refresh()方法来刷新容器\n// Instantiate all remaining (non-lazy-init) singletons.finishBeanFactoryInitialization(beanFactory);// &lt;=========\n\n显然从注释可以看出refresh()方法里面调用了finishBeanFactoryInitialization来初始化所有的单例对象\n// Instantiate all remaining (non-lazy-init) singletons.beanFactory.preInstantiateSingletons();// &lt;=========\n\n// Trigger initialization of all non-lazy singleton beans...for (String beanName : beanNames) &#123; // 这个beanNames数组里面装的就是我们之前所有的bean id，比如car, cat, dog\tRootBeanDefinition bd = getMergedLocalBeanDefinition(beanName);\tif (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) &#123;\t\tif (isFactoryBean(beanName)) &#123;\t\t\tfinal FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName);\t\t\tboolean isEagerInit;\t\t\tif (System.getSecurityManager() != null &amp;&amp; factory instanceof SmartFactoryBean) &#123;\t\t\t\tisEagerInit = AccessController.doPrivileged(new PrivilegedAction&lt;Boolean&gt;() &#123;\t\t\t\t\t@Override\t\t\t\t\tpublic Boolean run() &#123;\t\t\t\t\t\treturn ((SmartFactoryBean&lt;?&gt;) factory).isEagerInit();\t\t\t\t\t&#125;\t\t\t\t&#125;, getAccessControlContext());\t\t\t&#125;\t\t\telse &#123;\t\t\t\tisEagerInit = (factory instanceof SmartFactoryBean &amp;&amp;\t\t\t\t\t\t((SmartFactoryBean&lt;?&gt;) factory).isEagerInit());\t\t\t&#125;\t\t\tif (isEagerInit) &#123;\t\t\t\tgetBean(beanName);\t\t\t&#125;\t\t&#125;\t\telse &#123;\t\t\tgetBean(beanName);// &lt;=========\t\t&#125;\t&#125;&#125;\n\n初始化所有的非懒加载的单例bean\n@Overridepublic Object getBean(String name) throws BeansException &#123;\treturn doGetBean(name, null, null, false);// &lt;=========&#125;\n\n\n// Create bean instance.if (mbd.isSingleton()) &#123;\tsharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123;// &lt;=========\t\t@Override\t\tpublic Object getObject() throws BeansException &#123;\t\t\ttry &#123;\t\t\t\treturn createBean(beanName, mbd, args);\t\t\t&#125;\t\t\tcatch (BeansException ex) &#123;\t\t\t\t// Explicitly remove instance from singleton cache: It might have been put there\t\t\t\t// eagerly by the creation process, to allow for circular reference resolution.\t\t\t\t// Also remove any beans that received a temporary reference to the bean.\t\t\t\tdestroySingleton(beanName);\t\t\t\tthrow ex;\t\t\t&#125;\t\t&#125;\t&#125;);\tbean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd);&#125;\n\n调用getSingleton获取单实例，若获取不到则会调用createBean创建对象\ntry &#123;\tsingletonObject = singletonFactory.getObject();// &lt;=========\tnewSingleton = true;&#125;\n\n// Create bean instance.if (mbd.isSingleton()) &#123;\tsharedInstance = getSingleton(beanName, new ObjectFactory&lt;Object&gt;() &#123;\t\t@Override\t\tpublic Object getObject() throws BeansException &#123;\t\t\ttry &#123;\t\t\t\treturn createBean(beanName, mbd, args);// &lt;=========\t\t\t&#125;\t\t\tcatch (BeansException ex) &#123;\t\t\t\t// Explicitly remove instance from singleton cache: It might have been put there\t\t\t\t// eagerly by the creation process, to allow for circular reference resolution.\t\t\t\t// Also remove any beans that received a temporary reference to the bean.\t\t\t\tdestroySingleton(beanName);\t\t\t\tthrow ex;\t\t\t&#125;\t\t&#125;\t&#125;);\n\n调用createBean创建对象\nObject beanInstance = doCreateBean(beanName, mbdToUse, args);// &lt;=========if (logger.isDebugEnabled()) &#123;\tlogger.debug(&quot;Finished creating instance of bean &#x27;&quot; + beanName + &quot;&#x27;&quot;);&#125;\n\ncreateBean方法调完就会创建出来实例，beanInstance就是创建出来的实例，进去看下怎么创建的\ntry &#123;\tpopulateBean(beanName, mbd, instanceWrapper); // 为bean的属性赋值\tif (exposedObject != null) &#123;\t\texposedObject = initializeBean(beanName, exposedObject, mbd);// &lt;=========\t&#125;&#125;\n\n这里调了一个叫initializeBean的方法\n/** * Initialize the given bean instance, applying factory callbacks * as well as init methods and bean post processors. * &lt;p&gt;Called from &#123;@link #createBean&#125; for traditionally defined beans, * and from &#123;@link #initializeBean&#125; for existing bean instances. * @param beanName the bean name in the factory (for debugging purposes) * @param bean the new bean instance we may need to initialize * @param mbd the bean definition that the bean was created with * (can also be &#123;@code null&#125;, if given an existing bean instance) * @return the initialized bean instance (potentially wrapped) * @see BeanNameAware * @see BeanClassLoaderAware * @see BeanFactoryAware * @see #applyBeanPostProcessorsBeforeInitialization * @see #invokeInitMethods * @see #applyBeanPostProcessorsAfterInitialization */protected Object initializeBean(final String beanName, final Object bean, RootBeanDefinition mbd) &#123;\tif (System.getSecurityManager() != null) &#123;\t\tAccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123;\t\t\t@Override\t\t\tpublic Object run() &#123;\t\t\t\tinvokeAwareMethods(beanName, bean);\t\t\t\treturn null;\t\t\t&#125;\t\t&#125;, getAccessControlContext());\t&#125;\telse &#123;\t\tinvokeAwareMethods(beanName, bean);\t&#125;\tObject wrappedBean = bean;\tif (mbd == null || !mbd.isSynthetic()) &#123;\t\twrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName);// &lt;=========\t&#125;\ttry &#123;\t\tinvokeInitMethods(beanName, wrappedBean, mbd); // 执行初始化方法\t&#125;\tcatch (Throwable ex) &#123;\t\tthrow new BeanCreationException(\t\t\t\t(mbd != null ? mbd.getResourceDescription() : null),\t\t\t\tbeanName, &quot;Invocation of init method failed&quot;, ex);\t&#125;\tif (mbd == null || !mbd.isSynthetic()) &#123;\t\twrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName);\t&#125;\treturn wrappedBean;&#125;\n\n看到这里的applyBeanPostProcessorsBeforeInitialization熟悉不，长的像啥，就是在initializeBean的方法里面调到了我们定义的处理器MyBeanPostProcessor，可知是先为bean的属性赋值之后再调的处理器\n看到了没有，断点在invokeInitMethods(beanName, wrappedBean, mbd);这句话上面，表明先执行我们之前实现的postProcessBeforeInitialization方法里面的内容再来运行之前提到的那些初始化bean的方法\n再往下看，applyBeanPostProcessorsAfterInitialization眼熟不，长的像啥，表明先执行之前提到的那些初始化bean的方法之后再来运行我们之前实现的postProcessAfterInitialization方法里面的内容\n@Overridepublic Object applyBeanPostProcessorsBeforeInitialization(Object existingBean, String beanName)\t\tthrows BeansException &#123;\tObject result = existingBean;\tfor (BeanPostProcessor beanProcessor : getBeanPostProcessors()) &#123;\t\tresult = beanProcessor.postProcessBeforeInitialization(result, beanName);// &lt;=========\t\tif (result == null) &#123;\t\t\treturn result;\t\t&#125;\t&#125;\treturn result;&#125;\n\n这里逐个遍历了BeanPostProcessor，当前断点里面的这个beanProcessor变量里面的值就是我们之前定义的MyBeanPostProcessor类的对象。这里调用到了postProcessBeforeInitialization方法就是我们实现的那个。\n我们还知道了一旦我们实现的postProcessBeforeInitialization方法返回null之后，整个BeanPostProcessor就不会执行后面的其它的beanProcessor了，跳出for循环，直接就返回了\n@Componentpublic class MyBeanPostProcessor implements BeanPostProcessor &#123;    @Override    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;        System.out.println(&quot;MyBeanPostProcessor:postProcessBeforeInitialization():bean=&quot; + bean + &quot;, beanName=&quot; + beanName);// &lt;=========        return bean;    &#125;\n\n最后就进到我打断点的地方了\nBeanPostProcessor在Spring底层的使用\nApplicationContextAwareProcessor: 组件里面注入IOC容器\n\n实现一下这个接口：\npackage com.sicmatr1x.bean;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;@Componentpublic class Dog implements ApplicationContextAware &#123;    private ApplicationContext applicationContext;    public Dog() &#123;        System.out.println(&quot;Dog:constructor()&quot;);    &#125;    /**     * 对象创建并赋值之后调用     */    @PostConstruct    public void init() &#123;        System.out.println(&quot;Dog:init() by @PostConstruct&quot;);    &#125;    /**     * 容器移除对象之前调用     */    @PreDestroy    public void destroy() &#123;        System.out.println(&quot;Dog:destroy() by @PreDestroy&quot;);    &#125;    @Override    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;        this.applicationContext = applicationContext;    &#125;&#125;\n\n在Dog这个类里面，重写了setApplicationContext这个方法，我们可以在这个方法里面把获取到的IOC容器对象applicationContext赋值给我们的私有属性，然后就可以在其它需要用到的方法里面调到了\n那么它是如何实现这个功能的呢？上源码：\npackage org.springframework.context.support;import java.security.AccessControlContext;import java.security.AccessController;import java.security.PrivilegedAction;import org.springframework.beans.BeansException;import org.springframework.beans.factory.Aware;import org.springframework.beans.factory.config.BeanPostProcessor;import org.springframework.beans.factory.config.EmbeddedValueResolver;import org.springframework.context.ApplicationContextAware;import org.springframework.context.ApplicationEventPublisherAware;import org.springframework.context.ConfigurableApplicationContext;import org.springframework.context.EmbeddedValueResolverAware;import org.springframework.context.EnvironmentAware;import org.springframework.context.MessageSourceAware;import org.springframework.context.ResourceLoaderAware;import org.springframework.util.StringValueResolver;/** * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor&#125; * implementation that passes the ApplicationContext to beans that * implement the &#123;@link EnvironmentAware&#125;, &#123;@link EmbeddedValueResolverAware&#125;, * &#123;@link ResourceLoaderAware&#125;, &#123;@link ApplicationEventPublisherAware&#125;, * &#123;@link MessageSourceAware&#125; and/or &#123;@link ApplicationContextAware&#125; interfaces. * * &lt;p&gt;Implemented interfaces are satisfied in order of their mention above. * * &lt;p&gt;Application contexts will automatically register this with their * underlying bean factory. Applications do not use this directly. * * @author Juergen Hoeller * @author Costin Leau * @author Chris Beams * @since 10.10.2003 * @see org.springframework.context.EnvironmentAware * @see org.springframework.context.EmbeddedValueResolverAware * @see org.springframework.context.ResourceLoaderAware * @see org.springframework.context.ApplicationEventPublisherAware * @see org.springframework.context.MessageSourceAware * @see org.springframework.context.ApplicationContextAware * @see org.springframework.context.support.AbstractApplicationContext#refresh() */class ApplicationContextAwareProcessor implements BeanPostProcessor &#123;\tprivate final ConfigurableApplicationContext applicationContext;\tprivate final StringValueResolver embeddedValueResolver;\t/**\t * Create a new ApplicationContextAwareProcessor for the given context.\t */\tpublic ApplicationContextAwareProcessor(ConfigurableApplicationContext applicationContext) &#123;\t\tthis.applicationContext = applicationContext;\t\tthis.embeddedValueResolver = new EmbeddedValueResolver(applicationContext.getBeanFactory());\t&#125;\t@Override\tpublic Object postProcessBeforeInitialization(final Object bean, String beanName) throws BeansException &#123;\t\tAccessControlContext acc = null;\t\tif (System.getSecurityManager() != null &amp;&amp;\t\t\t\t(bean instanceof EnvironmentAware || bean instanceof EmbeddedValueResolverAware ||\t\t\t\t\t\tbean instanceof ResourceLoaderAware || bean instanceof ApplicationEventPublisherAware ||\t\t\t\t\t\tbean instanceof MessageSourceAware || bean instanceof ApplicationContextAware)) &#123;\t\t\tacc = this.applicationContext.getBeanFactory().getAccessControlContext();\t\t&#125;\t\tif (acc != null) &#123;\t\t\tAccessController.doPrivileged(new PrivilegedAction&lt;Object&gt;() &#123;\t\t\t\t@Override\t\t\t\tpublic Object run() &#123;\t\t\t\t\tinvokeAwareInterfaces(bean);\t\t\t\t\treturn null;\t\t\t\t&#125;\t\t\t&#125;, acc);\t\t&#125;\t\telse &#123;\t\t\tinvokeAwareInterfaces(bean);\t\t&#125;\t\treturn bean;\t&#125;\tprivate void invokeAwareInterfaces(Object bean) &#123;\t\tif (bean instanceof Aware) &#123;\t\t\tif (bean instanceof EnvironmentAware) &#123;\t\t\t\t((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment());\t\t\t&#125;\t\t\tif (bean instanceof EmbeddedValueResolverAware) &#123;\t\t\t\t((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver);\t\t\t&#125;\t\t\tif (bean instanceof ResourceLoaderAware) &#123;\t\t\t\t((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext);\t\t\t&#125;\t\t\tif (bean instanceof ApplicationEventPublisherAware) &#123;\t\t\t\t((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext);\t\t\t&#125;\t\t\tif (bean instanceof MessageSourceAware) &#123;\t\t\t\t((MessageSourceAware) bean).setMessageSource(this.applicationContext);\t\t\t&#125;\t\t\tif (bean instanceof ApplicationContextAware) &#123;\t\t\t\t((ApplicationContextAware) bean).setApplicationContext(this.applicationContext);\t\t\t&#125;\t\t&#125;\t&#125;\t@Override\tpublic Object postProcessAfterInitialization(Object bean, String beanName) &#123;\t\treturn bean;\t&#125;&#125;\n\n显然它也是一个BeanPostProcessor，我们看postProcessBeforeInitialization方法里面，判断了当前的bean是否实现了该接口，如果实现了就把获取到的applicationContext对象传给bean重写的setApplicationContext方法\n也可以debug验证一下，这里就不贴debug的过程了\n\nBeanValidationPostProcessor: 做数据校验\nInitDestroyAnnotationBeanPostProcessor: 处理PostConstruct和PreDestroy注解\n\n还记得之前讲的使用PostConstruct和PreDestroy注解来使spring调我们自己的方法吗，那两个注解起作用的背后就是InitDestroyAnnotationBeanPostProcessor在操作\n话不多说，来debug\n下面是方法调用栈\n\n\n这次就不从头开始看了，直接从InitDestroyAnnotationBeanPostProcessor的方法栈开始看\n@Overridepublic Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123;\tLifecycleMetadata metadata = findLifecycleMetadata(bean.getClass()); //找到dog bean的生命周期注解\ttry &#123;\t\tmetadata.invokeInitMethods(bean, beanName);//&lt;=========\t&#125;\tcatch (InvocationTargetException ex) &#123;\t\tthrow new BeanCreationException(beanName, &quot;Invocation of init method failed&quot;, ex.getTargetException());\t&#125;\tcatch (Throwable ex) &#123;\t\tthrow new BeanCreationException(beanName, &quot;Failed to invoke init method&quot;, ex);\t&#125;\treturn bean;&#125;\n\n然后用invokeInitMethods执行指定的生命周期的方法\npublic void invokeInitMethods(Object target, String beanName) throws Throwable &#123;\tCollection&lt;LifecycleElement&gt; initMethodsToIterate =\t\t\t(this.checkedInitMethods != null ? this.checkedInitMethods : this.initMethods);\tif (!initMethodsToIterate.isEmpty()) &#123;\t\tboolean debug = logger.isDebugEnabled();\t\tfor (LifecycleElement element : initMethodsToIterate) &#123;\t\t\tif (debug) &#123;\t\t\t\tlogger.debug(&quot;Invoking init method on bean &#x27;&quot; + beanName + &quot;&#x27;: &quot; + element.getMethod());\t\t\t&#125;\t\t\telement.invoke(target);//&lt;=========\t\t&#125;\t&#125;&#125;\n\n进到这个invoke方法里面看：\npublic void invoke(Object target) throws Throwable &#123;\tReflectionUtils.makeAccessible(this.method);\tthis.method.invoke(target, (Object[]) null);//&lt;=========&#125;\n\n可以看到这里调到了java反射里面的method的invoke方法来执行\n\nAutowiredAnnotationBeanPostProcessor: 用于处理@Autowired注解\n\n属性赋值@Value赋值主要功能为用指定的属性来初始化bean的属性\n使用方法：\n\n直接赋值基本数据类型\n使用SpEL表达式#&#123;&#125;\n可以用$&#123;&#125;取出配置文件中的值(环境变量中的值)\n\npackage org.springframework.beans.factory.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;/** * Annotation at the field or method/constructor parameter level * that indicates a default value expression for the affected argument. * * &lt;p&gt;Typically used for expression-driven dependency injection. Also supported * for dynamic resolution of handler method parameters, e.g. in Spring MVC. * * &lt;p&gt;A common use case is to assign default field values using * &quot;#&#123;systemProperties.myProp&#125;&quot; style expressions. * * &lt;p&gt;Note that actual processing of the &#123;@code @Value&#125; annotation is performed * by a &#123;@link org.springframework.beans.factory.config.BeanPostProcessor * BeanPostProcessor&#125; which in turn means that you &lt;em&gt;cannot&lt;/em&gt; use * &#123;@code @Value&#125; within * &#123;@link org.springframework.beans.factory.config.BeanPostProcessor * BeanPostProcessor&#125; or * &#123;@link org.springframework.beans.factory.config.BeanFactoryPostProcessor BeanFactoryPostProcessor&#125; * types. Please consult the javadoc for the &#123;@link AutowiredAnnotationBeanPostProcessor&#125; * class (which, by default, checks for the presence of this annotation). * * @author Juergen Hoeller * @since 3.0 * @see AutowiredAnnotationBeanPostProcessor * @see Autowired * @see org.springframework.beans.factory.config.BeanExpressionResolver * @see org.springframework.beans.factory.support.AutowireCandidateResolver#getSuggestedValue */@Target(&#123;ElementType.FIELD, ElementType.METHOD, ElementType.PARAMETER, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Value &#123;\t/**\t * The actual value expression: e.g. &quot;#&#123;systemProperties.myProp&#125;&quot;.\t */\tString value();&#125;\n\npublic class Person &#123;    /**     * 直接赋值     */    @Value(&quot;张三&quot;)    private String name;    /**     * SpEL表达式     */    @Value(&quot;#&#123;20-2&#125;&quot;)    private Integer age;\t//...&#125;\n\n@PropertySource加载外部配置文件如何使用，先看源码里面的注释有没有说：\npackage org.springframework.context.annotation;import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Repeatable;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import org.springframework.core.io.support.PropertySourceFactory;/** * Annotation providing a convenient and declarative mechanism for adding a * &#123;@link org.springframework.core.env.PropertySource PropertySource&#125; to Spring&#x27;s * &#123;@link org.springframework.core.env.Environment Environment&#125;. To be used in * conjunction with @&#123;@link Configuration&#125; classes. * * &lt;h3&gt;Example usage&lt;/h3&gt; * * &lt;p&gt;Given a file &#123;@code app.properties&#125; containing the key/value pair * &#123;@code testbean.name=myTestBean&#125;, the following &#123;@code @Configuration&#125; class * uses &#123;@code @PropertySource&#125; to contribute &#123;@code app.properties&#125; to the * &#123;@code Environment&#125;&#x27;s set of &#123;@code PropertySources&#125;. * * &lt;pre class=&quot;code&quot;&gt; * &amp;#064;Configuration * &amp;#064;PropertySource(&quot;classpath:/com/myco/app.properties&quot;) * public class AppConfig &#123; *     &amp;#064;Autowired *     Environment env; * *     &amp;#064;Bean *     public TestBean testBean() &#123; *         TestBean testBean = new TestBean(); *         testBean.setName(env.getProperty(&quot;testbean.name&quot;)); *         return testBean; *     &#125; * &#125;&lt;/pre&gt; * * Notice that the &#123;@code Environment&#125; object is @&#123;@link * org.springframework.beans.factory.annotation.Autowired Autowired&#125; into the * configuration class and then used when populating the &#123;@code TestBean&#125; object. Given * the configuration above, a call to &#123;@code testBean.getName()&#125; will return &quot;myTestBean&quot;. * * &lt;h3&gt;Resolving $&#123;...&#125; placeholders in &#123;@code &lt;bean&gt;&#125; and &#123;@code @Value&#125; annotations&lt;/h3&gt; * * In order to resolve $&#123;...&#125; placeholders in &#123;@code &lt;bean&gt;&#125; definitions or &#123;@code @Value&#125; * annotations using properties from a &#123;@code PropertySource&#125;, one must register * a &#123;@code PropertySourcesPlaceholderConfigurer&#125;. This happens automatically when using * &#123;@code &lt;context:property-placeholder&gt;&#125; in XML, but must be explicitly registered using * a &#123;@code static&#125; &#123;@code @Bean&#125; method when using &#123;@code @Configuration&#125; classes. See * the &quot;Working with externalized values&quot; section of @&#123;@link Configuration&#125;&#x27;s javadoc and * &quot;a note on BeanFactoryPostProcessor-returning @Bean methods&quot; of @&#123;@link Bean&#125;&#x27;s javadoc * for details and examples. * * &lt;h3&gt;Resolving $&#123;...&#125; placeholders within &#123;@code @PropertySource&#125; resource locations&lt;/h3&gt; * * Any $&#123;...&#125; placeholders present in a &#123;@code @PropertySource&#125; &#123;@linkplain #value() * resource location&#125; will be resolved against the set of property sources already * registered against the environment. For example: * * &lt;pre class=&quot;code&quot;&gt; * &amp;#064;Configuration * &amp;#064;PropertySource(&quot;classpath:/com/$&#123;my.placeholder:default/path&#125;/app.properties&quot;) * public class AppConfig &#123; *     &amp;#064;Autowired *     Environment env; * *     &amp;#064;Bean *     public TestBean testBean() &#123; *         TestBean testBean = new TestBean(); *         testBean.setName(env.getProperty(&quot;testbean.name&quot;)); *         return testBean; *     &#125; * &#125;&lt;/pre&gt; * * Assuming that &quot;my.placeholder&quot; is present in one of the property sources already * registered, e.g. system properties or environment variables, the placeholder will * be resolved to the corresponding value. If not, then &quot;default/path&quot; will be used as a * default. Expressing a default value (delimited by colon &quot;:&quot;) is optional.  If no * default is specified and a property cannot be resolved, an &#123;@code * IllegalArgumentException&#125; will be thrown. * * &lt;h3&gt;A note on property overriding with @PropertySource&lt;/h3&gt; * * In cases where a given property key exists in more than one &#123;@code .properties&#125; * file, the last &#123;@code @PropertySource&#125; annotation processed will &#x27;win&#x27; and override. * * For example, given two properties files &#123;@code a.properties&#125; and * &#123;@code b.properties&#125;, consider the following two configuration classes * that reference them with &#123;@code @PropertySource&#125; annotations: * * &lt;pre class=&quot;code&quot;&gt; * &amp;#064;Configuration * &amp;#064;PropertySource(&quot;classpath:/com/myco/a.properties&quot;) * public class ConfigA &#123; &#125; * * &amp;#064;Configuration * &amp;#064;PropertySource(&quot;classpath:/com/myco/b.properties&quot;) * public class ConfigB &#123; &#125; * &lt;/pre&gt; * * The override ordering depends on the order in which these classes are registered * with the application context. * &lt;pre class=&quot;code&quot;&gt; * AnnotationConfigApplicationContext ctx = *     new AnnotationConfigApplicationContext(); * ctx.register(ConfigA.class); * ctx.register(ConfigB.class); * ctx.refresh(); * &lt;/pre&gt; * * In the scenario above, the properties in &#123;@code b.properties&#125; will override any * duplicates that exist in &#123;@code a.properties&#125;, because &#123;@code ConfigB&#125; was registered * last. * * &lt;p&gt;In certain situations, it may not be possible or practical to tightly control * property source ordering when using &#123;@code @ProperySource&#125; annotations. For example, * if the &#123;@code @Configuration&#125; classes above were registered via component-scanning, * the ordering is difficult to predict. In such cases - and if overriding is important - * it is recommended that the user fall back to using the programmatic PropertySource API. * See &#123;@link org.springframework.core.env.ConfigurableEnvironment ConfigurableEnvironment&#125; * and &#123;@link org.springframework.core.env.MutablePropertySources MutablePropertySources&#125; * javadocs for details. * * @author Chris Beams * @author Juergen Hoeller * @author Phillip Webb * @since 3.1 * @see PropertySources * @see Configuration * @see org.springframework.core.env.PropertySource * @see org.springframework.core.env.ConfigurableEnvironment#getPropertySources() * @see org.springframework.core.env.MutablePropertySources */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Repeatable(PropertySources.class)public @interface PropertySource &#123;\t/**\t * Indicate the name of this property source. If omitted, a name will\t * be generated based on the description of the underlying resource.\t * @see org.springframework.core.env.PropertySource#getName()\t * @see org.springframework.core.io.Resource#getDescription()\t */\tString name() default &quot;&quot;;\t/**\t * Indicate the resource location(s) of the properties file to be loaded.\t * For example, &#123;@code &quot;classpath:/com/myco/app.properties&quot;&#125; or\t * &#123;@code &quot;file:/path/to/file&quot;&#125;.\t * &lt;p&gt;Resource location wildcards (e.g. *&amp;#42;/*.properties) are not permitted;\t * each location must evaluate to exactly one &#123;@code .properties&#125; resource.\t * &lt;p&gt;$&#123;...&#125; placeholders will be resolved against any/all property sources already\t * registered with the &#123;@code Environment&#125;. See &#123;@linkplain PropertySource above&#125;\t * for examples.\t * &lt;p&gt;Each location will be added to the enclosing &#123;@code Environment&#125; as its own\t * property source, and in the order declared.\t */\tString[] value();\t/**\t * Indicate if failure to find the a &#123;@link #value() property resource&#125; should be\t * ignored.\t * &lt;p&gt;&#123;@code true&#125; is appropriate if the properties file is completely optional.\t * Default is &#123;@code false&#125;.\t * @since 4.0\t */\tboolean ignoreResourceNotFound() default false;\t/**\t * A specific character encoding for the given resources, e.g. &quot;UTF-8&quot;.\t * @since 4.3\t */\tString encoding() default &quot;&quot;;\t/**\t * Specify a custom &#123;@link PropertySourceFactory&#125;, if any.\t * &lt;p&gt;By default, a default factory for standard resource files will be used.\t * @since 4.3\t * @see org.springframework.core.io.support.DefaultPropertySourceFactory\t * @see org.springframework.core.io.support.ResourcePropertySource\t */\tClass&lt;? extends PropertySourceFactory&gt; factory() default PropertySourceFactory.class;&#125;\n\n显然该注解作用的对象是类，保留到运行时\n再看参数：\n\nString[] value()\n\n\nIndicate the resource location(s) of the properties file to be loaded.\n\n这个参数用于指定配置文件的路径\n实践一下：\npackage com.sicmatr1x.config;import com.sicmatr1x.bean.Person;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;// 使用@PropertySource读取额外外部配置文件中的k/v保存到运行环境的环境变量中；加载完外部的配置文件后使用$&#123;&#125;取出配置文件中的值@PropertySource(value = &#123;&quot;classpath:/person.properties&quot;&#125;, encoding = &quot;UTF-8&quot;)@Configurationpublic class MainConfigOfPropertyValues &#123;    @Bean    public Person person()&#123;        return new Person();    &#125;&#125;\n\n在Person类中加入一个字段用于赋值properties文件中配置的值：\n@Value(&quot;$&#123;person.nickname&#125;&quot;)private String nickname;\n\nperson.properties：\nperson.nickname=法外狂徒\n\n输出：\nmainConfigOfPropertyValuespersonPerson&#123;name=&#x27;张三&#x27;, age=18, nickname=&#x27;法外狂徒&#x27;&#125;\n\n值得注意的是这里使用@Value(&quot;$&#123;person.nickname&#125;&quot;)获取到的是运行时环境变量中的值，也就是说还可以直接读取运行时环境变量来获取该值\nConfigurableEnvironment environment = applicationContext.getEnvironment();String property = environment.getProperty(&quot;person.nickname&quot;);System.out.println(property);\n\n自动装配自动装配：Spring利用依赖注入(DI)来完成对IOC容器中各个组件的依赖关系的赋值\n@Autowired &amp; @Qualifier &amp; @Primary\n@Autowired: 自动注入\n优先按照容器类型去容器中找对应的组件：等价于applicationContext.getBean(BookService.class)，找到就赋值\n如果找到多个相同类型的组件，则将属性名作为组件的id去容器中查找，等价于applicationContext.getBean(&quot;bookDao&quot;)\n这里若不想将属性名作为组件的id去容器中查找的话可以使用@Qualifier(&quot;bookDao&quot;)注解在属性上来手动指定组件的id\n自动装配默认一定要将属性赋值好，没有就报错，除非设置为非必须@Autowired(required = false)\n@Primary让Spring进行自动装配的时候默认使用首选的bean，注：该优先级低于@Qualifier明确指定的优先级\n\n\n\n@Autowired注解大家都用的比较多这里就不贴代码了，简单的测试一下将bookDao注入bookService里，然后从IOT容器中取出bookDao和bookService，通过比较发现bookService里的bookDao对象和IOT容器中的bookDao对象是同一个\nBookService&#123;bookDao=com.sicmatr1x.dao.BookDao@25b485ba&#125;com.sicmatr1x.dao.BookDao@25b485ba\n\n@Resource &amp; @InjectSpring还支持@Resource(定义在JSR250) 和 @Inject(定义在JSR330)，注意这两个注解是java规范里面的注解\n\n@Resource注解与@Autowired注解类似，可以用于实现自动装配的功能，默认按照组件名称装配\n@Inject使用此注解需要导入依赖，不支持修改为require&#x3D;false也不支持@Primary\n\n&lt;!-- https://mvnrepository.com/artifact/javax.inject/javax.inject --&gt;&lt;dependency&gt;    &lt;groupId&gt;javax.inject&lt;/groupId&gt;    &lt;artifactId&gt;javax.inject&lt;/artifactId&gt;    &lt;version&gt;1&lt;/version&gt;&lt;/dependency&gt;\n\n使用@Inject注解可能会在日志中输出下面这句话，这句话表面@Inject也支持许多自动装配的特性\nINFO: JSR-330 &#x27;javax.inject.Inject&#x27; annotation found and supported for autowiring\n\n方法、构造器位置的自动装配@Autowired可以用在构造器、参数、方法、属性上面，并且注入的bean均是从IOT容器中获取已经托管的bean，以下将会试验并证明这一点\n\n将@Autowired标注在set方法上\n\npackage com.sicmatr1x.bean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Componentpublic class Boss &#123;    private Car car;    public Car getCar() &#123;        return car;    &#125;    /**     * 标注在方法上时，spring容器创建当前对象会调用该方法完成赋值     * 方法使用的参数，自定义类型的值从IOC容器中获取     * @param car     */    @Autowired    public void setCar(Car car) &#123;        this.car = car;    &#125;    @Override    public String toString() &#123;        return &quot;Boss&#123;&quot; +                &quot;car=&quot; + car +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n从IOC容器中get出来看一下是否boss对象里面set进去的car对象就是从IOT容器中获取的那个car对象\nBoss boss = applicationContext.getBean(Boss.class);Car car = applicationContext.getBean(Car.class);System.out.println(boss);System.out.println(car);\n\n输出：\nBoss&#123;car=com.sicmatr1x.bean.Car@5b0abc94&#125;com.sicmatr1x.bean.Car@5b0abc94\n\n可以看到是同一个car对象\n\n将@Autowired标注在构造器上\n\n默认加入到IOC容器中的组件，容器在启动时会调用其无参构造器创建对象，再进行初始化赋值等操作\n如果组件只有一个有参构造器，这个有参构造器的@Autowired可以省略，参数位置的组件还是可以自动从容器中获取\npackage com.sicmatr1x.bean;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Componentpublic class Boss &#123;    private Car car;    @Autowired    public Boss(Car car) &#123;        this.car = car;        System.out.println(&quot;Boss:constructor()&quot;);    &#125;    public Car getCar() &#123;        return car;    &#125;    public void setCar(Car car) &#123;        this.car = car;    &#125;    @Override    public String toString() &#123;        return &quot;Boss&#123;&quot; +                &quot;car=&quot; + car +                &#x27;&#125;&#x27;;    &#125;&#125;\n\n输出：\nCar:constructorBoss:constructor()Boss&#123;car=com.sicmatr1x.bean.Car@214b199c&#125;com.sicmatr1x.bean.Car@214b199c\n\n说明构造器用到的组件也都是从容器中获取\n下面这种用法也定价于上面的用法：\npublic Boss(@Autowired Car car) &#123;    this.car = car;    System.out.println(&quot;Boss:constructor()&quot;);&#125;\n\n也可以在构造器上面使用@Bean注解，效果是一样的\n如果你的自定义组件想要使用Spring容器底层的一些组件，例如：ApplicationContext, BeanFactory…可以通过自定义组件实现xxxAware的方法\n比如之前讲过的Dog类通过实现ApplicationContextAware接口来获取到ApplicationContext对象\n这里再看一下ApplicationContextAware接口\npublic interface ApplicationContextAware extends Aware &#123;\t//...&#125;\n\n可以看到该类实现了Aware接口，点进去看一下Aware：\npackage org.springframework.beans.factory;/** * Marker superinterface indicating that a bean is eligible to be * notified by the Spring container of a particular framework object * through a callback-style method. Actual method signature is * determined by individual subinterfaces, but should typically * consist of just one void-returning method that accepts a single * argument. * * &lt;p&gt;Note that merely implementing &#123;@link Aware&#125; provides no default * functionality. Rather, processing must be done explicitly, for example * in a &#123;@link org.springframework.beans.factory.config.BeanPostProcessor BeanPostProcessor&#125;. * Refer to &#123;@link org.springframework.context.support.ApplicationContextAwareProcessor&#125; * and &#123;@link org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory&#125; * for examples of processing &#123;@code *Aware&#125; interface callbacks. * * @author Chris Beams * @since 3.1 */public interface Aware &#123;&#125;\n\n\nMarker superinterface indicating that a bean is eligible to be notified by the Spring container of a particular framework object through a callback-style method.\n\n显然这个接口是一个标记接口，其提供了一个回调风格的方法来让你获取到一个特定的 framework object\n这里演示几个常用的Aware接口的实现接口：\npackage com.sicmatr1x.bean;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanNameAware;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.context.EmbeddedValueResolverAware;import org.springframework.stereotype.Component;import org.springframework.util.StringValueResolver;@Componentpublic class Red implements ApplicationContextAware, BeanNameAware, EmbeddedValueResolverAware &#123;    private ApplicationContext applicationContext;    /**     * BeanNameAware     * @param name 获取IOC容器创建该对象时给这个对象生成的id     */    @Override    public void setBeanName(String name) &#123;        System.out.println(&quot;Red:setBeanName():Current bean name=&quot; + name);    &#125;    /**     * ApplicationContextAware     * @param applicationContext 获取IOC容器对象     * @throws BeansException     */    @Override    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123;        System.out.println(&quot;Red:setApplicationContext():applicationContext=&quot; + applicationContext);        this.applicationContext = applicationContext;    &#125;    /**     * EmbeddedValueResolverAware     * Set the StringValueResolver to use for resolving embedded definition values.     * 获取字符串解析器     * @param resolver     */    @Override    public void setEmbeddedValueResolver(StringValueResolver resolver) &#123;        String result = resolver.resolveStringValue(&quot;Hello, $&#123;os.name&#125;. #&#123;15*10&#125;&quot;);        System.out.println(&quot;Red:setEmbeddedValueResolver():result=&quot; + result);    &#125;&#125;\n\n输出：\nRed:setBeanName():Current bean name=redRed:setEmbeddedValueResolver():result=Hello, Windows 10. 150Red:setApplicationContext():applicationContext=org.springframework.context.annotation.\n\n@Profile环境搭建Spring提供的可以根据当前环境动态激活一系列组件的功能\n这里我们拟真一下有3个场的mysql数据源管理：\n先在pom.xml中引入数据源包\n&lt;!-- https://mvnrepository.com/artifact/com.mchange/c3p0 --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.mchange&lt;/groupId&gt;    &lt;artifactId&gt;c3p0&lt;/artifactId&gt;    &lt;version&gt;0.9.2&lt;/version&gt;&lt;/dependency&gt;\n\n创建数据源配置文件dbconfig.properties：\ndb.user=rootdb.password=123456db.driverClass=com.mysql.jdbc.Driver\n\n创建数据源配置类：\npackage com.sicmatr1x.config;import com.mchange.v2.c3p0.ComboPooledDataSource;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.EmbeddedValueResolverAware;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import org.springframework.util.StringValueResolver;import javax.sql.DataSource;import java.beans.PropertyVetoException;@PropertySource(&quot;classpath:/dbconfig.properties&quot;)@Configurationpublic class MainConfigOfProfile implements EmbeddedValueResolverAware &#123;    @Value(&quot;$&#123;db.user&#125;&quot;)    private String user;    private StringValueResolver valueResolver;    @Bean(&quot;devDataSource&quot;)    public DataSource dataSourceDev(@Value(&quot;$&#123;db.password&#125;&quot;) String pwd) throws PropertyVetoException &#123;        ComboPooledDataSource dataSource = new ComboPooledDataSource();        dataSource.setUser(user);        dataSource.setPassword(pwd);        dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/&quot;);        dataSource.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;);        return dataSource;    &#125;    @Bean(&quot;testDataSource&quot;)    public DataSource dataSourceTest(@Value(&quot;$&#123;db.password&#125;&quot;) String pwd) throws PropertyVetoException &#123;        ComboPooledDataSource dataSource = new ComboPooledDataSource();        dataSource.setUser(user);        dataSource.setPassword(pwd);        dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/test&quot;);        dataSource.setDriverClass(&quot;com.mysql.jdbc.Driver&quot;);        return dataSource;    &#125;    @Bean(&quot;prodDataSource&quot;)    public DataSource dataSourceProd(@Value(&quot;$&#123;db.password&#125;&quot;) String pwd) throws PropertyVetoException &#123;        ComboPooledDataSource dataSource = new ComboPooledDataSource();        dataSource.setUser(user);        dataSource.setPassword(pwd);        dataSource.setJdbcUrl(&quot;jdbc:mysql://localhost:3306/&quot;);        String driverName = this.valueResolver.resolveStringValue(&quot;$&#123;db.driverClass&#125;&quot;);        dataSource.setDriverClass(driverName);        return dataSource;    &#125;    @Override    public void setEmbeddedValueResolver(StringValueResolver resolver) &#123;        this.valueResolver = resolver;    &#125;&#125;\n\n这里用到了@PropertySource读取配置文件，以及el表达式从配置文件里读取配置项\n还用到了EmbeddedValueResolverAware来获取StringValueResolver\n写测试类run一下：\nimport com.sicmatr1x.bean.Boss;import com.sicmatr1x.bean.Car;import com.sicmatr1x.config.MainConfigOfAutowired;import com.sicmatr1x.config.MainConfigOfProfile;import com.sicmatr1x.dao.BookDao;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Primary;public class IOCTest_Profile &#123;    @Primary    @Bean    public BookDao bookDao() &#123;        return new BookDao();    &#125;    @Test    public void test01()&#123;        AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfProfile.class);        String[] beanNames = applicationContext.getBeanDefinitionNames();        for (String beanName : beanNames) &#123;            System.out.println(beanName);        &#125;        applicationContext.close();    &#125;&#125;\n\n输出：\nmainConfigOfProfiledevDataSourcetestDataSourceprodDataSource\n\n可以看到几个数据源已经正确的添加进来了\nAOP指在程序运行期间将某段代码切入到指定方法指定位置的进行运行的编程方式。其底层实现是动态代理\nAOP功能测试\n导入AOP模块\n\n&lt;dependency&gt;\t&lt;groupId&gt;org.springframework&lt;/groupId&gt;\t&lt;artifactId&gt;spring-aspects&lt;/artifactId&gt;\t&lt;version&gt;4.3.12.RELEASE&lt;/version&gt;&lt;/dependency&gt;\n\n\n创建业务逻辑类(MathCalculator)\n\npackage com.sicmatr1x.aop;public class MathCalculator &#123;    public int div(int i, int j) &#123;        return i/j;    &#125;&#125;\n\n我们希望在业务逻辑运行的时候将日志进行打印\n若我们直接在div(int i, int j)方法里面添加打印语句则是一个高耦合的做法\n\n定义一个日志切面类(LogAspects), 切面类里面的方法需要可以动态感知div(int i, int j)方法运行状态\n\n相当于通知方法：\n\n前置通知(@Before)：在目标方法运行之前运行\n后置通知(@After)：在目标方法运行之后运行\n返回通知(@AfterReturning)：在目标方法正常返回之后运行\n异常通知(@AfterThrowing)：在目标方法运行出现异常后运行\n环绕通知(@Around)：动态代理，手动推进目标方法运行(joinPoint.procced())\n\n\n给切面类(LogAspects)的目标方法标注何时运行\n\n\n@Before(“com.sicmatr1x.aop.MathCalculator.div(int, int)”)：指定具体的需要切入的方法\n@Before(“com.sicmatr1x.aop.MathCalculator.*(int, int)”)：切入MathCalculator的所有形参表的方法\n@Before(“com.sicmatr1x.aop.MathCalculator.*(..)”)：切入MathCalculator类的所有方法\n\n    @Before(&quot;com.sicmatr1x.aop.MathCalculator.*(..)&quot;)//    @Before(&quot;com.sicmatr1x.aop.MathCalculator.div(int, int)&quot;)    public void logStart() &#123;        System.out.println(&quot;div is starting, args:&quot;);    &#125;\n\n如果多个切入点表达式一样的话可以抽取出来：\npackage com.sicmatr1x.aop;import org.aspectj.lang.annotation.*;/** * 切面类 */@Aspectpublic class LogAspects &#123;    /**     * 抽取公共的切入点表达式     * 1. 本类引用 @Before(&quot;pointCut()&quot;)     * 2. 其它类引用 @Before(&quot;com.sicmatr1x.aop.LogAspects.pointCut()&quot;)     */    @Pointcut(&quot;execution(public int com.sicmatr1x.aop.MathCalculator.*(..))&quot;)    private void pointCut()&#123;&#125;    @Before(&quot;pointCut()&quot;)    public void logStart() &#123;        System.out.println(&quot;div is starting, args:&quot;);    &#125;    @After(&quot;pointCut()&quot;)    public void logEnd() &#123;        System.out.println(&quot;div is ending&quot;);    &#125;    @AfterReturning(&quot;pointCut()&quot;)    public void logReturn() &#123;        System.out.println(&quot;div is return, value:&quot;);    &#125;    @AfterThrowing(&quot;pointCut()&quot;)    public void logException() &#123;        System.out.println(&quot;div throws exception, error message:&quot;);    &#125;&#125;\n\n\n将切面类LogAspects和业务逻辑类MathCalculator都加入到容器中\n\n并使用@EnableAspectJAutoProxy注解开启Spring 基于注解的AOP功能\npackage com.sicmatr1x.config;import com.sicmatr1x.aop.LogAspects;import com.sicmatr1x.aop.MathCalculator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.EnableAspectJAutoProxy;@EnableAspectJAutoProxy@Configurationpublic class MainConfigOfAOP &#123;    @Bean    public MathCalculator mathCalculator()&#123;        return new MathCalculator();    &#125;    @Bean    public LogAspects logAspects()&#123;        return new LogAspects();    &#125;&#125;\n\n\n告诉Spring哪个类是切面类\n\n给切面类加上@Aspect注解即可\n@Aspectpublic class LogAspects &#123;\t//...&#125;\n\n编写测试类进行测试：\nimport com.sicmatr1x.aop.MathCalculator;import com.sicmatr1x.config.MainConfigOfAOP;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class IOCTest_AOP &#123;    @Test    public void test01()&#123;        // 创建IOC容器        AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class);        MathCalculator mathCalculator = new MathCalculator();        mathCalculator.div(1,1);                applicationContext.close();    &#125;&#125;\n\n输出结果中并没有输出任何东西，为什么呢，如果你是这样写测试类的话是不会有效果的，因为你使用的是自己new出来的一个MathCalculator对象而不是用脱光到IOT容器中的那个对象\nimport com.sicmatr1x.aop.MathCalculator;import com.sicmatr1x.config.MainConfigOfAOP;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class IOCTest_AOP &#123;    @Test    public void test01()&#123;        // 创建IOC容器        AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class);        // 自己new的对象没有AOP功能//        MathCalculator mathCalculator = new MathCalculator();//        mathCalculator.div(1,1);        // 从Spring容器中的对象才有AOP功能        MathCalculator mathCalculator = applicationContext.getBean(MathCalculator.class);        mathCalculator.div(1,1);        applicationContext.close();    &#125;&#125;\n\n输出结果：\ndiv is starting, args:div is endingdiv is return, value:\n\n可以看到切面执行顺序是@Before, @After, @AfterReturning\n刚刚忘记写输出args:的代码了，我们再来升级一下切面类\npackage com.sicmatr1x.aop;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.*;/** * 切面类 */@Aspectpublic class LogAspects &#123;    /**     * 抽取公共的切入点表达式     * 1. 本类引用 @Before(&quot;pointCut()&quot;)     * 2. 其它类引用 @Before(&quot;com.sicmatr1x.aop.LogAspects.pointCut()&quot;)     */    @Pointcut(&quot;execution(public int com.sicmatr1x.aop.MathCalculator.*(..))&quot;)    private void pointCut()&#123;&#125;    @Before(&quot;pointCut()&quot;)    public void logStart(JoinPoint joinPoint) &#123;        Object[] args = joinPoint.getArgs();        System.out.print(joinPoint.getSignature().getName() + &quot; div is starting, args:&quot;);        for(Object arg: args) &#123;            System.out.print(arg + &quot;,&quot;);        &#125;        System.out.println();    &#125;    @After(&quot;pointCut()&quot;)    public void logEnd(JoinPoint joinPoint) &#123;        System.out.println(joinPoint.getSignature().getName() + &quot; div is ending&quot;);    &#125;    @AfterReturning(value = &quot;pointCut()&quot;, returning = &quot;result&quot;)    public void logReturn(Object result) &#123;        System.out.println(&quot;div is return, value:&quot; + result);    &#125;    @AfterThrowing(value = &quot;pointCut()&quot;, throwing = &quot;exception&quot;)    public void logException(Exception exception) &#123;        System.out.println(&quot;div throws exception, error message:&quot;);    &#125;&#125;\n\n输出：\ndiv div is starting, args:1,1,div div is endingdiv is return, value:1\n\nAOP原理解析 @EnableAspectJAutoProxyCreator从上述AOP demo可以看出关键的一步是给spring开启AOP功能，所以我们先从这里开始看\n点进@EnableAspectJAutoProxy注解看源码：\n@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(AspectJAutoProxyRegistrar.class)public @interface EnableAspectJAutoProxy &#123;\t/**\t * Indicate whether subclass-based (CGLIB) proxies are to be created as opposed\t * to standard Java interface-based proxies. The default is &#123;@code false&#125;.\t */\tboolean proxyTargetClass() default false;\t/**\t * Indicate that the proxy should be exposed by the AOP framework as a &#123;@code ThreadLocal&#125;\t * for retrieval via the &#123;@link org.springframework.aop.framework.AopContext&#125; class.\t * Off by default, i.e. no guarantees that &#123;@code AopContext&#125; access will work.\t * @since 4.3.1\t */\tboolean exposeProxy() default false;&#125;\n\n可以看到这里用到了一个叫AspectJAutoProxyRegistrar的类：\n/** * Registers an &#123;@link org.springframework.aop.aspectj.annotation.AnnotationAwareAspectJAutoProxyCreator * AnnotationAwareAspectJAutoProxyCreator&#125; against the current &#123;@link BeanDefinitionRegistry&#125; * as appropriate based on a given @&#123;@link EnableAspectJAutoProxy&#125; annotation. * * @author Chris Beams * @author Juergen Hoeller * @since 3.1 * @see EnableAspectJAutoProxy */class AspectJAutoProxyRegistrar implements ImportBeanDefinitionRegistrar &#123;\t/**\t * Register, escalate, and configure the AspectJ auto proxy creator based on the value\t * of the @&#123;@link EnableAspectJAutoProxy#proxyTargetClass()&#125; attribute on the importing\t * &#123;@code @Configuration&#125; class.\t */\t@Override\tpublic void registerBeanDefinitions(\t\t\tAnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123;\t\tAopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);\t\tAnnotationAttributes enableAspectJAutoProxy =\t\t\t\tAnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);\t\tif (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) &#123;\t\t\tAopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);\t\t&#125;\t\tif (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) &#123;\t\t\tAopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);\t\t&#125;\t&#125;&#125;\n\n可以看到AspectJAutoProxyRegistrar这个类是一个ImportBeanDefinitionRegistrar接口的实现\n我们之前也实现过这个接口，实现类MyImportBeanDefinitionRegistrar，我们当时使用的功能是判断容器中有没有指定的bean，若有则再注册一个给定的bean到容器中\n打个断点从AopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);这里进入，看下注册了啥\nprivate static BeanDefinition registerOrEscalateApcAsRequired(Class&lt;?&gt; cls, BeanDefinitionRegistry registry, Object source) &#123;\tAssert.notNull(registry, &quot;BeanDefinitionRegistry must not be null&quot;);\tif (registry.containsBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME)) &#123;\t\tBeanDefinition apcDefinition = registry.getBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME);\t\tif (!cls.getName().equals(apcDefinition.getBeanClassName())) &#123;\t\t\tint currentPriority = findPriorityForClass(apcDefinition.getBeanClassName());\t\t\tint requiredPriority = findPriorityForClass(cls);\t\t\tif (currentPriority &lt; requiredPriority) &#123;\t\t\t\tapcDefinition.setBeanClassName(cls.getName());\t\t\t&#125;\t\t&#125;\t\treturn null;\t&#125;\tRootBeanDefinition beanDefinition = new RootBeanDefinition(cls);\tbeanDefinition.setSource(source);\tbeanDefinition.getPropertyValues().add(&quot;order&quot;, Ordered.HIGHEST_PRECEDENCE);\tbeanDefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\tregistry.registerBeanDefinition(AUTO_PROXY_CREATOR_BEAN_NAME, beanDefinition);\treturn beanDefinition;&#125;\n\n显然这里向容器中注册了一个ID为AUTO_PROXY_CREATOR_BEAN_NAME=org.springframework.aop.config.internalAutoProxyCreator的bean\nAnnotationAttributes enableAspectJAutoProxy =\t\tAnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);if (enableAspectJAutoProxy.getBoolean(&quot;proxyTargetClass&quot;)) &#123;\tAopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);&#125;if (enableAspectJAutoProxy.getBoolean(&quot;exposeProxy&quot;)) &#123;\tAopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);&#125;\n\n然后它拿了@EnableAspectJAutoProxy注解的信息并判断其属性proxyTargetClass, exposeProxy的值，并做相应的操作\n总结：在使用了@EnableAspectJAutoProxy注解之后发生了以下的事情\n\n@Import(AspectJAutoProxyRegistrar.class)给容器中导入了AspectJAutoProxyRegistrar\n利用AspectJAutoProxyRegistrar类自定义给容器中注册bean\ninternalAutoProxyCreator&#x3D;AnnotationAwareAspectJAutoProxyCreator\n给容器中注册一个AnnotationAwareAspectJAutoProxyCreator\nAnnotationAwareAspectJAutoProxyCreator：\nAnnotationAwareAspectJAutoProxyCreator extends AspectJAwareAdvisorAutoProxyCreator\nAspectJAwareAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator\nAspectJAwareAdvisorAutoProxyCreator extends AbstractAdvisorAutoProxyCreator\nAbstractAdvisorAutoProxyCreator extends AbstractAutoProxyCreator\nAbstractAutoProxyCreator extends ProxyProcessorSupport implements SmartInstantiationAwareBeanPostProcessor, BeanFactoryAware\n关注后置处理器(在bean初始化完成前后做的事情)；自动装配BeanFactoryAware\n\n\n\n\n\n\n\n\n\n\n\n还是从测试类开始走断点：\nimport com.sicmatr1x.aop.MathCalculator;import com.sicmatr1x.config.MainConfigOfAOP;import org.junit.Test;import org.springframework.context.annotation.AnnotationConfigApplicationContext;public class IOCTest_AOP &#123;    @Test    public void test01()&#123;        // 创建IOC容器        AnnotationConfigApplicationContext applicationContext = new AnnotationConfigApplicationContext(MainConfigOfAOP.class); // &lt;========= 传入配置类，创建IOC容器        // 从Spring容器中的对象才有AOP功能        MathCalculator mathCalculator = applicationContext.getBean(MathCalculator.class);        mathCalculator.div(1,1);        applicationContext.close();    &#125;&#125;\n\npublic AnnotationConfigApplicationContext(Class&lt;?&gt;... annotatedClasses) &#123;\tthis();\tregister(annotatedClasses);\trefresh(); // &lt;========= 调用refresh()刷新容器&#125;\n\n// Register bean processors that intercept bean creation.registerBeanPostProcessors(beanFactory); // &lt;========= 注册bean的后置处理器来方便拦截bean的创建\n\n\n传入配置类，创建IOC容器\n调用refresh()刷新容器\nregisterBeanPostProcessors(beanFactory)注册bean的后置处理器来方便拦截bean的创建\n先获取IOC容器已经定义了的需要创建对象的所有的BeanPostProcessor\n给容器中加别的BeanPostProcessor\n优先注册实现了PriorityOrdered接口的BeanPostProcessor\n再给容器中注册实现了Ordered接口的BeanPostProcessor\n注册没实现优先级接口的BeanPostProcessor\n注册BeanPostProcessor，实际上就是创建BeanPostProcessor对象，并保存到容器中：创建internalAutoProxyCreator的BeanPostProcessor1. 创建Bean的实例2. populateBean：给bean的各种属性赋值3. initializeBean：初始化bean：\ninvokeAwareMethods()：处理各种Aware接口的方法回调\napplyBeanPostProcessorsBeforeInitialization()：应用后置处理器的postProcessorsBeforeInitialization()方法\ninvokeInitMethods()：执行自定义的初始化方法\napplyBeanPostProcessorsAfterInitialization()：执行后置处理器的postProcessorsAfterInitialization()方法\nBeanPostProcessor(AnnotationAwareAspectJAutoProxyCreator)创建成功\n\n\n\n\n\n\n扩展原理\n\nWeb\n","categories":["Back-end"],"tags":["Spring Boot"]},{"title":"Oracle PL","url":"/2017/07/30/Database/Oracle/Oracle-PL/","content":"基础概念特点：\n\n模块化\n过程化\n提高操作性能，减少网络传输\n错误处理\n\n分类：\n\n匿名块\n存储过程(procedure)\n函数(function)\n包(package)\n触发器(trigger)\n\n编写 PL&#x2F;SQL函数PL&#x2F;SQL由三部分组成：\n\n定义部分\n可执行部分\n例外处理部分\n\n-- 定义部分declare-- 可执行部分Begin-- 例外处理部分exceptionEnd;\n\n--example:select first_name, email,salaryfrom employeeswhere employee_id=&amp;员工编号;-- 改写成为程序：set serveroutput on -- 在本次会话中开启系统输出显示-- 定义部分declare    v_name varchar2(20);    v_email varchar2(25);    v_sal number(8,2);begin-- 可执行部分    select first_name, email,salary    into v_name, v_email, v_sal    from employees    where employee_id=&amp;员工编号;    dbms_output.put_line(&#x27;姓名&#x27;||v_name||&#x27;邮箱&#x27;||v_email||&#x27;工资&#x27;||v_sal);exception -- 例外处理部分(异常处理)    when no_data_found then        dbms_output.put_line(&#x27;您输入的工号不存在&#x27;);    when others then        dbms_output.put_line(sqlerrm);--sqlerrm是系统显示异常的变量end;\n\n无参数返回值函数样例-- 计算个人所得税declare    v_salary number(8,2):=&amp;工资;    v_shouldTaxedNum number(8,2);    v_taxed number(8,2);begin    v_shouldTaxedNum := v_salary - 3500;    if v_shouldTaxedNum &lt;= 0 then        v_taxed := 0;    elsif v_shouldTaxedNum &lt;= 1500 then        v_taxed := v_shouldTaxedNum*0.03-0;    elsif v_shouldTaxedNum &lt;= 4500 then        v_taxed := v_shouldTaxedNum*0.1-105;    elsif v_shouldTaxedNum &lt;= 9000 then        v_taxed := v_shouldTaxedNum*0.2-555;    elsif v_shouldTaxedNum &lt;= 35000 then        v_taxed := v_shouldTaxedNum*0.25-1005;    elsif v_shouldTaxedNum &lt;= 55000 then        v_taxed := v_shouldTaxedNum*0.3-2755;    elsif v_shouldTaxedNum &lt;= 80000 then        v_taxed := v_shouldTaxedNum*0.35-5505;    else        v_taxed := v_shouldTaxedNum*0.45-13505;    end if;    dbms_output.put_line(&#x27;v_taxed=&#x27;||v_taxed);end;\n\n有参数返回值函数样例create or replace function f_tax(v_salary in number)return numberas    v_shouldTaxedNum number(8,2);    v_taxed number(8,2);begin    v_shouldTaxedNum := v_salary - 3500;    if v_shouldTaxedNum &lt;= 0 then        v_taxed := 0;    elsif v_shouldTaxedNum &lt;= 1500 then        v_taxed := v_shouldTaxedNum*0.03-0;    elsif v_shouldTaxedNum &lt;= 4500 then        v_taxed := v_shouldTaxedNum*0.1-105;    elsif v_shouldTaxedNum &lt;= 9000 then        v_taxed := v_shouldTaxedNum*0.2-555;    elsif v_shouldTaxedNum &lt;= 35000 then        v_taxed := v_shouldTaxedNum*0.25-1005;    elsif v_shouldTaxedNum &lt;= 55000 then        v_taxed := v_shouldTaxedNum*0.3-2755;    elsif v_shouldTaxedNum &lt;= 80000 then        v_taxed := v_shouldTaxedNum*0.35-5505;    else        v_taxed := v_shouldTaxedNum*0.45-13505;    end if;    return v_taxed;end;/show error;/*如果编译出现错误则显示错误信息*/-- 在查询语句中调用函数select employee_id, nvl(salary,0)+nvl(salary,0)*nvl(commission_pct,0) sal, f_tax(nvl(salary,0)+nvl(salary,0)*nvl(commission_pct,0)) taxfrom employees;\n\n规范函数样例/*函数名称：f_returngoodprice函数参数说明：输入参数：good_id：字符串函数返回值：该商品的销售单价：数值创建人：创建时间：修改人：修改时间：*/create or replace function f_returngoodprice(good_id varchar2)return number asv_goodprice t_goods.gprice%type;--锚定变量类型begin    select nvl(gprice,0)*nvl(gdiscount,1)        into v_goodprice        from t_goods            where upper(trim(gid))=upper(trim(good_id));    return v_goodprice;end f_returngoodprice;/show error;\n\n/*函数名称：f_returngmaxstocks函数参数说明：输入参数：good_id：字符串函数返回值：该商品的最大库存：数值创建人：创建时间：修改人：修改时间：*/create or replace function f_returngmaxstocks(good_id varchar2)return number asv_gmaxstocks t_goods.gmaxstocks%type;begin    select nvl(gmaxstocks,0)        into v_gmaxstocks        from t_goods            where upper(trim(gid))=upper(trim(good_id));    return v_gmaxstocks;end f_returngmaxstocks;/show error;\n\n自动主键编码create sequence seq_uiid;/*函数名称：f_createuiid函数参数说明：输入参数：函数返回值：使用序列生产的uiid主键创建人：创建时间：修改人：修改时间：*/create or replace function f_createuiid return varcahr2asv_uiid varchar2(6);v_seq number;begin    select seq_uiid.nextval into v_uiid from dual;    v_uiid:=trim(to_char(v_seq,&#x27;000000&#x27;));    return v_uiid;end f_createuiid;\n\n/*函数名称：f_createpmid函数参数说明：输入参数：函数返回值：使用序列生产的pmid主键创建人：创建时间：修改人：修改时间：*/create or replace function f_createpmid return varchar2asv_pmid varchar2(12);v_pmidin t_main_procure.pmid%type;begin    v_pmid:=&#x27;P&#x27;||to_char(sysdate,&#x27;yyyymm&#x27;);    select max(pmid)        into v_pmidin        from t_main_procure            where to_char(sysdate,&#x27;yyyymm&#x27;)=to_char(pdate,&#x27;yyyymm&#x27;);    if v_pmidin is null then        v_pmid:=v_pmid||&#x27;00001&#x27;;    else        v_pmid:=v_pmid||trim(to_char(to_number(substr(v_pmidin,8,5))+1,&#x27;00000&#x27;));    end if;    return v_pmid;end f_createpmid;/show error;select f_createpmid() from dual;\n\n/*函数名称：f_returnisenoughgoods函数参数说明：输入参数：good_id：字符串，num销售数量函数返回值：该商品的剩余库存是否够卖：数值创建人：创建时间：修改人：修改时间：*/create or replace function f_returnisenoughgoods(good_id varchar2, num number)return number asv_gstocks t_goods.gstocks%type;enough number(1,0):=-1;begin    select nvl(gstocks,0)        into v_gstocks        from t_goods            where upper(trim(gid))=upper(trim(good_id));    if v_gstocks-num&gt;0 then        enough:=1;    end if;    return enough;exception    when others then        return -2;end f_returnisenoughgoods;/show error;select f_returnisenoughgoods(&#x27;g0005&#x27;,15) from dual;\n\n操作函数显示用户有的对象：\nselect object_name,object_typefrom user_objects;\n\n查看函数代码：\ndesc user_sourceselect textfrom user_sourcewhere name=&#x27;F_RETURNISENOUGHGOODS&#x27;;\n\n删除函数：\ndrop function F_RETURNISENOUGHGOODS;\n\n存储过程存储过程样例：\n\n隐式游标：\ncursor的名称是：SQL：每执行一条SQL语句以后自动创建的私有内存空间\nSQL%found:布尔值，true:语句执行成功,false:失败\nSQL%rowcount:integer,insert,update,delete,select影响的行数\n\n-- 增加一张采购单/*存储过程名称：p_insertmainprocure输入参数：i_sid:供应商编号:i_memo:备注:default:test输出参数:o_result:1:添加成功,-1:发生错误,0:添加失败,-2:供应商不存在创建人：创建时间：*/create or replace procedure p_insertmainprocure(i_sid in t_main_procure.sid%type, i_memo in t_main_procure.pmemo%type default &#x27;test&#x27;, o_result out number)asv_count number:=0;begin    select count(sid)        into v_count        from t_supplier            where lower(trim(sid))=lower(trim(i_sid));    if v_count=0 then        o_result:=-2;        return o_result;    end if;    insert into t_main_procure        values(f_createpmid(), i_sid, sysdate, null, &#x27;1&#x27;, i_memo);    --这里的SQL为隐式游标，%用来提取属性(影响了多少行)    if SQL%rowcount&gt;0 then        o_result:=1;--添加数据成功    else        o_result:=0;--添加数据失败    end if;    commit;exception    when others then        o_result:=sqlcode;end p_insertmainprocure;\n\n-- 没有输出参数的存储过程可以这样调用exec p_insertmainprocure();-- 有输出参数的存储过程，只能在程序中调用declarev_result number;begin    p_insertmainprocure(&#x27;p002&#x27;,&#x27;通过存储过程添加&#x27;,v_result);    if v_result=1 then        dbms_output.put_line(&#x27;添加成功&#x27;);    elsif v_result=-2 then        dbms_output.put_line(&#x27;添加失败&#x27;);    else        dbms_output.put_line(&#x27;error&#x27;);    end if;end;\n\n-- 4)设计一个函数，实现订单编号的自动编码：&#x27;Oyyyymm00XXX&#x27;（练习）create or replace function f_createomidreturn varchar2as    v_omid varchar2(12);    v_maxomid t_main_order.omid%type;begin    v_omid:=&#x27;O&#x27;||to_char(sysdate,&#x27;yyyymm&#x27;);    ---去订单查询当月最大的那张单    select max(omid) into v_maxomid        from t_main_order where to_char(odate,&#x27;yyyymm&#x27;)=to_char(sysdate,&#x27;yyyymm&#x27;);    if v_maxomid is null then        v_omid:=v_omid||&#x27;00001&#x27;;--当月第一张单    else        v_omid:=v_omid||trim(to_char(to_number(substr(v_maxomid,8,5))+1,&#x27;00000&#x27;));    end if;-- --当月下一张单    return v_omid;exception    when others then        return null;end;/show error;select f_createomid from dual;添加订单明细数据:/*  存储过程名称:p_insertorderitems  输入参数:i_omid:订单编号;i_gid :商品编号；i_onum：数量,默认值为1  输出参数:o_result:1:添加成功,-1:发生错误，0：添加不成功,-2:输入数据不准确  创建人:miss lee  创建日期:  修改:*/create or replace procedure p_insertorderitems(i_omid in t_order_items.omid%type, i_gid in t_order_items.gid%type,  i_onum in number default 1,o_result out number)asv_count number:=0;begin    select count(omid) into v_count      --检查订单编号是否正确        from t_main_order where trim(omid)=trim(i_omid);    if v_count&lt;1 then        o_result:=-2;        return;  --退出程序    end if;    select count(gid) into v_count    --检查商品编号是否正确        from t_goods where trim(gid)=trim(i_gid);    if v_count&lt;1 then        o_result:=-2;        return;  --退出程序    end if;    insert into t_order_items        values(i_omid,i_gid,f_returngoodprice(i_gid),i_onum,null);    o_result:=1;    commit;exception    when others then        o_result:=sqlcode;        rollback; end;/show error;declarev_result number;begin    p_insertorderitems(&#x27;O20170800001&#x27;,&#x27;g0006&#x27;,10,o_result=&gt;v_result);    if v_result=1 then        dbms_output.put_line(&#x27;添加成功&#x27;);   elsif  v_result=-2 then        dbms_output.put_line(&#x27;数据不存在&#x27;);   else        dbms_output.put_line(v_result);   end if;end;create or replace function f_returngoodprice(good_id varchar2)   return number asv_goodprice t_goods.gprice%type;--锚定变量begin    select nvl(gprice,0)*nvl(gdiscount,1)        into v_goodprice        from t_goods            where upper(trim(gid))=upper(good_id); ---    return v_goodprice;exception    when others then        return 0;--自定义一个错误返回值end f_returngoodprice;\n\n操作返回结果为多条数据(列表)的情况create or replace procedure p_printemp(i_deptid number)asv_name employees.first_name%type;v_sal employees.salary%type;v_hdate employees.hire_date%type;-- 1.定义游标cursor cur_emp is    select first_name,salary,hire_date                    from employees            where department_id=i_deptid;begin    -- 2.打开游标    open cur_emp;    -- 3.提取数据    fetch cur_emp into v_name,v_sal,v_hdate;    if cur_emp%notfound then        dbms_output.put_line(&#x27;您输入的编号不存在&#x27;);    end if;    -- 循环提取    while(cur_emp%found) loop        dbms_output.put_line(v_name||&#x27;.&#x27;||v_sal||&#x27;.&#x27;||v_hdate);        fetch cur_emp into v_name,v_sal,v_hdate;    end loop;    --4.关闭游标    close cur_emp;exception    when others then        dbms_output.put_line(sqlerrm);end p_printemp;\n\n操作返回结果为多条数据(列表)的情况返回任意想要的属性值create or replace procedure p_printemp2(i_deptid number)as-- 1.定义游标cursor cur_emp is    select *        from employees            where department_id=i_deptid;-- 游标的行记录类型rec_emp cur_emp%rowtype;begin    -- 2.打开游标    open cur_emp;    -- 3.提取数据    fetch cur_emp into rec_emp;    if cur_emp%notfound then        dbms_output.put_line(&#x27;您输入的编号不存在&#x27;);    end if;    -- 循环提取    while(cur_emp%found) loop        dbms_output.put_line(rec_emp.last_name||&#x27;.&#x27;||rec_emp.salary);        fetch cur_emp into rec_emp;    end loop;    --4.关闭游标    close cur_emp;exception    when others then        dbms_output.put_line(sqlerrm);end p_printemp2;/show error;\n\nfor v_i in 1...1000 loopend loop;\n\ncreate or replace procedure p_printdeptandempas-- 1.定义游标cursor cur_dept is    select *        from departments;cursor cur_emp(deptno number) is    select *        from employees            where department_id=deptno;-- 游标的行记录类型rec_dept cur_dept%rowtype;rec_emp cur_emp%rowtype;begin    open cur_dept;    fetch cur_dept into rec_dept;    while(cur_dept%found) loop        dbms_output.put_line(&#x27;部门:&#x27;||&#x27;.&#x27;||rec_dept.department_id||&#x27;.&#x27;||rec_dept.department_name||&#x27;.&#x27;||rec_dept.location_id);        for rec_emp in cur_emp(rec_dept.department_id) loop            dbms_output.put_line(&#x27;    员工:&#x27;||&#x27;.&#x27;||rec_emp.employee_id||&#x27;.&#x27;||rec_emp.first_name||&#x27;.&#x27;||rec_emp.salary);        end loop;        fetch cur_dept into rec_dept;    end loop;    --4.关闭游标    close cur_dept;end p_printdeptandemp;/show error;\n\n定义异常declarev_location number;v_dept number;-- 1.定义异常名e_datanotnull exception;-- 2.将已有的异常关联到异常名pragma exception_init(e_datanotnull, -1400);e_depttohigh exception;begin    v_location:=&amp;部门编号    v_dept:=&amp;部门编号    if v_dept&gt;10000        raise e_depttohigh;    end if;    if v_location&gt;10000        -- 给自定义异常编异常号码需在(-20000,-30000)区间内        raise_application_error(-20001,&#x27;地址编号太大&#x27;);    end if;exception    when e_depttohigh then        dbms_output.put_line(&#x27;v_dept&gt;10000&#x27;);    when others then        dbms_output.put_line(sqlerrm);end;\n\n\n/*  存储过程名称:p_checkorder  功能描述：  0.检查该单据是否已经审核，若审核则抛出自定义异常  1.计算采购单的总金额  2.更新采购明细的商品的库存、单价(加权平均法)  3.更新采购单的状态为已审核  输入参数:i_pmid采购单编号;  输出参数:o_result:1:审核成功,0：发生未知错误  异常：-20001:该单据状态不是待审核;-20002:有商品超出最高库存(裁剪);-20003:该单据不存在;-2004:该单据没有明细  创建人:  创建日期:  修改:*/create or replace procedure p_checkorder(i_pmid T_MAIN_PROCURE.pmid%type, o_result out number)asv_count number:=0;v_pstate T_MAIN_PROCURE.pstate%type;v_pamount T_MAIN_PROCURE.pamount%type;v_gstocks T_GOODS.gstocks%type;v_gminstocks T_GOODS.gminstocks%type;-- 若已审核则抛出异常e_alreadychecked exception;-- 1.定义游标cursor cur_items is    select *        from T_PROCURE_ITEMS            where lower(trim(pmid))=lower(trim(i_pmid));-- 游标的行记录类型rec_items cur_items%rowtype;begin    v_pamount:=0;-- 判断采购单存不存在    select count(pmid)        into v_count        from T_MAIN_PROCURE            where lower(trim(pmid))=lower(trim(i_pmid));    if v_count=0 then        raise_application_error(-20003,&#x27;该单据不存在&#x27;);    end if;-- 0.检查该单据是否已经审核，若审核则抛出自定义异常    select pstate        into v_pstate        from T_MAIN_PROCURE        where lower(trim(pmid))=lower(trim(i_pmid));    if v_pstate&lt;&gt;1 then        raise_application_error(-20001,&#x27;该单据状态不是待审核&#x27;);    end if;--  1.计算采购单的总金额--  2.更新采购明细的商品的库存、单价(加权平均法)    open cur_items;    fetch cur_items into rec_items;    if cur_items%notfound then        raise_application_error(-20004,&#x27;该单据没有明细&#x27;);    end if;    while(cur_items%found) loop        update t_goods        set gstocks=gstocks+rec_items.pinum, gprice=round((gstocks*gprice+rec_items.pinum*rec_items.piprice        )/(gstocks+rec_items.pinum))        where gid=rec_items.gid;        v_pamount:=v_pamount+rec_items.pimoney;        fetch cur_items into rec_items;    end loop;    close cur_items;    dbms_output.put_line(&#x27;采购单&#x27;||i_pmid||&#x27;的总金额&#x27;||v_pamount);-- 3.更新采购单的状态为已审核    update T_MAIN_PROCURE set T_MAIN_PROCURE.pstate=&#x27;2&#x27;,T_MAIN_PROCURE.pamount=v_pamount    where lower(trim(pmid))=lower(trim(i_pmid));        o_result:=1;    commit;exception    when others then        o_result:=sqlcode;        rollback;end p_checkorder;/show error;\n\n触发器 trigger行级触发器样例\n:new 代表：\n\ninsert操作中添加的行记录\nupdate操作中更新以后的行记录\n\n\n\n:old 代表：\n\ndelete操作中删除的行记录\nupdate操作中更新以前的行记录\n\n\n若在触发器中想要阻止某个操作只能通过抛出一个异常来中断\ncreate or replace trigger tr_checkpitemsinsertbefore insert on t_procure_itemsfor each row --  行级触发器declare    v_state t_main_procure.pstate%type;begin    --  判断所添加的明细数据的单据是否是待审核    --  if not 待审核    select pstate        into v_state        from t_main_procure            where pmid=:new.pmid;    if v_state&lt;&gt;&#x27;1&#x27; then        raise_application_error(&#x27;-20001&#x27;,&#x27;该单据已经审核不能再添加&#x27;);    end if;end;/show error;\n\n触发器的分类\nDML操作：insert,update,delete\n视图的替代触发器\nDDL操作:create,alter\n数据库系统级别触发器\n\nDML 触发器timing:\n\nbefore:执行操作之前进行处理\nafter:执行操作之后进行处理\ninstead of:在视图上进行操作时进行替代\n\nobject_name:table or view的名字\ncreate or replace trigger trigger_nametiming r_body on object_namedeclare    beginend;\n\n合并触发器如果多个触发器是同一个表上，进行同一个时间介词(before,after)，同一个触发次数类型(语句级的，行级)则可合并触发器\ncreate or replace trigger tr_checkpitemsbefore update or insert or delete on t_procure_itemsfor each row --  行级触发器declare    v_state t_main_procure.pstate%type;begin    if inserting then        select pstate            into v_state            from t_main_procure                where pmid=:new.pmid;    elsif updating or deleting then        select pstate            into v_state            from t_main_procure                where pmid=:old.pmid;    end if;    if v_state&lt;&gt;&#x27;1&#x27; then        raise_application_error(&#x27;-20001&#x27;,&#x27;该单据已经审核不能再删除&#x27;);    end if;end;/show error;\n\ncreate or replace trigger tr_updateprocuremainmoneyafter update or delete of PPRICE,PNUM or insert on t_procure_itemsfor each rowdeclare    v_pamount t_main_procure.PAMOUNT%type;begin    if inserting then        update t_main_procure set            pamount=nvl(pamount,0)+:new.pinum*:new.piprice;                where pmid=:new.pmid;    elsif updating then        update t_main_procure set            pamount=nvl(pamount,0)-:old.pinum*:old.piprice+:new.pinum*:new.piprice;                where pmid=:new.pmid;    elsif deleting then        update t_main_procure set            pamount=nvl(pamount,0)-:old.pinum*:old.piprice;                where pmid=:new.pmid;    end if;   end;/show error;\n\n日志触发器样例create table log(lid number(9,0) primary key,employee_id number(6,0) references employees(employee_id),old_salary number(8,2),new_salary number(8,2),opdate Date,opuser varchar2(20));create sequence seq_lidstart with 1increment by 1;create or replace trigger tr_updatemployeesalaryafter update on employeesfor each rowdeclare    begin    insert into log values(seq_lid.nextval, :new.employee_id, :old.salary, :new.salary, sysdate, user);end;/show error;update employees set salary=20000where employee_id=100;\n\n登录触发器-- 记录用户的登录信息create or replace trigger tr_logonafter logon on databasebegin    insert into t_mylog    values(seq_log.nextval,user,default,&#x27;logon&#x27;,sys_context(&#x27;USERENV&#x27;,&#x27;IP_ADDRESS&#x27;));end;-- 记录用户的登出信息create or replace trigger tr_logoffbefore logoff on databasebegin    insert into t_mylog    values(seq_log.nextval,user,default,&#x27;logoff&#x27;,sys_context(&#x27;USERENV&#x27;,&#x27;IP_ADDRESS&#x27;));end;\n","categories":["Database"],"tags":["Back-end","Oracle"]},{"title":"Oracle Database","url":"/2018/08/15/Database/Oracle/Oracle-Database/","content":"数据库文件\nData files\nControl files:记录了当前数据库的结构信息,也包含数据文件及日志文件的信息以及相关的状态,归档信息等等在参数文件中描述其位置\nOnline redo log files(联机重做日志):记录了数据的所有变化,提供恢复机制,可以被分组管理\nUNDOfiles\nPassword file:密码\nArchive log files(归档日志):是redo log files的copy\nParameter file:数据库参数\n\nOracle Memory Structures\n\n\n\n\n\n\nSGA（System Global Area），即系统全局区，Oracle中最重要的内存区。\nPGA（Process Global Area），即程序全局区，一个进程的专用的内存区。\nUGA（User Global Area），即用户全局区，与特定的会话相关联。\nCGA  (CALL Global Area），即调用全剧区，如排序区，HASH JOIN区，位图合并区等\n\n专用服务器连接模式，UGA在PGA中分配。\n共享服务器连接模式，UGA在SGA中的Large Pool中分配。\nProgram Global Area(PGA)PGA包含有关单个服务器进程或单个后台进程的数据和控制信息。PGA在创建进程时分配，并在终止进程时回收。与由若干个进程共享的SGA相比，PGA是仅供一个进程使用的区。\n如果采用专用服务器连接模式，PGA中包含UGA，其他区域用来排序，散列和位图合并。PGA&#x3D;UGA+CGA(call global area 调用全局区&#x3D;排序区+散列区+位图合并区 )\nUGA&#x3D;User session+Cursor state(即private SQL区)+SORT_AREA_RETAINED\nUser session区：会话信息区，存放用户权限，角色，性能统计等信息\nCURSOR（私有SQL 区）就是一个句柄，即指针或引用，指向sql私有区（一个用户的能打开的cursor数由参数open_cursors决定）。然后sql私有区有指针指向共享sql区。私有sql区有两个部分\n固定部分：绑定信息，数据结构信息，指针。随session的创建而创建，结束而释放（pmon）\n动态部分：执行sql的中间结果集，如多表联查，排序。随sql的创建而创建，结束而释放。\nSystem Global area(SGA)系统全局区\n共享池（Shared pool）： 共享池是内存中最关键的部分之一，是oracle缓存程序数据的地方，在共享池中，保留着每一条执行过的sql解析后的全部信息。由于分配给共享池的内存区域是有限的（分配太对会消耗过多CPU资源，分配太少会影响性能）， 所以当有新的SQL执行的时候， 原先已经加载的sql会根据LRU（最近最少使用算法）进行管理。\n\nlibrary cache （库高速缓存区）：存储已经解析过的sql的信息。\ndictionary cache（数据字典缓存）：存放系统参数。\nResult Cache （结果高速缓存）：用于存储和检索高速缓存的结果。\nSQL query result cache :  将SQL语句的查询结果直接存储在 SQL query result cache中，再次执行相同语句的时候会直接调用内存中的结果集，减少I&#x2F;O的消耗。\nPL&#x2F;SQL function result cache :  将PL&#x2F;SQL函数的正确执行的结果存放在  PL&#x2F;SQL Function Result Cache中，  再次执行相同函数时直接调用内存中的结果集 ，减少IO消耗  。\n\n\n\n\nFixed SGA（固定SGA）：里面存储了内存中其他区的位置。\n\nRedo buffer（重做缓冲区）：如果数据需要写到在线重做日志中，则在写至磁盘之前要在 Redo Buffer 中临时缓存这些数据。数据在重做缓冲区中停留的时间不会太长，oracle会通过以下机制，将数据通过LGWR从 Redo Buffer 中 flush 到磁盘上：\n\n每3秒一次\n请求提交 commit\n要求 LGWR 切换日志\n重做缓冲区 1&#x2F;3 满，或者包含了 1MB的缓存重做日志数据\n\n\nBlock buffer cache（块缓冲区）：将脏数据写入磁盘之前或者从磁盘读取数据块之后，这些数据会存放在Block buffer cache 中。为了根据不同的需求保留数据，oracle把这块内存分成了三个部分\n\ndefaul pool （默认池）：所有段块一般都在defaul pool中。在oracle 8.0 之前的版本， defaul pool 就是唯一缓冲区池。\nkeep pool （保留池） ：频繁访问的段会存放在 keep pool 中，以此来防止数据 aging\nrecycle pool （回收池） ：将随机大段与其他段分开保存，访问很随机的大段可以放在 recycle pool 中，因为大块会导致过量的缓存区 flush，并且如果当你在想用这个块的时候，此时的数据也许已经aging而退出缓存。\n\n\nLarge pool （大池） ：用于大块内存的分配。shared pool 不会处理过大的内存块，所以这部分数据就交给 large pool 进行处理， 并且处理方式与 shared pool不同，large pool 不会缓存和重用这些大块，在这些内存用完之后，会立即释放。large pool 专用以下几种情况：\n\n共享服务器连接，用于在SGA中分配 UGA区，当用户断开以后，UGA会被快速释放。\n语句并行执行，允许分配进行间的消息缓存区，这些缓冲区用于协调并行查询服务器。一旦发送了缓冲区中的消息，便立即释放\n备份，备份缓冲区很大，在oracle用完了这些缓冲区，就会被立即释放。\n\n\nJava pool（Jave 池） ：在运行Java的时候会用到 java pool。\n\nStream pool （流池）：10G版本 引入，用于缓存流进程在数据库间复制&#x2F;移动数据时使用的队列消息，是 oracle advanced queue（oracle 高级队列）技术的一种拓展应用，需要注意的是，如果stream pool 设置过小，在应用EXPDP技术时，会产生错误信息。\n\n\n共享池 shared pool解析的过程是一个相当复杂的过程，它要考虑各种可能的异常情况比如SQL语句涉及到的对象不存在、提交的用户没有权限等等而且还需要考虑如何执行SQL语句采用什么方式去获职数据等解析的最终结果是要产生oracle自己内部的执行计划从而指导SQL的执行过程。可以看到，解析的过程是一个非常消耗资源的过程。因此oracle在解析用户提交的SQL语句的过程中如果对每次出现的新的SQL语句，都按照标准过程完整的从头到尾解析一遍的话效率太低尤其随着并发用户数量的增加、数据量的增加数据库的整体性能将直线下降。\nshared pool &#x3D; Library cache + dictionay cache\n共享池oracle会将用户提交来的SQL语句都缓存在内存中。每次处理新的一条SQL语句时都会先在内存中查看是否有相同的SQL语句如果相同则可以减少最重要的解析工作〔也就是生成执行计划)从而节省了大量的资源：反之如果没有找到相同的SQL语句，则必须重新从头到尾进行完整的解析过程这部分存放SQL语句的内存就叫做共享池( shared pool)当然shared pool里不仅仅是SQL语句，还包括管理shared pool的内存结构以及执行计划、控制信息等等内存结构，oracle通过内存结构管理.\nbuffer catch\n\nORACLE使用HASH算法，把buffer cache中每个buffer的buffer header串联起来，组成多条hash chain，一條hash chain由一個hash Bucket管理，hash bucket就是链的链头，从链头引出独立的双向链。一個hash buffer chains latch来保护多个hash chain\n根据LRU（Least Recently User）算法，对buffer cache进行分配和换出（age out）管理\n通常数据的访问和修改都是需要通过buffer cache来完成的,当一个server process访问数据的时候,首先需要确定的是,我们所需要的数据在buffer cache中是否存在,如果数据在buffer中存在呢,我们还需要根据data buffer的状态,来判断是否进行db block gets还是consistent gets,如果数据在buffer中不存在,则我们需要在buffer cache中寻找足够的空间来加载我们所需要的数据,如果在buffer cache中我们找不到足够的空间,那么我们就需要触发DBWn进程,去写出脏数据,用来释放我们的buffer空间.\n\n\nOracle通过几个list来对buffer进行管理.其中最为突出的就是LRU List还有Dirty List,这些list上面存放的就是具体指向buffer的指针.\nLRU List主要就是用来维护内存中的buffer,按照我们LRU(Least Recently Used)的方式来进行管理.那么针对不同的Oracle版本呢,管理的方式也不同.但是有一点需要了解的是,当数据库初始化的时候,所有的buffer都被捕HASH到LRU List上进行管理.当我们从数据文件中读取数据的时候我们现在要在LRU List上面寻找free的buffer,然后将数据读取到我们所找到的这个free buffer中.只要数据被修改了,那么这个buffer的状态就变为了dirty,那么Oracle就会把这个buffer从LRU List移到Dirty List(Checkpoint Queue)中去.在Dirty List上的buffer都是一些候选的稍后会被DBWn写出到数据文件的buffer,那么这里还有一点需要注意的是:一个buffer要么存在于LRU List上面,要么存在于Dirty List上面,不可能同时存在于两个List上面.\n\n\nRedo log Buffer 日志缓冲区日志中记录数据块的地址，更改的时间以及对数据块做了哪些改变。\nOracle在执行任何DML和DDL操作改变数据之前，都会将恢复所需要的信息，先写入redo log buffer，然后再写入database buffer cache。\n\n如果数据和回滚数据不在database buffer cache中，server process会将它们从dbf文件中读取到database buffer cache中。\nserver process会在要修改的数据行上添加行级锁。\nserver process将数据的变化信息和回滚所需的信息都写入redo log buffer。\nserver process将对数据所做的修改后的数据信息写入database buffer cache,然后将database buffer cache中的这些数据标记为脏数据（此时内存中的数据和磁盘上的数据是不一致的）。\nLGWR将重做日志缓冲区中的数据写入重做日志文件中。\nDBWn将database buffer cache的脏数据写入数据文件中。\n\nLog Writer(LGWR)每次 mommit 都会将 redo log buffer 写入到 redo log file\nLGWR的触发条件：\n\n事务提交时\nLog buffer中的数据超过1m时\n当log buffer中的数据超过_log_io_size隐含值时\n每隔3s\n\n当事务提交时，会产生一个提交的redo record,这个redo record写入log buffer后，服务器进程（server process)会触发LGWR进行日志写操作。\n有些系统中，平均每个事务的大小很大，有的为1m甚至更大，但是平均下来每秒的事务数却很小，这样通过提交来触发LGWR工作的机会很小，很有可能导致数据的积压，而数据量超过1m触发LGWR进行日志写操作正是为了解决这种情况。\n_log_io_size参数的默认值是log buffer的三分之一，这个参数的意义是当log buffer中的buffer占用量超过这个参数的数值时会触发LGWR进行日志写操作，从而防止log buffer空间被消耗殆尽。\n如果一个系统长时间没有事务提交，log buffer中的空间也很空闲，就可能导致log buffer中的数据长时间不写入redo log file中，增加数据丢失的风险，所以oralce通过每隔3s触发一次LGWR进行日志写操作大大的降低了这种风险。\nBackground ProcessesDatabase Writer(DBWrn)DBWrn:将脏数据写到 data file\nSystem monitorProcess monitorCheckpoint(CKPT)出发之后就会将内存中的脏数据写入维护局文件中用于保存内存与文件的内容同步.\n用于降低实例崩溃后的恢复时间.\nRead ConsistencySCN:数据库在某一个时间的状态\n\n\nOracle Storage HierarchyRecovery用 redo log files 来进行回滚.\n\nOptimizer(优化器)\n\n自动优化查询语句.\n优化器（optimizer）是oracle数据库内置的一个核心子系统。优化器的目的是按照一定的判断原则来得到它认为的目标SQL在当前的情形下的最高效的执行路径，也就是为了得到目标SQL的最佳执行计划。依据所选择执行计划时所用的判断原则，oracle数据库里的优化器又分为RBO（基于原则的优化器）和CBO（基于成本的优化器，SQL的成本根据统计信息算出）两种。\n表上无索引:Full Table ScanRowid Scan查询表的x%的数据:Sample Table Scan\nOracle性能优化之 Oracle里的优化器\nhttps://blog.csdn.net/u010081710/article/details/73733214\nRBO（基于原则的优化器）Oracle会在代码里事先为各种类型的执行路径定一个等级，一共15个等级，从等级1到等级15，oracle认为等级1的执行路径是效率最高的，等级15是执行效率最差的。对于等级相同的执行计划，oracle根据目标对象的在数据字典中缓存的顺序判断选择哪一种执行计划。RBO是一种适合于OLTP类型SQL语句的优化器。相对于CBO而言，RBO有着先天的缺陷，一旦SQL语句的执行计划出现问题，将很难调整。那么RBO执行计划出现问题，怎么调整目标SQL的执行计划呢？一般有如下方法：等价改写目标SQL，比如在where条件对number和date类型的列添加0（deptno+0&gt;100），varchar2或char类型的列可以添加一个“空字符”，例如“||”。对于多表连接的SQL，可以改变from表的连接顺序（RBO会按照从右往左的顺序决定谁是驱动表，谁是被驱动表。）来达到改变目标SQL执行计划的目的。我们也可以改变相关对象在数据字典中缓存的顺序（创建顺序），来改变执行计划。RBO最大的缺点是以oracle内置代码的规则作为判断标准，而并没有考虑到实际目标表的数据量以及数据分布情况。\nCBO（基于成本的优化器，SQL的成本根据统计信息算出）CBO选择执行计划时，以目标SQL成本为判断原则，CBO会选择一条执行成本最小的执行计划作为SQL的执行计划，各条执行路径的成本通过目标SQL语句所涉及的表、索引、列等的统计信息算出。这里的成本是oracle通过相关对象的统计信息计算出来的一个值，它实际上代表目标SQL对应执行步骤所消耗的IO、CPU、网络资源（针对于dblink下的分布式数据库系统而言）的消耗量，oracle会把网络资源的消耗量计算在IO成本内，实际上你看到的成本为IO、CPU资源，另外需要注意的是，oracle在未引入系统统计信息之前，CBO所计算的成本值实际全是基于IO计算的。\n&#x2F;&#x2F;TODO: Optimizer Operators(PPT43-59)\nindex 索引如果一个数据表中存有海量的数据记录，当对表执行指定条件的查询时。常规的查询方法会将所有的记录都读取出来，然后再把读取的每一条记录与查询条件进行对比，最后返回满足条件的记录。这样进行操作的时间开销和I&#x2F;O开销都很大。对于这种情况，就可以考虑通过建立索引来减小系统开销。\n如果要在表中查询指定的记录，在没有索引的情况下，必须遍历整个表，而有了索引之后，只需要在索引中找到符合查询条件的索引字段值，就可以通过保存在索引中的ROWID快速找到表中对应的记录。例如，如果将表看做一本书，索引的作用类似于书中的目录。在没有目录的情况下，要在书中查找指定的内容必须阅读全文，而有了目录之后，只需要通过目录就可以快速找到包含所需内容的页码（相当于ROWID）。\n用户可以在Oracle中创建多种类型的索引，以适应各种表的特点。按照索引数据的存储方式可以将索引分为B树索引、位图索引、反向键索引和基于函数的索引；按照索引列的唯一性可以分为唯一索引和非唯一索引；按照索引列的个数可以分为单列索引和复合索引。\n索引分类\nb*tree index：几乎所有的关系型数据库中都有b*tree类型索引，也是被最多使用的。其树结构与二叉树比较类似，根据rid快速定位所访问的行。\n反向索引：反转了b*tree索引码中的字节，是索引条目分配更均匀，多用于并行服务器环境下，用于减少索引叶的竞争。\nDescending Index 降序索引：8i中新出现的索引类型，针对逆向排序的查询。\n位图索引：使用位图来管理与数据行的对应关系，多用于OLAP系统。\n函数索引：这种索引中保存了数据列基于function返回的值，在select * from table where function(column)&#x3D;value这种类型的语句中起作用。\n\n\n\n逻辑上：\n\nSingle column 单行索引\nConcatenated 多行索引\nUnique 唯一索引\nNonUnique 非唯一索引\nFunction-based函数索引\nDomain 域索引\n\n物理上：\n\nPartitioned 分区索引\nNonPartitioned 非分区索引\nB-tree：\nNormal 正常型B树\nRever Key 反转型B树\nBitmap 位图索引\n\n\n\n索引结构：\n\nB-tree：\n\n适合与大量的增、删、改（OLTP）；\n不能用包含OR操作符的查询；\n适合高基数的列（唯一值多）\n典型的树状结构；\n每个结点都是数据块；\n大多都是物理上一层、两层或三层不定，逻辑上三层；\n叶子块数据是排序的，从左向右递增；\n在分支块和根块中放的是索引的范围；\n\n\nBitmap:\n\n适合与决策支持系统\n做UPDATE代价非常高\n非常适合OR操作符的查询\n基数比较少的时候才能建位图索引\n\n\n\nhttps://www.jianshu.com/p/ebf56728e087\nhttps://www.jb51.net/article/50703.htm\n\nExecution Plans 执行计划什么是Oracle执行计划？\n执行计划是一条查询语句在Oracle中的执行过程或访问路径的描述.\n\n错误案例and 的优先级高于 or 所以导致 or 后面的语句没有做id相等的筛选操作,导致出现巨量数据\nSELECT  SCAC,        CODE,        COUNT(*)FROM    SSM_VOYAGE v               ,        SSM_VOYAGE_STOP s          ,        SSM_VOYAGE_STOP_SNAPSHOT ss,        CMN_CRR c                  ,        SSM_CRR_OP_LOOP opWHERE   v.VOYAGE_ID              = s.VOYAGE_ID        AND s.LATEST_SNAPSHOT_ID = ss.VOY_STOP_SNAPSHOT_ID        AND v.CRR_ID             = c.CRR_ID        AND v.LOOP_ID            = op.LOOP_ID        AND        (                ss.ETA_IODT     IS NULL                AND ss.ATA_IODT IS NULL        )        OR        (                ss.ETD_IODT     IS NULL                AND ss.ATD_IODT IS NULL        )GROUP BY SCAC,        CODEORDER BY SCAC,        CODESQL&gt; @planPLAN_TABLE_OUTPUT--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Plan hash value: 3890023033--------------------------------------------------------------------------------------------------------------| Id  | Operation                 | Name                     | Rows  | Bytes |TempSpc| Cost (%CPU)| Time     |--------------------------------------------------------------------------------------------------------------|   0 | SELECT STATEMENT          |                          | 96475 |  9044K|       |    18E  (0)|999:59:59 ||   1 |  SORT GROUP BY            |                          | 96475 |  9044K|       |            |          ||   2 |   CONCATENATION           |                          |       |       |       |            |          ||   3 |    MERGE JOIN CARTESIAN   |                          |    18E|    15E|       |    18E  (0)|999:59:59 ||   4 |     MERGE JOIN CARTESIAN  |                          |  6689T|   499P|       |    41T  (1)|999:59:59 ||   5 |      MERGE JOIN CARTESIAN |                          |  1463G|    97T|       |    11G  (1)|999:59:59 ||   6 |       MERGE JOIN CARTESIAN|                          |    10M|   585M|       |   993K  (1)| 03:18:41 ||   7 |        TABLE ACCESS FULL  | CMN_CRR                  |    46 |   414 |       |    15   (0)| 00:00:01 ||   8 |        BUFFER SORT        |                          |   226K|    10M|       |   993K  (1)| 03:18:41 ||*  9 |         TABLE ACCESS FULL | SSM_VOYAGE_STOP_SNAPSHOT |   226K|    10M|       | 21595   (1)| 00:04:20 ||  10 |       BUFFER SORT         |                          |   140K|  1923K|       |    11G  (1)|999:59:59 ||  11 |        TABLE ACCESS FULL  | SSM_VOYAGE               |   140K|  1923K|       |  1135   (1)| 00:00:14 ||  12 |      BUFFER SORT          |                          |  4570 | 50270 |       |    41T  (1)|999:59:59 ||  13 |       TABLE ACCESS FULL   | SSM_CRR_OP_LOOP          |  4570 | 50270 |       |    28   (0)| 00:00:01 ||  14 |     BUFFER SORT           |                          |   780K|  9144K|       |    18E  (0)|999:59:59 ||  15 |      TABLE ACCESS FULL    | SSM_VOYAGE_STOP          |   780K|  9144K|       |  4134   (1)| 00:00:50 ||* 16 |    HASH JOIN              |                          |   162K|    14M|       | 30114   (1)| 00:06:02 ||  17 |     TABLE ACCESS FULL     | CMN_CRR                  |    46 |   414 |       |    15   (0)| 00:00:01 ||* 18 |     HASH JOIN             |                          |   162K|    13M|       | 30097   (1)| 00:06:02 ||  19 |      TABLE ACCESS FULL    | SSM_CRR_OP_LOOP          |  4570 | 50270 |       |    29   (0)| 00:00:01 ||* 20 |      HASH JOIN            |                          |   168K|    12M|  3576K| 30067   (1)| 00:06:01 ||  21 |       TABLE ACCESS FULL   | SSM_VOYAGE               |   140K|  1923K|       |  1136   (1)| 00:00:14 ||* 22 |       HASH JOIN           |                          |   170K|    10M|    10M| 27792   (1)| 00:05:34 ||* 23 |        TABLE ACCESS FULL  | SSM_VOYAGE_STOP_SNAPSHOT |   170K|  8306K|       | 21597   (1)| 00:04:20 ||  24 |        TABLE ACCESS FULL  | SSM_VOYAGE_STOP          |   780K|  9144K|       |  4135   (1)| 00:00:50 |--------------------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):---------------------------------------------------   9 - filter(&quot;SS&quot;.&quot;ETD_IODT&quot; IS NULL AND &quot;SS&quot;.&quot;ATD_IODT&quot; IS NULL)  16 - access(&quot;V&quot;.&quot;CRR_ID&quot;=&quot;C&quot;.&quot;CRR_ID&quot;)  18 - access(&quot;V&quot;.&quot;LOOP_ID&quot;=&quot;OP&quot;.&quot;LOOP_ID&quot;)  20 - access(&quot;V&quot;.&quot;VOYAGE_ID&quot;=&quot;S&quot;.&quot;VOYAGE_ID&quot;)  22 - access(&quot;S&quot;.&quot;LATEST_SNAPSHOT_ID&quot;=&quot;SS&quot;.&quot;VOY_STOP_SNAPSHOT_ID&quot;)  23 - filter(&quot;SS&quot;.&quot;ETA_IODT&quot; IS NULL AND &quot;SS&quot;.&quot;ATA_IODT&quot; IS NULL AND (LNNVL(&quot;SS&quot;.&quot;ETD_IODT&quot; IS NULL)              OR LNNVL(&quot;SS&quot;.&quot;ATD_IODT&quot; IS NULL)))42 rows selected.\n","categories":["Database"],"tags":["Back-end","Oracle"]},{"title":"Oracle SQL","url":"/2017/07/30/Database/Oracle/Oracle-SQL/","content":"Oracle 服务器配置Oracle 服务器实例一个实例只能用于访问一个数据库\n由内存和后台进程组成\n由SID标识\nOracle的内存结构主要组成：\n\n专用进程实例：一个服务器进程对应一个用户进程\n多进程实例一个服务器进程对应多个用户进程(轮流服务)\n安装11G\n创建和配置数据库\n服务器类\n典型安装：配置安装位置与密码\n\n初始数据库用户username:Sys\nusername:Systempassword:安装时设置\n登录数据库系统用户：\n\nsys,system(超级管理员)默认密码:安装时创建\nsysman(用于企业管理)默认密码:安装时创建\nscott(管理员)默认密码:tiger\n\n启动sqlplus应用程序(稍后登录)\nsqlplus /nolog\n\n用户登录命令\nconn username/password@连接字符串 as 身份(sysdba/sysoper/normal(默认))\n\n以Sys身份登录()\n\n若sqlplus所运行的操作系统的登录身份在ora_dba组内的话不需要密码\n\nconn sys as sysdba或conn &#x2F; as sysdba\n\n\n若sqlplus所运行的操作系统的登录身份不在ora_dba组内\n\nconn sys&#x2F;安装时设置的密码 as sysdba\n\n\n\n锁定&#x2F;解锁用户：\nalter user 用户名 account lock/unlock;\n\n物理数据库存储在：\n程序安装目录\\app\\admin\\oradata\\数据库名D:\\app\\admin\\oradata\\orcl\n连接远程服务器网络服务的配置(相当于保存连接，会保存用户名和密码)：\n需要：IP，端口，服务名，用户名和密码。(还需要开启监听程序)\n\nconn system/root@10.1.59.26:1521/orcl;\n\n本地网络服务名配置\n打开Net Configuration Assistant\n本地网络服务名配置\n添加\n输入要连接的数据库名\nTCP\n主机名输入要连接的主机的IP地址\n测试成功后\n输入数据库显示在本地的名称，例如：db\n使用该名称登录数据库：conn system/root@db\n\n配置管理数据库创建数据库：\n\n打开Database Configuration Assistant(简称DBCA)\n创建数据库\n选择模板：事务处理\n输入全局数据库名，访问时使用SID访问该数据库\n设置各个用户密码\n\n\n查询所有表信息dba_tables:数据库中的所有的表对象\nuser_tables:当前登录的用户所拥有的表对象\n--example:select table_name,tablespace_name from user_tables;\n\nall_tables:当前登录的用户有权访问的表对象\n--example:select owner,table_name,tablespace_name from all_tables;\n\n\n数据块体系结构数据库开启顺序shutdown-&gt;(读参数文件init.ora)nomount-&gt;(读控制文件)mount-&gt;(读所有文件)open\nstartup mount; -- 进入读控制文件状态alter database open; -- 进入读所有文件状态\n\n表空间一个表会在一个表空间里以离散的数据块的形式存储。组成一张表的全部数据块称为一个segment(数据段)。事实上Oracle为了保证性能会将一张表里的数据块已连续的形式进行存储，每一个连续的数据存储空间成为一个数据区。\n\n创建表空间：\ncreate tablespace 空间名 datafile &#x27;d:/空间名.dbf&#x27; size 10m autoextend on next 10m maxsize 1g;create tablespace table0725 datafile &#x27;d:/0725.dbf&#x27; size 10m autoextend on next 10m maxsize 500m;--example:create tablespace shoppingtp datafile &#x27;d:/shoppingtp01.dbf&#x27; size 10m autoextend on next 10m maxsize 1g;alter tablespace shoppingtp add datafile &#x27;d:/shoppingtp02.dbf&#x27; size 10m autoextend on next 10m maxsize 1g;\n\n添加文件到表空间(扩大表空间)：\nalter tablespace tptest add datafile &#x27;d:/tptest02.dbf&#x27; size 10m;\n\n查询表空间:\nselect name from v$tablespace;-- 解释表dba_data_filesdesc dba_data_files;-- 查看SHOPPINGTP表空间的信息select file_name,tablespace_name,bytes,blocks from dba_data_files where tablespace_name=&#x27;SHOPPINGTP&#x27;;\n\n删除表空间：\ndrop tablespace xxx;--若表空间非空drop tablespace xxx including contents and datafiles;--example:drop tablespace table0725 including contents and datafiles;\n\n查看表空间资源分配策略：\nshow parameter resource_limit\n\n创建表要解决的问题: where(表存在哪),whose(谁能操作表)\n\n用户权限管理数据库模型：\n\n层次模型\n网络模型\n关系模型\n面向对象的数据模型\n\n用户验证方式：数据库验证、操作系统验证。\ndesc dba_users;select username,password,created,default_tablespace from dba_users;select username,created from dba_users;-- 查询用户默认表空间select username,default_tablespace from dba_users;\n创建用户：\n-- 密码验证abccreate user test_user identified by abc;-- 创建一个默认表空间为tptest的用户且其在表空间上的配额为100M,密码默认为过期create user test_user2 identified by abc default tablespace tptest quota 100m on tptest password expire;--example:create user shopping_user identified by abc default tablespace shoppingtp quota unlimited on shoppingtp;\n\n修改用户：\n-- 修改用户默认表空间alter user test_user default tablespace table0725;\n\n删除用户：\ndrop user test_user;\n\n查询用户:\nselect * from all_users;\n\n\n权限\n系统权限(system privelege)\n对象权限(object privelege)\n\nselect, update, delete, inseret, execute, index, reference, alter, read\n赋予权限：\n-- 将create session权限(可以登录)赋予test_usergrant create session to test_user;-- 将create table权限(可以建表)赋予test_usergrant create table to test_user;-- 将查询表t4的权限赋予test_usergrant select on t4 to test_user;\n\n回收权限：\n-- 将insert t4的权限从test_user回收revoke insert on t4 from test_user;\n\n访问其他用户创建的表需要以下操作：\n-- t4表由test_user2创建-- 使用test_user来访问t4表-- test_user2与test_user同级-- 将查询表t4的权限赋予test_usergrant select on t4 to test_user;-- 将插入表t4的权限赋予test_usergrant insert on t4 to test_user;select * from test_user2.t4;\n\n角色-- 将connect角色与resource角色赋予test_usergrant connect,resource to test_user2;\n\n\n创建概要文件-- show parameter resource_limit;alter system set resource_limit = TRUE;\n\n创建概要文件\ncreate profile pro_test limitsessions_per_user 3 -- 每个用户的会话允许个数connect_time 3 -- 该用户每个会话的存活时间(分钟)failed_login_attempts 2 -- 密码错误次数;create profile pro_test limitsessions_per_user 3connect_time 3failed_login_attempts 2;\n\n查看用户对应的概要文件\nselect username,profile from dba_users;-- 修改用户test_user的概要文件为pro_testalter user test_user profile pro_test; \n\n\n表对象关系型数据库中的完整性约束：\n\n实体完整性：每个表都要有主键(primary key)\n域完整性：每个数据项都要符合其对应的数据类型与长度等约束\n引用完整性：外键\n自定义完整性：check给数据项制定合法规则\n\n创建表：\n--example:create table t_orders(oid char(8) primary key, -- 主键uiid char(6) references t_user(uiid), -- 外键(列级约束)uiid char(6) constraint fk_uiid reference t_user(uiid),-- 有约束名的外键foreign key(uiid2) constraint fk_uiid2 reference t_user(uiid), -- 表级有约束名的外键customer varchar2(20) not null, -- 非空只能做列级约束odate date default sysdate, -- 默认当前系统时间girlfriend char(8) unique, -- 唯一，不能重复onum number(2) check(onum&gt;0), -- check实现自定义约束);\n\n--example:成绩表--5W(学生数)*10(门课)=500000*1K(每条大小)=500M--4(个学期)*500M=2000M=2Gcreate table cs(--省略)pctfree 10 --当表空间剩余空闲空间&lt;10%时停止插入操作pctused 40 --当停止插入操作后表空间使用&lt;40%时恢复插入操作STORAGE( -- 存储参数设置INTIAL 4096M -- 初始化导入数据大小NEXT 500M -- 空间不够增加多少)\n\n将已有的表另存为新表(不会复制外键约束)：\ncreate table emp as select * from employee;\n\n删除数据：\n-- 删除数据，可带条件，可恢复(速度慢)delete * from emp;-- 截断：不可恢复删除数据(速度快)，保留表结构truncate table emp;-- 删除数据和表，不可恢复drop table emp;\n\n\n\n分区范围(RANGE)分区例子：\n根据商品价格分区\n根据订单金额分区\n/*3商品信息表*/create table T_GOODS(GID CHAR(6) PRIMARY KEY,GNAME VARCHAR2(20) NOT NULL,GTID CHAR(6) references T_TYPE(GTID),GPRICE NUMBER(12,3) check(GPRICE&gt;0),GDISCOUNT NUMBER(5,2) DEFAULT 1,GSTOCKS NUMBER(7,2),GDATE DATE DEFAULT sysdate,GMINSTOCKS NUMBER(7,2) check(GMINSTOCKS&gt;0),GMEMO VARCHAR2(50))TABLESPACE shoppingtppctfree 10 --商品信息表更新比较频繁pctused 40 --说明STORAGE (    INITIAL 2G--说明   NEXT 500M--说明)partition by range(GPRICE) -- 根据商品价格来分区(partition part01 values less then(100) tp01,partition part02 values less then(200) tp02,partition part03 values less then(300) tp03,partition part04 values less then(maxvalue) tp04);\n\n列表(LIST)分区对可枚举类型进行分区\n例子：\n根据商品类型分区\n根据性别分区\n/*7订单主表*/create table T_MAIN_ORDER(OMID CHAR(12) PRIMARY KEY,UIID CHAR(6) references T_USER(UIID),ODATE DATE DEFAULT sysdate,OAMOUNT NUMBER(12,3),OSTATE CHAR(1) check(PSTATE = 1 or PSTATE = 2 or PSTATE = 3 or PSTATE = 4),PMEMO VARCHAR2(50))TABLESPACE shoppingtppctfree 10 --说明pctused 40 --说明STORAGE (    INITIAL 1G--说明   NEXT 500M--说明)-- 假设数据分析之后-- 第一种情况-- PSTATE = 1占10%-- PSTATE = 2占10%-- PSTATE = 3占30%-- PSTATE = 4占40%-- 建议1和2分一个区-- 3分一个区partition by list(OSTATE)(partition part01 values(&#x27;1&#x27;,&#x27;2&#x27;),partition part02 values(&#x27;3&#x27;),partition part03 values(&#x27;4&#x27;))-- 第二种情况-- 经常查询1的频率80%-- 2的频率10%-- 3的频率10%-- 4基本不查询partition by list(OSTATE)(partition part01 values(&#x27;1&#x27;),partition part02 values(&#x27;3&#x27;,&#x27;2&#x27;),partition part03 values(&#x27;4&#x27;));\n\nHASH分区例子：\n根据商品编号分区\n根据订单编号分区\n/*1注册用户表*/create table T_USER(UIID CHAR(6) PRIMARY KEY,UNAME VARCHAR2(20) NOT NULL,UBIRTHDAY DATE,USEX CHAR(1) check(USEX =&#x27;F&#x27; or USEX =&#x27;M&#x27;),UADDRESS VARCHAR2(50),UADDRESS VARCHAR2(20))TABLESPACE shoppingtppctfree 10 --说明pctused 40 --说明STORAGE (    INITIAL 1G--用户可能   NEXT 100M--说明)partition by hash(UIID)(partition part01 tablespace shoppingtp01,partition part02 tablespace shoppingtp02);\n\n\n锁Oracle会给修改、插入的数据加一个行级锁，一次只允许一个用户修改数据，若此时还有其他用户在进行查询会返回修改前的版本。\n\n当用户对数据进行insert&#x2F;update&#x2F;delete操作的时候回自动加上行级锁，失误结束的时候解锁\nselect … from … for update加上行级锁，事务结束的时候解锁\n可以使用lock table语句对表进行表级锁\n\n\n行共享 (ROW SHARE) – 禁止排他锁定表\n行排他(ROW EXCLUSIVE) – 禁止使用排他锁和共享锁\n共享锁(SHARE)锁定表，仅允许其他用户查询表中的行禁止其他用户插入、更新和删除&gt;行多个用户可以同时在同一个表上应用此锁\n共享行排他(SHARE ROW EXCLUSIVE) – 比共享锁更多的限制，禁止使用共享锁及更高的锁\n排他(EXCLUSIVE) – 限制最强的表锁，仅允许其他用户查询该表的行。禁止修改和锁定表\n\n\n死锁：Oracle会自动检测并智能结束其中一个锁\n\n-- 共享锁：其他用户只能查询，不可修改lock table t_studentuser in share mod;\n\n\nSQL集合查询并集\nselect e1.*,&#x27;经理为King&#x27;from employees e1 join employees e2on e1.manager_id=e2.employee_idwhere e2.last_name=&#x27;King&#x27;union allselect employees.*,&#x27;高工资&#x27;from employeeswhere salary&gt;10000union allselect employees.*,&#x27;部门为1700&#x27;from employeeswhere department_id in (    select department_id    from departments    where location_id=1700);\n\n视图-- 创建视图create view v_90 asselect * from employees where department_id=90;-- 查询视图select * from v_90;-- 插入视图insert into v_90values(...);\n\n动态 SQL使用execute immediate语句来执行位于字符串中的SQL语句\n使用动态SQL创建用户需要sys权限\ncreate or replace procedure p_createstudentuserascursor cur_userid is    select userid        from system.t_studentuser;v_userid system.t_studentuser.userid%type;begin    open cur_userid;    fetch cur_userid into v_userid;    while (cur_userid%found) loop        execute immediate &#x27;create user &#x27;||v_userid&#x27; identified by abc&#x27;;        execute immediate &#x27;grant connect,resource,create view to &#x27;||v_userid;        fetch cur_userid into v_userid;    end loop;    close cur_userid;end;\n\n\nTips使用序列来代替需要自增的属性-- 创建序列-- 序列名seq_empid-- 从100开始自增，每次自增2create sequence seq_empidstart with 100increment by 2;-- 使用序列-- 使用nextval来获取下一个值-- 使用currval来获取当前值insert into empvalues(seq_empid.nextval,&#x27;辑&#x27;,&#x27;罗&#x27;,&#x27;12345678@qq.com&#x27;,&#x27;123456789&#x27;,to_date(&#x27;2017-07-26&#x27;,&#x27;yyyy-mm-dd&#x27;),&#x27;FI_MGR&#x27;,50000,0.1,null,60);\n\n-- nvl(commission_pct,0)若commission_pct属性为空则设为0-- 若commission_pct属性的值为空则设为0再+0.1update employee set commission_pct=nvl(commission_pct,0)+0.1\n\n使用虚拟表dual来进行查询-- 查询当前系统时间-- 注意：sysdate不是dual的一个属性，而是获取当前系统时间的函数select sysdate from dual; \n\n以指定格式获取当前日期select to_char(sysdate,&#x27;yyyy-mm-dd&#x27;) from dual;select to_char(sysdate,&#x27;yyyy&quot;年&quot;mm&quot;月&quot;dd&quot;日&quot;&#x27;) from dual;select to_char(sysdate,&#x27;yyyy-mm-dd hh:mi:ss&#x27;) from dual;\n\n日期计算-- 在获取30天后的日期select sysdate+30 from dual;-- 计算相差天数select trunc(sysdate-to_date(&#x27;2014-09-07&#x27;, &#x27;yyyy-mm-dd&#x27;)) 入学天数 from dual;-- 计算相差月份数select trunc(months_between(sysdate-to_date(&#x27;2014-09-07&#x27;, &#x27;yyyy-mm-dd&#x27;))) 入学月份 from dual;\n\n绑定变量select * from employeeswhere manager_id=&amp;经理编号;select * from employeeswhere first_name like &#x27;%&amp;名称%&#x27;;\n\n显示指定条数的数据在查询结果后系统会自动增加一个rownum行号\nselect *from(select * from employees)where rownum&lt;10;select *from(    select * from employees    order by salary desc)where rownum&lt;10;\n\nnull处理函数nvl2(被判断的属性,若不为空的值,若为空的值)null处理函数coalesece()-- 以此从参数里面找非空的作为值select *coalesece(ifmanager,ifbase,iftemp) jobid,coalesece(msal,bsal,tsal) salfrom test;\n\n函数decode()decode(temp,’1’,’经理’，’2’,’业务员’,’3’,’临时工’,’其他’)\n若temp的值为1则整个值为经理\n如何将Excel表数据导入Oracle数据库步骤：\n\n将excel另存为由制表符分割的txt\n创建一个控制文件(input.ctl)，如下：\n\n\n导入\n导入文件地址\n以追加模式(append或insert,replace替换)导入表t_studentuser\n字段分割符为’09’即制表符\n表的属性\n\nload datainfile &#x27;d:\\student.txt&#x27;append into table t_studentuserfields terminated by X&#x27;09&#x27;(userid,manager,emp01,emp02,emp03)\n\n\n在cmd中使用sqlldr工具导入，命令如下\n\ncmd&gt;sqlldr userid=system/abc123 control=&#x27;d:\\input.ctl&#x27;\n\n\nQ &amp; AQ: QRA-12560：TNS 协议适配器错误\nA: OracleServiceORCL服务没有开启,cmd 中输入net stop oracleserviceorcl 来开启\nQ: QRA-28000：the account is locked\nA: 用户已被锁定。需要使用该用户上一级用户执行以下命令来解锁。命令如下：alter user 被锁定的用户名 account unlock;\nQ: 修改密码\nA: \n\n修改其它账户的密码： 命令：alter user system identified by abc 123; system 为需要修改的用户名， abc 123 为新密码\n修改本账户密码：登陆后,输入 password 输入新密码即可。\n\nQ: 监听程序无法识别连接描述符中请求服务\nA: \nQ: 无监听程序\nA: 没开监听服务。配置监听程序,打开程序Net Configuration Assistant进行配置\nQ: 删除了某个表空间的数据文件之后无法打开数据库\n\n\nORA-01109数据库未打开\nORA-01157无法标识&#x2F;锁定数据文件\n\n\nA: 删除出问题的数据文件:Alter database ‘d: tpshopping01.dbf drop offline\nQ: ORA-00942 表或视图不存在\nA: 真的不存在或查询的用户权限不够。\nQ: ORA-01549 表空间非空，请使用including contents选项\nA: 需要使用以下命令来删除表空间(同时会删除表空间里的数据与文件)drop tablespace table0725 including contents and datafiles;\nQ: 设置日期格式\nA: Oracle默认日期格式为：’26-7月 -17’，可使用以下代码来替换Oracle格式日期，to_date(‘2017-07-26’,’yyyy-mm-dd’)\nQ: 删除有外键的数据\nA: 监听器位置：D:\\app\\admin\\product\\11.2.0\\dbhome_1\\NETWORK\\ADMIN\n","categories":["Database"],"tags":["Back-end","Oracle"]},{"title":"Redis","url":"/2019/12/06/Database/Redis/Redis/","content":"Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker.\n缓存中间件 Memcache和Redis的区别\nMemcache：代码层次类似Hash\n支持简单数据类型\n不支持数据持久化存储\n不支持主从\n不支持分片\n\n\nRedis：\n数据类型丰富\nstring（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。\n\n\n支持数据持久化存储\n支持主从\n支持分片\n\n\n\n基本概念基本命令启动服务器：\nredis-server.exe redis.windows.conf\n\n连接服务器：\nredis-cli.exe -h 127.0.0.1 -p 6379\n\n键值对操作：\nset myKey abcget myKeyDEL myKey\n\n配置文件Redis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf(Windows 名为 redis.windows.conf)。\n查看配置Redis CONFIG 命令格式如下:CONFIG GET CONFIG_SETTING_NAME\nCONFIG GET loglevel\n\n编辑配置CONFIG SET 命令基本语法：CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE\nCONFIG SET loglevel &quot;notice&quot;\n\nQ &amp; AQ: 从海量Key里查询出某一固定前缀的Key\n摸清数据规模，问清楚边界\n\n使用指令 KEYS pattern 可以查找所有符合给定模式pattern的key\nKEYS patternKEYS tes*\n\n缺点：\n\nKEYS指令一次性返回所有匹配的key可能会因为key数量过大使服务器卡顿\n\n解决：使用SCAN指令无阻塞提取\nSCAN cursor [MATCH pattern] [COUNT count]\n\n\nSCAN指令使用到了一个基于游标的迭代器，需要基于上一次的游标来延续之前的迭代过程\n以0作为游标的开始来开启新的迭代，直到命令返回游标0完成一次遍历\n\n缺点：一次返回的数量不可控，只能是大概率符合count参数。可能会返回重复的key，可以使用Set来接返回的数据\n从0开始迭代匹配tes*的key，一次返回10条结果，把上一次返回的结果中的位置设置成下一次的cursor\nSCAN 0 match tes* count 10\n\nQ: 使用Redis实现分布式锁特性：\n\n互斥性：任意时刻只能有一个客户端获取锁\n安全性：锁只能被持有该锁的客户端删除\n死锁：若获取锁的客户端宕机则可能会导致死锁\n容错：部分redis结点宕机时，客户端仍要能够获取锁和释放锁\n\n可以使用指令SETNX key value: 如果key不存在，则创建并赋值\n\n时间复杂度O(1)\n返回值：1:成功, 0:失败\n\nsetnx locknx test\n\n客户端可以先set locknx然后执行对应操作，此时如果有其它客户端想要获得锁会set不成功\n缺点：存在长期有效问题，即不会过期\n解决方法：使用有过期时间的指令：EXPIRE key seconds\nsetnx locknx testexpire locknx 2\n\n缺点：若程序执行完setnx locknx就挂了，就不会设置超时时间也不会释放锁\n解决方法：使用指令 SET key value [EX seconds] [PX milliseconds] [NX|XX]\n\nEX second: 设置键的过期时间为 second秒\nPX millisecond: 设置键的过期时间为 millisecond毫秒\nNX: 只在键不存在时，才对键进行设置操作\nXX: 只在键已经存在时，才对键进行设置操作\nSET操作完成时，返回OK，否则返回nil\n\nset locktarget 12345 ex 10 nx\n\nQ: 大量key同时过期的注意事项大量key集中过期时，由于清除大量的key很耗时，会出现短暂卡顿现象\n解决方案：\n\n在设置key过期时间的时候加一个随机偏移时间\n\nQ: 如何使用Redis做异步队列使用List作为队列，RPUSH生产消息，LPOP消费消息\nrpush testlist aaarpush testlist bbbrpush testlist ccclpop testlistlpop testlist\n\n缺点：\n\n没有等待队列里有值就直接消费\n\n解决：\n\n通过在应用层引入Sleep机制去调用LPOP重试\n或使用指令BLPOP key [key…] timeout: 阻塞直到队列有消息或超时\n\n\n缺点：只能供一个消费者消费\n解决：使用pub&#x2F;sub主题订阅者模式\n缺点：消息的发布是无状态的，无法保证可达\n\n\n\n\n\n数据类型Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。\nRedis底层数据类型基础：\n\n简单动态字符串\n链表\n字典\n跳跃表\n数据集合\n压缩列表\n对象\n\nStringstring 类型是二进制安全的(可以包含任何数据，比如jpg)。意思是 redis 的 string 可以包含任何数据。比如jpg图片或者序列化的对象。\nstring 类型是 Redis 最基本的数据类型，string 类型的值最大能存储 512MB。\nSET chinese &quot;中文&quot;get chinese\n\nHashRedis hash 是一个键值(key&#x3D;&gt;value)对集合。\nRedis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\nHMSET 设置了两个 field&#x3D;&gt;value 对, HGET 获取对应 field 对应的 value。每个 hash 可以存储 232 -1 键值对（40多亿）。\nHMSET test field1 &quot;Hello&quot; field2 &quot;World&quot;HGET test field1HGET test field2\n\nListRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)\nlpush testList redislpush testList mongodblpush testList rabitmqlrange testList 0 10\n\nSet集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。集合中最大的成员数为 232 - 1(4294967295, 每个集合可存储40多亿个成员)。\n添加一个 string 元素到 key 对应的 set 集合中，成功返回1，如果元素已经在集合中返回 0，如果 key 对应的 set 不存在则返回错误。\nsadd testSet redissadd testSet mongodbsadd testSet rabitmqsadd testSet rabitmqsmembers testSet\n\nzset(sorted set：有序集合)不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。zset的成员是唯一的,但分数(score)却可以重复。\nzadd testZset 0 rediszadd testZset 0.3 mongodbzadd testZset 0.1 rabitmqzadd testZset 9.9 solaceZRANGEBYSCORE testZset 0 1000\n\n各数据结构的应用场景\n\n类型\n简介\n特性\n场景\n\n\n\nString(字符串)\n二进制安全\n可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M\n---\n\n\nHash(字典)\n键值对集合,即编程语言中的Map类型\n适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去)\n存储、读取、修改用户属性\n\n\nList(列表)\n链表(双向链表)\n增删快,提供了操作某一段元素的API\n1,最新消息排行等功能(比如朋友圈的时间线) 2,消息队列\n\n\nSet(集合)\n哈希表实现,元素不重复\n1、添加、删除,查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作\n1、共同好友 2、利用唯一性,统计访问网站的所有独立ip 3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐\n\n\nSorted Set(有序集合)\n将Set中的元素增加一个权重参数score,元素按score有序排列\n数据插入集合时,已经进行天然排序\n1、排行榜 2、带权重的消息队列\n\n\n\n\nRedis 命令启动 redis 客户端：\nredis-cli\n\nPING\n\n连接到主机为 127.0.0.1，端口为 6379 ，密码为 mypass 的 redis 服务上。\nredis-cli -h host -p port -a passwordredis-cli -h 127.0.0.1 -p 6379 -a &quot;mypass&quot;\n\nRedis keys 命令\nDEL key\n\n\n该命令用于在 key 存在时删除 key。\n\n\nDUMP key\n\n\n序列化给定 key ，并返回被序列化的值。\n\n\nEXISTS key\n\n\n检查给定 key 是否存在。\n\n\nEXPIRE key seconds\n\n\n为给定 key 设置过期时间，以秒计。\n\n\nEXPIREAT key timestamp\n\n\nEXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。\n\n\nPEXPIRE key milliseconds\n\n\n设置 key 的过期时间以毫秒计。\n\n\nPEXPIREAT key milliseconds-timestamp\n\n\n设置 key 过期时间的时间戳(unix timestamp) 以毫秒计\n\n\nKEYS pattern\n\n\n查找所有符合给定模式( pattern)的 key 。\n\n\nMOVE key db\n\n\n将当前数据库的 key 移动到给定的数据库 db 当中。\n\n\n   PERSIST key\n\n\n移除 key 的过期时间，key 将持久保持。\n\n\n   PTTL key\n\n\n以毫秒为单位返回 key 的剩余的过期时间。\n\n\n   TTL key\n\n\n以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。\n\n\n   RANDOMKEY\n\n\n从当前数据库中随机返回一个 key 。\n\n\n   RENAME key newkey\n\n\n修改 key 的名称\n\n\n   RENAMENX key newkey\n\n\n仅当 newkey 不存在时，将 key 改名为 newkey 。\n\n\n   TYPE key\n\n\n返回 key 所储存的值的类型。\n\nRedis 字符串命令\n   SET key value \n置指定 key 的值\n\n\n   GET key \n取指定 key 的值。\n\n\n   GETRANGE key start end \n回 key 中字符串值的子字符\n\n\n   GETSET key value\n给定 key 的值设为 value ，并返回 key 的旧值(old value)。\n\n\n   GETBIT key offset\nkey 所储存的字符串值，获取指定偏移量上的位(bit)。\n\n\n   MGET key1 [key2..]\n取所有(一个或多个)给定 key 的值。\n\n\n   SETBIT key offset value\nkey 所储存的字符串值，设置或清除指定偏移量上的位(bit)。\n\n\n   SETEX key seconds value\n值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。\n\n\n   SETNX key value\n有在 key 不存在时设置 key 的值。\n\n\n   SETRANGE key offset value\n\n\nvalue 参数覆写给定 key 所储存的字符串值，从偏移量 offset 开始。\n\n\n   STRLEN key\n\n\n回 key 所储存的字符串值的长度。\n\n\n   MSET key value [key value …]\n\n\n时设置一个或多个 key-value 对。\n\n\n   MSETNX key value [key value …]\n\n\n时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。\n\n\n   PSETEX key milliseconds value\n\n\n个命令和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX 命令那样，以秒为单位。\n\n\n   INCR key\n\n\nkey 中储存的数字值增一。\n\n\n   INCRBY key increment\n\n\nkey 所储存的值加上给定的增量值（increment） 。\n\n\n   INCRBYFLOAT key increment\n\n\nkey 所储存的值加上给定的浮点增量值（increment） 。\n\n\n   DECR key\n\n\nkey 中储存的数字值减一。\n\n\n   DECRBY key decrement\n\n\nkey 所储存的值减去给定的减量值（decrement） 。\n\n\n   APPEND key value\n\n\n果 key 已经存在并且是一个字符串， APPEND 命令将指定的 value 追加到该 key 原来值（value）的末尾。\n\nRedis hash 命令\n   HDEL key field1 [field2] \n除一个或多个哈希表字段\n\n\n   HEXISTS key field \n看哈希表 key 中，指定的字段是否存在。\n\n\n   HGET key field \n取存储在哈希表中指定字段的值。\n\n\n   HGETALL key \n取在哈希表中指定 key 的所有字段和值\n\n\n   HINCRBY key field increment \n哈希表 key 中的指定字段的整数值加上增量 increment 。\n\n\n   HINCRBYFLOAT key field increment \n哈希表 key 中的指定字段的浮点数值加上增量 increment 。\n\n\n   HKEYS key \n取所有哈希表中的字段\n\n\n   HLEN key \n取哈希表中字段的数量\n\n\n   HMGET key field1 [field2] \n取所有给定字段的值\n\n\n   HMSET key field1 value1 [field2 value2 ]\n\n\n时将多个 field-value (域-值)对设置到哈希表 key 中。\n\n\n   HSET key field value\n\n\n哈希表 key 中的字段 field 的值设为 value 。\n\n\n   HSETNX key field value\n\n\n有在字段 field 不存在时，设置哈希表字段的值。\n\n\n   HVALS key\n\n\n取哈希表中所有值\n\n\n   HSCAN key cursor [MATCH pattern] [COUNT count]\n\n\n代哈希表中的键值对。\n\nRedis 列表命令\n   BLPOP key1 [key2 ] timeout \n出并获取列表的第一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n   BRPOP key1 [key2 ] timeout \n出并获取列表的最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n   BRPOPLPUSH source destination timeout \n列表中弹出一个值，将弹出的元素插入到另外一个列表中并返回它； 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。\n\n\n   LINDEX key index \n过索引获取列表中的元素\n\n\n   LINSERT key BEFORE|AFTER pivot value \n列表的元素前或者后插入元素\n\n\n   LLEN key \n取列表长度\n\n\n   LPOP key \n出并获取列表的第一个元素\n\n\n   LPUSH key value1 [value2] \n一个或多个值插入到列表头部\n\n\n   LPUSHX key value \n一个值插入到已存在的列表头部\n\n\n   LRANGE key start stop\n\n\n取列表指定范围内的元素\n\n\n   LREM key count value\n\n\n除列表元素\n\n\n   LSET key index value\n\n\n过索引设置列表元素的值\n\n\n   LTRIM key start stop\n\n\n一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。\n\n\n   RPOP key\n\n\n除列表的最后一个元素，返回值为移除的元素。\n\n\n   RPOPLPUSH source destination\n\n\n除列表的最后一个元素，并将该元素添加到另一个列表并返回\n\n\n   RPUSH key value1 [value2]\n\n\n列表中添加一个或多个值\n\n\n   RPUSHX key value\n\n\n已存在的列表添加值\n\nRedis 集合命令\n   SADD key member1 [member2] \n集合添加一个或多个成员\n\n\n   SCARD key \n取集合的成员数\n\n\n   SDIFF key1 [key2] \n回给定所有集合的差集\n\n\n   SDIFFSTORE destination key1 [key2] \n回给定所有集合的差集并存储在 destination 中\n\n\n   SINTER key1 [key2] \n回给定所有集合的交集\n\n\n   SINTERSTORE destination key1 [key2] \n回给定所有集合的交集并存储在 destination 中\n\n\n   SISMEMBER key member \n断 member 元素是否是集合 key 的成员\n\n\n   SMEMBERS key \n回集合中的所有成员\n\n\n   SMOVE source destination member \nmember 元素从 source 集合移动到 destination 集合\n\n\n   SPOP key\n\n\n除并返回集合中的一个随机元素\n\n\n   SRANDMEMBER key [count]\n\n\n回集合中一个或多个随机数\n\n\n   SREM key member1 [member2]\n\n\n除集合中一个或多个成员\n\n\n   SUNION key1 [key2]\n\n\n回所有给定集合的并集\n\n\n   SUNIONSTORE destination key1 [key2]\n\n\n有给定集合的并集存储在 destination 集合中\n\n\n   SSCAN key cursor [MATCH pattern] [COUNT count]\n\n\n代集合中的元素\n\nRedis 有序集合命令\n   ZADD key score1 member1 [score2 member2] \n有序集合添加一个或多个成员，或者更新已存在成员的分数\n\n\n   ZCARD key \n取有序集合的成员数\n\n\n   ZCOUNT key min max \n算在有序集合中指定区间分数的成员数\n\n\n   ZINCRBY key increment member \n序集合中对指定成员的分数加上增量 increment\n\n\n   ZINTERSTORE destination numkeys key [key …] \n算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中\n\n\n   ZLEXCOUNT key min max \n有序集合中计算指定字典区间内成员数量\n\n\n   ZRANGE key start stop [WITHSCORES] \n过索引区间返回有序集合指定区间内的成员\n\n\n   ZRANGEBYLEX key min max [LIMIT offset count] \n过字典区间返回有序集合的成员\n\n\n   ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT] \n过分数返回有序集合指定区间内的成员\n\n\n   ZRANK key member\n\n\n回有序集合中指定成员的索引\n\n\n   ZREM key member [member …]\n\n\n除有序集合中的一个或多个成员\n\n\n   ZREMRANGEBYLEX key min max\n\n\n除有序集合中给定的字典区间的所有成员\n\n\n   ZREMRANGEBYRANK key start stop\n\n\n除有序集合中给定的排名区间的所有成员\n\n\n   ZREMRANGEBYSCORE key min max\n\n\n除有序集合中给定的分数区间的所有成员\n\n\n   ZREVRANGE key start stop [WITHSCORES]\n\n\n回有序集中指定区间内的成员，通过索引，分数从高到底\n\n\n   ZREVRANGEBYSCORE key max min [WITHSCORES]\n\n\n回有序集中指定分数区间内的成员，分数从高到低排序\n\n\n   ZREVRANK key member\n\n\n回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序\n\n\n   ZSCORE key member\n\n\n回有序集中，成员的分数值\n\n\n   ZUNIONSTORE destination numkeys key [key …]\n\n\n算给定的一个或多个有序集的并集，并存储在新的 key 中\n\n\n   ZSCAN key cursor [MATCH pattern] [COUNT count]\n\n\n代有序集合中的元素（包括元素成员和元素分值）\n\nRedis HyperLogLog 命令Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。\n但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。\n\n   PFADD key element [element …] \n加指定元素到 HyperLogLog 中。\n\n\n   PFCOUNT key [key …] \n回给定 HyperLogLog 的基数估算值。\n\n\n   PFMERGE destkey sourcekey [sourcekey …] \n多个 HyperLogLog 合并为一个 HyperLogLog\n\n\n\nRedis 发布订阅\n   PSUBSCRIBE pattern [pattern …] \n阅一个或多个符合给定模式的频道。\n\n\n   PUBSUB subcommand [argument [argument …]] \n看订阅与发布系统状态。\n\n\n   PUBLISH channel message \n信息发送到指定的频道。\n\n\n   PUNSUBSCRIBE [pattern [pattern …]] \n订所有给定模式的频道。\n\n\n   SUBSCRIBE channel [channel …] \n阅给定的一个或多个频道的信息。\n\n\n   UNSUBSCRIBE [channel [channel …]] \n退订给定的频道。\n\n\n\nRedis 事务\n批量操作在发送 EXEC 命令前被放入队列缓存。\n收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。\n在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n\n\n   DISCARD \n消事务，放弃执行事务块内的所有命令。\n\n\n   EXEC \n行所有事务块内的命令。\n\n\n   MULTI \n记一个事务块的开始。\n\n\n   UNWATCH \n消 WATCH 命令对所有 key 的监视。\n\n\n   WATCH key [key …] \n视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。\n\n\n\nRedis 脚本命令\n   EVAL script numkeys key [key …] arg [arg …] \n行 Lua 脚本。\n\n\n   EVALSHA sha1 numkeys key [key …] arg [arg …] \n行 Lua 脚本。\n\n\n   SCRIPT EXISTS script [script …] \n看指定的脚本是否已经被保存在缓存当中。\n\n\n   SCRIPT FLUSH \n脚本缓存中移除所有脚本。\n\n\n   SCRIPT KILL \n死当前正在运行的 Lua 脚本。\n\n\n   SCRIPT LOAD script \n脚本 script 添加到脚本缓存中，但并不立即执行这个脚本。\n\n\n\nRedis 连接命令\n   AUTH password \n证密码是否正确\n\n\n   ECHO message \n印字符串\n\n\n   PING \n看服务是否运行\n\n\n   QUIT \n闭当前连接\n\n\n   SELECT index \n换到指定的数据库\n\n\n\nredis 127.0.0.1:6379&gt; AUTH PASSWORD(error) ERR Client sent AUTH, but no password is setredis 127.0.0.1:6379&gt; CONFIG SET requirepass &quot;mypass&quot;OKredis 127.0.0.1:6379&gt; AUTH mypassOk\n\nRedis 服务器命令\n   BGREWRITEAOF \n步执行一个 AOF（AppendOnly File） 文件重写操作\n\n\n   BGSAVE \n后台异步保存当前数据库的数据到磁盘\n\n\n   CLIENT KILL [ip:port] [ID client-id] \n闭客户端连接\n\n\n   CLIENT LIST \n取连接到服务器的客户端连接列表\n\n\n   CLIENT GETNAME \n取连接的名称\n\n\n   CLIENT PAUSE timeout \n指定时间内终止运行来自客户端的命令\n\n\n   CLIENT SETNAME connection-name \n置当前连接的名称\n\n\n   CLUSTER SLOTS \n取集群节点的映射数组\n\n\n   COMMAND \n取 Redis 命令详情数组\n\n\n   COMMAND COUNT\n\n\n取 Redis 命令总数\n\n\n   COMMAND GETKEYS\n\n\n取给定命令的所有键\n\n\n   TIME\n\n\n回当前服务器时间\n\n\n   COMMAND INFO command-name [command-name …]\n\n\n取指定 Redis 命令描述的数组\n\n\n   CONFIG GET parameter\n\n\n取指定配置参数的值\n\n\n   CONFIG REWRITE\n\n\n启动 Redis 服务器时所指定的 redis.conf 配置文件进行改写\n\n\n   CONFIG SET parameter value\n\n\n改 redis 配置参数，无需重启\n\n\n   CONFIG RESETSTAT\n\n\n置 INFO 命令中的某些统计数据\n\n\n   DBSIZE\n\n\n回当前数据库的 key 的数量\n\n\n   DEBUG OBJECT key\n\n\n取 key 的调试信息\n\n\n   DEBUG SEGFAULT\n\n\nRedis 服务崩溃\n\n\n   FLUSHALL\n\n\n除所有数据库的所有key\n\n\n   FLUSHDB\n\n\n除当前数据库的所有key\n\n\n   INFO [section]\n\n\n取 Redis 服务器的各种信息和统计数值\n\n\n   LASTSAVE\n\n\n回最近一次 Redis 成功将数据保存到磁盘上的时间，以 UNIX 时间戳格式表示\n\n\n   MONITOR\n\n\n时打印出 Redis 服务器接收到的命令，调试用\n\n\n   ROLE\n\n\n回主从实例所属的角色\n\n\n   SAVE\n\n\n步保存数据到硬盘\n\n\n   SHUTDOWN [NOSAVE] [SAVE]\n\n\n步保存数据到硬盘，并关闭服务器\n\n\n   SLAVEOF host port\n\n\n当前服务器转变为指定服务器的从属服务器(slave server)\n\n\n   SLOWLOG subcommand [argument]\n\n\n理 redis 的慢日志\n\n\n   SYNC\n\n\n于复制功能(replication)的内部命令\n\nRedis 数据备份与恢复在 redis 安装目录中创建dump.rdb文件:\nSAVE\n\n如果需要恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可。获取 redis 目录可以使用 CONFIG 命令:\nCONFIG GET dir\n\nRedis 安全查看是否设置了密码验证：\nCONFIG get requirepass\n\n默认情况下 requirepass 参数是空的，这就意味着你无需通过密码验证就可以连接到 redis 服务。\n你可以通过以下命令来修改该参数：\nCONFIG set requirepass &quot;Tuesday2&quot;\n\n登录：\nAUTH &quot;runoob&quot;\n\n性能调优Redis可以达到100000+QPS(Query Per Second, 每秒查询次数)\n原理：\n\n完全基于内存，绝大部分请求是纯粹的内存操作，执行效率高\n数据结构简单，对数据操作简单\n采用单线程，单线程也能处理高并发请求，避免频繁创建与销毁线程占用资源，避免了频繁的上下文切换和锁竞争\n使用多路I&#x2F;O复用模型，非阻塞IO\n\nRedis采用的I&#x2F;O多路复用函数：epol&#x2F;kqueue&#x2F;evport&#x2F;select\n优先选择时间复杂度O(1)的I&#x2F;O多路复用函数作为底层实现，若当前编译环境无其它更优的函数则默认调用select\n基于react设计模式监听I&#x2F;O事件\n多路I&#x2F;O复用模型FD(File Descriptor): 文件描述符\n一个打开的文件通过唯一的描述符进行引用，该描述符是打开文件的元数据到文件本身的映射。\n传统I&#x2F;O复用模型\nRedis 持久化\nRDB(快照)持久化：保存某个时间点的全量数据快照\nAOF(Append-Only-File)持久化：保存写状态\n\nRDB(快照)持久化：保存某个时间点的全量数据快照RDB持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。RDB是Redis默认的持久化方式，会在对应的目录下生产一个dump.rdb文件，重启会通过加载dump.rdb文件恢复数据。\n优点：\n只有一个文件dump.rdb，方便持久化；\n容灾性好，一个文件可以保存到安全的磁盘；\n性能最大化，fork子进程来完成写操作，让主进程继续处理命令，所以是IO最大化（使用- 单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能) ；\n如果数据集偏大，RDB的启动效率会比AOF更高。\n\n缺点：\n数据安全性低。\n如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟。\n\nRDB(快照)持久化策略通过redis.conf来配置save 900 1 # 900秒内如果有1条写入指令就触发一次快照save 300 10 # 300秒内如果有10条写入指令就触发一次快照，若10&gt;变动数&gt;0，则会等到900秒后才备份save 60 10000stop-writes-on-bgsave-error yes # 当备份进程出错则主进程停止写入rdbcompression yes # 在备份时压缩rdb文件再保存\n\nrdb文件操作手动持久化：\n\nSAVE：阻塞Redis的服务器进程，直到RDB文件被创建完毕\nBGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程\n使用到了系统调用fork()：创建进程，实现了Copy-on-Write\nCopy-on-Write(写时复制)：如果有多个调用者同时要求相同资源，他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本给该调用者，而其他调用者所见到的最初的资源仍保持不变\n\n\n\nSAVELASTSAVEBGSAVELASTSAVE\n\n自动持久化：\n\n根据redis.conf配置里的 SAVE m n定时触发(用的是BGSAVE)\n主从复制时，主节点自动触发\n执行Debug Reload\n执行Shutdown且没有开启AOF持久化\n\n缺点：\n\n内存数据全部同步，数据量大时会因为I&#x2F;O影响性能\n可能会因为Redis挂掉而丢失当前至最近一次快照期间的数据\n\nAOF(Append-Only-File)持久化：保存写状态AOF持久化是以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，文件中可以看到详细的操作记录。她的出现是为了弥补RDB的不足（数据的不一致性），所以它采用日志的形式来记录每个写操作，并追加到文件中。Redis 重启的会根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。与快照持久化相比，AOF 持久化的实时性更好，因此已成为主流的持久化方案。 默认情况下 Redis 没有开启 AOF持久化\n\n记录下除了查询以外的所有变更数据库状态的指令\n以append的形式追加保存到AOF文件中(增量)\n\n优点：\n\n数据安全性更高，AOF持久化可以配置appendfsync属性\n通过append模式写文件，即使中途服务器宕机，可以通过redis-check-aof工具解决数据一致性问题。\nAOF机制的rewrite模式。\n\n缺点：\n\nAOF文件不断增大\n日志重写：\n调用fork()创建子进程\n子进程把新的AOF写到一个临时文件里，不依赖原来的AOF文件\n主进程持续把新的变动同时写到内存和原来的AOF里\n主进程获取子进程重写AOF完成的信号，往新的AOF同步增量变动\n使用新的AOF文件替换老AOF文件\n\n\n\n\n根据同步策略的不同，AOF在运行效率上往往会慢于RDB。\n\nAOF持久化策略通过redis.conf来配置默认情况下 Redis 没有开启 AOF持久化，可以通过设置 appendonly 参数开启：\nappendonly yes\n\n\nappendfsync always：每次有数据修改发生时都会写入AOF文件\nappendfsync everysec：每秒钟同步一次，将多个写命令同步到硬盘\nappendfsync no：让操作系统决定何时进行同步\n\nAOF vs RDBRDB：\n\n优点：全量数据快照，文件小，恢复快\n缺点：无法保存最近一次快照之后的数据\n\nAOF：\n\n优点：可读性高，适合保存增量数据，数据不易丢失\n缺点：文件体积大，恢复时间长\n\nRDB-AOF混合持久化方式(Redis默认)使用BGSAVE做镜像全量持久化，AOF做增量持久化\n通过redis.conf来配置appendonly yesappendfilename &quot;appendonly.aof&quot;appendfsync everysec # 配置文件写入方式：always一旦缓存区发生变化就及时写入, everysec每隔一秒写入, no由操作系统来觉得写入时间，一般是缓存区满时写入\n\nPipeline\nPipeline和Linux的管道机制类似\n基于请求&#x2F;响应模型，单个请求处理需要一一应答\nPipeline批量执行指令，节省多次IO往返时间\n有顺序依赖的指令需要分批发送\n\nRedis同步机制主从同步全同步过程：\n\nSlave发送sync命令到Master\nMaster启动一个后台进程，将Redis中的数据快照保存到文件中\nMaster将保存数据快照期间接受到的写命令缓存起来\nMaster完成写文件操作后，将文件发送给Slave\n使用新的RDB文件替换掉就的RDB文件\nMaster将这期间收集的增量写命令发送给Slave端\n\n增量同步过程：\n\nMaster接收到用户的操作指令，判断是否需要传播到Slave\n将操作记录追加到AOF文件\n将操作传播到其它Slave：\n对齐主从库\n往响应缓存写入指令\n将缓存中的数据发送给Slave\n\n主从模式缺点：当Master挂掉之后将无法写入数据\nRedis Sentinel 哨兵模式用于解决主从同步Master宕机后的主从切换问题：\n\n监控：检查主从服务器是否运行正常\n提醒：通过API向管理员或其它应用程序发送故障通知\n自动故障迁移：主从切换，自动选举一个Slave为Master\n\n流言协议Gossip\n每个节点都随机地与对方通信，最终所有节点的状态达成一致\n种子节点定期随机向其它节点发送节点列表以及需要传播的消息\n不保证信息一定会传递给所有节点，但是最终会趋于一致\n\nRedis集群如何从海量数据里快速找到所需？\n分片：按照某种规则去划分数据，分散存储在多个节点上\n缺点：常规的按照哈希划分无法实现节点的动态增减\n原理一致性哈希算法：对2^32取模，将哈希值空间组织成虚拟的圆环\n集成到系统集成到 Java可以使用 jedis包\n集成到数据库Redis 设置过期时间Redis可以对存储在缓存中的数据设置过期时间。作为一个缓存数据库，这是非常实用的功能。之前写过一篇前后端交互的文章讲过，Token 或者一些登录信息，尤其是短信验证码都是有时间限制的，按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。而有一个好的方案其实就是将这些验证信息存入Redis设置过期时间，如果设置了存活时间30分钟，那么半小时之后这些数据就会从Redis中进行删除。那说到删除，Redis是如果做到对这些数据进行删除的呢：\n\n定期删除：Redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 Key，检查其是否过期，如果过期就删除。为什么是随机抽取而不是检查所有key？因为你如果设置的key成千上万，每100毫秒都将所有存在的key检查一遍，会给CPU带来比较大的压力。\n惰性删除 ：定期删除可能会导致很多过期 Key 到了时间并没有被删除掉。用户在获取key的时候，redis会检查一下，这个key如果设置过期时间那么是否过期了，如果过期就删除这个key。\n\n但是只是使用定期删除 + 惰性删除的删除机制还是存在一个致命问题：如果定期删除漏掉了很多过期 Key，而且用户长时间也没有使用到这些过期key，就会导致这些过期key堆积在内存里，导致Redis内存块被消耗殆尽。所以有了Redis内存淘汰机制的诞生。\n\n可能出现的问题缓存雪崩缓存处理过程：接收到请求请求，先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。\n缓存雪崩：缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至down机。\n解决办法：\n\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。\n如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。\n设置热点数据永远不过期。\n\n缓存穿透简介：缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。\n解决办法：\n\n接口层增加校验，如用户鉴权校验，id做基础校验，id&lt;&#x3D;0的直接拦截；\n从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置30秒\n\n缓存击穿简介： 缓存击穿是指缓存中没有但数据库中有的数据，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大\n解决方法：\n\n设置热点数据永远不过期。\n加互斥锁\n\n","categories":["Back-end"],"tags":["高并发","Redis"]}]